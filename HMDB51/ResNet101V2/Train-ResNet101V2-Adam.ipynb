{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet_v2 import ResNet101V2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13017</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13018</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13019</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13020</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13021</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "13017  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "13018  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "13019  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "13020  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "13021  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13022/13022 [00:47<00:00, 273.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13022, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X_train = np.array(train_image,np.float16)\n",
    "\n",
    "# shape of the array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image class\n",
       "5504  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5505  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5506  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5507  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5508  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv('../data/val.csv')\n",
    "val.sort_values(by=['class', 'image'])\n",
    "val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5509/5509 [00:31<00:00, 172.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "val_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(val.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/val_frame/'+val['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    val_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5509, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X_test = np.array(val_image,np.float16)\n",
    "\n",
    "# shape of the array\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image    13022\n",
      "class       51\n",
      "dtype: int64\n",
      "image    5509\n",
      "class      51\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# separating the target\n",
    "y_train = train['class']\n",
    "y_test = val['class']\n",
    "print(train.nunique())\n",
    "print(val.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13022, 51)\n",
      "(5509, 51)\n"
     ]
    }
   ],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained ResNet101V2 model\n",
    "base_model = ResNet101V2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, None, None, 6 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, None, None, 6 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, None, None, 2 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, None, None, 2 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, None, None, 2 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, None, None, 6 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, None, None, 2 0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, None, None, 2 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, None, None, 2 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, None, None, 5 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, None, None, 5 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, None, None, 5 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, None, None, 5 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, None, None, 1 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, None, None, 5 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, None, None, 5 2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, None, None, 5 0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, None, None, 1 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, None, None, 1 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, None, None, 1 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, None, None, 1 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, None, None, 1 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, None, None, 1 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, None, None, 1 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, None, None, 2 0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, None, None, 2 0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, None, None, 1 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, None, None, 1 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, None, None, 2 0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, None, None, 2 0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, None, None, 1 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, None, None, 1 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, None, None, 2 262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, None, None, 2 0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, None, None, 2 0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, None, None, 2 589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, None, None, 2 0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, None, None, 1 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, None, None, 1 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, None, None, 1 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, None, None, 2 0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, None, None, 2 0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, None, None, 1 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, None, None, 1 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, None, None, 1 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, None, None, 2 0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, None, None, 2 0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, None, None, 1 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, None, None, 1 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, None, None, 1 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, None, None, 2 0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, None, None, 2 0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, None, None, 1 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, None, None, 1 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, None, None, 1 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, None, None, 2 0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, None, None, 2 0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, None, None, 1 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, None, None, 1 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, None, None, 1 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, None, None, 2 0           conv4_block14_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, None, None, 2 0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, None, None, 1 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, None, None, 1 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, None, None, 1 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, None, None, 2 0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, None, None, 2 0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, None, None, 1 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, None, None, 1 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, None, None, 1 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, None, None, 2 0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, None, None, 2 0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, None, None, 1 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, None, None, 1 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, None, None, 1 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, None, None, 2 0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, None, None, 2 0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, None, None, 1 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, None, None, 1 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, None, None, 1 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, None, None, 2 0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, None, None, 2 0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, None, None, 1 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, None, None, 1 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, None, None, 1 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, None, None, 2 0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, None, None, 2 0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, None, None, 1 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, None, None, 1 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, None, None, 1 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, None, None, 2 0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, None, None, 2 0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, None, None, 1 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, None, None, 1 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, None, None, 1 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, None, None, 2 0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block21_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, None, None, 2 0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, None, None, 1 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, None, None, 1 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, None, None, 1 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, None, None, 2 0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, None, None, 2 0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, None, None, 1 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, None, None, 1 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, None, None, 1 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, None, None, 2 262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, None, None, 2 0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, None, None, 2 0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, None, None, 2 589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, None, None, 2 1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, None, None, 2 0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 1 0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, None, None, 1 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, None, None, 1 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, None, None, 1 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, None, None, 1 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, None, None, 2 0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, None, None, 2 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, None, None, 2 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, None, None, 2 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, None, None, 5 0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, None, None, 2 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, None, None, 2 0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,626,560\n",
      "Trainable params: 42,528,896\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'resnet101v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((3, 3), (3, 3)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (7, 7),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'pool1_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'pool1_pool',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'pool1_pool',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['pool1_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['pool1_pool', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_0_conv', 0, 0, {}],\n",
       "     ['conv2_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv2_block1_out', 0, 0, {}],\n",
       "     ['conv2_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv2_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv2_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv2_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv2_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv2_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv2_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv2_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}],\n",
       "     ['conv2_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_0_conv', 0, 0, {}],\n",
       "     ['conv3_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block1_out', 0, 0, {}],\n",
       "     ['conv3_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv3_block2_out', 0, 0, {}],\n",
       "     ['conv3_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv3_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv3_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv3_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv3_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv3_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv3_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv3_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv3_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}],\n",
       "     ['conv3_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv3_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_0_conv', 0, 0, {}],\n",
       "     ['conv4_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block1_out', 0, 0, {}],\n",
       "     ['conv4_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block2_out', 0, 0, {}],\n",
       "     ['conv4_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block4_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block4_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block4_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block4_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block4_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block4_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block4_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block4_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block3_out', 0, 0, {}],\n",
       "     ['conv4_block4_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block5_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block5_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block5_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block5_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block5_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block5_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block5_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block5_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block4_out', 0, 0, {}],\n",
       "     ['conv4_block5_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block6_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block6_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block6_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block6_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block6_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block6_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block6_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block6_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block5_out', 0, 0, {}],\n",
       "     ['conv4_block6_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block7_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block7_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block7_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block7_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block7_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block7_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block7_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block7_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block6_out', 0, 0, {}],\n",
       "     ['conv4_block7_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block8_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block8_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block8_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block8_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block8_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block8_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block8_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block7_out', 0, 0, {}],\n",
       "     ['conv4_block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block9_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block9_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block9_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block9_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block9_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block9_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block9_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block9_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block8_out', 0, 0, {}],\n",
       "     ['conv4_block9_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block10_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block10_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block10_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block10_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block10_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block10_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block10_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block10_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block9_out', 0, 0, {}],\n",
       "     ['conv4_block10_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block11_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block11_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block11_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block11_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block11_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block11_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block11_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block11_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block10_out', 0, 0, {}],\n",
       "     ['conv4_block11_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block12_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block12_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block12_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block12_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block12_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block12_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block12_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block12_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block11_out', 0, 0, {}],\n",
       "     ['conv4_block12_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block13_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block13_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block13_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block13_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block13_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block13_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block13_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block13_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block12_out', 0, 0, {}],\n",
       "     ['conv4_block13_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block14_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block14_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block14_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block14_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block14_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block14_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block14_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block14_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block13_out', 0, 0, {}],\n",
       "     ['conv4_block14_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block15_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block15_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block15_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block15_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block15_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block15_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block15_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block15_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block14_out', 0, 0, {}],\n",
       "     ['conv4_block15_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block16_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block16_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block16_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block16_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block16_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block16_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block16_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block16_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block15_out', 0, 0, {}],\n",
       "     ['conv4_block16_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block17_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block17_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block17_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block17_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block17_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block17_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block17_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block16_out', 0, 0, {}],\n",
       "     ['conv4_block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block18_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block18_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block18_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block18_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block18_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block18_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block18_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block18_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block17_out', 0, 0, {}],\n",
       "     ['conv4_block18_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block19_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block19_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block19_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block19_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block19_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block19_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block19_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block19_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block18_out', 0, 0, {}],\n",
       "     ['conv4_block19_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block20_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block20_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block20_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block20_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block20_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block20_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block20_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block20_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block19_out', 0, 0, {}],\n",
       "     ['conv4_block20_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block21_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block21_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block21_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block21_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block21_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block21_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block21_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block21_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block20_out', 0, 0, {}],\n",
       "     ['conv4_block21_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block22_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block22_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block22_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block22_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block22_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block22_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block22_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv4_block21_out', 0, 0, {}],\n",
       "     ['conv4_block22_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv4_block23_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block23_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv4_block23_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv4_block23_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv4_block23_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv4_block22_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv4_block23_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1024,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv4_block23_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv4_block23_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['max_pooling2d_3', 0, 0, {}],\n",
       "     ['conv4_block23_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv4_block23_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block1_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block1_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block1_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block1_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block1_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_0_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_0_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block1_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block1_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block1_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_0_conv', 0, 0, {}],\n",
       "     ['conv5_block1_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block2_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block2_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block2_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block2_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block2_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block2_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block2_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block2_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block1_out', 0, 0, {}],\n",
       "     ['conv5_block2_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_preact_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_preact_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_preact_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_preact_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_1_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_1_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_1_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_pad',\n",
       "   'class_name': 'ZeroPadding2D',\n",
       "   'config': {'name': 'conv5_block3_2_pad',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'padding': ((1, 1), (1, 1)),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['conv5_block3_1_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 512,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_pad', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv5_block3_2_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_2_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv5_block3_2_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv5_block3_2_bn', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv5_block3_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2048,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_2_relu', 0, 0, {}]]]},\n",
       "  {'name': 'conv5_block3_out',\n",
       "   'class_name': 'Add',\n",
       "   'config': {'name': 'conv5_block3_out',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32'},\n",
       "   'inbound_nodes': [[['conv5_block2_out', 0, 0, {}],\n",
       "     ['conv5_block3_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'post_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'post_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 1.001e-05,\n",
       "    'center': True,\n",
       "    'scale': True,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv5_block3_out', 0, 0, {}]]]},\n",
       "  {'name': 'post_relu',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'post_relu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['post_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['post_relu', 0, 0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 13:57:34.062969\n",
      "(13022, 7, 7, 2048)\n",
      "2020-03-17 16:14:19.003689\n"
     ]
    }
   ],
   "source": [
    "t1=datetime.datetime.now()\n",
    "print(t1)\n",
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)\n",
    "t2=datetime.datetime.now()\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 17:58:32.482920\n",
      "(5509, 7, 7, 2048)\n",
      "2020-03-17 17:58:32.487930\n"
     ]
    }
   ],
   "source": [
    "t3=datetime.datetime.now()\n",
    "print(t3)\n",
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "t4=datetime.datetime.now()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(13022, 7*7*2048)\n",
    "X_test = X_test.reshape(5509, 7*7*2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the pixel values\n",
    "max = X_train.max()\n",
    "X_train = X_train/max\n",
    "X_test = X_test/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/ResNet101V2_X_test.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/ResNet101V2_X_train.pkl') \n",
    "joblib.dump(X_test, '../Pickle/ResNet101V2_X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/ResNet101V2_X_train.pkl') \n",
    "X_test = joblib.load('../Pickle/ResNet101V2_X_test.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13022, 100352)\n",
      "(5509, 100352)\n",
      "(13022, 51)\n",
      "(5509, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(100352,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 51)                6579      \n",
      "=================================================================\n",
      "Total params: 103,457,075\n",
      "Trainable params: 103,457,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_1',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 100352),\n",
       "    'dtype': 'float32',\n",
       "    'units': 1024,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 512,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 256,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 128,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 51,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightResNet101V2.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 18:03:56.974931\n",
      "Train on 13022 samples, validate on 5509 samples\n",
      "Epoch 1/100\n",
      "13022/13022 [==============================] - ETA: 6:47 - loss: 3.9319 - accuracy: 0.03 - ETA: 4:43 - loss: 3.9338 - accuracy: 0.02 - ETA: 3:49 - loss: 3.9326 - accuracy: 0.02 - ETA: 3:25 - loss: 3.9320 - accuracy: 0.02 - ETA: 3:14 - loss: 3.9326 - accuracy: 0.02 - ETA: 3:08 - loss: 3.9249 - accuracy: 0.02 - ETA: 3:03 - loss: 3.9314 - accuracy: 0.02 - ETA: 2:59 - loss: 3.9255 - accuracy: 0.03 - ETA: 2:56 - loss: 3.9266 - accuracy: 0.03 - ETA: 2:52 - loss: 3.9258 - accuracy: 0.03 - ETA: 2:48 - loss: 3.9207 - accuracy: 0.03 - ETA: 2:43 - loss: 3.9201 - accuracy: 0.03 - ETA: 2:41 - loss: 3.9201 - accuracy: 0.03 - ETA: 2:38 - loss: 3.9213 - accuracy: 0.03 - ETA: 2:36 - loss: 3.9203 - accuracy: 0.03 - ETA: 2:34 - loss: 3.9191 - accuracy: 0.03 - ETA: 2:32 - loss: 3.9180 - accuracy: 0.03 - ETA: 2:30 - loss: 3.9150 - accuracy: 0.03 - ETA: 2:28 - loss: 3.9113 - accuracy: 0.03 - ETA: 2:26 - loss: 3.9063 - accuracy: 0.03 - ETA: 2:24 - loss: 3.9048 - accuracy: 0.03 - ETA: 2:22 - loss: 3.9034 - accuracy: 0.03 - ETA: 2:20 - loss: 3.9024 - accuracy: 0.03 - ETA: 2:18 - loss: 3.9019 - accuracy: 0.04 - ETA: 2:16 - loss: 3.9005 - accuracy: 0.04 - ETA: 2:14 - loss: 3.8995 - accuracy: 0.04 - ETA: 2:12 - loss: 3.8971 - accuracy: 0.04 - ETA: 2:10 - loss: 3.8934 - accuracy: 0.04 - ETA: 2:09 - loss: 3.8934 - accuracy: 0.04 - ETA: 2:07 - loss: 3.8919 - accuracy: 0.04 - ETA: 2:05 - loss: 3.8860 - accuracy: 0.04 - ETA: 2:03 - loss: 3.8852 - accuracy: 0.04 - ETA: 2:01 - loss: 3.8828 - accuracy: 0.04 - ETA: 1:59 - loss: 3.8792 - accuracy: 0.04 - ETA: 1:57 - loss: 3.8767 - accuracy: 0.04 - ETA: 1:55 - loss: 3.8748 - accuracy: 0.04 - ETA: 1:53 - loss: 3.8739 - accuracy: 0.04 - ETA: 1:52 - loss: 3.8700 - accuracy: 0.04 - ETA: 1:50 - loss: 3.8689 - accuracy: 0.04 - ETA: 1:48 - loss: 3.8669 - accuracy: 0.04 - ETA: 1:46 - loss: 3.8629 - accuracy: 0.04 - ETA: 1:45 - loss: 3.8617 - accuracy: 0.04 - ETA: 1:43 - loss: 3.8550 - accuracy: 0.05 - ETA: 1:41 - loss: 3.8504 - accuracy: 0.05 - ETA: 1:39 - loss: 3.8488 - accuracy: 0.05 - ETA: 1:38 - loss: 3.8451 - accuracy: 0.05 - ETA: 1:36 - loss: 3.8422 - accuracy: 0.05 - ETA: 1:34 - loss: 3.8376 - accuracy: 0.05 - ETA: 1:32 - loss: 3.8353 - accuracy: 0.05 - ETA: 1:31 - loss: 3.8303 - accuracy: 0.05 - ETA: 1:29 - loss: 3.8261 - accuracy: 0.05 - ETA: 1:27 - loss: 3.8187 - accuracy: 0.05 - ETA: 1:25 - loss: 3.8148 - accuracy: 0.05 - ETA: 1:24 - loss: 3.8111 - accuracy: 0.05 - ETA: 1:22 - loss: 3.8090 - accuracy: 0.05 - ETA: 1:20 - loss: 3.8059 - accuracy: 0.05 - ETA: 1:18 - loss: 3.8008 - accuracy: 0.05 - ETA: 1:17 - loss: 3.7958 - accuracy: 0.06 - ETA: 1:15 - loss: 3.7895 - accuracy: 0.06 - ETA: 1:13 - loss: 3.7839 - accuracy: 0.06 - ETA: 1:11 - loss: 3.7790 - accuracy: 0.06 - ETA: 1:09 - loss: 3.7754 - accuracy: 0.06 - ETA: 1:08 - loss: 3.7705 - accuracy: 0.06 - ETA: 1:06 - loss: 3.7645 - accuracy: 0.06 - ETA: 1:04 - loss: 3.7573 - accuracy: 0.06 - ETA: 1:02 - loss: 3.7528 - accuracy: 0.06 - ETA: 1:01 - loss: 3.7457 - accuracy: 0.07 - ETA: 59s - loss: 3.7399 - accuracy: 0.0716 - ETA: 57s - loss: 3.7364 - accuracy: 0.072 - ETA: 55s - loss: 3.7316 - accuracy: 0.073 - ETA: 54s - loss: 3.7276 - accuracy: 0.074 - ETA: 52s - loss: 3.7214 - accuracy: 0.076 - ETA: 50s - loss: 3.7185 - accuracy: 0.076 - ETA: 48s - loss: 3.7149 - accuracy: 0.077 - ETA: 46s - loss: 3.7101 - accuracy: 0.079 - ETA: 45s - loss: 3.7043 - accuracy: 0.081 - ETA: 43s - loss: 3.6967 - accuracy: 0.083 - ETA: 41s - loss: 3.6926 - accuracy: 0.083 - ETA: 39s - loss: 3.6886 - accuracy: 0.085 - ETA: 38s - loss: 3.6842 - accuracy: 0.086 - ETA: 36s - loss: 3.6790 - accuracy: 0.087 - ETA: 34s - loss: 3.6729 - accuracy: 0.088 - ETA: 32s - loss: 3.6677 - accuracy: 0.089 - ETA: 31s - loss: 3.6613 - accuracy: 0.090 - ETA: 29s - loss: 3.6564 - accuracy: 0.091 - ETA: 27s - loss: 3.6530 - accuracy: 0.092 - ETA: 25s - loss: 3.6470 - accuracy: 0.093 - ETA: 24s - loss: 3.6411 - accuracy: 0.095 - ETA: 22s - loss: 3.6320 - accuracy: 0.097 - ETA: 20s - loss: 3.6286 - accuracy: 0.097 - ETA: 18s - loss: 3.6242 - accuracy: 0.098 - ETA: 17s - loss: 3.6217 - accuracy: 0.099 - ETA: 15s - loss: 3.6173 - accuracy: 0.100 - ETA: 13s - loss: 3.6124 - accuracy: 0.101 - ETA: 11s - loss: 3.6093 - accuracy: 0.101 - ETA: 10s - loss: 3.6037 - accuracy: 0.103 - ETA: 8s - loss: 3.5988 - accuracy: 0.104 - ETA: 6s - loss: 3.5912 - accuracy: 0.10 - ETA: 4s - loss: 3.5863 - accuracy: 0.10 - ETA: 3s - loss: 3.5795 - accuracy: 0.10 - ETA: 1s - loss: 3.5725 - accuracy: 0.10 - 206s 16ms/step - loss: 3.5701 - accuracy: 0.1103 - val_loss: 3.6052 - val_accuracy: 0.1116\n",
      "Epoch 2/100\n",
      "13022/13022 [==============================] - ETA: 3:19 - loss: 3.1283 - accuracy: 0.19 - ETA: 3:05 - loss: 3.0273 - accuracy: 0.22 - ETA: 2:58 - loss: 3.0297 - accuracy: 0.23 - ETA: 2:56 - loss: 3.0328 - accuracy: 0.22 - ETA: 2:53 - loss: 2.9792 - accuracy: 0.24 - ETA: 2:51 - loss: 2.9543 - accuracy: 0.24 - ETA: 2:49 - loss: 2.9657 - accuracy: 0.23 - ETA: 2:46 - loss: 2.9596 - accuracy: 0.23 - ETA: 2:44 - loss: 2.9495 - accuracy: 0.23 - ETA: 2:42 - loss: 2.9207 - accuracy: 0.24 - ETA: 2:40 - loss: 2.9211 - accuracy: 0.24 - ETA: 2:38 - loss: 2.9045 - accuracy: 0.24 - ETA: 2:36 - loss: 2.8928 - accuracy: 0.24 - ETA: 2:34 - loss: 2.8941 - accuracy: 0.24 - ETA: 2:32 - loss: 2.8944 - accuracy: 0.24 - ETA: 2:30 - loss: 2.8812 - accuracy: 0.25 - ETA: 2:28 - loss: 2.8845 - accuracy: 0.25 - ETA: 2:27 - loss: 2.8861 - accuracy: 0.24 - ETA: 2:25 - loss: 2.9009 - accuracy: 0.24 - ETA: 2:23 - loss: 2.8962 - accuracy: 0.24 - ETA: 2:21 - loss: 2.8957 - accuracy: 0.24 - ETA: 2:19 - loss: 2.9071 - accuracy: 0.24 - ETA: 2:17 - loss: 2.9027 - accuracy: 0.24 - ETA: 2:15 - loss: 2.8979 - accuracy: 0.24 - ETA: 2:14 - loss: 2.8902 - accuracy: 0.24 - ETA: 2:12 - loss: 2.8779 - accuracy: 0.25 - ETA: 2:10 - loss: 2.8781 - accuracy: 0.25 - ETA: 2:08 - loss: 2.8763 - accuracy: 0.25 - ETA: 2:07 - loss: 2.8747 - accuracy: 0.25 - ETA: 2:05 - loss: 2.8685 - accuracy: 0.25 - ETA: 2:03 - loss: 2.8659 - accuracy: 0.25 - ETA: 2:01 - loss: 2.8594 - accuracy: 0.25 - ETA: 2:00 - loss: 2.8523 - accuracy: 0.25 - ETA: 1:58 - loss: 2.8440 - accuracy: 0.26 - ETA: 1:56 - loss: 2.8382 - accuracy: 0.26 - ETA: 1:54 - loss: 2.8278 - accuracy: 0.26 - ETA: 1:53 - loss: 2.8250 - accuracy: 0.26 - ETA: 1:51 - loss: 2.8225 - accuracy: 0.26 - ETA: 1:49 - loss: 2.8164 - accuracy: 0.26 - ETA: 1:48 - loss: 2.8148 - accuracy: 0.26 - ETA: 1:46 - loss: 2.8063 - accuracy: 0.26 - ETA: 1:44 - loss: 2.7965 - accuracy: 0.27 - ETA: 1:43 - loss: 2.7917 - accuracy: 0.27 - ETA: 1:41 - loss: 2.7901 - accuracy: 0.27 - ETA: 1:39 - loss: 2.7856 - accuracy: 0.27 - ETA: 1:37 - loss: 2.7789 - accuracy: 0.27 - ETA: 1:35 - loss: 2.7664 - accuracy: 0.27 - ETA: 1:34 - loss: 2.7679 - accuracy: 0.27 - ETA: 1:32 - loss: 2.7600 - accuracy: 0.28 - ETA: 1:30 - loss: 2.7581 - accuracy: 0.28 - ETA: 1:28 - loss: 2.7561 - accuracy: 0.28 - ETA: 1:27 - loss: 2.7496 - accuracy: 0.28 - ETA: 1:25 - loss: 2.7426 - accuracy: 0.28 - ETA: 1:23 - loss: 2.7373 - accuracy: 0.28 - ETA: 1:21 - loss: 2.7298 - accuracy: 0.28 - ETA: 1:20 - loss: 2.7258 - accuracy: 0.28 - ETA: 1:18 - loss: 2.7200 - accuracy: 0.28 - ETA: 1:16 - loss: 2.7187 - accuracy: 0.29 - ETA: 1:14 - loss: 2.7124 - accuracy: 0.29 - ETA: 1:13 - loss: 2.7063 - accuracy: 0.29 - ETA: 1:11 - loss: 2.7020 - accuracy: 0.29 - ETA: 1:09 - loss: 2.6969 - accuracy: 0.29 - ETA: 1:07 - loss: 2.6900 - accuracy: 0.29 - ETA: 1:06 - loss: 2.6864 - accuracy: 0.29 - ETA: 1:04 - loss: 2.6849 - accuracy: 0.29 - ETA: 1:02 - loss: 2.6770 - accuracy: 0.30 - ETA: 1:00 - loss: 2.6700 - accuracy: 0.30 - ETA: 59s - loss: 2.6655 - accuracy: 0.3037 - ETA: 57s - loss: 2.6593 - accuracy: 0.305 - ETA: 55s - loss: 2.6523 - accuracy: 0.306 - ETA: 53s - loss: 2.6467 - accuracy: 0.308 - ETA: 52s - loss: 2.6412 - accuracy: 0.308 - ETA: 50s - loss: 2.6369 - accuracy: 0.310 - ETA: 48s - loss: 2.6351 - accuracy: 0.310 - ETA: 46s - loss: 2.6313 - accuracy: 0.311 - ETA: 45s - loss: 2.6301 - accuracy: 0.312 - ETA: 43s - loss: 2.6249 - accuracy: 0.313 - ETA: 41s - loss: 2.6216 - accuracy: 0.313 - ETA: 39s - loss: 2.6137 - accuracy: 0.315 - ETA: 38s - loss: 2.6106 - accuracy: 0.316 - ETA: 36s - loss: 2.6051 - accuracy: 0.318 - ETA: 34s - loss: 2.6002 - accuracy: 0.319 - ETA: 32s - loss: 2.5965 - accuracy: 0.320 - ETA: 31s - loss: 2.5952 - accuracy: 0.320 - ETA: 29s - loss: 2.5910 - accuracy: 0.321 - ETA: 27s - loss: 2.5866 - accuracy: 0.322 - ETA: 25s - loss: 2.5810 - accuracy: 0.324 - ETA: 24s - loss: 2.5752 - accuracy: 0.325 - ETA: 22s - loss: 2.5728 - accuracy: 0.325 - ETA: 20s - loss: 2.5670 - accuracy: 0.327 - ETA: 18s - loss: 2.5597 - accuracy: 0.329 - ETA: 17s - loss: 2.5562 - accuracy: 0.330 - ETA: 15s - loss: 2.5532 - accuracy: 0.331 - ETA: 13s - loss: 2.5466 - accuracy: 0.332 - ETA: 11s - loss: 2.5427 - accuracy: 0.332 - ETA: 10s - loss: 2.5389 - accuracy: 0.333 - ETA: 8s - loss: 2.5368 - accuracy: 0.333 - ETA: 6s - loss: 2.5320 - accuracy: 0.33 - ETA: 4s - loss: 2.5294 - accuracy: 0.33 - ETA: 3s - loss: 2.5247 - accuracy: 0.33 - ETA: 1s - loss: 2.5222 - accuracy: 0.33 - 204s 16ms/step - loss: 2.5214 - accuracy: 0.3372 - val_loss: 3.0542 - val_accuracy: 0.2131\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 3:16 - loss: 2.5110 - accuracy: 0.33 - ETA: 3:04 - loss: 2.2323 - accuracy: 0.41 - ETA: 2:59 - loss: 2.1896 - accuracy: 0.42 - ETA: 2:56 - loss: 2.1427 - accuracy: 0.43 - ETA: 2:53 - loss: 2.1466 - accuracy: 0.42 - ETA: 2:51 - loss: 2.1335 - accuracy: 0.42 - ETA: 2:49 - loss: 2.1075 - accuracy: 0.43 - ETA: 2:48 - loss: 2.1139 - accuracy: 0.43 - ETA: 2:45 - loss: 2.0867 - accuracy: 0.44 - ETA: 2:43 - loss: 2.0650 - accuracy: 0.44 - ETA: 2:41 - loss: 2.0623 - accuracy: 0.44 - ETA: 2:39 - loss: 2.0680 - accuracy: 0.44 - ETA: 2:37 - loss: 2.0606 - accuracy: 0.44 - ETA: 2:35 - loss: 2.0481 - accuracy: 0.45 - ETA: 2:33 - loss: 2.0358 - accuracy: 0.45 - ETA: 2:32 - loss: 2.0426 - accuracy: 0.45 - ETA: 2:30 - loss: 2.0376 - accuracy: 0.45 - ETA: 2:29 - loss: 2.0228 - accuracy: 0.45 - ETA: 2:26 - loss: 2.0333 - accuracy: 0.45 - ETA: 2:24 - loss: 2.0188 - accuracy: 0.45 - ETA: 2:23 - loss: 2.0042 - accuracy: 0.45 - ETA: 2:21 - loss: 1.9991 - accuracy: 0.45 - ETA: 2:19 - loss: 1.9894 - accuracy: 0.45 - ETA: 2:17 - loss: 1.9782 - accuracy: 0.46 - ETA: 2:16 - loss: 1.9782 - accuracy: 0.46 - ETA: 2:14 - loss: 1.9639 - accuracy: 0.46 - ETA: 2:12 - loss: 1.9643 - accuracy: 0.46 - ETA: 2:10 - loss: 1.9635 - accuracy: 0.46 - ETA: 2:09 - loss: 1.9504 - accuracy: 0.46 - ETA: 2:07 - loss: 1.9500 - accuracy: 0.46 - ETA: 2:05 - loss: 1.9518 - accuracy: 0.46 - ETA: 2:03 - loss: 1.9570 - accuracy: 0.46 - ETA: 2:01 - loss: 1.9442 - accuracy: 0.46 - ETA: 2:00 - loss: 1.9405 - accuracy: 0.46 - ETA: 1:58 - loss: 1.9355 - accuracy: 0.46 - ETA: 1:56 - loss: 1.9369 - accuracy: 0.46 - ETA: 1:54 - loss: 1.9397 - accuracy: 0.46 - ETA: 1:52 - loss: 1.9388 - accuracy: 0.46 - ETA: 1:51 - loss: 1.9369 - accuracy: 0.46 - ETA: 1:49 - loss: 1.9337 - accuracy: 0.46 - ETA: 1:47 - loss: 1.9274 - accuracy: 0.46 - ETA: 1:45 - loss: 1.9258 - accuracy: 0.47 - ETA: 1:44 - loss: 1.9228 - accuracy: 0.47 - ETA: 1:42 - loss: 1.9235 - accuracy: 0.47 - ETA: 1:40 - loss: 1.9261 - accuracy: 0.46 - ETA: 1:38 - loss: 1.9264 - accuracy: 0.46 - ETA: 1:36 - loss: 1.9229 - accuracy: 0.47 - ETA: 1:34 - loss: 1.9188 - accuracy: 0.47 - ETA: 1:33 - loss: 1.9192 - accuracy: 0.47 - ETA: 1:31 - loss: 1.9175 - accuracy: 0.46 - ETA: 1:29 - loss: 1.9112 - accuracy: 0.47 - ETA: 1:27 - loss: 1.9076 - accuracy: 0.47 - ETA: 1:25 - loss: 1.9057 - accuracy: 0.47 - ETA: 1:24 - loss: 1.8999 - accuracy: 0.47 - ETA: 1:22 - loss: 1.8962 - accuracy: 0.47 - ETA: 1:20 - loss: 1.8973 - accuracy: 0.47 - ETA: 1:18 - loss: 1.8943 - accuracy: 0.47 - ETA: 1:17 - loss: 1.8925 - accuracy: 0.47 - ETA: 1:15 - loss: 1.8921 - accuracy: 0.47 - ETA: 1:13 - loss: 1.8881 - accuracy: 0.47 - ETA: 1:11 - loss: 1.8849 - accuracy: 0.48 - ETA: 1:09 - loss: 1.8801 - accuracy: 0.48 - ETA: 1:08 - loss: 1.8769 - accuracy: 0.48 - ETA: 1:06 - loss: 1.8744 - accuracy: 0.48 - ETA: 1:04 - loss: 1.8706 - accuracy: 0.48 - ETA: 1:02 - loss: 1.8631 - accuracy: 0.48 - ETA: 1:01 - loss: 1.8627 - accuracy: 0.48 - ETA: 59s - loss: 1.8581 - accuracy: 0.4875 - ETA: 57s - loss: 1.8603 - accuracy: 0.487 - ETA: 55s - loss: 1.8565 - accuracy: 0.488 - ETA: 54s - loss: 1.8502 - accuracy: 0.490 - ETA: 52s - loss: 1.8490 - accuracy: 0.489 - ETA: 50s - loss: 1.8475 - accuracy: 0.489 - ETA: 48s - loss: 1.8458 - accuracy: 0.490 - ETA: 46s - loss: 1.8427 - accuracy: 0.491 - ETA: 45s - loss: 1.8440 - accuracy: 0.490 - ETA: 43s - loss: 1.8417 - accuracy: 0.491 - ETA: 41s - loss: 1.8391 - accuracy: 0.491 - ETA: 39s - loss: 1.8380 - accuracy: 0.492 - ETA: 38s - loss: 1.8320 - accuracy: 0.494 - ETA: 36s - loss: 1.8341 - accuracy: 0.493 - ETA: 34s - loss: 1.8321 - accuracy: 0.493 - ETA: 32s - loss: 1.8251 - accuracy: 0.495 - ETA: 31s - loss: 1.8233 - accuracy: 0.496 - ETA: 29s - loss: 1.8221 - accuracy: 0.496 - ETA: 27s - loss: 1.8216 - accuracy: 0.496 - ETA: 25s - loss: 1.8201 - accuracy: 0.497 - ETA: 24s - loss: 1.8164 - accuracy: 0.498 - ETA: 22s - loss: 1.8140 - accuracy: 0.498 - ETA: 20s - loss: 1.8131 - accuracy: 0.498 - ETA: 18s - loss: 1.8134 - accuracy: 0.498 - ETA: 17s - loss: 1.8113 - accuracy: 0.499 - ETA: 15s - loss: 1.8088 - accuracy: 0.500 - ETA: 13s - loss: 1.8065 - accuracy: 0.500 - ETA: 11s - loss: 1.8071 - accuracy: 0.500 - ETA: 10s - loss: 1.8046 - accuracy: 0.501 - ETA: 8s - loss: 1.8028 - accuracy: 0.502 - ETA: 6s - loss: 1.8019 - accuracy: 0.50 - ETA: 4s - loss: 1.7977 - accuracy: 0.50 - ETA: 3s - loss: 1.7960 - accuracy: 0.50 - ETA: 1s - loss: 1.7944 - accuracy: 0.50 - 205s 16ms/step - loss: 1.7930 - accuracy: 0.5059 - val_loss: 2.6012 - val_accuracy: 0.3643\n",
      "Epoch 4/100\n",
      "13022/13022 [==============================] - ETA: 3:10 - loss: 1.5622 - accuracy: 0.54 - ETA: 3:03 - loss: 1.4502 - accuracy: 0.57 - ETA: 2:58 - loss: 1.3818 - accuracy: 0.59 - ETA: 2:53 - loss: 1.3918 - accuracy: 0.59 - ETA: 2:49 - loss: 1.3905 - accuracy: 0.58 - ETA: 2:46 - loss: 1.3995 - accuracy: 0.58 - ETA: 2:44 - loss: 1.3899 - accuracy: 0.58 - ETA: 2:43 - loss: 1.4000 - accuracy: 0.58 - ETA: 2:41 - loss: 1.3949 - accuracy: 0.59 - ETA: 2:39 - loss: 1.4078 - accuracy: 0.58 - ETA: 2:37 - loss: 1.4311 - accuracy: 0.57 - ETA: 2:36 - loss: 1.4383 - accuracy: 0.58 - ETA: 2:34 - loss: 1.4348 - accuracy: 0.58 - ETA: 2:32 - loss: 1.4343 - accuracy: 0.58 - ETA: 2:30 - loss: 1.4433 - accuracy: 0.58 - ETA: 2:28 - loss: 1.4616 - accuracy: 0.57 - ETA: 2:26 - loss: 1.4572 - accuracy: 0.57 - ETA: 2:23 - loss: 1.4429 - accuracy: 0.58 - ETA: 2:21 - loss: 1.4454 - accuracy: 0.58 - ETA: 2:20 - loss: 1.4408 - accuracy: 0.58 - ETA: 2:18 - loss: 1.4321 - accuracy: 0.58 - ETA: 2:17 - loss: 1.4334 - accuracy: 0.58 - ETA: 2:15 - loss: 1.4272 - accuracy: 0.58 - ETA: 2:14 - loss: 1.4315 - accuracy: 0.58 - ETA: 2:12 - loss: 1.4332 - accuracy: 0.58 - ETA: 2:10 - loss: 1.4254 - accuracy: 0.58 - ETA: 2:08 - loss: 1.4229 - accuracy: 0.58 - ETA: 2:06 - loss: 1.4344 - accuracy: 0.58 - ETA: 2:04 - loss: 1.4348 - accuracy: 0.58 - ETA: 2:03 - loss: 1.4318 - accuracy: 0.58 - ETA: 2:01 - loss: 1.4281 - accuracy: 0.58 - ETA: 1:59 - loss: 1.4319 - accuracy: 0.58 - ETA: 1:57 - loss: 1.4307 - accuracy: 0.58 - ETA: 1:56 - loss: 1.4299 - accuracy: 0.58 - ETA: 1:54 - loss: 1.4245 - accuracy: 0.58 - ETA: 1:52 - loss: 1.4172 - accuracy: 0.59 - ETA: 1:50 - loss: 1.4102 - accuracy: 0.59 - ETA: 1:48 - loss: 1.4109 - accuracy: 0.59 - ETA: 1:47 - loss: 1.4159 - accuracy: 0.59 - ETA: 1:45 - loss: 1.4165 - accuracy: 0.59 - ETA: 1:43 - loss: 1.4116 - accuracy: 0.59 - ETA: 1:42 - loss: 1.4142 - accuracy: 0.59 - ETA: 1:40 - loss: 1.4157 - accuracy: 0.59 - ETA: 1:38 - loss: 1.4165 - accuracy: 0.59 - ETA: 1:36 - loss: 1.4140 - accuracy: 0.59 - ETA: 1:35 - loss: 1.4123 - accuracy: 0.59 - ETA: 1:33 - loss: 1.4043 - accuracy: 0.59 - ETA: 1:31 - loss: 1.4028 - accuracy: 0.59 - ETA: 1:30 - loss: 1.4026 - accuracy: 0.59 - ETA: 1:28 - loss: 1.4003 - accuracy: 0.59 - ETA: 1:26 - loss: 1.4003 - accuracy: 0.59 - ETA: 1:24 - loss: 1.3976 - accuracy: 0.59 - ETA: 1:23 - loss: 1.3975 - accuracy: 0.59 - ETA: 1:21 - loss: 1.3939 - accuracy: 0.59 - ETA: 1:19 - loss: 1.3948 - accuracy: 0.59 - ETA: 1:18 - loss: 1.3946 - accuracy: 0.59 - ETA: 1:16 - loss: 1.3933 - accuracy: 0.59 - ETA: 1:14 - loss: 1.3928 - accuracy: 0.60 - ETA: 1:12 - loss: 1.3926 - accuracy: 0.60 - ETA: 1:11 - loss: 1.3909 - accuracy: 0.60 - ETA: 1:09 - loss: 1.3877 - accuracy: 0.60 - ETA: 1:07 - loss: 1.3882 - accuracy: 0.60 - ETA: 1:06 - loss: 1.3815 - accuracy: 0.60 - ETA: 1:04 - loss: 1.3765 - accuracy: 0.60 - ETA: 1:02 - loss: 1.3768 - accuracy: 0.60 - ETA: 1:01 - loss: 1.3770 - accuracy: 0.60 - ETA: 59s - loss: 1.3762 - accuracy: 0.6055 - ETA: 57s - loss: 1.3778 - accuracy: 0.604 - ETA: 56s - loss: 1.3771 - accuracy: 0.605 - ETA: 54s - loss: 1.3741 - accuracy: 0.606 - ETA: 52s - loss: 1.3754 - accuracy: 0.606 - ETA: 50s - loss: 1.3782 - accuracy: 0.605 - ETA: 49s - loss: 1.3735 - accuracy: 0.607 - ETA: 47s - loss: 1.3714 - accuracy: 0.607 - ETA: 45s - loss: 1.3681 - accuracy: 0.608 - ETA: 43s - loss: 1.3678 - accuracy: 0.608 - ETA: 42s - loss: 1.3714 - accuracy: 0.607 - ETA: 40s - loss: 1.3716 - accuracy: 0.607 - ETA: 38s - loss: 1.3692 - accuracy: 0.607 - ETA: 37s - loss: 1.3670 - accuracy: 0.608 - ETA: 35s - loss: 1.3692 - accuracy: 0.607 - ETA: 33s - loss: 1.3677 - accuracy: 0.607 - ETA: 31s - loss: 1.3661 - accuracy: 0.608 - ETA: 30s - loss: 1.3643 - accuracy: 0.608 - ETA: 28s - loss: 1.3634 - accuracy: 0.608 - ETA: 26s - loss: 1.3664 - accuracy: 0.607 - ETA: 25s - loss: 1.3667 - accuracy: 0.607 - ETA: 23s - loss: 1.3655 - accuracy: 0.608 - ETA: 21s - loss: 1.3687 - accuracy: 0.608 - ETA: 20s - loss: 1.3678 - accuracy: 0.608 - ETA: 18s - loss: 1.3665 - accuracy: 0.608 - ETA: 16s - loss: 1.3668 - accuracy: 0.608 - ETA: 14s - loss: 1.3672 - accuracy: 0.608 - ETA: 13s - loss: 1.3679 - accuracy: 0.608 - ETA: 11s - loss: 1.3683 - accuracy: 0.608 - ETA: 9s - loss: 1.3653 - accuracy: 0.609 - ETA: 8s - loss: 1.3635 - accuracy: 0.60 - ETA: 6s - loss: 1.3589 - accuracy: 0.61 - ETA: 4s - loss: 1.3594 - accuracy: 0.61 - ETA: 2s - loss: 1.3611 - accuracy: 0.61 - ETA: 1s - loss: 1.3614 - accuracy: 0.61 - 201s 15ms/step - loss: 1.3615 - accuracy: 0.6097 - val_loss: 2.4989 - val_accuracy: 0.3451\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 3:09 - loss: 1.2204 - accuracy: 0.60 - ETA: 2:58 - loss: 1.2264 - accuracy: 0.60 - ETA: 2:55 - loss: 1.1652 - accuracy: 0.64 - ETA: 2:51 - loss: 1.1407 - accuracy: 0.65 - ETA: 2:50 - loss: 1.1004 - accuracy: 0.66 - ETA: 2:48 - loss: 1.1504 - accuracy: 0.65 - ETA: 2:47 - loss: 1.1418 - accuracy: 0.65 - ETA: 2:45 - loss: 1.1074 - accuracy: 0.66 - ETA: 2:43 - loss: 1.1143 - accuracy: 0.67 - ETA: 2:40 - loss: 1.1284 - accuracy: 0.67 - ETA: 2:38 - loss: 1.1243 - accuracy: 0.67 - ETA: 2:36 - loss: 1.1195 - accuracy: 0.67 - ETA: 2:34 - loss: 1.1370 - accuracy: 0.66 - ETA: 2:33 - loss: 1.1404 - accuracy: 0.66 - ETA: 2:32 - loss: 1.1261 - accuracy: 0.67 - ETA: 2:30 - loss: 1.1269 - accuracy: 0.66 - ETA: 2:28 - loss: 1.1153 - accuracy: 0.67 - ETA: 2:27 - loss: 1.1093 - accuracy: 0.67 - ETA: 2:25 - loss: 1.1101 - accuracy: 0.67 - ETA: 2:23 - loss: 1.1038 - accuracy: 0.67 - ETA: 2:22 - loss: 1.0987 - accuracy: 0.67 - ETA: 2:20 - loss: 1.0960 - accuracy: 0.67 - ETA: 2:18 - loss: 1.1008 - accuracy: 0.67 - ETA: 2:16 - loss: 1.1043 - accuracy: 0.67 - ETA: 2:14 - loss: 1.1092 - accuracy: 0.67 - ETA: 2:13 - loss: 1.1066 - accuracy: 0.67 - ETA: 2:11 - loss: 1.1069 - accuracy: 0.67 - ETA: 2:09 - loss: 1.1056 - accuracy: 0.67 - ETA: 2:07 - loss: 1.1002 - accuracy: 0.67 - ETA: 2:05 - loss: 1.1062 - accuracy: 0.67 - ETA: 2:04 - loss: 1.1132 - accuracy: 0.67 - ETA: 2:02 - loss: 1.1096 - accuracy: 0.67 - ETA: 2:00 - loss: 1.1066 - accuracy: 0.67 - ETA: 1:58 - loss: 1.1039 - accuracy: 0.67 - ETA: 1:57 - loss: 1.1025 - accuracy: 0.67 - ETA: 1:55 - loss: 1.1072 - accuracy: 0.67 - ETA: 1:53 - loss: 1.1168 - accuracy: 0.67 - ETA: 1:51 - loss: 1.1177 - accuracy: 0.67 - ETA: 1:49 - loss: 1.1157 - accuracy: 0.67 - ETA: 1:47 - loss: 1.1158 - accuracy: 0.67 - ETA: 1:46 - loss: 1.1131 - accuracy: 0.67 - ETA: 1:44 - loss: 1.1137 - accuracy: 0.67 - ETA: 1:42 - loss: 1.1164 - accuracy: 0.66 - ETA: 1:40 - loss: 1.1146 - accuracy: 0.66 - ETA: 1:38 - loss: 1.1113 - accuracy: 0.67 - ETA: 1:37 - loss: 1.1085 - accuracy: 0.67 - ETA: 1:35 - loss: 1.1086 - accuracy: 0.66 - ETA: 1:33 - loss: 1.1078 - accuracy: 0.67 - ETA: 1:31 - loss: 1.1085 - accuracy: 0.67 - ETA: 1:30 - loss: 1.1100 - accuracy: 0.67 - ETA: 1:28 - loss: 1.1121 - accuracy: 0.66 - ETA: 1:26 - loss: 1.1139 - accuracy: 0.66 - ETA: 1:25 - loss: 1.1136 - accuracy: 0.66 - ETA: 1:23 - loss: 1.1120 - accuracy: 0.66 - ETA: 1:22 - loss: 1.1107 - accuracy: 0.66 - ETA: 1:20 - loss: 1.1138 - accuracy: 0.66 - ETA: 1:18 - loss: 1.1189 - accuracy: 0.66 - ETA: 1:17 - loss: 1.1203 - accuracy: 0.66 - ETA: 1:15 - loss: 1.1179 - accuracy: 0.66 - ETA: 1:13 - loss: 1.1186 - accuracy: 0.66 - ETA: 1:11 - loss: 1.1191 - accuracy: 0.66 - ETA: 1:10 - loss: 1.1173 - accuracy: 0.66 - ETA: 1:08 - loss: 1.1157 - accuracy: 0.66 - ETA: 1:06 - loss: 1.1171 - accuracy: 0.66 - ETA: 1:04 - loss: 1.1139 - accuracy: 0.66 - ETA: 1:03 - loss: 1.1128 - accuracy: 0.66 - ETA: 1:01 - loss: 1.1104 - accuracy: 0.66 - ETA: 59s - loss: 1.1102 - accuracy: 0.6683 - ETA: 57s - loss: 1.1074 - accuracy: 0.669 - ETA: 55s - loss: 1.1100 - accuracy: 0.669 - ETA: 54s - loss: 1.1092 - accuracy: 0.669 - ETA: 52s - loss: 1.1079 - accuracy: 0.670 - ETA: 50s - loss: 1.1058 - accuracy: 0.670 - ETA: 48s - loss: 1.1070 - accuracy: 0.670 - ETA: 47s - loss: 1.1035 - accuracy: 0.671 - ETA: 45s - loss: 1.1047 - accuracy: 0.671 - ETA: 43s - loss: 1.1028 - accuracy: 0.671 - ETA: 41s - loss: 1.1030 - accuracy: 0.671 - ETA: 40s - loss: 1.1029 - accuracy: 0.671 - ETA: 38s - loss: 1.1046 - accuracy: 0.671 - ETA: 36s - loss: 1.1036 - accuracy: 0.671 - ETA: 34s - loss: 1.1050 - accuracy: 0.671 - ETA: 33s - loss: 1.1049 - accuracy: 0.671 - ETA: 31s - loss: 1.1032 - accuracy: 0.671 - ETA: 29s - loss: 1.1030 - accuracy: 0.671 - ETA: 27s - loss: 1.1017 - accuracy: 0.671 - ETA: 25s - loss: 1.1022 - accuracy: 0.671 - ETA: 24s - loss: 1.0995 - accuracy: 0.673 - ETA: 22s - loss: 1.0991 - accuracy: 0.673 - ETA: 20s - loss: 1.0963 - accuracy: 0.674 - ETA: 18s - loss: 1.0957 - accuracy: 0.674 - ETA: 17s - loss: 1.0957 - accuracy: 0.674 - ETA: 15s - loss: 1.0936 - accuracy: 0.674 - ETA: 13s - loss: 1.0922 - accuracy: 0.675 - ETA: 11s - loss: 1.0926 - accuracy: 0.675 - ETA: 10s - loss: 1.0895 - accuracy: 0.676 - ETA: 8s - loss: 1.0893 - accuracy: 0.676 - ETA: 6s - loss: 1.0874 - accuracy: 0.67 - ETA: 4s - loss: 1.0863 - accuracy: 0.67 - ETA: 3s - loss: 1.0867 - accuracy: 0.67 - ETA: 1s - loss: 1.0852 - accuracy: 0.67 - 205s 16ms/step - loss: 1.0847 - accuracy: 0.6775 - val_loss: 2.3356 - val_accuracy: 0.3944\n",
      "Epoch 6/100\n",
      "13022/13022 [==============================] - ETA: 3:22 - loss: 0.8004 - accuracy: 0.74 - ETA: 3:07 - loss: 0.9027 - accuracy: 0.71 - ETA: 3:01 - loss: 0.8879 - accuracy: 0.71 - ETA: 3:00 - loss: 0.9035 - accuracy: 0.70 - ETA: 2:57 - loss: 0.8936 - accuracy: 0.72 - ETA: 2:53 - loss: 0.8410 - accuracy: 0.73 - ETA: 2:50 - loss: 0.8306 - accuracy: 0.73 - ETA: 2:47 - loss: 0.8433 - accuracy: 0.73 - ETA: 2:45 - loss: 0.8529 - accuracy: 0.73 - ETA: 2:42 - loss: 0.8664 - accuracy: 0.72 - ETA: 2:40 - loss: 0.8622 - accuracy: 0.72 - ETA: 2:38 - loss: 0.8537 - accuracy: 0.73 - ETA: 2:36 - loss: 0.8475 - accuracy: 0.73 - ETA: 2:34 - loss: 0.8669 - accuracy: 0.73 - ETA: 2:32 - loss: 0.8816 - accuracy: 0.72 - ETA: 2:30 - loss: 0.8814 - accuracy: 0.72 - ETA: 2:29 - loss: 0.8778 - accuracy: 0.72 - ETA: 2:27 - loss: 0.8954 - accuracy: 0.72 - ETA: 2:25 - loss: 0.8947 - accuracy: 0.72 - ETA: 2:23 - loss: 0.8962 - accuracy: 0.72 - ETA: 2:21 - loss: 0.8896 - accuracy: 0.72 - ETA: 2:19 - loss: 0.8987 - accuracy: 0.72 - ETA: 2:18 - loss: 0.9001 - accuracy: 0.72 - ETA: 2:16 - loss: 0.8941 - accuracy: 0.72 - ETA: 2:14 - loss: 0.8884 - accuracy: 0.72 - ETA: 2:13 - loss: 0.8870 - accuracy: 0.72 - ETA: 2:11 - loss: 0.8931 - accuracy: 0.72 - ETA: 2:09 - loss: 0.8972 - accuracy: 0.72 - ETA: 2:07 - loss: 0.8955 - accuracy: 0.72 - ETA: 2:05 - loss: 0.8907 - accuracy: 0.72 - ETA: 2:04 - loss: 0.8907 - accuracy: 0.72 - ETA: 2:02 - loss: 0.8883 - accuracy: 0.72 - ETA: 2:00 - loss: 0.8863 - accuracy: 0.72 - ETA: 1:59 - loss: 0.8805 - accuracy: 0.72 - ETA: 1:57 - loss: 0.8808 - accuracy: 0.73 - ETA: 1:55 - loss: 0.8817 - accuracy: 0.72 - ETA: 1:53 - loss: 0.8805 - accuracy: 0.72 - ETA: 1:52 - loss: 0.8788 - accuracy: 0.73 - ETA: 1:50 - loss: 0.8796 - accuracy: 0.73 - ETA: 1:48 - loss: 0.8774 - accuracy: 0.73 - ETA: 1:46 - loss: 0.8764 - accuracy: 0.73 - ETA: 1:45 - loss: 0.8784 - accuracy: 0.73 - ETA: 1:43 - loss: 0.8815 - accuracy: 0.72 - ETA: 1:41 - loss: 0.8825 - accuracy: 0.72 - ETA: 1:39 - loss: 0.8831 - accuracy: 0.72 - ETA: 1:38 - loss: 0.8809 - accuracy: 0.72 - ETA: 1:36 - loss: 0.8826 - accuracy: 0.72 - ETA: 1:34 - loss: 0.8793 - accuracy: 0.73 - ETA: 1:32 - loss: 0.8843 - accuracy: 0.72 - ETA: 1:31 - loss: 0.8848 - accuracy: 0.73 - ETA: 1:29 - loss: 0.8875 - accuracy: 0.72 - ETA: 1:27 - loss: 0.8906 - accuracy: 0.72 - ETA: 1:25 - loss: 0.8915 - accuracy: 0.72 - ETA: 1:23 - loss: 0.8908 - accuracy: 0.72 - ETA: 1:22 - loss: 0.8887 - accuracy: 0.72 - ETA: 1:20 - loss: 0.8886 - accuracy: 0.73 - ETA: 1:18 - loss: 0.8889 - accuracy: 0.73 - ETA: 1:16 - loss: 0.8906 - accuracy: 0.72 - ETA: 1:15 - loss: 0.8905 - accuracy: 0.72 - ETA: 1:13 - loss: 0.8914 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8891 - accuracy: 0.72 - ETA: 1:09 - loss: 0.8885 - accuracy: 0.72 - ETA: 1:08 - loss: 0.8890 - accuracy: 0.72 - ETA: 1:06 - loss: 0.8904 - accuracy: 0.72 - ETA: 1:04 - loss: 0.8921 - accuracy: 0.72 - ETA: 1:02 - loss: 0.8894 - accuracy: 0.72 - ETA: 1:01 - loss: 0.8892 - accuracy: 0.72 - ETA: 59s - loss: 0.8874 - accuracy: 0.7299 - ETA: 57s - loss: 0.8896 - accuracy: 0.729 - ETA: 55s - loss: 0.8911 - accuracy: 0.729 - ETA: 54s - loss: 0.8915 - accuracy: 0.729 - ETA: 52s - loss: 0.8931 - accuracy: 0.728 - ETA: 50s - loss: 0.8898 - accuracy: 0.730 - ETA: 48s - loss: 0.8871 - accuracy: 0.730 - ETA: 47s - loss: 0.8871 - accuracy: 0.731 - ETA: 45s - loss: 0.8865 - accuracy: 0.731 - ETA: 43s - loss: 0.8856 - accuracy: 0.731 - ETA: 41s - loss: 0.8876 - accuracy: 0.731 - ETA: 40s - loss: 0.8889 - accuracy: 0.731 - ETA: 38s - loss: 0.8869 - accuracy: 0.732 - ETA: 36s - loss: 0.8858 - accuracy: 0.732 - ETA: 34s - loss: 0.8830 - accuracy: 0.733 - ETA: 33s - loss: 0.8818 - accuracy: 0.734 - ETA: 31s - loss: 0.8807 - accuracy: 0.734 - ETA: 29s - loss: 0.8796 - accuracy: 0.734 - ETA: 27s - loss: 0.8787 - accuracy: 0.735 - ETA: 26s - loss: 0.8787 - accuracy: 0.735 - ETA: 24s - loss: 0.8791 - accuracy: 0.735 - ETA: 22s - loss: 0.8773 - accuracy: 0.735 - ETA: 20s - loss: 0.8763 - accuracy: 0.735 - ETA: 18s - loss: 0.8757 - accuracy: 0.736 - ETA: 17s - loss: 0.8734 - accuracy: 0.736 - ETA: 15s - loss: 0.8744 - accuracy: 0.736 - ETA: 13s - loss: 0.8755 - accuracy: 0.736 - ETA: 11s - loss: 0.8723 - accuracy: 0.736 - ETA: 10s - loss: 0.8724 - accuracy: 0.736 - ETA: 8s - loss: 0.8753 - accuracy: 0.736 - ETA: 6s - loss: 0.8743 - accuracy: 0.73 - ETA: 4s - loss: 0.8738 - accuracy: 0.73 - ETA: 3s - loss: 0.8726 - accuracy: 0.73 - ETA: 1s - loss: 0.8710 - accuracy: 0.73 - 205s 16ms/step - loss: 0.8698 - accuracy: 0.7378 - val_loss: 2.4187 - val_accuracy: 0.3745\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 3:02 - loss: 0.7503 - accuracy: 0.75 - ETA: 2:56 - loss: 0.6911 - accuracy: 0.76 - ETA: 2:52 - loss: 0.7367 - accuracy: 0.76 - ETA: 2:49 - loss: 0.7524 - accuracy: 0.76 - ETA: 2:49 - loss: 0.7708 - accuracy: 0.76 - ETA: 2:47 - loss: 0.7489 - accuracy: 0.76 - ETA: 2:44 - loss: 0.7244 - accuracy: 0.77 - ETA: 2:43 - loss: 0.7175 - accuracy: 0.78 - ETA: 2:41 - loss: 0.7299 - accuracy: 0.77 - ETA: 2:39 - loss: 0.7390 - accuracy: 0.77 - ETA: 2:38 - loss: 0.7346 - accuracy: 0.77 - ETA: 2:36 - loss: 0.7277 - accuracy: 0.77 - ETA: 2:34 - loss: 0.7142 - accuracy: 0.78 - ETA: 2:32 - loss: 0.7150 - accuracy: 0.78 - ETA: 2:31 - loss: 0.7133 - accuracy: 0.77 - ETA: 2:29 - loss: 0.7176 - accuracy: 0.77 - ETA: 2:28 - loss: 0.7142 - accuracy: 0.77 - ETA: 2:27 - loss: 0.7112 - accuracy: 0.77 - ETA: 2:25 - loss: 0.7117 - accuracy: 0.77 - ETA: 2:23 - loss: 0.7157 - accuracy: 0.77 - ETA: 2:21 - loss: 0.7113 - accuracy: 0.77 - ETA: 2:19 - loss: 0.7073 - accuracy: 0.77 - ETA: 2:18 - loss: 0.7068 - accuracy: 0.78 - ETA: 2:16 - loss: 0.7069 - accuracy: 0.78 - ETA: 2:14 - loss: 0.7082 - accuracy: 0.78 - ETA: 2:13 - loss: 0.7119 - accuracy: 0.78 - ETA: 2:11 - loss: 0.7100 - accuracy: 0.78 - ETA: 2:09 - loss: 0.7059 - accuracy: 0.78 - ETA: 2:07 - loss: 0.7076 - accuracy: 0.78 - ETA: 2:06 - loss: 0.7128 - accuracy: 0.78 - ETA: 2:04 - loss: 0.7103 - accuracy: 0.78 - ETA: 2:02 - loss: 0.7125 - accuracy: 0.77 - ETA: 2:01 - loss: 0.7104 - accuracy: 0.77 - ETA: 1:59 - loss: 0.7142 - accuracy: 0.77 - ETA: 1:57 - loss: 0.7137 - accuracy: 0.78 - ETA: 1:55 - loss: 0.7153 - accuracy: 0.77 - ETA: 1:54 - loss: 0.7132 - accuracy: 0.78 - ETA: 1:52 - loss: 0.7106 - accuracy: 0.78 - ETA: 1:50 - loss: 0.7141 - accuracy: 0.77 - ETA: 1:49 - loss: 0.7091 - accuracy: 0.78 - ETA: 1:47 - loss: 0.7049 - accuracy: 0.78 - ETA: 1:45 - loss: 0.7048 - accuracy: 0.78 - ETA: 1:43 - loss: 0.7045 - accuracy: 0.78 - ETA: 1:42 - loss: 0.7054 - accuracy: 0.78 - ETA: 1:40 - loss: 0.7050 - accuracy: 0.78 - ETA: 1:38 - loss: 0.7044 - accuracy: 0.78 - ETA: 1:36 - loss: 0.7072 - accuracy: 0.78 - ETA: 1:34 - loss: 0.7055 - accuracy: 0.78 - ETA: 1:33 - loss: 0.7028 - accuracy: 0.78 - ETA: 1:31 - loss: 0.7029 - accuracy: 0.78 - ETA: 1:29 - loss: 0.7054 - accuracy: 0.78 - ETA: 1:27 - loss: 0.7061 - accuracy: 0.78 - ETA: 1:25 - loss: 0.7052 - accuracy: 0.78 - ETA: 1:24 - loss: 0.7054 - accuracy: 0.78 - ETA: 1:22 - loss: 0.7088 - accuracy: 0.78 - ETA: 1:20 - loss: 0.7071 - accuracy: 0.78 - ETA: 1:18 - loss: 0.7058 - accuracy: 0.78 - ETA: 1:17 - loss: 0.7053 - accuracy: 0.78 - ETA: 1:15 - loss: 0.7026 - accuracy: 0.78 - ETA: 1:13 - loss: 0.7011 - accuracy: 0.78 - ETA: 1:11 - loss: 0.7009 - accuracy: 0.78 - ETA: 1:10 - loss: 0.6996 - accuracy: 0.78 - ETA: 1:08 - loss: 0.6995 - accuracy: 0.78 - ETA: 1:06 - loss: 0.7013 - accuracy: 0.78 - ETA: 1:04 - loss: 0.7030 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7033 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7037 - accuracy: 0.78 - ETA: 59s - loss: 0.7010 - accuracy: 0.7823 - ETA: 57s - loss: 0.7011 - accuracy: 0.782 - ETA: 55s - loss: 0.6995 - accuracy: 0.782 - ETA: 54s - loss: 0.7004 - accuracy: 0.782 - ETA: 52s - loss: 0.6966 - accuracy: 0.783 - ETA: 50s - loss: 0.6961 - accuracy: 0.783 - ETA: 48s - loss: 0.6980 - accuracy: 0.782 - ETA: 47s - loss: 0.7000 - accuracy: 0.782 - ETA: 45s - loss: 0.6998 - accuracy: 0.781 - ETA: 43s - loss: 0.7033 - accuracy: 0.780 - ETA: 41s - loss: 0.7026 - accuracy: 0.780 - ETA: 40s - loss: 0.7004 - accuracy: 0.781 - ETA: 38s - loss: 0.6998 - accuracy: 0.781 - ETA: 36s - loss: 0.6995 - accuracy: 0.782 - ETA: 34s - loss: 0.7000 - accuracy: 0.781 - ETA: 32s - loss: 0.6977 - accuracy: 0.782 - ETA: 31s - loss: 0.6948 - accuracy: 0.783 - ETA: 29s - loss: 0.6959 - accuracy: 0.783 - ETA: 27s - loss: 0.6953 - accuracy: 0.782 - ETA: 25s - loss: 0.6958 - accuracy: 0.782 - ETA: 24s - loss: 0.6941 - accuracy: 0.783 - ETA: 22s - loss: 0.6928 - accuracy: 0.784 - ETA: 20s - loss: 0.6930 - accuracy: 0.784 - ETA: 18s - loss: 0.6926 - accuracy: 0.784 - ETA: 17s - loss: 0.6928 - accuracy: 0.784 - ETA: 15s - loss: 0.6911 - accuracy: 0.784 - ETA: 13s - loss: 0.6903 - accuracy: 0.785 - ETA: 11s - loss: 0.6909 - accuracy: 0.785 - ETA: 10s - loss: 0.6894 - accuracy: 0.785 - ETA: 8s - loss: 0.6897 - accuracy: 0.785 - ETA: 6s - loss: 0.6896 - accuracy: 0.78 - ETA: 4s - loss: 0.6890 - accuracy: 0.78 - ETA: 3s - loss: 0.6898 - accuracy: 0.78 - ETA: 1s - loss: 0.6889 - accuracy: 0.78 - 203s 16ms/step - loss: 0.6878 - accuracy: 0.7860 - val_loss: 2.3960 - val_accuracy: 0.3816\n",
      "Epoch 8/100\n",
      "13022/13022 [==============================] - ETA: 2:51 - loss: 0.5293 - accuracy: 0.85 - ETA: 2:54 - loss: 0.5293 - accuracy: 0.83 - ETA: 2:50 - loss: 0.5524 - accuracy: 0.82 - ETA: 2:47 - loss: 0.5761 - accuracy: 0.82 - ETA: 2:47 - loss: 0.5665 - accuracy: 0.82 - ETA: 2:44 - loss: 0.5575 - accuracy: 0.83 - ETA: 2:42 - loss: 0.5662 - accuracy: 0.82 - ETA: 2:41 - loss: 0.5574 - accuracy: 0.82 - ETA: 2:40 - loss: 0.5600 - accuracy: 0.82 - ETA: 2:38 - loss: 0.5416 - accuracy: 0.83 - ETA: 2:37 - loss: 0.5441 - accuracy: 0.83 - ETA: 2:34 - loss: 0.5508 - accuracy: 0.82 - ETA: 2:33 - loss: 0.5607 - accuracy: 0.82 - ETA: 2:32 - loss: 0.5569 - accuracy: 0.82 - ETA: 2:30 - loss: 0.5669 - accuracy: 0.82 - ETA: 2:27 - loss: 0.5631 - accuracy: 0.82 - ETA: 2:25 - loss: 0.5521 - accuracy: 0.83 - ETA: 2:24 - loss: 0.5572 - accuracy: 0.83 - ETA: 2:22 - loss: 0.5588 - accuracy: 0.82 - ETA: 2:21 - loss: 0.5628 - accuracy: 0.82 - ETA: 2:20 - loss: 0.5682 - accuracy: 0.82 - ETA: 2:19 - loss: 0.5681 - accuracy: 0.82 - ETA: 2:17 - loss: 0.5691 - accuracy: 0.82 - ETA: 2:16 - loss: 0.5725 - accuracy: 0.82 - ETA: 2:15 - loss: 0.5670 - accuracy: 0.82 - ETA: 2:13 - loss: 0.5623 - accuracy: 0.82 - ETA: 2:11 - loss: 0.5659 - accuracy: 0.82 - ETA: 2:10 - loss: 0.5682 - accuracy: 0.82 - ETA: 2:07 - loss: 0.5715 - accuracy: 0.82 - ETA: 2:06 - loss: 0.5695 - accuracy: 0.82 - ETA: 2:04 - loss: 0.5690 - accuracy: 0.82 - ETA: 2:02 - loss: 0.5690 - accuracy: 0.82 - ETA: 2:00 - loss: 0.5620 - accuracy: 0.82 - ETA: 1:58 - loss: 0.5592 - accuracy: 0.82 - ETA: 1:57 - loss: 0.5633 - accuracy: 0.82 - ETA: 1:55 - loss: 0.5611 - accuracy: 0.82 - ETA: 1:53 - loss: 0.5625 - accuracy: 0.82 - ETA: 1:51 - loss: 0.5601 - accuracy: 0.82 - ETA: 1:50 - loss: 0.5557 - accuracy: 0.82 - ETA: 1:48 - loss: 0.5573 - accuracy: 0.82 - ETA: 1:46 - loss: 0.5558 - accuracy: 0.82 - ETA: 1:44 - loss: 0.5559 - accuracy: 0.82 - ETA: 1:42 - loss: 0.5554 - accuracy: 0.82 - ETA: 1:40 - loss: 0.5566 - accuracy: 0.82 - ETA: 1:39 - loss: 0.5581 - accuracy: 0.82 - ETA: 1:37 - loss: 0.5599 - accuracy: 0.82 - ETA: 1:35 - loss: 0.5593 - accuracy: 0.82 - ETA: 1:33 - loss: 0.5621 - accuracy: 0.82 - ETA: 1:31 - loss: 0.5595 - accuracy: 0.82 - ETA: 1:30 - loss: 0.5602 - accuracy: 0.82 - ETA: 1:28 - loss: 0.5616 - accuracy: 0.82 - ETA: 1:26 - loss: 0.5613 - accuracy: 0.82 - ETA: 1:24 - loss: 0.5615 - accuracy: 0.82 - ETA: 1:23 - loss: 0.5618 - accuracy: 0.82 - ETA: 1:21 - loss: 0.5642 - accuracy: 0.82 - ETA: 1:19 - loss: 0.5627 - accuracy: 0.82 - ETA: 1:17 - loss: 0.5611 - accuracy: 0.82 - ETA: 1:16 - loss: 0.5613 - accuracy: 0.82 - ETA: 1:14 - loss: 0.5641 - accuracy: 0.82 - ETA: 1:12 - loss: 0.5641 - accuracy: 0.82 - ETA: 1:10 - loss: 0.5661 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5659 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5668 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5680 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5670 - accuracy: 0.82 - ETA: 1:02 - loss: 0.5661 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5673 - accuracy: 0.82 - ETA: 58s - loss: 0.5652 - accuracy: 0.8238 - ETA: 56s - loss: 0.5645 - accuracy: 0.824 - ETA: 55s - loss: 0.5649 - accuracy: 0.824 - ETA: 53s - loss: 0.5651 - accuracy: 0.824 - ETA: 51s - loss: 0.5638 - accuracy: 0.824 - ETA: 49s - loss: 0.5643 - accuracy: 0.825 - ETA: 48s - loss: 0.5626 - accuracy: 0.825 - ETA: 46s - loss: 0.5616 - accuracy: 0.825 - ETA: 44s - loss: 0.5626 - accuracy: 0.825 - ETA: 43s - loss: 0.5638 - accuracy: 0.825 - ETA: 41s - loss: 0.5619 - accuracy: 0.826 - ETA: 39s - loss: 0.5636 - accuracy: 0.825 - ETA: 37s - loss: 0.5634 - accuracy: 0.825 - ETA: 36s - loss: 0.5635 - accuracy: 0.825 - ETA: 34s - loss: 0.5633 - accuracy: 0.825 - ETA: 32s - loss: 0.5636 - accuracy: 0.825 - ETA: 30s - loss: 0.5634 - accuracy: 0.825 - ETA: 29s - loss: 0.5628 - accuracy: 0.825 - ETA: 27s - loss: 0.5627 - accuracy: 0.825 - ETA: 25s - loss: 0.5616 - accuracy: 0.826 - ETA: 23s - loss: 0.5648 - accuracy: 0.825 - ETA: 22s - loss: 0.5647 - accuracy: 0.825 - ETA: 20s - loss: 0.5647 - accuracy: 0.826 - ETA: 18s - loss: 0.5635 - accuracy: 0.826 - ETA: 16s - loss: 0.5657 - accuracy: 0.826 - ETA: 15s - loss: 0.5657 - accuracy: 0.826 - ETA: 13s - loss: 0.5674 - accuracy: 0.826 - ETA: 11s - loss: 0.5663 - accuracy: 0.826 - ETA: 9s - loss: 0.5673 - accuracy: 0.826 - ETA: 8s - loss: 0.5683 - accuracy: 0.82 - ETA: 6s - loss: 0.5691 - accuracy: 0.82 - ETA: 4s - loss: 0.5682 - accuracy: 0.82 - ETA: 3s - loss: 0.5677 - accuracy: 0.82 - ETA: 1s - loss: 0.5675 - accuracy: 0.82 - 204s 16ms/step - loss: 0.5664 - accuracy: 0.8270 - val_loss: 2.4796 - val_accuracy: 0.3839\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:58 - loss: 0.4383 - accuracy: 0.86 - ETA: 2:54 - loss: 0.5205 - accuracy: 0.83 - ETA: 2:52 - loss: 0.4585 - accuracy: 0.85 - ETA: 2:50 - loss: 0.4910 - accuracy: 0.84 - ETA: 2:48 - loss: 0.5079 - accuracy: 0.84 - ETA: 2:46 - loss: 0.5177 - accuracy: 0.84 - ETA: 2:44 - loss: 0.5070 - accuracy: 0.84 - ETA: 2:43 - loss: 0.5012 - accuracy: 0.84 - ETA: 2:41 - loss: 0.5044 - accuracy: 0.84 - ETA: 2:39 - loss: 0.5032 - accuracy: 0.84 - ETA: 2:38 - loss: 0.5016 - accuracy: 0.84 - ETA: 2:36 - loss: 0.4965 - accuracy: 0.84 - ETA: 2:34 - loss: 0.5096 - accuracy: 0.84 - ETA: 2:33 - loss: 0.5141 - accuracy: 0.84 - ETA: 2:31 - loss: 0.5172 - accuracy: 0.84 - ETA: 2:29 - loss: 0.5071 - accuracy: 0.84 - ETA: 2:27 - loss: 0.5090 - accuracy: 0.84 - ETA: 2:26 - loss: 0.5116 - accuracy: 0.84 - ETA: 2:24 - loss: 0.5071 - accuracy: 0.84 - ETA: 2:22 - loss: 0.5117 - accuracy: 0.84 - ETA: 2:20 - loss: 0.5207 - accuracy: 0.84 - ETA: 2:18 - loss: 0.5206 - accuracy: 0.84 - ETA: 2:17 - loss: 0.5184 - accuracy: 0.84 - ETA: 2:15 - loss: 0.5151 - accuracy: 0.84 - ETA: 2:14 - loss: 0.5137 - accuracy: 0.84 - ETA: 2:12 - loss: 0.5140 - accuracy: 0.84 - ETA: 2:10 - loss: 0.5212 - accuracy: 0.84 - ETA: 2:08 - loss: 0.5140 - accuracy: 0.84 - ETA: 2:07 - loss: 0.5187 - accuracy: 0.84 - ETA: 2:05 - loss: 0.5133 - accuracy: 0.84 - ETA: 2:03 - loss: 0.5119 - accuracy: 0.84 - ETA: 2:02 - loss: 0.5090 - accuracy: 0.84 - ETA: 2:00 - loss: 0.5087 - accuracy: 0.84 - ETA: 1:58 - loss: 0.5042 - accuracy: 0.84 - ETA: 1:56 - loss: 0.5047 - accuracy: 0.84 - ETA: 1:55 - loss: 0.5052 - accuracy: 0.84 - ETA: 1:53 - loss: 0.5020 - accuracy: 0.84 - ETA: 1:51 - loss: 0.5072 - accuracy: 0.84 - ETA: 1:49 - loss: 0.5071 - accuracy: 0.84 - ETA: 1:47 - loss: 0.5076 - accuracy: 0.84 - ETA: 1:46 - loss: 0.5084 - accuracy: 0.84 - ETA: 1:44 - loss: 0.5086 - accuracy: 0.84 - ETA: 1:42 - loss: 0.5086 - accuracy: 0.84 - ETA: 1:40 - loss: 0.5095 - accuracy: 0.84 - ETA: 1:38 - loss: 0.5087 - accuracy: 0.84 - ETA: 1:37 - loss: 0.5068 - accuracy: 0.84 - ETA: 1:35 - loss: 0.5049 - accuracy: 0.84 - ETA: 1:33 - loss: 0.5067 - accuracy: 0.84 - ETA: 1:32 - loss: 0.5070 - accuracy: 0.84 - ETA: 1:30 - loss: 0.5085 - accuracy: 0.84 - ETA: 1:28 - loss: 0.5106 - accuracy: 0.84 - ETA: 1:26 - loss: 0.5099 - accuracy: 0.84 - ETA: 1:25 - loss: 0.5080 - accuracy: 0.84 - ETA: 1:23 - loss: 0.5071 - accuracy: 0.84 - ETA: 1:21 - loss: 0.5065 - accuracy: 0.84 - ETA: 1:19 - loss: 0.5073 - accuracy: 0.84 - ETA: 1:18 - loss: 0.5036 - accuracy: 0.84 - ETA: 1:16 - loss: 0.5013 - accuracy: 0.84 - ETA: 1:14 - loss: 0.5015 - accuracy: 0.84 - ETA: 1:12 - loss: 0.5022 - accuracy: 0.84 - ETA: 1:11 - loss: 0.4997 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4989 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4984 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4971 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4974 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5003 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5014 - accuracy: 0.84 - ETA: 58s - loss: 0.4996 - accuracy: 0.8465 - ETA: 57s - loss: 0.4995 - accuracy: 0.846 - ETA: 55s - loss: 0.4975 - accuracy: 0.847 - ETA: 53s - loss: 0.4973 - accuracy: 0.847 - ETA: 51s - loss: 0.4991 - accuracy: 0.846 - ETA: 50s - loss: 0.4983 - accuracy: 0.847 - ETA: 48s - loss: 0.5003 - accuracy: 0.847 - ETA: 46s - loss: 0.5001 - accuracy: 0.847 - ETA: 44s - loss: 0.5006 - accuracy: 0.847 - ETA: 43s - loss: 0.5022 - accuracy: 0.847 - ETA: 41s - loss: 0.5019 - accuracy: 0.847 - ETA: 39s - loss: 0.5037 - accuracy: 0.846 - ETA: 37s - loss: 0.5012 - accuracy: 0.847 - ETA: 36s - loss: 0.5024 - accuracy: 0.846 - ETA: 34s - loss: 0.5016 - accuracy: 0.846 - ETA: 32s - loss: 0.5016 - accuracy: 0.846 - ETA: 30s - loss: 0.5004 - accuracy: 0.847 - ETA: 29s - loss: 0.4998 - accuracy: 0.847 - ETA: 27s - loss: 0.4999 - accuracy: 0.847 - ETA: 25s - loss: 0.4999 - accuracy: 0.847 - ETA: 23s - loss: 0.4994 - accuracy: 0.847 - ETA: 22s - loss: 0.4997 - accuracy: 0.847 - ETA: 20s - loss: 0.4982 - accuracy: 0.847 - ETA: 18s - loss: 0.4975 - accuracy: 0.848 - ETA: 17s - loss: 0.4967 - accuracy: 0.848 - ETA: 15s - loss: 0.4972 - accuracy: 0.848 - ETA: 13s - loss: 0.4981 - accuracy: 0.847 - ETA: 11s - loss: 0.4975 - accuracy: 0.848 - ETA: 10s - loss: 0.4981 - accuracy: 0.847 - ETA: 8s - loss: 0.4988 - accuracy: 0.847 - ETA: 6s - loss: 0.4981 - accuracy: 0.84 - ETA: 4s - loss: 0.4984 - accuracy: 0.84 - ETA: 3s - loss: 0.4989 - accuracy: 0.84 - ETA: 1s - loss: 0.4984 - accuracy: 0.84 - 203s 16ms/step - loss: 0.4996 - accuracy: 0.8472 - val_loss: 2.5551 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "13022/13022 [==============================] - ETA: 2:51 - loss: 0.4032 - accuracy: 0.86 - ETA: 2:47 - loss: 0.3947 - accuracy: 0.88 - ETA: 2:48 - loss: 0.4188 - accuracy: 0.88 - ETA: 2:46 - loss: 0.4192 - accuracy: 0.87 - ETA: 2:45 - loss: 0.3890 - accuracy: 0.88 - ETA: 2:44 - loss: 0.3855 - accuracy: 0.88 - ETA: 2:44 - loss: 0.3931 - accuracy: 0.88 - ETA: 2:42 - loss: 0.4099 - accuracy: 0.88 - ETA: 2:41 - loss: 0.4187 - accuracy: 0.87 - ETA: 2:39 - loss: 0.4318 - accuracy: 0.87 - ETA: 2:38 - loss: 0.4423 - accuracy: 0.86 - ETA: 2:36 - loss: 0.4363 - accuracy: 0.86 - ETA: 2:34 - loss: 0.4283 - accuracy: 0.87 - ETA: 2:33 - loss: 0.4241 - accuracy: 0.87 - ETA: 2:31 - loss: 0.4261 - accuracy: 0.87 - ETA: 2:29 - loss: 0.4182 - accuracy: 0.87 - ETA: 2:28 - loss: 0.4163 - accuracy: 0.87 - ETA: 2:25 - loss: 0.4190 - accuracy: 0.87 - ETA: 2:23 - loss: 0.4154 - accuracy: 0.87 - ETA: 2:22 - loss: 0.4185 - accuracy: 0.87 - ETA: 2:20 - loss: 0.4143 - accuracy: 0.87 - ETA: 2:18 - loss: 0.4160 - accuracy: 0.87 - ETA: 2:17 - loss: 0.4186 - accuracy: 0.87 - ETA: 2:15 - loss: 0.4202 - accuracy: 0.87 - ETA: 2:13 - loss: 0.4164 - accuracy: 0.87 - ETA: 2:11 - loss: 0.4176 - accuracy: 0.87 - ETA: 2:10 - loss: 0.4145 - accuracy: 0.87 - ETA: 2:08 - loss: 0.4130 - accuracy: 0.87 - ETA: 2:07 - loss: 0.4134 - accuracy: 0.87 - ETA: 2:04 - loss: 0.4160 - accuracy: 0.87 - ETA: 2:03 - loss: 0.4205 - accuracy: 0.87 - ETA: 2:01 - loss: 0.4193 - accuracy: 0.87 - ETA: 1:59 - loss: 0.4207 - accuracy: 0.87 - ETA: 1:58 - loss: 0.4178 - accuracy: 0.87 - ETA: 1:56 - loss: 0.4166 - accuracy: 0.87 - ETA: 1:54 - loss: 0.4165 - accuracy: 0.87 - ETA: 1:52 - loss: 0.4166 - accuracy: 0.87 - ETA: 1:50 - loss: 0.4137 - accuracy: 0.87 - ETA: 1:48 - loss: 0.4164 - accuracy: 0.87 - ETA: 1:47 - loss: 0.4170 - accuracy: 0.87 - ETA: 1:45 - loss: 0.4186 - accuracy: 0.87 - ETA: 1:43 - loss: 0.4184 - accuracy: 0.87 - ETA: 1:41 - loss: 0.4190 - accuracy: 0.87 - ETA: 1:40 - loss: 0.4168 - accuracy: 0.87 - ETA: 1:38 - loss: 0.4154 - accuracy: 0.87 - ETA: 1:36 - loss: 0.4194 - accuracy: 0.87 - ETA: 1:35 - loss: 0.4178 - accuracy: 0.87 - ETA: 1:33 - loss: 0.4150 - accuracy: 0.87 - ETA: 1:31 - loss: 0.4182 - accuracy: 0.87 - ETA: 1:29 - loss: 0.4181 - accuracy: 0.87 - ETA: 1:28 - loss: 0.4186 - accuracy: 0.87 - ETA: 1:26 - loss: 0.4186 - accuracy: 0.87 - ETA: 1:24 - loss: 0.4206 - accuracy: 0.87 - ETA: 1:22 - loss: 0.4231 - accuracy: 0.87 - ETA: 1:21 - loss: 0.4255 - accuracy: 0.87 - ETA: 1:19 - loss: 0.4235 - accuracy: 0.87 - ETA: 1:17 - loss: 0.4252 - accuracy: 0.87 - ETA: 1:15 - loss: 0.4242 - accuracy: 0.87 - ETA: 1:14 - loss: 0.4221 - accuracy: 0.87 - ETA: 1:12 - loss: 0.4249 - accuracy: 0.87 - ETA: 1:10 - loss: 0.4255 - accuracy: 0.87 - ETA: 1:08 - loss: 0.4243 - accuracy: 0.87 - ETA: 1:07 - loss: 0.4242 - accuracy: 0.87 - ETA: 1:05 - loss: 0.4238 - accuracy: 0.87 - ETA: 1:03 - loss: 0.4223 - accuracy: 0.87 - ETA: 1:01 - loss: 0.4220 - accuracy: 0.87 - ETA: 1:00 - loss: 0.4208 - accuracy: 0.87 - ETA: 58s - loss: 0.4211 - accuracy: 0.8742 - ETA: 56s - loss: 0.4204 - accuracy: 0.874 - ETA: 55s - loss: 0.4199 - accuracy: 0.874 - ETA: 53s - loss: 0.4187 - accuracy: 0.874 - ETA: 51s - loss: 0.4185 - accuracy: 0.874 - ETA: 49s - loss: 0.4186 - accuracy: 0.874 - ETA: 48s - loss: 0.4176 - accuracy: 0.874 - ETA: 46s - loss: 0.4157 - accuracy: 0.875 - ETA: 44s - loss: 0.4159 - accuracy: 0.874 - ETA: 42s - loss: 0.4163 - accuracy: 0.874 - ETA: 41s - loss: 0.4151 - accuracy: 0.875 - ETA: 39s - loss: 0.4144 - accuracy: 0.875 - ETA: 37s - loss: 0.4151 - accuracy: 0.875 - ETA: 35s - loss: 0.4152 - accuracy: 0.875 - ETA: 34s - loss: 0.4162 - accuracy: 0.875 - ETA: 32s - loss: 0.4158 - accuracy: 0.875 - ETA: 30s - loss: 0.4162 - accuracy: 0.874 - ETA: 28s - loss: 0.4171 - accuracy: 0.874 - ETA: 27s - loss: 0.4176 - accuracy: 0.874 - ETA: 25s - loss: 0.4178 - accuracy: 0.874 - ETA: 23s - loss: 0.4173 - accuracy: 0.874 - ETA: 22s - loss: 0.4164 - accuracy: 0.874 - ETA: 20s - loss: 0.4151 - accuracy: 0.875 - ETA: 18s - loss: 0.4160 - accuracy: 0.875 - ETA: 16s - loss: 0.4184 - accuracy: 0.874 - ETA: 15s - loss: 0.4170 - accuracy: 0.875 - ETA: 13s - loss: 0.4158 - accuracy: 0.875 - ETA: 11s - loss: 0.4152 - accuracy: 0.876 - ETA: 9s - loss: 0.4145 - accuracy: 0.876 - ETA: 8s - loss: 0.4158 - accuracy: 0.87 - ETA: 6s - loss: 0.4153 - accuracy: 0.87 - ETA: 4s - loss: 0.4155 - accuracy: 0.87 - ETA: 2s - loss: 0.4157 - accuracy: 0.87 - ETA: 1s - loss: 0.4151 - accuracy: 0.87 - 200s 15ms/step - loss: 0.4142 - accuracy: 0.8768 - val_loss: 2.6630 - val_accuracy: 0.3718\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:49 - loss: 0.3013 - accuracy: 0.91 - ETA: 2:48 - loss: 0.3799 - accuracy: 0.88 - ETA: 2:47 - loss: 0.3984 - accuracy: 0.87 - ETA: 2:46 - loss: 0.3611 - accuracy: 0.88 - ETA: 2:45 - loss: 0.3654 - accuracy: 0.88 - ETA: 2:43 - loss: 0.3479 - accuracy: 0.88 - ETA: 2:41 - loss: 0.3616 - accuracy: 0.88 - ETA: 2:39 - loss: 0.3630 - accuracy: 0.88 - ETA: 2:38 - loss: 0.3737 - accuracy: 0.88 - ETA: 2:37 - loss: 0.3688 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3722 - accuracy: 0.88 - ETA: 2:34 - loss: 0.3771 - accuracy: 0.88 - ETA: 2:32 - loss: 0.3771 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3835 - accuracy: 0.87 - ETA: 2:28 - loss: 0.3813 - accuracy: 0.87 - ETA: 2:26 - loss: 0.3736 - accuracy: 0.87 - ETA: 2:24 - loss: 0.3786 - accuracy: 0.87 - ETA: 2:23 - loss: 0.3737 - accuracy: 0.87 - ETA: 2:21 - loss: 0.3743 - accuracy: 0.87 - ETA: 2:20 - loss: 0.3673 - accuracy: 0.88 - ETA: 2:19 - loss: 0.3640 - accuracy: 0.88 - ETA: 2:18 - loss: 0.3596 - accuracy: 0.88 - ETA: 2:16 - loss: 0.3694 - accuracy: 0.88 - ETA: 2:15 - loss: 0.3754 - accuracy: 0.87 - ETA: 2:13 - loss: 0.3808 - accuracy: 0.87 - ETA: 2:12 - loss: 0.3827 - accuracy: 0.87 - ETA: 2:11 - loss: 0.3797 - accuracy: 0.87 - ETA: 2:10 - loss: 0.3770 - accuracy: 0.88 - ETA: 2:08 - loss: 0.3835 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3784 - accuracy: 0.88 - ETA: 2:05 - loss: 0.3797 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3844 - accuracy: 0.88 - ETA: 2:02 - loss: 0.3840 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3839 - accuracy: 0.88 - ETA: 1:58 - loss: 0.3834 - accuracy: 0.88 - ETA: 1:57 - loss: 0.3841 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3807 - accuracy: 0.88 - ETA: 1:53 - loss: 0.3818 - accuracy: 0.88 - ETA: 1:51 - loss: 0.3794 - accuracy: 0.88 - ETA: 1:49 - loss: 0.3799 - accuracy: 0.88 - ETA: 1:47 - loss: 0.3784 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3814 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3790 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3790 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3798 - accuracy: 0.88 - ETA: 1:39 - loss: 0.3765 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3756 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3756 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3728 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3708 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3760 - accuracy: 0.88 - ETA: 1:28 - loss: 0.3743 - accuracy: 0.88 - ETA: 1:26 - loss: 0.3735 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3722 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3727 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3711 - accuracy: 0.88 - ETA: 1:19 - loss: 0.3710 - accuracy: 0.88 - ETA: 1:17 - loss: 0.3703 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3684 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3664 - accuracy: 0.88 - ETA: 1:11 - loss: 0.3658 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3651 - accuracy: 0.88 - ETA: 1:08 - loss: 0.3661 - accuracy: 0.88 - ETA: 1:06 - loss: 0.3658 - accuracy: 0.88 - ETA: 1:04 - loss: 0.3649 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3647 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3657 - accuracy: 0.88 - ETA: 59s - loss: 0.3663 - accuracy: 0.8875 - ETA: 57s - loss: 0.3661 - accuracy: 0.887 - ETA: 56s - loss: 0.3663 - accuracy: 0.887 - ETA: 54s - loss: 0.3654 - accuracy: 0.888 - ETA: 52s - loss: 0.3647 - accuracy: 0.888 - ETA: 50s - loss: 0.3659 - accuracy: 0.887 - ETA: 49s - loss: 0.3663 - accuracy: 0.887 - ETA: 47s - loss: 0.3646 - accuracy: 0.887 - ETA: 45s - loss: 0.3637 - accuracy: 0.888 - ETA: 43s - loss: 0.3646 - accuracy: 0.887 - ETA: 41s - loss: 0.3636 - accuracy: 0.888 - ETA: 40s - loss: 0.3636 - accuracy: 0.888 - ETA: 38s - loss: 0.3620 - accuracy: 0.888 - ETA: 36s - loss: 0.3615 - accuracy: 0.889 - ETA: 34s - loss: 0.3606 - accuracy: 0.889 - ETA: 33s - loss: 0.3608 - accuracy: 0.889 - ETA: 31s - loss: 0.3618 - accuracy: 0.889 - ETA: 29s - loss: 0.3619 - accuracy: 0.889 - ETA: 27s - loss: 0.3606 - accuracy: 0.889 - ETA: 25s - loss: 0.3600 - accuracy: 0.889 - ETA: 24s - loss: 0.3593 - accuracy: 0.889 - ETA: 22s - loss: 0.3584 - accuracy: 0.889 - ETA: 20s - loss: 0.3580 - accuracy: 0.890 - ETA: 18s - loss: 0.3578 - accuracy: 0.890 - ETA: 17s - loss: 0.3608 - accuracy: 0.890 - ETA: 15s - loss: 0.3609 - accuracy: 0.889 - ETA: 13s - loss: 0.3614 - accuracy: 0.889 - ETA: 11s - loss: 0.3610 - accuracy: 0.890 - ETA: 10s - loss: 0.3613 - accuracy: 0.889 - ETA: 8s - loss: 0.3617 - accuracy: 0.889 - ETA: 6s - loss: 0.3605 - accuracy: 0.88 - ETA: 4s - loss: 0.3602 - accuracy: 0.88 - ETA: 3s - loss: 0.3595 - accuracy: 0.89 - ETA: 1s - loss: 0.3595 - accuracy: 0.89 - 204s 16ms/step - loss: 0.3594 - accuracy: 0.8898 - val_loss: 2.6518 - val_accuracy: 0.3908\n",
      "Epoch 12/100\n",
      "13022/13022 [==============================] - ETA: 2:54 - loss: 0.2692 - accuracy: 0.93 - ETA: 3:00 - loss: 0.2779 - accuracy: 0.92 - ETA: 2:58 - loss: 0.2977 - accuracy: 0.91 - ETA: 2:53 - loss: 0.3162 - accuracy: 0.90 - ETA: 2:51 - loss: 0.3184 - accuracy: 0.90 - ETA: 2:50 - loss: 0.3083 - accuracy: 0.90 - ETA: 2:46 - loss: 0.3231 - accuracy: 0.90 - ETA: 2:44 - loss: 0.3164 - accuracy: 0.91 - ETA: 2:42 - loss: 0.3186 - accuracy: 0.90 - ETA: 2:40 - loss: 0.3135 - accuracy: 0.90 - ETA: 2:37 - loss: 0.3171 - accuracy: 0.90 - ETA: 2:36 - loss: 0.3161 - accuracy: 0.90 - ETA: 2:33 - loss: 0.3269 - accuracy: 0.90 - ETA: 2:31 - loss: 0.3262 - accuracy: 0.90 - ETA: 2:30 - loss: 0.3240 - accuracy: 0.90 - ETA: 2:27 - loss: 0.3161 - accuracy: 0.90 - ETA: 2:26 - loss: 0.3173 - accuracy: 0.90 - ETA: 2:24 - loss: 0.3146 - accuracy: 0.90 - ETA: 2:22 - loss: 0.3168 - accuracy: 0.90 - ETA: 2:21 - loss: 0.3189 - accuracy: 0.90 - ETA: 2:19 - loss: 0.3204 - accuracy: 0.90 - ETA: 2:18 - loss: 0.3250 - accuracy: 0.90 - ETA: 2:16 - loss: 0.3241 - accuracy: 0.90 - ETA: 2:14 - loss: 0.3212 - accuracy: 0.90 - ETA: 2:12 - loss: 0.3178 - accuracy: 0.90 - ETA: 2:11 - loss: 0.3146 - accuracy: 0.90 - ETA: 2:09 - loss: 0.3238 - accuracy: 0.90 - ETA: 2:07 - loss: 0.3215 - accuracy: 0.90 - ETA: 2:05 - loss: 0.3218 - accuracy: 0.90 - ETA: 2:04 - loss: 0.3189 - accuracy: 0.90 - ETA: 2:02 - loss: 0.3150 - accuracy: 0.90 - ETA: 2:00 - loss: 0.3113 - accuracy: 0.90 - ETA: 1:58 - loss: 0.3157 - accuracy: 0.90 - ETA: 1:57 - loss: 0.3153 - accuracy: 0.90 - ETA: 1:55 - loss: 0.3121 - accuracy: 0.90 - ETA: 1:53 - loss: 0.3091 - accuracy: 0.90 - ETA: 1:51 - loss: 0.3119 - accuracy: 0.90 - ETA: 1:50 - loss: 0.3088 - accuracy: 0.90 - ETA: 1:48 - loss: 0.3100 - accuracy: 0.90 - ETA: 1:46 - loss: 0.3104 - accuracy: 0.90 - ETA: 1:45 - loss: 0.3127 - accuracy: 0.90 - ETA: 1:43 - loss: 0.3100 - accuracy: 0.90 - ETA: 1:41 - loss: 0.3133 - accuracy: 0.90 - ETA: 1:40 - loss: 0.3145 - accuracy: 0.90 - ETA: 1:38 - loss: 0.3132 - accuracy: 0.90 - ETA: 1:36 - loss: 0.3124 - accuracy: 0.90 - ETA: 1:34 - loss: 0.3102 - accuracy: 0.90 - ETA: 1:33 - loss: 0.3085 - accuracy: 0.90 - ETA: 1:31 - loss: 0.3074 - accuracy: 0.90 - ETA: 1:29 - loss: 0.3054 - accuracy: 0.91 - ETA: 1:28 - loss: 0.3020 - accuracy: 0.91 - ETA: 1:26 - loss: 0.3010 - accuracy: 0.91 - ETA: 1:24 - loss: 0.3010 - accuracy: 0.91 - ETA: 1:23 - loss: 0.3015 - accuracy: 0.91 - ETA: 1:21 - loss: 0.3028 - accuracy: 0.91 - ETA: 1:19 - loss: 0.3037 - accuracy: 0.91 - ETA: 1:17 - loss: 0.3031 - accuracy: 0.91 - ETA: 1:16 - loss: 0.3015 - accuracy: 0.91 - ETA: 1:14 - loss: 0.3021 - accuracy: 0.91 - ETA: 1:12 - loss: 0.3014 - accuracy: 0.91 - ETA: 1:11 - loss: 0.3043 - accuracy: 0.91 - ETA: 1:09 - loss: 0.3033 - accuracy: 0.91 - ETA: 1:07 - loss: 0.3046 - accuracy: 0.91 - ETA: 1:05 - loss: 0.3063 - accuracy: 0.91 - ETA: 1:04 - loss: 0.3062 - accuracy: 0.91 - ETA: 1:02 - loss: 0.3086 - accuracy: 0.90 - ETA: 1:00 - loss: 0.3076 - accuracy: 0.90 - ETA: 58s - loss: 0.3062 - accuracy: 0.9099 - ETA: 57s - loss: 0.3057 - accuracy: 0.910 - ETA: 55s - loss: 0.3050 - accuracy: 0.910 - ETA: 53s - loss: 0.3047 - accuracy: 0.910 - ETA: 51s - loss: 0.3039 - accuracy: 0.910 - ETA: 50s - loss: 0.3023 - accuracy: 0.910 - ETA: 48s - loss: 0.3025 - accuracy: 0.911 - ETA: 46s - loss: 0.3018 - accuracy: 0.911 - ETA: 44s - loss: 0.3020 - accuracy: 0.911 - ETA: 43s - loss: 0.3044 - accuracy: 0.911 - ETA: 41s - loss: 0.3049 - accuracy: 0.911 - ETA: 39s - loss: 0.3055 - accuracy: 0.910 - ETA: 37s - loss: 0.3069 - accuracy: 0.909 - ETA: 36s - loss: 0.3071 - accuracy: 0.909 - ETA: 34s - loss: 0.3059 - accuracy: 0.910 - ETA: 32s - loss: 0.3057 - accuracy: 0.910 - ETA: 31s - loss: 0.3055 - accuracy: 0.910 - ETA: 29s - loss: 0.3046 - accuracy: 0.910 - ETA: 27s - loss: 0.3045 - accuracy: 0.910 - ETA: 25s - loss: 0.3059 - accuracy: 0.910 - ETA: 24s - loss: 0.3064 - accuracy: 0.909 - ETA: 22s - loss: 0.3058 - accuracy: 0.909 - ETA: 20s - loss: 0.3056 - accuracy: 0.910 - ETA: 18s - loss: 0.3049 - accuracy: 0.910 - ETA: 17s - loss: 0.3033 - accuracy: 0.910 - ETA: 15s - loss: 0.3035 - accuracy: 0.910 - ETA: 13s - loss: 0.3030 - accuracy: 0.910 - ETA: 11s - loss: 0.3048 - accuracy: 0.910 - ETA: 10s - loss: 0.3059 - accuracy: 0.910 - ETA: 8s - loss: 0.3081 - accuracy: 0.909 - ETA: 6s - loss: 0.3069 - accuracy: 0.90 - ETA: 4s - loss: 0.3064 - accuracy: 0.90 - ETA: 3s - loss: 0.3065 - accuracy: 0.90 - ETA: 1s - loss: 0.3052 - accuracy: 0.91 - 202s 16ms/step - loss: 0.3055 - accuracy: 0.9102 - val_loss: 2.7935 - val_accuracy: 0.3806\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:45 - loss: 0.2994 - accuracy: 0.90 - ETA: 2:49 - loss: 0.3632 - accuracy: 0.89 - ETA: 2:49 - loss: 0.3628 - accuracy: 0.90 - ETA: 2:46 - loss: 0.3418 - accuracy: 0.90 - ETA: 2:44 - loss: 0.3348 - accuracy: 0.90 - ETA: 2:43 - loss: 0.3322 - accuracy: 0.90 - ETA: 2:42 - loss: 0.3255 - accuracy: 0.90 - ETA: 2:40 - loss: 0.3311 - accuracy: 0.90 - ETA: 2:38 - loss: 0.3246 - accuracy: 0.90 - ETA: 2:36 - loss: 0.3044 - accuracy: 0.90 - ETA: 2:34 - loss: 0.3041 - accuracy: 0.90 - ETA: 2:33 - loss: 0.3048 - accuracy: 0.90 - ETA: 2:32 - loss: 0.2967 - accuracy: 0.91 - ETA: 2:29 - loss: 0.2949 - accuracy: 0.91 - ETA: 2:28 - loss: 0.2888 - accuracy: 0.91 - ETA: 2:26 - loss: 0.2950 - accuracy: 0.90 - ETA: 2:25 - loss: 0.2952 - accuracy: 0.91 - ETA: 2:23 - loss: 0.2929 - accuracy: 0.91 - ETA: 2:21 - loss: 0.2915 - accuracy: 0.91 - ETA: 2:20 - loss: 0.2913 - accuracy: 0.91 - ETA: 2:18 - loss: 0.2933 - accuracy: 0.91 - ETA: 2:16 - loss: 0.2898 - accuracy: 0.91 - ETA: 2:14 - loss: 0.2867 - accuracy: 0.91 - ETA: 2:13 - loss: 0.2852 - accuracy: 0.91 - ETA: 2:11 - loss: 0.2832 - accuracy: 0.91 - ETA: 2:10 - loss: 0.2893 - accuracy: 0.91 - ETA: 2:08 - loss: 0.2904 - accuracy: 0.91 - ETA: 2:06 - loss: 0.2872 - accuracy: 0.91 - ETA: 2:04 - loss: 0.2924 - accuracy: 0.91 - ETA: 2:03 - loss: 0.2925 - accuracy: 0.91 - ETA: 2:01 - loss: 0.2899 - accuracy: 0.91 - ETA: 1:59 - loss: 0.2933 - accuracy: 0.91 - ETA: 1:57 - loss: 0.2964 - accuracy: 0.91 - ETA: 1:56 - loss: 0.2967 - accuracy: 0.91 - ETA: 1:54 - loss: 0.2957 - accuracy: 0.91 - ETA: 1:52 - loss: 0.2942 - accuracy: 0.91 - ETA: 1:51 - loss: 0.2943 - accuracy: 0.91 - ETA: 1:49 - loss: 0.2943 - accuracy: 0.91 - ETA: 1:47 - loss: 0.2934 - accuracy: 0.91 - ETA: 1:45 - loss: 0.2921 - accuracy: 0.91 - ETA: 1:44 - loss: 0.2904 - accuracy: 0.91 - ETA: 1:42 - loss: 0.2873 - accuracy: 0.91 - ETA: 1:40 - loss: 0.2907 - accuracy: 0.91 - ETA: 1:39 - loss: 0.2896 - accuracy: 0.91 - ETA: 1:37 - loss: 0.2881 - accuracy: 0.91 - ETA: 1:35 - loss: 0.2876 - accuracy: 0.91 - ETA: 1:33 - loss: 0.2864 - accuracy: 0.91 - ETA: 1:32 - loss: 0.2876 - accuracy: 0.91 - ETA: 1:30 - loss: 0.2878 - accuracy: 0.91 - ETA: 1:27 - loss: 0.2899 - accuracy: 0.91 - ETA: 1:25 - loss: 0.2896 - accuracy: 0.91 - ETA: 1:23 - loss: 0.2880 - accuracy: 0.91 - ETA: 1:21 - loss: 0.2890 - accuracy: 0.91 - ETA: 1:19 - loss: 0.2927 - accuracy: 0.91 - ETA: 1:18 - loss: 0.2940 - accuracy: 0.91 - ETA: 1:16 - loss: 0.2931 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2930 - accuracy: 0.91 - ETA: 1:13 - loss: 0.2914 - accuracy: 0.91 - ETA: 1:11 - loss: 0.2903 - accuracy: 0.91 - ETA: 1:09 - loss: 0.2895 - accuracy: 0.91 - ETA: 1:08 - loss: 0.2882 - accuracy: 0.91 - ETA: 1:06 - loss: 0.2883 - accuracy: 0.91 - ETA: 1:05 - loss: 0.2887 - accuracy: 0.91 - ETA: 1:03 - loss: 0.2880 - accuracy: 0.91 - ETA: 1:01 - loss: 0.2865 - accuracy: 0.91 - ETA: 1:00 - loss: 0.2858 - accuracy: 0.91 - ETA: 58s - loss: 0.2858 - accuracy: 0.9134 - ETA: 56s - loss: 0.2840 - accuracy: 0.913 - ETA: 54s - loss: 0.2847 - accuracy: 0.913 - ETA: 53s - loss: 0.2864 - accuracy: 0.913 - ETA: 51s - loss: 0.2872 - accuracy: 0.913 - ETA: 49s - loss: 0.2861 - accuracy: 0.913 - ETA: 48s - loss: 0.2862 - accuracy: 0.913 - ETA: 46s - loss: 0.2864 - accuracy: 0.913 - ETA: 44s - loss: 0.2877 - accuracy: 0.913 - ETA: 43s - loss: 0.2891 - accuracy: 0.912 - ETA: 41s - loss: 0.2886 - accuracy: 0.913 - ETA: 39s - loss: 0.2877 - accuracy: 0.913 - ETA: 38s - loss: 0.2871 - accuracy: 0.913 - ETA: 36s - loss: 0.2873 - accuracy: 0.913 - ETA: 34s - loss: 0.2872 - accuracy: 0.913 - ETA: 33s - loss: 0.2873 - accuracy: 0.913 - ETA: 31s - loss: 0.2869 - accuracy: 0.913 - ETA: 29s - loss: 0.2858 - accuracy: 0.914 - ETA: 28s - loss: 0.2859 - accuracy: 0.914 - ETA: 26s - loss: 0.2864 - accuracy: 0.914 - ETA: 24s - loss: 0.2852 - accuracy: 0.914 - ETA: 23s - loss: 0.2867 - accuracy: 0.914 - ETA: 21s - loss: 0.2870 - accuracy: 0.914 - ETA: 19s - loss: 0.2860 - accuracy: 0.914 - ETA: 18s - loss: 0.2855 - accuracy: 0.914 - ETA: 16s - loss: 0.2848 - accuracy: 0.914 - ETA: 14s - loss: 0.2836 - accuracy: 0.914 - ETA: 13s - loss: 0.2828 - accuracy: 0.914 - ETA: 11s - loss: 0.2826 - accuracy: 0.915 - ETA: 9s - loss: 0.2832 - accuracy: 0.914 - ETA: 7s - loss: 0.2840 - accuracy: 0.91 - ETA: 6s - loss: 0.2857 - accuracy: 0.91 - ETA: 4s - loss: 0.2845 - accuracy: 0.91 - ETA: 2s - loss: 0.2844 - accuracy: 0.91 - ETA: 1s - loss: 0.2841 - accuracy: 0.91 - 196s 15ms/step - loss: 0.2852 - accuracy: 0.9147 - val_loss: 2.6590 - val_accuracy: 0.4160\n",
      "Epoch 14/100\n",
      "13022/13022 [==============================] - ETA: 2:54 - loss: 0.2127 - accuracy: 0.92 - ETA: 2:50 - loss: 0.2717 - accuracy: 0.92 - ETA: 2:53 - loss: 0.2518 - accuracy: 0.92 - ETA: 2:53 - loss: 0.2406 - accuracy: 0.92 - ETA: 2:51 - loss: 0.2405 - accuracy: 0.92 - ETA: 2:49 - loss: 0.2397 - accuracy: 0.92 - ETA: 2:46 - loss: 0.2429 - accuracy: 0.92 - ETA: 2:43 - loss: 0.2365 - accuracy: 0.92 - ETA: 2:41 - loss: 0.2529 - accuracy: 0.92 - ETA: 2:38 - loss: 0.2529 - accuracy: 0.92 - ETA: 2:36 - loss: 0.2517 - accuracy: 0.92 - ETA: 2:34 - loss: 0.2553 - accuracy: 0.92 - ETA: 2:33 - loss: 0.2581 - accuracy: 0.92 - ETA: 2:31 - loss: 0.2621 - accuracy: 0.92 - ETA: 2:29 - loss: 0.2592 - accuracy: 0.92 - ETA: 2:27 - loss: 0.2533 - accuracy: 0.92 - ETA: 2:25 - loss: 0.2604 - accuracy: 0.92 - ETA: 2:24 - loss: 0.2642 - accuracy: 0.92 - ETA: 2:22 - loss: 0.2586 - accuracy: 0.92 - ETA: 2:21 - loss: 0.2561 - accuracy: 0.92 - ETA: 2:19 - loss: 0.2525 - accuracy: 0.92 - ETA: 2:18 - loss: 0.2541 - accuracy: 0.92 - ETA: 2:16 - loss: 0.2516 - accuracy: 0.92 - ETA: 2:14 - loss: 0.2515 - accuracy: 0.92 - ETA: 2:12 - loss: 0.2528 - accuracy: 0.92 - ETA: 2:10 - loss: 0.2553 - accuracy: 0.92 - ETA: 2:09 - loss: 0.2546 - accuracy: 0.92 - ETA: 2:07 - loss: 0.2567 - accuracy: 0.92 - ETA: 2:05 - loss: 0.2559 - accuracy: 0.92 - ETA: 2:03 - loss: 0.2549 - accuracy: 0.92 - ETA: 2:02 - loss: 0.2516 - accuracy: 0.92 - ETA: 2:00 - loss: 0.2497 - accuracy: 0.92 - ETA: 1:58 - loss: 0.2515 - accuracy: 0.92 - ETA: 1:56 - loss: 0.2503 - accuracy: 0.92 - ETA: 1:54 - loss: 0.2546 - accuracy: 0.92 - ETA: 1:53 - loss: 0.2556 - accuracy: 0.92 - ETA: 1:51 - loss: 0.2556 - accuracy: 0.92 - ETA: 1:49 - loss: 0.2571 - accuracy: 0.92 - ETA: 1:48 - loss: 0.2575 - accuracy: 0.92 - ETA: 1:46 - loss: 0.2562 - accuracy: 0.92 - ETA: 1:44 - loss: 0.2537 - accuracy: 0.92 - ETA: 1:42 - loss: 0.2563 - accuracy: 0.92 - ETA: 1:40 - loss: 0.2558 - accuracy: 0.92 - ETA: 1:39 - loss: 0.2555 - accuracy: 0.92 - ETA: 1:37 - loss: 0.2545 - accuracy: 0.92 - ETA: 1:35 - loss: 0.2543 - accuracy: 0.92 - ETA: 1:33 - loss: 0.2539 - accuracy: 0.92 - ETA: 1:32 - loss: 0.2516 - accuracy: 0.92 - ETA: 1:30 - loss: 0.2500 - accuracy: 0.92 - ETA: 1:28 - loss: 0.2492 - accuracy: 0.92 - ETA: 1:26 - loss: 0.2477 - accuracy: 0.92 - ETA: 1:25 - loss: 0.2464 - accuracy: 0.92 - ETA: 1:23 - loss: 0.2489 - accuracy: 0.92 - ETA: 1:21 - loss: 0.2490 - accuracy: 0.92 - ETA: 1:20 - loss: 0.2498 - accuracy: 0.92 - ETA: 1:18 - loss: 0.2493 - accuracy: 0.92 - ETA: 1:16 - loss: 0.2502 - accuracy: 0.92 - ETA: 1:14 - loss: 0.2490 - accuracy: 0.92 - ETA: 1:13 - loss: 0.2495 - accuracy: 0.92 - ETA: 1:11 - loss: 0.2480 - accuracy: 0.92 - ETA: 1:09 - loss: 0.2479 - accuracy: 0.92 - ETA: 1:08 - loss: 0.2498 - accuracy: 0.92 - ETA: 1:06 - loss: 0.2500 - accuracy: 0.92 - ETA: 1:04 - loss: 0.2514 - accuracy: 0.92 - ETA: 1:02 - loss: 0.2510 - accuracy: 0.92 - ETA: 1:01 - loss: 0.2513 - accuracy: 0.92 - ETA: 59s - loss: 0.2502 - accuracy: 0.9244 - ETA: 57s - loss: 0.2499 - accuracy: 0.924 - ETA: 56s - loss: 0.2491 - accuracy: 0.924 - ETA: 54s - loss: 0.2513 - accuracy: 0.923 - ETA: 52s - loss: 0.2500 - accuracy: 0.924 - ETA: 50s - loss: 0.2500 - accuracy: 0.923 - ETA: 49s - loss: 0.2491 - accuracy: 0.924 - ETA: 47s - loss: 0.2478 - accuracy: 0.924 - ETA: 45s - loss: 0.2473 - accuracy: 0.924 - ETA: 44s - loss: 0.2463 - accuracy: 0.924 - ETA: 42s - loss: 0.2460 - accuracy: 0.924 - ETA: 40s - loss: 0.2460 - accuracy: 0.924 - ETA: 38s - loss: 0.2464 - accuracy: 0.924 - ETA: 37s - loss: 0.2462 - accuracy: 0.924 - ETA: 35s - loss: 0.2483 - accuracy: 0.924 - ETA: 33s - loss: 0.2489 - accuracy: 0.924 - ETA: 32s - loss: 0.2487 - accuracy: 0.924 - ETA: 30s - loss: 0.2485 - accuracy: 0.924 - ETA: 28s - loss: 0.2484 - accuracy: 0.924 - ETA: 26s - loss: 0.2484 - accuracy: 0.924 - ETA: 25s - loss: 0.2482 - accuracy: 0.924 - ETA: 23s - loss: 0.2479 - accuracy: 0.924 - ETA: 21s - loss: 0.2475 - accuracy: 0.924 - ETA: 20s - loss: 0.2478 - accuracy: 0.924 - ETA: 18s - loss: 0.2472 - accuracy: 0.925 - ETA: 16s - loss: 0.2470 - accuracy: 0.924 - ETA: 14s - loss: 0.2467 - accuracy: 0.924 - ETA: 13s - loss: 0.2466 - accuracy: 0.925 - ETA: 11s - loss: 0.2496 - accuracy: 0.924 - ETA: 9s - loss: 0.2497 - accuracy: 0.924 - ETA: 8s - loss: 0.2493 - accuracy: 0.92 - ETA: 6s - loss: 0.2485 - accuracy: 0.92 - ETA: 4s - loss: 0.2479 - accuracy: 0.92 - ETA: 2s - loss: 0.2474 - accuracy: 0.92 - ETA: 1s - loss: 0.2475 - accuracy: 0.92 - 198s 15ms/step - loss: 0.2473 - accuracy: 0.9255 - val_loss: 2.8263 - val_accuracy: 0.3814\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:46 - loss: 0.2240 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1732 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1640 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1533 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1688 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1736 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1750 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1948 - accuracy: 0.94 - ETA: 2:39 - loss: 0.1973 - accuracy: 0.94 - ETA: 2:38 - loss: 0.1937 - accuracy: 0.94 - ETA: 2:36 - loss: 0.2015 - accuracy: 0.94 - ETA: 2:34 - loss: 0.2047 - accuracy: 0.94 - ETA: 2:32 - loss: 0.2041 - accuracy: 0.94 - ETA: 2:30 - loss: 0.2028 - accuracy: 0.94 - ETA: 2:28 - loss: 0.2053 - accuracy: 0.94 - ETA: 2:27 - loss: 0.2018 - accuracy: 0.94 - ETA: 2:24 - loss: 0.1974 - accuracy: 0.94 - ETA: 2:23 - loss: 0.1943 - accuracy: 0.94 - ETA: 2:22 - loss: 0.1950 - accuracy: 0.94 - ETA: 2:21 - loss: 0.1969 - accuracy: 0.94 - ETA: 2:19 - loss: 0.2006 - accuracy: 0.94 - ETA: 2:17 - loss: 0.1963 - accuracy: 0.94 - ETA: 2:15 - loss: 0.1989 - accuracy: 0.94 - ETA: 2:14 - loss: 0.2011 - accuracy: 0.94 - ETA: 2:12 - loss: 0.2007 - accuracy: 0.94 - ETA: 2:10 - loss: 0.2033 - accuracy: 0.94 - ETA: 2:08 - loss: 0.2067 - accuracy: 0.94 - ETA: 2:07 - loss: 0.2080 - accuracy: 0.94 - ETA: 2:05 - loss: 0.2112 - accuracy: 0.94 - ETA: 2:04 - loss: 0.2096 - accuracy: 0.94 - ETA: 2:02 - loss: 0.2148 - accuracy: 0.94 - ETA: 2:00 - loss: 0.2155 - accuracy: 0.94 - ETA: 1:58 - loss: 0.2119 - accuracy: 0.94 - ETA: 1:57 - loss: 0.2125 - accuracy: 0.94 - ETA: 1:55 - loss: 0.2113 - accuracy: 0.94 - ETA: 1:53 - loss: 0.2112 - accuracy: 0.94 - ETA: 1:51 - loss: 0.2124 - accuracy: 0.94 - ETA: 1:49 - loss: 0.2129 - accuracy: 0.94 - ETA: 1:47 - loss: 0.2122 - accuracy: 0.94 - ETA: 1:46 - loss: 0.2134 - accuracy: 0.94 - ETA: 1:44 - loss: 0.2125 - accuracy: 0.94 - ETA: 1:42 - loss: 0.2146 - accuracy: 0.94 - ETA: 1:41 - loss: 0.2132 - accuracy: 0.94 - ETA: 1:39 - loss: 0.2130 - accuracy: 0.94 - ETA: 1:37 - loss: 0.2110 - accuracy: 0.94 - ETA: 1:35 - loss: 0.2160 - accuracy: 0.94 - ETA: 1:34 - loss: 0.2145 - accuracy: 0.94 - ETA: 1:32 - loss: 0.2158 - accuracy: 0.94 - ETA: 1:30 - loss: 0.2146 - accuracy: 0.94 - ETA: 1:28 - loss: 0.2147 - accuracy: 0.94 - ETA: 1:27 - loss: 0.2144 - accuracy: 0.94 - ETA: 1:25 - loss: 0.2150 - accuracy: 0.94 - ETA: 1:23 - loss: 0.2135 - accuracy: 0.94 - ETA: 1:21 - loss: 0.2146 - accuracy: 0.94 - ETA: 1:20 - loss: 0.2136 - accuracy: 0.94 - ETA: 1:18 - loss: 0.2142 - accuracy: 0.94 - ETA: 1:16 - loss: 0.2146 - accuracy: 0.94 - ETA: 1:15 - loss: 0.2153 - accuracy: 0.94 - ETA: 1:13 - loss: 0.2170 - accuracy: 0.94 - ETA: 1:11 - loss: 0.2156 - accuracy: 0.94 - ETA: 1:10 - loss: 0.2139 - accuracy: 0.94 - ETA: 1:08 - loss: 0.2125 - accuracy: 0.94 - ETA: 1:06 - loss: 0.2151 - accuracy: 0.94 - ETA: 1:04 - loss: 0.2151 - accuracy: 0.94 - ETA: 1:03 - loss: 0.2151 - accuracy: 0.94 - ETA: 1:01 - loss: 0.2168 - accuracy: 0.94 - ETA: 59s - loss: 0.2167 - accuracy: 0.9408 - ETA: 58s - loss: 0.2175 - accuracy: 0.940 - ETA: 56s - loss: 0.2170 - accuracy: 0.939 - ETA: 54s - loss: 0.2162 - accuracy: 0.940 - ETA: 52s - loss: 0.2177 - accuracy: 0.939 - ETA: 51s - loss: 0.2184 - accuracy: 0.939 - ETA: 49s - loss: 0.2188 - accuracy: 0.939 - ETA: 47s - loss: 0.2194 - accuracy: 0.939 - ETA: 45s - loss: 0.2189 - accuracy: 0.939 - ETA: 44s - loss: 0.2189 - accuracy: 0.939 - ETA: 42s - loss: 0.2184 - accuracy: 0.939 - ETA: 40s - loss: 0.2211 - accuracy: 0.939 - ETA: 39s - loss: 0.2214 - accuracy: 0.939 - ETA: 37s - loss: 0.2203 - accuracy: 0.939 - ETA: 35s - loss: 0.2199 - accuracy: 0.940 - ETA: 33s - loss: 0.2204 - accuracy: 0.939 - ETA: 32s - loss: 0.2204 - accuracy: 0.939 - ETA: 30s - loss: 0.2208 - accuracy: 0.939 - ETA: 28s - loss: 0.2216 - accuracy: 0.940 - ETA: 27s - loss: 0.2211 - accuracy: 0.940 - ETA: 25s - loss: 0.2207 - accuracy: 0.940 - ETA: 23s - loss: 0.2208 - accuracy: 0.940 - ETA: 21s - loss: 0.2210 - accuracy: 0.940 - ETA: 20s - loss: 0.2209 - accuracy: 0.940 - ETA: 18s - loss: 0.2206 - accuracy: 0.940 - ETA: 16s - loss: 0.2208 - accuracy: 0.940 - ETA: 14s - loss: 0.2205 - accuracy: 0.940 - ETA: 13s - loss: 0.2199 - accuracy: 0.940 - ETA: 11s - loss: 0.2200 - accuracy: 0.940 - ETA: 9s - loss: 0.2196 - accuracy: 0.940 - ETA: 8s - loss: 0.2198 - accuracy: 0.93 - ETA: 6s - loss: 0.2200 - accuracy: 0.93 - ETA: 4s - loss: 0.2204 - accuracy: 0.93 - ETA: 2s - loss: 0.2198 - accuracy: 0.93 - ETA: 1s - loss: 0.2195 - accuracy: 0.94 - 199s 15ms/step - loss: 0.2198 - accuracy: 0.9399 - val_loss: 2.8137 - val_accuracy: 0.3993\n",
      "Epoch 16/100\n",
      "13022/13022 [==============================] - ETA: 2:46 - loss: 0.2375 - accuracy: 0.92 - ETA: 2:46 - loss: 0.2195 - accuracy: 0.93 - ETA: 2:43 - loss: 0.2262 - accuracy: 0.92 - ETA: 2:43 - loss: 0.2223 - accuracy: 0.92 - ETA: 2:42 - loss: 0.2064 - accuracy: 0.92 - ETA: 2:42 - loss: 0.2077 - accuracy: 0.93 - ETA: 2:41 - loss: 0.1985 - accuracy: 0.93 - ETA: 2:38 - loss: 0.1933 - accuracy: 0.93 - ETA: 2:37 - loss: 0.1949 - accuracy: 0.93 - ETA: 2:34 - loss: 0.1895 - accuracy: 0.93 - ETA: 2:32 - loss: 0.1986 - accuracy: 0.93 - ETA: 2:30 - loss: 0.1996 - accuracy: 0.93 - ETA: 2:28 - loss: 0.1987 - accuracy: 0.93 - ETA: 2:27 - loss: 0.2046 - accuracy: 0.93 - ETA: 2:25 - loss: 0.2030 - accuracy: 0.93 - ETA: 2:24 - loss: 0.1984 - accuracy: 0.93 - ETA: 2:22 - loss: 0.2025 - accuracy: 0.93 - ETA: 2:20 - loss: 0.1995 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1977 - accuracy: 0.93 - ETA: 2:18 - loss: 0.1990 - accuracy: 0.93 - ETA: 2:16 - loss: 0.1936 - accuracy: 0.94 - ETA: 2:14 - loss: 0.1881 - accuracy: 0.94 - ETA: 2:13 - loss: 0.1878 - accuracy: 0.94 - ETA: 2:11 - loss: 0.1891 - accuracy: 0.94 - ETA: 2:09 - loss: 0.1906 - accuracy: 0.94 - ETA: 2:08 - loss: 0.1892 - accuracy: 0.94 - ETA: 2:06 - loss: 0.1908 - accuracy: 0.94 - ETA: 2:05 - loss: 0.1915 - accuracy: 0.94 - ETA: 2:03 - loss: 0.1929 - accuracy: 0.94 - ETA: 2:01 - loss: 0.1947 - accuracy: 0.94 - ETA: 1:59 - loss: 0.1994 - accuracy: 0.93 - ETA: 1:58 - loss: 0.1977 - accuracy: 0.93 - ETA: 1:56 - loss: 0.1973 - accuracy: 0.94 - ETA: 1:54 - loss: 0.2011 - accuracy: 0.94 - ETA: 1:53 - loss: 0.2025 - accuracy: 0.93 - ETA: 1:51 - loss: 0.2023 - accuracy: 0.93 - ETA: 1:49 - loss: 0.2044 - accuracy: 0.93 - ETA: 1:48 - loss: 0.2052 - accuracy: 0.93 - ETA: 1:46 - loss: 0.2052 - accuracy: 0.93 - ETA: 1:44 - loss: 0.2044 - accuracy: 0.93 - ETA: 1:43 - loss: 0.2027 - accuracy: 0.93 - ETA: 1:41 - loss: 0.2041 - accuracy: 0.93 - ETA: 1:39 - loss: 0.2039 - accuracy: 0.93 - ETA: 1:38 - loss: 0.2052 - accuracy: 0.93 - ETA: 1:36 - loss: 0.2041 - accuracy: 0.93 - ETA: 1:35 - loss: 0.2034 - accuracy: 0.93 - ETA: 1:33 - loss: 0.2066 - accuracy: 0.93 - ETA: 1:31 - loss: 0.2059 - accuracy: 0.93 - ETA: 1:29 - loss: 0.2051 - accuracy: 0.93 - ETA: 1:28 - loss: 0.2058 - accuracy: 0.93 - ETA: 1:26 - loss: 0.2043 - accuracy: 0.93 - ETA: 1:24 - loss: 0.2046 - accuracy: 0.93 - ETA: 1:23 - loss: 0.2045 - accuracy: 0.93 - ETA: 1:21 - loss: 0.2054 - accuracy: 0.93 - ETA: 1:19 - loss: 0.2076 - accuracy: 0.93 - ETA: 1:18 - loss: 0.2068 - accuracy: 0.93 - ETA: 1:16 - loss: 0.2067 - accuracy: 0.93 - ETA: 1:14 - loss: 0.2060 - accuracy: 0.93 - ETA: 1:13 - loss: 0.2057 - accuracy: 0.93 - ETA: 1:11 - loss: 0.2060 - accuracy: 0.93 - ETA: 1:09 - loss: 0.2061 - accuracy: 0.93 - ETA: 1:08 - loss: 0.2062 - accuracy: 0.93 - ETA: 1:06 - loss: 0.2066 - accuracy: 0.93 - ETA: 1:04 - loss: 0.2073 - accuracy: 0.93 - ETA: 1:02 - loss: 0.2063 - accuracy: 0.93 - ETA: 1:01 - loss: 0.2062 - accuracy: 0.93 - ETA: 59s - loss: 0.2067 - accuracy: 0.9395 - ETA: 57s - loss: 0.2092 - accuracy: 0.938 - ETA: 55s - loss: 0.2090 - accuracy: 0.938 - ETA: 54s - loss: 0.2076 - accuracy: 0.939 - ETA: 52s - loss: 0.2063 - accuracy: 0.939 - ETA: 50s - loss: 0.2067 - accuracy: 0.939 - ETA: 49s - loss: 0.2071 - accuracy: 0.939 - ETA: 47s - loss: 0.2062 - accuracy: 0.939 - ETA: 45s - loss: 0.2044 - accuracy: 0.939 - ETA: 43s - loss: 0.2052 - accuracy: 0.939 - ETA: 42s - loss: 0.2068 - accuracy: 0.939 - ETA: 40s - loss: 0.2062 - accuracy: 0.939 - ETA: 38s - loss: 0.2062 - accuracy: 0.939 - ETA: 37s - loss: 0.2061 - accuracy: 0.939 - ETA: 35s - loss: 0.2063 - accuracy: 0.939 - ETA: 33s - loss: 0.2065 - accuracy: 0.939 - ETA: 31s - loss: 0.2058 - accuracy: 0.939 - ETA: 30s - loss: 0.2054 - accuracy: 0.940 - ETA: 28s - loss: 0.2046 - accuracy: 0.940 - ETA: 26s - loss: 0.2046 - accuracy: 0.940 - ETA: 25s - loss: 0.2043 - accuracy: 0.940 - ETA: 23s - loss: 0.2039 - accuracy: 0.940 - ETA: 21s - loss: 0.2047 - accuracy: 0.940 - ETA: 20s - loss: 0.2042 - accuracy: 0.940 - ETA: 18s - loss: 0.2031 - accuracy: 0.940 - ETA: 16s - loss: 0.2032 - accuracy: 0.940 - ETA: 14s - loss: 0.2034 - accuracy: 0.940 - ETA: 13s - loss: 0.2039 - accuracy: 0.940 - ETA: 11s - loss: 0.2030 - accuracy: 0.940 - ETA: 9s - loss: 0.2024 - accuracy: 0.940 - ETA: 8s - loss: 0.2028 - accuracy: 0.94 - ETA: 6s - loss: 0.2029 - accuracy: 0.94 - ETA: 4s - loss: 0.2018 - accuracy: 0.94 - ETA: 2s - loss: 0.2007 - accuracy: 0.94 - ETA: 1s - loss: 0.2007 - accuracy: 0.94 - 197s 15ms/step - loss: 0.2002 - accuracy: 0.9417 - val_loss: 2.7114 - val_accuracy: 0.4101\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:44 - loss: 0.1038 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1704 - accuracy: 0.94 - ETA: 2:47 - loss: 0.1666 - accuracy: 0.95 - ETA: 2:46 - loss: 0.1751 - accuracy: 0.94 - ETA: 2:43 - loss: 0.1594 - accuracy: 0.94 - ETA: 2:41 - loss: 0.1986 - accuracy: 0.93 - ETA: 2:39 - loss: 0.2010 - accuracy: 0.94 - ETA: 2:37 - loss: 0.2057 - accuracy: 0.94 - ETA: 2:35 - loss: 0.1972 - accuracy: 0.94 - ETA: 2:33 - loss: 0.1915 - accuracy: 0.94 - ETA: 2:32 - loss: 0.1825 - accuracy: 0.94 - ETA: 2:30 - loss: 0.1796 - accuracy: 0.94 - ETA: 2:29 - loss: 0.1712 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1688 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1713 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1703 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1657 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1615 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1644 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1637 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1633 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1650 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1650 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1670 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1664 - accuracy: 0.95 - ETA: 2:08 - loss: 0.1648 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1649 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1662 - accuracy: 0.95 - ETA: 2:03 - loss: 0.1666 - accuracy: 0.95 - ETA: 2:01 - loss: 0.1658 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1685 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1706 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1686 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1676 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1691 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1711 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1722 - accuracy: 0.94 - ETA: 1:49 - loss: 0.1735 - accuracy: 0.94 - ETA: 1:47 - loss: 0.1732 - accuracy: 0.94 - ETA: 1:46 - loss: 0.1720 - accuracy: 0.94 - ETA: 1:44 - loss: 0.1716 - accuracy: 0.94 - ETA: 1:43 - loss: 0.1692 - accuracy: 0.94 - ETA: 1:41 - loss: 0.1686 - accuracy: 0.94 - ETA: 1:39 - loss: 0.1690 - accuracy: 0.94 - ETA: 1:38 - loss: 0.1710 - accuracy: 0.94 - ETA: 1:36 - loss: 0.1703 - accuracy: 0.94 - ETA: 1:34 - loss: 0.1706 - accuracy: 0.94 - ETA: 1:32 - loss: 0.1726 - accuracy: 0.94 - ETA: 1:30 - loss: 0.1729 - accuracy: 0.94 - ETA: 1:29 - loss: 0.1728 - accuracy: 0.94 - ETA: 1:27 - loss: 0.1729 - accuracy: 0.94 - ETA: 1:25 - loss: 0.1716 - accuracy: 0.94 - ETA: 1:23 - loss: 0.1707 - accuracy: 0.94 - ETA: 1:22 - loss: 0.1715 - accuracy: 0.94 - ETA: 1:20 - loss: 0.1722 - accuracy: 0.94 - ETA: 1:18 - loss: 0.1736 - accuracy: 0.94 - ETA: 1:16 - loss: 0.1720 - accuracy: 0.94 - ETA: 1:15 - loss: 0.1716 - accuracy: 0.94 - ETA: 1:13 - loss: 0.1729 - accuracy: 0.94 - ETA: 1:11 - loss: 0.1736 - accuracy: 0.94 - ETA: 1:10 - loss: 0.1750 - accuracy: 0.94 - ETA: 1:08 - loss: 0.1759 - accuracy: 0.94 - ETA: 1:06 - loss: 0.1749 - accuracy: 0.94 - ETA: 1:04 - loss: 0.1752 - accuracy: 0.94 - ETA: 1:03 - loss: 0.1748 - accuracy: 0.94 - ETA: 1:01 - loss: 0.1755 - accuracy: 0.94 - ETA: 59s - loss: 0.1790 - accuracy: 0.9480 - ETA: 57s - loss: 0.1810 - accuracy: 0.948 - ETA: 56s - loss: 0.1812 - accuracy: 0.947 - ETA: 54s - loss: 0.1837 - accuracy: 0.947 - ETA: 52s - loss: 0.1859 - accuracy: 0.946 - ETA: 50s - loss: 0.1866 - accuracy: 0.947 - ETA: 49s - loss: 0.1854 - accuracy: 0.947 - ETA: 47s - loss: 0.1861 - accuracy: 0.946 - ETA: 45s - loss: 0.1862 - accuracy: 0.946 - ETA: 44s - loss: 0.1861 - accuracy: 0.947 - ETA: 42s - loss: 0.1862 - accuracy: 0.946 - ETA: 40s - loss: 0.1869 - accuracy: 0.946 - ETA: 39s - loss: 0.1864 - accuracy: 0.946 - ETA: 37s - loss: 0.1870 - accuracy: 0.946 - ETA: 35s - loss: 0.1870 - accuracy: 0.946 - ETA: 33s - loss: 0.1867 - accuracy: 0.946 - ETA: 32s - loss: 0.1864 - accuracy: 0.946 - ETA: 30s - loss: 0.1861 - accuracy: 0.946 - ETA: 28s - loss: 0.1865 - accuracy: 0.946 - ETA: 26s - loss: 0.1865 - accuracy: 0.946 - ETA: 25s - loss: 0.1870 - accuracy: 0.946 - ETA: 23s - loss: 0.1868 - accuracy: 0.946 - ETA: 21s - loss: 0.1860 - accuracy: 0.946 - ETA: 20s - loss: 0.1855 - accuracy: 0.947 - ETA: 18s - loss: 0.1862 - accuracy: 0.947 - ETA: 16s - loss: 0.1876 - accuracy: 0.946 - ETA: 14s - loss: 0.1862 - accuracy: 0.946 - ETA: 13s - loss: 0.1869 - accuracy: 0.946 - ETA: 11s - loss: 0.1866 - accuracy: 0.946 - ETA: 9s - loss: 0.1870 - accuracy: 0.946 - ETA: 8s - loss: 0.1877 - accuracy: 0.94 - ETA: 6s - loss: 0.1869 - accuracy: 0.94 - ETA: 4s - loss: 0.1869 - accuracy: 0.94 - ETA: 2s - loss: 0.1855 - accuracy: 0.94 - ETA: 1s - loss: 0.1849 - accuracy: 0.94 - 198s 15ms/step - loss: 0.1842 - accuracy: 0.9480 - val_loss: 2.7885 - val_accuracy: 0.3897\n",
      "Epoch 18/100\n",
      "13022/13022 [==============================] - ETA: 2:42 - loss: 0.1019 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1818 - accuracy: 0.94 - ETA: 2:41 - loss: 0.1487 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1351 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1604 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1548 - accuracy: 0.95 - ETA: 2:39 - loss: 0.1519 - accuracy: 0.95 - ETA: 2:38 - loss: 0.1532 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1595 - accuracy: 0.94 - ETA: 2:35 - loss: 0.1554 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1603 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1708 - accuracy: 0.95 - ETA: 2:30 - loss: 0.1764 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1742 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1769 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1773 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1756 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1758 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1716 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1696 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1664 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1652 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1636 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1633 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1632 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1704 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1725 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1716 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1707 - accuracy: 0.95 - ETA: 2:02 - loss: 0.1697 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1729 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1735 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1716 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1684 - accuracy: 0.95 - ETA: 1:53 - loss: 0.1675 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1717 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1736 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1719 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1697 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1709 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1734 - accuracy: 0.95 - ETA: 1:41 - loss: 0.1730 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1709 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1713 - accuracy: 0.95 - ETA: 1:36 - loss: 0.1735 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1714 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1699 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1702 - accuracy: 0.95 - ETA: 1:29 - loss: 0.1701 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1697 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1704 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1704 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1687 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1683 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1676 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1676 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1671 - accuracy: 0.95 - ETA: 1:14 - loss: 0.1673 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1690 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1674 - accuracy: 0.95 - ETA: 1:09 - loss: 0.1674 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1676 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1666 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1665 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1654 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1650 - accuracy: 0.95 - ETA: 59s - loss: 0.1683 - accuracy: 0.9524 - ETA: 57s - loss: 0.1725 - accuracy: 0.951 - ETA: 55s - loss: 0.1722 - accuracy: 0.951 - ETA: 54s - loss: 0.1717 - accuracy: 0.951 - ETA: 52s - loss: 0.1718 - accuracy: 0.951 - ETA: 50s - loss: 0.1706 - accuracy: 0.951 - ETA: 48s - loss: 0.1718 - accuracy: 0.950 - ETA: 47s - loss: 0.1717 - accuracy: 0.950 - ETA: 45s - loss: 0.1725 - accuracy: 0.950 - ETA: 43s - loss: 0.1736 - accuracy: 0.951 - ETA: 42s - loss: 0.1732 - accuracy: 0.951 - ETA: 40s - loss: 0.1739 - accuracy: 0.951 - ETA: 38s - loss: 0.1726 - accuracy: 0.951 - ETA: 36s - loss: 0.1733 - accuracy: 0.951 - ETA: 35s - loss: 0.1749 - accuracy: 0.951 - ETA: 33s - loss: 0.1748 - accuracy: 0.951 - ETA: 31s - loss: 0.1739 - accuracy: 0.951 - ETA: 30s - loss: 0.1729 - accuracy: 0.952 - ETA: 28s - loss: 0.1729 - accuracy: 0.951 - ETA: 26s - loss: 0.1741 - accuracy: 0.951 - ETA: 25s - loss: 0.1726 - accuracy: 0.952 - ETA: 23s - loss: 0.1728 - accuracy: 0.952 - ETA: 21s - loss: 0.1731 - accuracy: 0.952 - ETA: 19s - loss: 0.1735 - accuracy: 0.951 - ETA: 18s - loss: 0.1735 - accuracy: 0.951 - ETA: 16s - loss: 0.1762 - accuracy: 0.951 - ETA: 14s - loss: 0.1753 - accuracy: 0.951 - ETA: 13s - loss: 0.1748 - accuracy: 0.951 - ETA: 11s - loss: 0.1747 - accuracy: 0.951 - ETA: 9s - loss: 0.1759 - accuracy: 0.951 - ETA: 8s - loss: 0.1750 - accuracy: 0.95 - ETA: 6s - loss: 0.1747 - accuracy: 0.95 - ETA: 4s - loss: 0.1752 - accuracy: 0.95 - ETA: 2s - loss: 0.1747 - accuracy: 0.95 - ETA: 1s - loss: 0.1756 - accuracy: 0.95 - 198s 15ms/step - loss: 0.1759 - accuracy: 0.9518 - val_loss: 3.0540 - val_accuracy: 0.3712\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:49 - loss: 0.1012 - accuracy: 0.97 - ETA: 2:50 - loss: 0.2606 - accuracy: 0.94 - ETA: 2:45 - loss: 0.2234 - accuracy: 0.95 - ETA: 2:43 - loss: 0.2321 - accuracy: 0.94 - ETA: 2:45 - loss: 0.2089 - accuracy: 0.95 - ETA: 2:43 - loss: 0.2103 - accuracy: 0.94 - ETA: 2:40 - loss: 0.2007 - accuracy: 0.94 - ETA: 2:38 - loss: 0.1983 - accuracy: 0.94 - ETA: 2:37 - loss: 0.1891 - accuracy: 0.94 - ETA: 2:34 - loss: 0.1860 - accuracy: 0.94 - ETA: 2:32 - loss: 0.1853 - accuracy: 0.94 - ETA: 2:30 - loss: 0.1772 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1788 - accuracy: 0.95 - ETA: 2:28 - loss: 0.1751 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1690 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1637 - accuracy: 0.95 - ETA: 2:22 - loss: 0.1616 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1755 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1729 - accuracy: 0.95 - ETA: 2:19 - loss: 0.1717 - accuracy: 0.95 - ETA: 2:17 - loss: 0.1821 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1791 - accuracy: 0.95 - ETA: 2:14 - loss: 0.1782 - accuracy: 0.95 - ETA: 2:12 - loss: 0.1756 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1726 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1705 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1709 - accuracy: 0.95 - ETA: 2:06 - loss: 0.1686 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1663 - accuracy: 0.95 - ETA: 2:02 - loss: 0.1676 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1649 - accuracy: 0.95 - ETA: 1:58 - loss: 0.1686 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1687 - accuracy: 0.95 - ETA: 1:55 - loss: 0.1673 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1722 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1714 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1687 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1702 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1717 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1702 - accuracy: 0.95 - ETA: 1:43 - loss: 0.1681 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1684 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1673 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1656 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1644 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1667 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1688 - accuracy: 0.95 - ETA: 1:31 - loss: 0.1695 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1707 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1688 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1676 - accuracy: 0.95 - ETA: 1:24 - loss: 0.1661 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1656 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1636 - accuracy: 0.95 - ETA: 1:19 - loss: 0.1624 - accuracy: 0.95 - ETA: 1:17 - loss: 0.1614 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1605 - accuracy: 0.95 - ETA: 1:14 - loss: 0.1591 - accuracy: 0.95 - ETA: 1:12 - loss: 0.1604 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1585 - accuracy: 0.95 - ETA: 1:09 - loss: 0.1637 - accuracy: 0.95 - ETA: 1:07 - loss: 0.1657 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1665 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1675 - accuracy: 0.95 - ETA: 1:02 - loss: 0.1673 - accuracy: 0.95 - ETA: 1:00 - loss: 0.1685 - accuracy: 0.95 - ETA: 59s - loss: 0.1680 - accuracy: 0.9532 - ETA: 57s - loss: 0.1692 - accuracy: 0.952 - ETA: 55s - loss: 0.1690 - accuracy: 0.952 - ETA: 54s - loss: 0.1686 - accuracy: 0.953 - ETA: 52s - loss: 0.1686 - accuracy: 0.953 - ETA: 50s - loss: 0.1696 - accuracy: 0.953 - ETA: 48s - loss: 0.1701 - accuracy: 0.953 - ETA: 47s - loss: 0.1700 - accuracy: 0.953 - ETA: 45s - loss: 0.1691 - accuracy: 0.953 - ETA: 43s - loss: 0.1690 - accuracy: 0.953 - ETA: 42s - loss: 0.1686 - accuracy: 0.953 - ETA: 40s - loss: 0.1684 - accuracy: 0.952 - ETA: 38s - loss: 0.1685 - accuracy: 0.952 - ETA: 36s - loss: 0.1698 - accuracy: 0.952 - ETA: 35s - loss: 0.1695 - accuracy: 0.952 - ETA: 33s - loss: 0.1704 - accuracy: 0.952 - ETA: 31s - loss: 0.1699 - accuracy: 0.952 - ETA: 30s - loss: 0.1691 - accuracy: 0.952 - ETA: 28s - loss: 0.1695 - accuracy: 0.952 - ETA: 26s - loss: 0.1688 - accuracy: 0.952 - ETA: 25s - loss: 0.1695 - accuracy: 0.952 - ETA: 23s - loss: 0.1699 - accuracy: 0.952 - ETA: 21s - loss: 0.1693 - accuracy: 0.952 - ETA: 20s - loss: 0.1688 - accuracy: 0.952 - ETA: 18s - loss: 0.1688 - accuracy: 0.952 - ETA: 16s - loss: 0.1685 - accuracy: 0.953 - ETA: 14s - loss: 0.1684 - accuracy: 0.953 - ETA: 13s - loss: 0.1679 - accuracy: 0.953 - ETA: 11s - loss: 0.1673 - accuracy: 0.953 - ETA: 9s - loss: 0.1684 - accuracy: 0.953 - ETA: 8s - loss: 0.1682 - accuracy: 0.95 - ETA: 6s - loss: 0.1680 - accuracy: 0.95 - ETA: 4s - loss: 0.1670 - accuracy: 0.95 - ETA: 2s - loss: 0.1677 - accuracy: 0.95 - ETA: 1s - loss: 0.1672 - accuracy: 0.95 - 197s 15ms/step - loss: 0.1669 - accuracy: 0.9538 - val_loss: 3.0265 - val_accuracy: 0.3861\n",
      "Epoch 20/100\n",
      "13022/13022 [==============================] - ETA: 2:53 - loss: 0.1475 - accuracy: 0.94 - ETA: 2:58 - loss: 0.1614 - accuracy: 0.94 - ETA: 2:55 - loss: 0.1646 - accuracy: 0.95 - ETA: 2:52 - loss: 0.1472 - accuracy: 0.95 - ETA: 2:49 - loss: 0.1445 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1412 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1457 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1325 - accuracy: 0.95 - ETA: 2:38 - loss: 0.1418 - accuracy: 0.95 - ETA: 2:36 - loss: 0.1505 - accuracy: 0.95 - ETA: 2:34 - loss: 0.1459 - accuracy: 0.95 - ETA: 2:33 - loss: 0.1470 - accuracy: 0.95 - ETA: 2:31 - loss: 0.1424 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1404 - accuracy: 0.95 - ETA: 2:27 - loss: 0.1431 - accuracy: 0.95 - ETA: 2:26 - loss: 0.1414 - accuracy: 0.95 - ETA: 2:24 - loss: 0.1495 - accuracy: 0.95 - ETA: 2:23 - loss: 0.1471 - accuracy: 0.95 - ETA: 2:21 - loss: 0.1435 - accuracy: 0.95 - ETA: 2:20 - loss: 0.1401 - accuracy: 0.95 - ETA: 2:18 - loss: 0.1425 - accuracy: 0.95 - ETA: 2:16 - loss: 0.1415 - accuracy: 0.95 - ETA: 2:15 - loss: 0.1423 - accuracy: 0.95 - ETA: 2:13 - loss: 0.1439 - accuracy: 0.95 - ETA: 2:11 - loss: 0.1442 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1417 - accuracy: 0.95 - ETA: 2:07 - loss: 0.1437 - accuracy: 0.95 - ETA: 2:05 - loss: 0.1467 - accuracy: 0.95 - ETA: 2:04 - loss: 0.1471 - accuracy: 0.95 - ETA: 2:02 - loss: 0.1451 - accuracy: 0.95 - ETA: 2:00 - loss: 0.1453 - accuracy: 0.95 - ETA: 1:59 - loss: 0.1438 - accuracy: 0.95 - ETA: 1:57 - loss: 0.1409 - accuracy: 0.95 - ETA: 1:56 - loss: 0.1443 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1423 - accuracy: 0.95 - ETA: 1:52 - loss: 0.1431 - accuracy: 0.95 - ETA: 1:50 - loss: 0.1435 - accuracy: 0.95 - ETA: 1:49 - loss: 0.1489 - accuracy: 0.95 - ETA: 1:47 - loss: 0.1490 - accuracy: 0.95 - ETA: 1:45 - loss: 0.1480 - accuracy: 0.95 - ETA: 1:44 - loss: 0.1463 - accuracy: 0.95 - ETA: 1:42 - loss: 0.1466 - accuracy: 0.95 - ETA: 1:40 - loss: 0.1477 - accuracy: 0.95 - ETA: 1:38 - loss: 0.1462 - accuracy: 0.95 - ETA: 1:37 - loss: 0.1486 - accuracy: 0.95 - ETA: 1:35 - loss: 0.1476 - accuracy: 0.95 - ETA: 1:33 - loss: 0.1458 - accuracy: 0.95 - ETA: 1:32 - loss: 0.1468 - accuracy: 0.95 - ETA: 1:30 - loss: 0.1473 - accuracy: 0.95 - ETA: 1:28 - loss: 0.1461 - accuracy: 0.95 - ETA: 1:26 - loss: 0.1453 - accuracy: 0.95 - ETA: 1:25 - loss: 0.1438 - accuracy: 0.95 - ETA: 1:23 - loss: 0.1432 - accuracy: 0.95 - ETA: 1:21 - loss: 0.1446 - accuracy: 0.95 - ETA: 1:20 - loss: 0.1445 - accuracy: 0.95 - ETA: 1:18 - loss: 0.1448 - accuracy: 0.95 - ETA: 1:16 - loss: 0.1440 - accuracy: 0.95 - ETA: 1:15 - loss: 0.1439 - accuracy: 0.95 - ETA: 1:13 - loss: 0.1427 - accuracy: 0.95 - ETA: 1:11 - loss: 0.1429 - accuracy: 0.95 - ETA: 1:09 - loss: 0.1434 - accuracy: 0.95 - ETA: 1:08 - loss: 0.1420 - accuracy: 0.95 - ETA: 1:06 - loss: 0.1414 - accuracy: 0.95 - ETA: 1:04 - loss: 0.1424 - accuracy: 0.95 - ETA: 1:03 - loss: 0.1422 - accuracy: 0.95 - ETA: 1:01 - loss: 0.1429 - accuracy: 0.95 - ETA: 59s - loss: 0.1426 - accuracy: 0.9584 - ETA: 58s - loss: 0.1430 - accuracy: 0.958 - ETA: 56s - loss: 0.1429 - accuracy: 0.958 - ETA: 54s - loss: 0.1425 - accuracy: 0.958 - ETA: 52s - loss: 0.1427 - accuracy: 0.958 - ETA: 51s - loss: 0.1435 - accuracy: 0.958 - ETA: 49s - loss: 0.1423 - accuracy: 0.958 - ETA: 47s - loss: 0.1425 - accuracy: 0.958 - ETA: 45s - loss: 0.1426 - accuracy: 0.958 - ETA: 44s - loss: 0.1418 - accuracy: 0.958 - ETA: 42s - loss: 0.1413 - accuracy: 0.958 - ETA: 40s - loss: 0.1405 - accuracy: 0.958 - ETA: 39s - loss: 0.1395 - accuracy: 0.959 - ETA: 37s - loss: 0.1400 - accuracy: 0.959 - ETA: 35s - loss: 0.1414 - accuracy: 0.958 - ETA: 34s - loss: 0.1407 - accuracy: 0.958 - ETA: 32s - loss: 0.1403 - accuracy: 0.959 - ETA: 30s - loss: 0.1403 - accuracy: 0.959 - ETA: 28s - loss: 0.1434 - accuracy: 0.958 - ETA: 27s - loss: 0.1437 - accuracy: 0.958 - ETA: 25s - loss: 0.1446 - accuracy: 0.958 - ETA: 23s - loss: 0.1451 - accuracy: 0.958 - ETA: 21s - loss: 0.1448 - accuracy: 0.958 - ETA: 20s - loss: 0.1454 - accuracy: 0.958 - ETA: 18s - loss: 0.1453 - accuracy: 0.958 - ETA: 16s - loss: 0.1448 - accuracy: 0.958 - ETA: 15s - loss: 0.1452 - accuracy: 0.958 - ETA: 13s - loss: 0.1443 - accuracy: 0.958 - ETA: 11s - loss: 0.1438 - accuracy: 0.958 - ETA: 9s - loss: 0.1439 - accuracy: 0.958 - ETA: 8s - loss: 0.1443 - accuracy: 0.95 - ETA: 6s - loss: 0.1434 - accuracy: 0.95 - ETA: 4s - loss: 0.1430 - accuracy: 0.95 - ETA: 2s - loss: 0.1428 - accuracy: 0.95 - ETA: 1s - loss: 0.1429 - accuracy: 0.95 - 199s 15ms/step - loss: 0.1428 - accuracy: 0.9594 - val_loss: 2.8107 - val_accuracy: 0.4320\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:43 - loss: 0.1379 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1414 - accuracy: 0.95 - ETA: 2:43 - loss: 0.1571 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1407 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1355 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1395 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1257 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1216 - accuracy: 0.97 - ETA: 2:33 - loss: 0.1218 - accuracy: 0.97 - ETA: 2:33 - loss: 0.1220 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1189 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1245 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1195 - accuracy: 0.97 - ETA: 2:25 - loss: 0.1138 - accuracy: 0.97 - ETA: 2:24 - loss: 0.1128 - accuracy: 0.97 - ETA: 2:23 - loss: 0.1210 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1210 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1215 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1210 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1215 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1184 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1177 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1167 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1225 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1197 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1214 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1296 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1264 - accuracy: 0.96 - ETA: 2:03 - loss: 0.1266 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1236 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1235 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1237 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1267 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1276 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1265 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1273 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1264 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1266 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1277 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1308 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1292 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1336 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1354 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1341 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1341 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1341 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1392 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1382 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1382 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1366 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1375 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1360 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1351 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1362 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1360 - accuracy: 0.96 - ETA: 1:18 - loss: 0.1371 - accuracy: 0.96 - ETA: 1:16 - loss: 0.1361 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1362 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1359 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1350 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1345 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1356 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1365 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1357 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1355 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1375 - accuracy: 0.96 - ETA: 59s - loss: 0.1380 - accuracy: 0.9608 - ETA: 58s - loss: 0.1397 - accuracy: 0.960 - ETA: 56s - loss: 0.1400 - accuracy: 0.960 - ETA: 54s - loss: 0.1413 - accuracy: 0.959 - ETA: 52s - loss: 0.1400 - accuracy: 0.959 - ETA: 51s - loss: 0.1417 - accuracy: 0.959 - ETA: 49s - loss: 0.1415 - accuracy: 0.959 - ETA: 47s - loss: 0.1434 - accuracy: 0.959 - ETA: 46s - loss: 0.1443 - accuracy: 0.959 - ETA: 44s - loss: 0.1453 - accuracy: 0.959 - ETA: 42s - loss: 0.1447 - accuracy: 0.959 - ETA: 40s - loss: 0.1448 - accuracy: 0.959 - ETA: 39s - loss: 0.1441 - accuracy: 0.959 - ETA: 37s - loss: 0.1437 - accuracy: 0.959 - ETA: 35s - loss: 0.1443 - accuracy: 0.959 - ETA: 33s - loss: 0.1439 - accuracy: 0.960 - ETA: 32s - loss: 0.1441 - accuracy: 0.959 - ETA: 30s - loss: 0.1451 - accuracy: 0.959 - ETA: 28s - loss: 0.1464 - accuracy: 0.959 - ETA: 27s - loss: 0.1477 - accuracy: 0.958 - ETA: 25s - loss: 0.1474 - accuracy: 0.959 - ETA: 23s - loss: 0.1470 - accuracy: 0.959 - ETA: 21s - loss: 0.1467 - accuracy: 0.959 - ETA: 20s - loss: 0.1458 - accuracy: 0.959 - ETA: 18s - loss: 0.1459 - accuracy: 0.959 - ETA: 16s - loss: 0.1462 - accuracy: 0.959 - ETA: 15s - loss: 0.1465 - accuracy: 0.959 - ETA: 13s - loss: 0.1467 - accuracy: 0.959 - ETA: 11s - loss: 0.1458 - accuracy: 0.959 - ETA: 9s - loss: 0.1457 - accuracy: 0.959 - ETA: 8s - loss: 0.1452 - accuracy: 0.95 - ETA: 6s - loss: 0.1457 - accuracy: 0.95 - ETA: 4s - loss: 0.1459 - accuracy: 0.95 - ETA: 2s - loss: 0.1453 - accuracy: 0.95 - ETA: 1s - loss: 0.1460 - accuracy: 0.95 - 201s 15ms/step - loss: 0.1457 - accuracy: 0.9594 - val_loss: 3.1259 - val_accuracy: 0.3759\n",
      "Epoch 22/100\n",
      "13022/13022 [==============================] - ETA: 3:01 - loss: 0.1097 - accuracy: 0.96 - ETA: 2:58 - loss: 0.1352 - accuracy: 0.96 - ETA: 2:53 - loss: 0.1766 - accuracy: 0.96 - ETA: 2:50 - loss: 0.1961 - accuracy: 0.95 - ETA: 2:47 - loss: 0.1900 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1881 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1728 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1671 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1552 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1526 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1503 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1417 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1372 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1323 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1340 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1369 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1465 - accuracy: 0.96 - ETA: 2:24 - loss: 0.1449 - accuracy: 0.96 - ETA: 2:22 - loss: 0.1459 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1451 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1461 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1432 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1456 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1457 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1449 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1416 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1400 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1386 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1400 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1385 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1374 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1368 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1347 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1359 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1340 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1349 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1349 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1348 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1345 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1341 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1343 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1341 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1341 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1352 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1335 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1335 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1351 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1337 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1330 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1326 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1329 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1329 - accuracy: 0.96 - ETA: 1:20 - loss: 0.1330 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1345 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1340 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1370 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1377 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1378 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1402 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1387 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1378 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1380 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1393 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1387 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1374 - accuracy: 0.96 - ETA: 59s - loss: 0.1373 - accuracy: 0.9631 - ETA: 58s - loss: 0.1363 - accuracy: 0.963 - ETA: 56s - loss: 0.1363 - accuracy: 0.963 - ETA: 55s - loss: 0.1373 - accuracy: 0.963 - ETA: 53s - loss: 0.1373 - accuracy: 0.963 - ETA: 52s - loss: 0.1369 - accuracy: 0.963 - ETA: 50s - loss: 0.1367 - accuracy: 0.963 - ETA: 48s - loss: 0.1375 - accuracy: 0.963 - ETA: 47s - loss: 0.1368 - accuracy: 0.963 - ETA: 45s - loss: 0.1367 - accuracy: 0.962 - ETA: 44s - loss: 0.1359 - accuracy: 0.962 - ETA: 42s - loss: 0.1360 - accuracy: 0.962 - ETA: 40s - loss: 0.1365 - accuracy: 0.962 - ETA: 39s - loss: 0.1368 - accuracy: 0.962 - ETA: 37s - loss: 0.1370 - accuracy: 0.962 - ETA: 35s - loss: 0.1364 - accuracy: 0.962 - ETA: 34s - loss: 0.1376 - accuracy: 0.962 - ETA: 32s - loss: 0.1365 - accuracy: 0.962 - ETA: 30s - loss: 0.1355 - accuracy: 0.962 - ETA: 29s - loss: 0.1363 - accuracy: 0.962 - ETA: 27s - loss: 0.1363 - accuracy: 0.962 - ETA: 25s - loss: 0.1353 - accuracy: 0.962 - ETA: 23s - loss: 0.1347 - accuracy: 0.963 - ETA: 22s - loss: 0.1344 - accuracy: 0.963 - ETA: 20s - loss: 0.1352 - accuracy: 0.963 - ETA: 18s - loss: 0.1351 - accuracy: 0.963 - ETA: 17s - loss: 0.1347 - accuracy: 0.963 - ETA: 15s - loss: 0.1349 - accuracy: 0.963 - ETA: 13s - loss: 0.1351 - accuracy: 0.963 - ETA: 11s - loss: 0.1354 - accuracy: 0.963 - ETA: 10s - loss: 0.1363 - accuracy: 0.963 - ETA: 8s - loss: 0.1372 - accuracy: 0.963 - ETA: 6s - loss: 0.1383 - accuracy: 0.96 - ETA: 4s - loss: 0.1381 - accuracy: 0.96 - ETA: 3s - loss: 0.1378 - accuracy: 0.96 - ETA: 1s - loss: 0.1382 - accuracy: 0.96 - 211s 16ms/step - loss: 0.1387 - accuracy: 0.9628 - val_loss: 2.8560 - val_accuracy: 0.4121\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 3:13 - loss: 0.1083 - accuracy: 0.96 - ETA: 3:14 - loss: 0.1174 - accuracy: 0.97 - ETA: 3:13 - loss: 0.1116 - accuracy: 0.96 - ETA: 3:12 - loss: 0.1278 - accuracy: 0.95 - ETA: 3:13 - loss: 0.1393 - accuracy: 0.95 - ETA: 3:17 - loss: 0.1489 - accuracy: 0.95 - ETA: 3:18 - loss: 0.1509 - accuracy: 0.95 - ETA: 3:19 - loss: 0.1430 - accuracy: 0.96 - ETA: 3:15 - loss: 0.1443 - accuracy: 0.95 - ETA: 3:11 - loss: 0.1377 - accuracy: 0.96 - ETA: 3:08 - loss: 0.1370 - accuracy: 0.96 - ETA: 3:05 - loss: 0.1365 - accuracy: 0.96 - ETA: 3:03 - loss: 0.1368 - accuracy: 0.96 - ETA: 3:00 - loss: 0.1459 - accuracy: 0.95 - ETA: 2:58 - loss: 0.1469 - accuracy: 0.95 - ETA: 2:55 - loss: 0.1504 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1459 - accuracy: 0.95 - ETA: 2:50 - loss: 0.1516 - accuracy: 0.95 - ETA: 2:48 - loss: 0.1540 - accuracy: 0.96 - ETA: 2:46 - loss: 0.1519 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1511 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1502 - accuracy: 0.96 - ETA: 2:38 - loss: 0.1485 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1453 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1449 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1444 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1411 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1396 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1380 - accuracy: 0.96 - ETA: 2:20 - loss: 0.1378 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1383 - accuracy: 0.96 - ETA: 2:15 - loss: 0.1411 - accuracy: 0.96 - ETA: 2:13 - loss: 0.1431 - accuracy: 0.96 - ETA: 2:10 - loss: 0.1416 - accuracy: 0.96 - ETA: 2:08 - loss: 0.1417 - accuracy: 0.96 - ETA: 2:06 - loss: 0.1396 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1385 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1365 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1354 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1360 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1369 - accuracy: 0.96 - ETA: 1:55 - loss: 0.1378 - accuracy: 0.96 - ETA: 1:53 - loss: 0.1377 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1366 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1378 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1374 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1390 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1386 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1426 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1430 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1450 - accuracy: 0.96 - ETA: 1:36 - loss: 0.1444 - accuracy: 0.96 - ETA: 1:34 - loss: 0.1432 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1428 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1430 - accuracy: 0.96 - ETA: 1:29 - loss: 0.1415 - accuracy: 0.96 - ETA: 1:27 - loss: 0.1442 - accuracy: 0.96 - ETA: 1:25 - loss: 0.1442 - accuracy: 0.96 - ETA: 1:23 - loss: 0.1435 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1432 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1423 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1419 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1416 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1408 - accuracy: 0.96 - ETA: 1:11 - loss: 0.1399 - accuracy: 0.96 - ETA: 1:09 - loss: 0.1419 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1415 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1410 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1407 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1403 - accuracy: 0.96 - ETA: 59s - loss: 0.1407 - accuracy: 0.9615 - ETA: 57s - loss: 0.1407 - accuracy: 0.961 - ETA: 55s - loss: 0.1416 - accuracy: 0.960 - ETA: 53s - loss: 0.1415 - accuracy: 0.960 - ETA: 51s - loss: 0.1409 - accuracy: 0.961 - ETA: 49s - loss: 0.1409 - accuracy: 0.961 - ETA: 47s - loss: 0.1398 - accuracy: 0.961 - ETA: 45s - loss: 0.1391 - accuracy: 0.961 - ETA: 43s - loss: 0.1387 - accuracy: 0.961 - ETA: 41s - loss: 0.1388 - accuracy: 0.961 - ETA: 39s - loss: 0.1389 - accuracy: 0.961 - ETA: 38s - loss: 0.1392 - accuracy: 0.961 - ETA: 36s - loss: 0.1393 - accuracy: 0.961 - ETA: 34s - loss: 0.1389 - accuracy: 0.961 - ETA: 32s - loss: 0.1397 - accuracy: 0.961 - ETA: 30s - loss: 0.1393 - accuracy: 0.961 - ETA: 28s - loss: 0.1395 - accuracy: 0.960 - ETA: 26s - loss: 0.1388 - accuracy: 0.960 - ETA: 24s - loss: 0.1384 - accuracy: 0.960 - ETA: 22s - loss: 0.1386 - accuracy: 0.960 - ETA: 20s - loss: 0.1379 - accuracy: 0.961 - ETA: 18s - loss: 0.1384 - accuracy: 0.961 - ETA: 16s - loss: 0.1381 - accuracy: 0.961 - ETA: 14s - loss: 0.1373 - accuracy: 0.961 - ETA: 12s - loss: 0.1362 - accuracy: 0.961 - ETA: 10s - loss: 0.1362 - accuracy: 0.961 - ETA: 9s - loss: 0.1356 - accuracy: 0.962 - ETA: 7s - loss: 0.1357 - accuracy: 0.96 - ETA: 5s - loss: 0.1365 - accuracy: 0.96 - ETA: 3s - loss: 0.1366 - accuracy: 0.96 - ETA: 1s - loss: 0.1365 - accuracy: 0.96 - 219s 17ms/step - loss: 0.1363 - accuracy: 0.9623 - val_loss: 3.2004 - val_accuracy: 0.3915\n",
      "Epoch 24/100\n",
      "13022/13022 [==============================] - ETA: 2:51 - loss: 0.1595 - accuracy: 0.95 - ETA: 2:48 - loss: 0.2253 - accuracy: 0.94 - ETA: 2:50 - loss: 0.2030 - accuracy: 0.95 - ETA: 2:50 - loss: 0.1806 - accuracy: 0.95 - ETA: 2:47 - loss: 0.1864 - accuracy: 0.95 - ETA: 2:44 - loss: 0.1823 - accuracy: 0.95 - ETA: 2:44 - loss: 0.1862 - accuracy: 0.95 - ETA: 2:42 - loss: 0.1800 - accuracy: 0.95 - ETA: 2:41 - loss: 0.1627 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1664 - accuracy: 0.95 - ETA: 2:40 - loss: 0.1628 - accuracy: 0.95 - ETA: 2:38 - loss: 0.1570 - accuracy: 0.95 - ETA: 2:37 - loss: 0.1497 - accuracy: 0.95 - ETA: 2:35 - loss: 0.1488 - accuracy: 0.95 - ETA: 2:34 - loss: 0.1458 - accuracy: 0.95 - ETA: 2:32 - loss: 0.1402 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1351 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1343 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1337 - accuracy: 0.96 - ETA: 2:26 - loss: 0.1352 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1346 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1308 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1290 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1276 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1352 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1320 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1324 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1338 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1327 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1314 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1296 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1305 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1299 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1329 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1320 - accuracy: 0.96 - ETA: 1:58 - loss: 0.1348 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1344 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1350 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1372 - accuracy: 0.96 - ETA: 1:50 - loss: 0.1357 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1356 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1337 - accuracy: 0.96 - ETA: 1:44 - loss: 0.1352 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1369 - accuracy: 0.96 - ETA: 1:41 - loss: 0.1356 - accuracy: 0.96 - ETA: 1:39 - loss: 0.1346 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1342 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1340 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1324 - accuracy: 0.96 - ETA: 1:32 - loss: 0.1318 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1321 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1314 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1329 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1319 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1305 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1317 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1317 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1311 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1302 - accuracy: 0.96 - ETA: 1:13 - loss: 0.1289 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1288 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1273 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1268 - accuracy: 0.96 - ETA: 1:06 - loss: 0.1272 - accuracy: 0.96 - ETA: 1:04 - loss: 0.1265 - accuracy: 0.96 - ETA: 1:02 - loss: 0.1271 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1264 - accuracy: 0.96 - ETA: 59s - loss: 0.1254 - accuracy: 0.9656 - ETA: 57s - loss: 0.1248 - accuracy: 0.965 - ETA: 55s - loss: 0.1241 - accuracy: 0.966 - ETA: 54s - loss: 0.1230 - accuracy: 0.966 - ETA: 52s - loss: 0.1244 - accuracy: 0.965 - ETA: 50s - loss: 0.1239 - accuracy: 0.965 - ETA: 48s - loss: 0.1234 - accuracy: 0.965 - ETA: 46s - loss: 0.1223 - accuracy: 0.966 - ETA: 45s - loss: 0.1233 - accuracy: 0.966 - ETA: 43s - loss: 0.1240 - accuracy: 0.966 - ETA: 41s - loss: 0.1242 - accuracy: 0.966 - ETA: 39s - loss: 0.1234 - accuracy: 0.966 - ETA: 38s - loss: 0.1231 - accuracy: 0.966 - ETA: 36s - loss: 0.1230 - accuracy: 0.966 - ETA: 34s - loss: 0.1234 - accuracy: 0.966 - ETA: 32s - loss: 0.1233 - accuracy: 0.965 - ETA: 31s - loss: 0.1230 - accuracy: 0.966 - ETA: 29s - loss: 0.1234 - accuracy: 0.966 - ETA: 27s - loss: 0.1230 - accuracy: 0.966 - ETA: 25s - loss: 0.1235 - accuracy: 0.966 - ETA: 24s - loss: 0.1225 - accuracy: 0.966 - ETA: 22s - loss: 0.1215 - accuracy: 0.966 - ETA: 20s - loss: 0.1215 - accuracy: 0.966 - ETA: 18s - loss: 0.1219 - accuracy: 0.966 - ETA: 17s - loss: 0.1212 - accuracy: 0.966 - ETA: 15s - loss: 0.1213 - accuracy: 0.966 - ETA: 13s - loss: 0.1216 - accuracy: 0.966 - ETA: 11s - loss: 0.1209 - accuracy: 0.966 - ETA: 10s - loss: 0.1206 - accuracy: 0.966 - ETA: 8s - loss: 0.1201 - accuracy: 0.967 - ETA: 6s - loss: 0.1200 - accuracy: 0.96 - ETA: 4s - loss: 0.1205 - accuracy: 0.96 - ETA: 3s - loss: 0.1196 - accuracy: 0.96 - ETA: 1s - loss: 0.1195 - accuracy: 0.96 - 202s 16ms/step - loss: 0.1205 - accuracy: 0.9665 - val_loss: 2.9136 - val_accuracy: 0.4090\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:55 - loss: 0.0483 - accuracy: 0.99 - ETA: 2:50 - loss: 0.0648 - accuracy: 0.97 - ETA: 2:51 - loss: 0.0776 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0676 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:43 - loss: 0.0797 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0758 - accuracy: 0.97 - ETA: 2:41 - loss: 0.0726 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0903 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0848 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0896 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0904 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0912 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0981 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0944 - accuracy: 0.97 - ETA: 2:26 - loss: 0.0950 - accuracy: 0.97 - ETA: 2:25 - loss: 0.1046 - accuracy: 0.97 - ETA: 2:23 - loss: 0.1046 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1018 - accuracy: 0.97 - ETA: 2:19 - loss: 0.1028 - accuracy: 0.97 - ETA: 2:18 - loss: 0.1010 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0980 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0962 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0982 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0990 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0986 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0974 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0994 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0997 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0991 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0974 - accuracy: 0.97 - ETA: 1:58 - loss: 0.1012 - accuracy: 0.97 - ETA: 1:56 - loss: 0.1020 - accuracy: 0.97 - ETA: 1:55 - loss: 0.1009 - accuracy: 0.97 - ETA: 1:53 - loss: 0.1021 - accuracy: 0.97 - ETA: 1:51 - loss: 0.1038 - accuracy: 0.97 - ETA: 1:50 - loss: 0.1035 - accuracy: 0.97 - ETA: 1:48 - loss: 0.1022 - accuracy: 0.97 - ETA: 1:46 - loss: 0.1030 - accuracy: 0.97 - ETA: 1:45 - loss: 0.1034 - accuracy: 0.97 - ETA: 1:43 - loss: 0.1026 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1022 - accuracy: 0.97 - ETA: 1:39 - loss: 0.1019 - accuracy: 0.97 - ETA: 1:38 - loss: 0.1012 - accuracy: 0.97 - ETA: 1:36 - loss: 0.1006 - accuracy: 0.97 - ETA: 1:35 - loss: 0.1020 - accuracy: 0.97 - ETA: 1:33 - loss: 0.1022 - accuracy: 0.97 - ETA: 1:31 - loss: 0.1029 - accuracy: 0.97 - ETA: 1:29 - loss: 0.1062 - accuracy: 0.97 - ETA: 1:28 - loss: 0.1052 - accuracy: 0.97 - ETA: 1:26 - loss: 0.1055 - accuracy: 0.97 - ETA: 1:24 - loss: 0.1051 - accuracy: 0.97 - ETA: 1:23 - loss: 0.1048 - accuracy: 0.97 - ETA: 1:21 - loss: 0.1039 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1027 - accuracy: 0.97 - ETA: 1:18 - loss: 0.1026 - accuracy: 0.97 - ETA: 1:16 - loss: 0.1020 - accuracy: 0.97 - ETA: 1:14 - loss: 0.1019 - accuracy: 0.97 - ETA: 1:12 - loss: 0.1011 - accuracy: 0.97 - ETA: 1:11 - loss: 0.1010 - accuracy: 0.97 - ETA: 1:09 - loss: 0.1017 - accuracy: 0.97 - ETA: 1:07 - loss: 0.1015 - accuracy: 0.97 - ETA: 1:06 - loss: 0.1003 - accuracy: 0.97 - ETA: 1:04 - loss: 0.1002 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0999 - accuracy: 0.97 - ETA: 1:01 - loss: 0.1013 - accuracy: 0.97 - ETA: 59s - loss: 0.1015 - accuracy: 0.9727 - ETA: 57s - loss: 0.1006 - accuracy: 0.972 - ETA: 55s - loss: 0.1006 - accuracy: 0.972 - ETA: 54s - loss: 0.0999 - accuracy: 0.972 - ETA: 52s - loss: 0.0996 - accuracy: 0.972 - ETA: 50s - loss: 0.1013 - accuracy: 0.972 - ETA: 49s - loss: 0.1024 - accuracy: 0.972 - ETA: 47s - loss: 0.1024 - accuracy: 0.972 - ETA: 45s - loss: 0.1042 - accuracy: 0.972 - ETA: 44s - loss: 0.1044 - accuracy: 0.971 - ETA: 42s - loss: 0.1050 - accuracy: 0.971 - ETA: 40s - loss: 0.1046 - accuracy: 0.971 - ETA: 38s - loss: 0.1039 - accuracy: 0.972 - ETA: 37s - loss: 0.1058 - accuracy: 0.971 - ETA: 35s - loss: 0.1060 - accuracy: 0.971 - ETA: 33s - loss: 0.1054 - accuracy: 0.971 - ETA: 32s - loss: 0.1078 - accuracy: 0.971 - ETA: 30s - loss: 0.1071 - accuracy: 0.971 - ETA: 28s - loss: 0.1074 - accuracy: 0.971 - ETA: 26s - loss: 0.1067 - accuracy: 0.971 - ETA: 25s - loss: 0.1067 - accuracy: 0.971 - ETA: 23s - loss: 0.1066 - accuracy: 0.971 - ETA: 21s - loss: 0.1068 - accuracy: 0.971 - ETA: 20s - loss: 0.1071 - accuracy: 0.971 - ETA: 18s - loss: 0.1080 - accuracy: 0.971 - ETA: 16s - loss: 0.1101 - accuracy: 0.970 - ETA: 14s - loss: 0.1103 - accuracy: 0.970 - ETA: 13s - loss: 0.1100 - accuracy: 0.970 - ETA: 11s - loss: 0.1099 - accuracy: 0.970 - ETA: 9s - loss: 0.1094 - accuracy: 0.970 - ETA: 8s - loss: 0.1091 - accuracy: 0.97 - ETA: 6s - loss: 0.1089 - accuracy: 0.97 - ETA: 4s - loss: 0.1086 - accuracy: 0.97 - ETA: 2s - loss: 0.1088 - accuracy: 0.97 - ETA: 1s - loss: 0.1083 - accuracy: 0.97 - 198s 15ms/step - loss: 0.1087 - accuracy: 0.9707 - val_loss: 3.1184 - val_accuracy: 0.3877\n",
      "Epoch 26/100\n",
      "13022/13022 [==============================] - ETA: 2:48 - loss: 0.1236 - accuracy: 0.95 - ETA: 2:53 - loss: 0.1163 - accuracy: 0.96 - ETA: 2:52 - loss: 0.1223 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1032 - accuracy: 0.96 - ETA: 2:49 - loss: 0.1162 - accuracy: 0.96 - ETA: 2:47 - loss: 0.1075 - accuracy: 0.96 - ETA: 2:44 - loss: 0.0968 - accuracy: 0.96 - ETA: 2:42 - loss: 0.1080 - accuracy: 0.96 - ETA: 2:39 - loss: 0.1056 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1030 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1007 - accuracy: 0.96 - ETA: 2:34 - loss: 0.1069 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1059 - accuracy: 0.96 - ETA: 2:30 - loss: 0.1067 - accuracy: 0.96 - ETA: 2:29 - loss: 0.1124 - accuracy: 0.96 - ETA: 2:27 - loss: 0.1104 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1109 - accuracy: 0.96 - ETA: 2:23 - loss: 0.1084 - accuracy: 0.96 - ETA: 2:21 - loss: 0.1140 - accuracy: 0.96 - ETA: 2:19 - loss: 0.1128 - accuracy: 0.96 - ETA: 2:17 - loss: 0.1124 - accuracy: 0.96 - ETA: 2:16 - loss: 0.1095 - accuracy: 0.96 - ETA: 2:14 - loss: 0.1099 - accuracy: 0.96 - ETA: 2:12 - loss: 0.1148 - accuracy: 0.96 - ETA: 2:11 - loss: 0.1137 - accuracy: 0.96 - ETA: 2:09 - loss: 0.1152 - accuracy: 0.96 - ETA: 2:07 - loss: 0.1172 - accuracy: 0.96 - ETA: 2:05 - loss: 0.1156 - accuracy: 0.96 - ETA: 2:04 - loss: 0.1177 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1181 - accuracy: 0.96 - ETA: 2:01 - loss: 0.1177 - accuracy: 0.96 - ETA: 1:59 - loss: 0.1178 - accuracy: 0.96 - ETA: 1:57 - loss: 0.1184 - accuracy: 0.96 - ETA: 1:56 - loss: 0.1179 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1164 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1144 - accuracy: 0.96 - ETA: 1:51 - loss: 0.1124 - accuracy: 0.96 - ETA: 1:49 - loss: 0.1117 - accuracy: 0.96 - ETA: 1:48 - loss: 0.1126 - accuracy: 0.96 - ETA: 1:46 - loss: 0.1113 - accuracy: 0.96 - ETA: 1:45 - loss: 0.1102 - accuracy: 0.96 - ETA: 1:43 - loss: 0.1088 - accuracy: 0.96 - ETA: 1:42 - loss: 0.1100 - accuracy: 0.96 - ETA: 1:40 - loss: 0.1105 - accuracy: 0.96 - ETA: 1:38 - loss: 0.1102 - accuracy: 0.96 - ETA: 1:37 - loss: 0.1100 - accuracy: 0.96 - ETA: 1:35 - loss: 0.1101 - accuracy: 0.96 - ETA: 1:33 - loss: 0.1107 - accuracy: 0.96 - ETA: 1:31 - loss: 0.1127 - accuracy: 0.96 - ETA: 1:30 - loss: 0.1108 - accuracy: 0.96 - ETA: 1:28 - loss: 0.1104 - accuracy: 0.96 - ETA: 1:26 - loss: 0.1105 - accuracy: 0.96 - ETA: 1:24 - loss: 0.1107 - accuracy: 0.96 - ETA: 1:22 - loss: 0.1109 - accuracy: 0.96 - ETA: 1:21 - loss: 0.1119 - accuracy: 0.96 - ETA: 1:19 - loss: 0.1128 - accuracy: 0.96 - ETA: 1:17 - loss: 0.1128 - accuracy: 0.96 - ETA: 1:15 - loss: 0.1122 - accuracy: 0.96 - ETA: 1:14 - loss: 0.1125 - accuracy: 0.96 - ETA: 1:12 - loss: 0.1121 - accuracy: 0.96 - ETA: 1:10 - loss: 0.1124 - accuracy: 0.96 - ETA: 1:08 - loss: 0.1125 - accuracy: 0.96 - ETA: 1:07 - loss: 0.1121 - accuracy: 0.96 - ETA: 1:05 - loss: 0.1110 - accuracy: 0.96 - ETA: 1:03 - loss: 0.1102 - accuracy: 0.96 - ETA: 1:01 - loss: 0.1096 - accuracy: 0.96 - ETA: 59s - loss: 0.1110 - accuracy: 0.9678 - ETA: 58s - loss: 0.1100 - accuracy: 0.968 - ETA: 56s - loss: 0.1098 - accuracy: 0.968 - ETA: 54s - loss: 0.1090 - accuracy: 0.968 - ETA: 53s - loss: 0.1080 - accuracy: 0.969 - ETA: 51s - loss: 0.1082 - accuracy: 0.969 - ETA: 49s - loss: 0.1093 - accuracy: 0.969 - ETA: 47s - loss: 0.1092 - accuracy: 0.969 - ETA: 46s - loss: 0.1092 - accuracy: 0.969 - ETA: 44s - loss: 0.1093 - accuracy: 0.969 - ETA: 42s - loss: 0.1088 - accuracy: 0.969 - ETA: 40s - loss: 0.1088 - accuracy: 0.969 - ETA: 39s - loss: 0.1084 - accuracy: 0.969 - ETA: 37s - loss: 0.1076 - accuracy: 0.969 - ETA: 35s - loss: 0.1079 - accuracy: 0.969 - ETA: 34s - loss: 0.1074 - accuracy: 0.969 - ETA: 32s - loss: 0.1067 - accuracy: 0.969 - ETA: 30s - loss: 0.1071 - accuracy: 0.969 - ETA: 28s - loss: 0.1071 - accuracy: 0.969 - ETA: 27s - loss: 0.1081 - accuracy: 0.969 - ETA: 25s - loss: 0.1077 - accuracy: 0.969 - ETA: 23s - loss: 0.1074 - accuracy: 0.969 - ETA: 21s - loss: 0.1089 - accuracy: 0.969 - ETA: 20s - loss: 0.1086 - accuracy: 0.969 - ETA: 18s - loss: 0.1087 - accuracy: 0.969 - ETA: 16s - loss: 0.1086 - accuracy: 0.969 - ETA: 15s - loss: 0.1079 - accuracy: 0.969 - ETA: 13s - loss: 0.1081 - accuracy: 0.969 - ETA: 11s - loss: 0.1081 - accuracy: 0.969 - ETA: 9s - loss: 0.1088 - accuracy: 0.969 - ETA: 8s - loss: 0.1085 - accuracy: 0.96 - ETA: 6s - loss: 0.1077 - accuracy: 0.96 - ETA: 4s - loss: 0.1079 - accuracy: 0.96 - ETA: 2s - loss: 0.1083 - accuracy: 0.96 - ETA: 1s - loss: 0.1077 - accuracy: 0.96 - 200s 15ms/step - loss: 0.1073 - accuracy: 0.9697 - val_loss: 2.8952 - val_accuracy: 0.4271\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:46 - loss: 0.0853 - accuracy: 0.98 - ETA: 2:44 - loss: 0.0704 - accuracy: 0.98 - ETA: 2:47 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:46 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0652 - accuracy: 0.98 - ETA: 2:40 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0617 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0733 - accuracy: 0.98 - ETA: 2:37 - loss: 0.0734 - accuracy: 0.98 - ETA: 2:35 - loss: 0.0944 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0891 - accuracy: 0.97 - ETA: 2:32 - loss: 0.0899 - accuracy: 0.97 - ETA: 2:30 - loss: 0.0917 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0921 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0990 - accuracy: 0.97 - ETA: 2:25 - loss: 0.1041 - accuracy: 0.97 - ETA: 2:24 - loss: 0.1009 - accuracy: 0.97 - ETA: 2:22 - loss: 0.0981 - accuracy: 0.97 - ETA: 2:20 - loss: 0.0953 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0990 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0985 - accuracy: 0.97 - ETA: 2:15 - loss: 0.0972 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0987 - accuracy: 0.97 - ETA: 2:11 - loss: 0.1000 - accuracy: 0.97 - ETA: 2:09 - loss: 0.1024 - accuracy: 0.97 - ETA: 2:08 - loss: 0.1004 - accuracy: 0.97 - ETA: 2:06 - loss: 0.1007 - accuracy: 0.97 - ETA: 2:05 - loss: 0.1001 - accuracy: 0.97 - ETA: 2:03 - loss: 0.0982 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0969 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0974 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0967 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0954 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0987 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0976 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0971 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0958 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0947 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0981 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0976 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0959 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0956 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0981 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0995 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0991 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0991 - accuracy: 0.97 - ETA: 1:31 - loss: 0.1023 - accuracy: 0.97 - ETA: 1:29 - loss: 0.1041 - accuracy: 0.97 - ETA: 1:27 - loss: 0.1034 - accuracy: 0.97 - ETA: 1:26 - loss: 0.1029 - accuracy: 0.97 - ETA: 1:24 - loss: 0.1015 - accuracy: 0.97 - ETA: 1:22 - loss: 0.1012 - accuracy: 0.97 - ETA: 1:20 - loss: 0.1013 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1013 - accuracy: 0.97 - ETA: 1:17 - loss: 0.1009 - accuracy: 0.97 - ETA: 1:15 - loss: 0.1010 - accuracy: 0.97 - ETA: 1:14 - loss: 0.1009 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0999 - accuracy: 0.97 - ETA: 1:10 - loss: 0.1003 - accuracy: 0.97 - ETA: 1:09 - loss: 0.1007 - accuracy: 0.97 - ETA: 1:07 - loss: 0.1001 - accuracy: 0.97 - ETA: 1:05 - loss: 0.1017 - accuracy: 0.97 - ETA: 1:03 - loss: 0.1032 - accuracy: 0.97 - ETA: 1:02 - loss: 0.1035 - accuracy: 0.97 - ETA: 1:00 - loss: 0.1026 - accuracy: 0.97 - ETA: 59s - loss: 0.1032 - accuracy: 0.9740 - ETA: 57s - loss: 0.1035 - accuracy: 0.974 - ETA: 55s - loss: 0.1044 - accuracy: 0.974 - ETA: 54s - loss: 0.1044 - accuracy: 0.973 - ETA: 52s - loss: 0.1045 - accuracy: 0.973 - ETA: 50s - loss: 0.1047 - accuracy: 0.973 - ETA: 49s - loss: 0.1052 - accuracy: 0.973 - ETA: 47s - loss: 0.1059 - accuracy: 0.973 - ETA: 45s - loss: 0.1062 - accuracy: 0.972 - ETA: 43s - loss: 0.1076 - accuracy: 0.972 - ETA: 42s - loss: 0.1084 - accuracy: 0.972 - ETA: 40s - loss: 0.1085 - accuracy: 0.972 - ETA: 38s - loss: 0.1091 - accuracy: 0.972 - ETA: 37s - loss: 0.1097 - accuracy: 0.972 - ETA: 35s - loss: 0.1090 - accuracy: 0.972 - ETA: 33s - loss: 0.1090 - accuracy: 0.972 - ETA: 31s - loss: 0.1083 - accuracy: 0.972 - ETA: 30s - loss: 0.1078 - accuracy: 0.972 - ETA: 28s - loss: 0.1077 - accuracy: 0.972 - ETA: 26s - loss: 0.1080 - accuracy: 0.971 - ETA: 25s - loss: 0.1074 - accuracy: 0.972 - ETA: 23s - loss: 0.1074 - accuracy: 0.971 - ETA: 21s - loss: 0.1097 - accuracy: 0.971 - ETA: 20s - loss: 0.1102 - accuracy: 0.971 - ETA: 18s - loss: 0.1099 - accuracy: 0.971 - ETA: 16s - loss: 0.1105 - accuracy: 0.971 - ETA: 14s - loss: 0.1097 - accuracy: 0.971 - ETA: 13s - loss: 0.1097 - accuracy: 0.971 - ETA: 11s - loss: 0.1093 - accuracy: 0.971 - ETA: 9s - loss: 0.1090 - accuracy: 0.971 - ETA: 8s - loss: 0.1087 - accuracy: 0.97 - ETA: 6s - loss: 0.1089 - accuracy: 0.97 - ETA: 4s - loss: 0.1080 - accuracy: 0.97 - ETA: 2s - loss: 0.1086 - accuracy: 0.97 - ETA: 1s - loss: 0.1086 - accuracy: 0.97 - 197s 15ms/step - loss: 0.1083 - accuracy: 0.9710 - val_loss: 3.0507 - val_accuracy: 0.4028\n",
      "Epoch 28/100\n",
      "13022/13022 [==============================] - ETA: 2:45 - loss: 0.1434 - accuracy: 0.96 - ETA: 2:44 - loss: 0.1634 - accuracy: 0.95 - ETA: 2:45 - loss: 0.1388 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1253 - accuracy: 0.96 - ETA: 2:43 - loss: 0.1210 - accuracy: 0.96 - ETA: 2:41 - loss: 0.1247 - accuracy: 0.96 - ETA: 2:40 - loss: 0.1177 - accuracy: 0.96 - ETA: 2:37 - loss: 0.1172 - accuracy: 0.96 - ETA: 2:36 - loss: 0.1172 - accuracy: 0.96 - ETA: 2:35 - loss: 0.1139 - accuracy: 0.96 - ETA: 2:33 - loss: 0.1059 - accuracy: 0.96 - ETA: 2:31 - loss: 0.1036 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1086 - accuracy: 0.96 - ETA: 2:28 - loss: 0.1049 - accuracy: 0.97 - ETA: 2:27 - loss: 0.1064 - accuracy: 0.96 - ETA: 2:25 - loss: 0.1023 - accuracy: 0.97 - ETA: 2:23 - loss: 0.1056 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1038 - accuracy: 0.97 - ETA: 2:20 - loss: 0.1117 - accuracy: 0.96 - ETA: 2:18 - loss: 0.1101 - accuracy: 0.97 - ETA: 2:16 - loss: 0.1131 - accuracy: 0.97 - ETA: 2:15 - loss: 0.1108 - accuracy: 0.97 - ETA: 2:13 - loss: 0.1086 - accuracy: 0.97 - ETA: 2:11 - loss: 0.1075 - accuracy: 0.97 - ETA: 2:10 - loss: 0.1062 - accuracy: 0.97 - ETA: 2:08 - loss: 0.1115 - accuracy: 0.97 - ETA: 2:07 - loss: 0.1089 - accuracy: 0.97 - ETA: 2:05 - loss: 0.1105 - accuracy: 0.97 - ETA: 2:03 - loss: 0.1115 - accuracy: 0.96 - ETA: 2:02 - loss: 0.1113 - accuracy: 0.96 - ETA: 2:00 - loss: 0.1129 - accuracy: 0.97 - ETA: 1:58 - loss: 0.1114 - accuracy: 0.97 - ETA: 1:57 - loss: 0.1102 - accuracy: 0.97 - ETA: 1:55 - loss: 0.1105 - accuracy: 0.97 - ETA: 1:53 - loss: 0.1082 - accuracy: 0.97 - ETA: 1:51 - loss: 0.1072 - accuracy: 0.97 - ETA: 1:50 - loss: 0.1058 - accuracy: 0.97 - ETA: 1:48 - loss: 0.1061 - accuracy: 0.97 - ETA: 1:46 - loss: 0.1045 - accuracy: 0.97 - ETA: 1:45 - loss: 0.1031 - accuracy: 0.97 - ETA: 1:43 - loss: 0.1043 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1050 - accuracy: 0.97 - ETA: 1:40 - loss: 0.1054 - accuracy: 0.97 - ETA: 1:38 - loss: 0.1035 - accuracy: 0.97 - ETA: 1:36 - loss: 0.1026 - accuracy: 0.97 - ETA: 1:34 - loss: 0.1030 - accuracy: 0.97 - ETA: 1:32 - loss: 0.1020 - accuracy: 0.97 - ETA: 1:31 - loss: 0.1029 - accuracy: 0.97 - ETA: 1:29 - loss: 0.1027 - accuracy: 0.97 - ETA: 1:27 - loss: 0.1039 - accuracy: 0.97 - ETA: 1:26 - loss: 0.1028 - accuracy: 0.97 - ETA: 1:24 - loss: 0.1035 - accuracy: 0.97 - ETA: 1:22 - loss: 0.1024 - accuracy: 0.97 - ETA: 1:21 - loss: 0.1026 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1024 - accuracy: 0.97 - ETA: 1:17 - loss: 0.1018 - accuracy: 0.97 - ETA: 1:15 - loss: 0.1032 - accuracy: 0.97 - ETA: 1:14 - loss: 0.1029 - accuracy: 0.97 - ETA: 1:12 - loss: 0.1018 - accuracy: 0.97 - ETA: 1:10 - loss: 0.1019 - accuracy: 0.97 - ETA: 1:09 - loss: 0.1019 - accuracy: 0.97 - ETA: 1:07 - loss: 0.1015 - accuracy: 0.97 - ETA: 1:05 - loss: 0.1006 - accuracy: 0.97 - ETA: 1:04 - loss: 0.1005 - accuracy: 0.97 - ETA: 1:02 - loss: 0.1013 - accuracy: 0.97 - ETA: 1:00 - loss: 0.1008 - accuracy: 0.97 - ETA: 58s - loss: 0.1031 - accuracy: 0.9714 - ETA: 57s - loss: 0.1029 - accuracy: 0.971 - ETA: 55s - loss: 0.1033 - accuracy: 0.971 - ETA: 53s - loss: 0.1031 - accuracy: 0.971 - ETA: 52s - loss: 0.1033 - accuracy: 0.971 - ETA: 50s - loss: 0.1027 - accuracy: 0.970 - ETA: 48s - loss: 0.1019 - accuracy: 0.971 - ETA: 47s - loss: 0.1022 - accuracy: 0.971 - ETA: 45s - loss: 0.1019 - accuracy: 0.971 - ETA: 43s - loss: 0.1014 - accuracy: 0.971 - ETA: 42s - loss: 0.1006 - accuracy: 0.971 - ETA: 40s - loss: 0.1004 - accuracy: 0.971 - ETA: 38s - loss: 0.1000 - accuracy: 0.971 - ETA: 36s - loss: 0.0997 - accuracy: 0.971 - ETA: 35s - loss: 0.1009 - accuracy: 0.971 - ETA: 33s - loss: 0.1009 - accuracy: 0.971 - ETA: 31s - loss: 0.1039 - accuracy: 0.971 - ETA: 30s - loss: 0.1040 - accuracy: 0.971 - ETA: 28s - loss: 0.1052 - accuracy: 0.971 - ETA: 26s - loss: 0.1055 - accuracy: 0.970 - ETA: 25s - loss: 0.1047 - accuracy: 0.970 - ETA: 23s - loss: 0.1038 - accuracy: 0.971 - ETA: 21s - loss: 0.1033 - accuracy: 0.971 - ETA: 19s - loss: 0.1035 - accuracy: 0.971 - ETA: 18s - loss: 0.1032 - accuracy: 0.971 - ETA: 16s - loss: 0.1039 - accuracy: 0.970 - ETA: 14s - loss: 0.1033 - accuracy: 0.971 - ETA: 13s - loss: 0.1029 - accuracy: 0.971 - ETA: 11s - loss: 0.1031 - accuracy: 0.971 - ETA: 9s - loss: 0.1036 - accuracy: 0.970 - ETA: 8s - loss: 0.1043 - accuracy: 0.97 - ETA: 6s - loss: 0.1041 - accuracy: 0.97 - ETA: 4s - loss: 0.1041 - accuracy: 0.97 - ETA: 2s - loss: 0.1050 - accuracy: 0.97 - ETA: 1s - loss: 0.1048 - accuracy: 0.97 - 197s 15ms/step - loss: 0.1045 - accuracy: 0.9707 - val_loss: 3.1134 - val_accuracy: 0.3549\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:52 - loss: 0.0913 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0707 - accuracy: 0.98 - ETA: 2:53 - loss: 0.0695 - accuracy: 0.98 - ETA: 2:48 - loss: 0.0724 - accuracy: 0.97 - ETA: 2:46 - loss: 0.0732 - accuracy: 0.97 - ETA: 2:44 - loss: 0.0681 - accuracy: 0.98 - ETA: 2:42 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:41 - loss: 0.0818 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0814 - accuracy: 0.97 - ETA: 2:38 - loss: 0.1019 - accuracy: 0.97 - ETA: 2:36 - loss: 0.1135 - accuracy: 0.97 - ETA: 2:34 - loss: 0.1243 - accuracy: 0.96 - ETA: 2:32 - loss: 0.1185 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1148 - accuracy: 0.97 - ETA: 2:28 - loss: 0.1121 - accuracy: 0.97 - ETA: 2:26 - loss: 0.1115 - accuracy: 0.97 - ETA: 2:24 - loss: 0.1115 - accuracy: 0.97 - ETA: 2:23 - loss: 0.1090 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1046 - accuracy: 0.97 - ETA: 2:19 - loss: 0.1012 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0983 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0961 - accuracy: 0.97 - ETA: 2:14 - loss: 0.1047 - accuracy: 0.97 - ETA: 2:12 - loss: 0.1028 - accuracy: 0.97 - ETA: 2:10 - loss: 0.1003 - accuracy: 0.97 - ETA: 2:09 - loss: 0.1010 - accuracy: 0.97 - ETA: 2:07 - loss: 0.1004 - accuracy: 0.97 - ETA: 2:05 - loss: 0.1024 - accuracy: 0.97 - ETA: 2:04 - loss: 0.1012 - accuracy: 0.97 - ETA: 2:02 - loss: 0.1019 - accuracy: 0.97 - ETA: 2:01 - loss: 0.1017 - accuracy: 0.97 - ETA: 1:59 - loss: 0.1024 - accuracy: 0.97 - ETA: 1:57 - loss: 0.1008 - accuracy: 0.97 - ETA: 1:55 - loss: 0.0993 - accuracy: 0.97 - ETA: 1:54 - loss: 0.1015 - accuracy: 0.97 - ETA: 1:52 - loss: 0.1003 - accuracy: 0.97 - ETA: 1:50 - loss: 0.1015 - accuracy: 0.97 - ETA: 1:48 - loss: 0.1003 - accuracy: 0.97 - ETA: 1:46 - loss: 0.1004 - accuracy: 0.97 - ETA: 1:45 - loss: 0.1002 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0996 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0978 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0974 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0982 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0981 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0974 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0993 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0994 - accuracy: 0.97 - ETA: 1:29 - loss: 0.1003 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0999 - accuracy: 0.97 - ETA: 1:26 - loss: 0.1041 - accuracy: 0.97 - ETA: 1:24 - loss: 0.1046 - accuracy: 0.97 - ETA: 1:23 - loss: 0.1039 - accuracy: 0.97 - ETA: 1:21 - loss: 0.1039 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1061 - accuracy: 0.97 - ETA: 1:17 - loss: 0.1058 - accuracy: 0.97 - ETA: 1:16 - loss: 0.1063 - accuracy: 0.97 - ETA: 1:14 - loss: 0.1056 - accuracy: 0.97 - ETA: 1:12 - loss: 0.1056 - accuracy: 0.97 - ETA: 1:11 - loss: 0.1062 - accuracy: 0.97 - ETA: 1:09 - loss: 0.1052 - accuracy: 0.97 - ETA: 1:07 - loss: 0.1052 - accuracy: 0.97 - ETA: 1:05 - loss: 0.1047 - accuracy: 0.97 - ETA: 1:04 - loss: 0.1049 - accuracy: 0.97 - ETA: 1:02 - loss: 0.1063 - accuracy: 0.97 - ETA: 1:00 - loss: 0.1080 - accuracy: 0.97 - ETA: 58s - loss: 0.1082 - accuracy: 0.9729 - ETA: 57s - loss: 0.1077 - accuracy: 0.973 - ETA: 55s - loss: 0.1077 - accuracy: 0.972 - ETA: 54s - loss: 0.1070 - accuracy: 0.973 - ETA: 52s - loss: 0.1059 - accuracy: 0.973 - ETA: 50s - loss: 0.1049 - accuracy: 0.973 - ETA: 48s - loss: 0.1044 - accuracy: 0.974 - ETA: 47s - loss: 0.1059 - accuracy: 0.973 - ETA: 45s - loss: 0.1063 - accuracy: 0.973 - ETA: 43s - loss: 0.1068 - accuracy: 0.973 - ETA: 42s - loss: 0.1071 - accuracy: 0.972 - ETA: 40s - loss: 0.1060 - accuracy: 0.973 - ETA: 38s - loss: 0.1056 - accuracy: 0.973 - ETA: 36s - loss: 0.1046 - accuracy: 0.973 - ETA: 35s - loss: 0.1048 - accuracy: 0.973 - ETA: 33s - loss: 0.1047 - accuracy: 0.973 - ETA: 31s - loss: 0.1041 - accuracy: 0.973 - ETA: 30s - loss: 0.1039 - accuracy: 0.973 - ETA: 28s - loss: 0.1040 - accuracy: 0.973 - ETA: 26s - loss: 0.1043 - accuracy: 0.973 - ETA: 24s - loss: 0.1044 - accuracy: 0.973 - ETA: 23s - loss: 0.1045 - accuracy: 0.973 - ETA: 21s - loss: 0.1042 - accuracy: 0.973 - ETA: 19s - loss: 0.1038 - accuracy: 0.973 - ETA: 18s - loss: 0.1032 - accuracy: 0.973 - ETA: 16s - loss: 0.1037 - accuracy: 0.973 - ETA: 14s - loss: 0.1030 - accuracy: 0.973 - ETA: 13s - loss: 0.1025 - accuracy: 0.973 - ETA: 11s - loss: 0.1030 - accuracy: 0.973 - ETA: 9s - loss: 0.1029 - accuracy: 0.973 - ETA: 8s - loss: 0.1027 - accuracy: 0.97 - ETA: 6s - loss: 0.1024 - accuracy: 0.97 - ETA: 4s - loss: 0.1024 - accuracy: 0.97 - ETA: 2s - loss: 0.1029 - accuracy: 0.97 - ETA: 1s - loss: 0.1030 - accuracy: 0.97 - 197s 15ms/step - loss: 0.1034 - accuracy: 0.9732 - val_loss: 3.0360 - val_accuracy: 0.3915\n",
      "Epoch 30/100\n",
      "13022/13022 [==============================] - ETA: 3:02 - loss: 0.0639 - accuracy: 0.97 - ETA: 2:53 - loss: 0.1626 - accuracy: 0.96 - ETA: 2:48 - loss: 0.1199 - accuracy: 0.97 - ETA: 2:44 - loss: 0.1247 - accuracy: 0.97 - ETA: 2:43 - loss: 0.1228 - accuracy: 0.97 - ETA: 2:40 - loss: 0.1168 - accuracy: 0.97 - ETA: 2:38 - loss: 0.1169 - accuracy: 0.97 - ETA: 2:37 - loss: 0.1120 - accuracy: 0.97 - ETA: 2:36 - loss: 0.1079 - accuracy: 0.97 - ETA: 2:34 - loss: 0.1037 - accuracy: 0.97 - ETA: 2:33 - loss: 0.1035 - accuracy: 0.97 - ETA: 2:31 - loss: 0.1032 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1041 - accuracy: 0.97 - ETA: 2:27 - loss: 0.1030 - accuracy: 0.97 - ETA: 2:26 - loss: 0.1044 - accuracy: 0.97 - ETA: 2:24 - loss: 0.1017 - accuracy: 0.97 - ETA: 2:22 - loss: 0.1008 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1015 - accuracy: 0.97 - ETA: 2:19 - loss: 0.1005 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0967 - accuracy: 0.97 - ETA: 2:15 - loss: 0.1010 - accuracy: 0.97 - ETA: 2:14 - loss: 0.1010 - accuracy: 0.97 - ETA: 2:12 - loss: 0.1018 - accuracy: 0.97 - ETA: 2:11 - loss: 0.1013 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0999 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0988 - accuracy: 0.97 - ETA: 2:05 - loss: 0.1001 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0984 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0974 - accuracy: 0.97 - ETA: 2:00 - loss: 0.0981 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0972 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0973 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0986 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0978 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0990 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0978 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0984 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0992 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0996 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0994 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0980 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0972 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0968 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0948 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0941 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0927 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0918 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0925 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0923 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0913 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0923 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0917 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0910 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0909 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0929 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0948 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0937 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0927 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0925 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0920 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0920 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0912 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0911 - accuracy: 0.97 - ETA: 58s - loss: 0.0902 - accuracy: 0.9750 - ETA: 57s - loss: 0.0920 - accuracy: 0.975 - ETA: 55s - loss: 0.0913 - accuracy: 0.975 - ETA: 53s - loss: 0.0907 - accuracy: 0.975 - ETA: 52s - loss: 0.0905 - accuracy: 0.975 - ETA: 50s - loss: 0.0901 - accuracy: 0.975 - ETA: 48s - loss: 0.0896 - accuracy: 0.975 - ETA: 47s - loss: 0.0895 - accuracy: 0.975 - ETA: 45s - loss: 0.0894 - accuracy: 0.975 - ETA: 43s - loss: 0.0900 - accuracy: 0.975 - ETA: 42s - loss: 0.0925 - accuracy: 0.975 - ETA: 40s - loss: 0.0927 - accuracy: 0.975 - ETA: 38s - loss: 0.0919 - accuracy: 0.975 - ETA: 36s - loss: 0.0914 - accuracy: 0.975 - ETA: 35s - loss: 0.0912 - accuracy: 0.975 - ETA: 33s - loss: 0.0909 - accuracy: 0.975 - ETA: 31s - loss: 0.0907 - accuracy: 0.975 - ETA: 30s - loss: 0.0909 - accuracy: 0.975 - ETA: 28s - loss: 0.0910 - accuracy: 0.975 - ETA: 26s - loss: 0.0907 - accuracy: 0.975 - ETA: 25s - loss: 0.0906 - accuracy: 0.975 - ETA: 23s - loss: 0.0910 - accuracy: 0.975 - ETA: 21s - loss: 0.0909 - accuracy: 0.975 - ETA: 19s - loss: 0.0911 - accuracy: 0.975 - ETA: 18s - loss: 0.0913 - accuracy: 0.975 - ETA: 16s - loss: 0.0911 - accuracy: 0.975 - ETA: 14s - loss: 0.0910 - accuracy: 0.975 - ETA: 13s - loss: 0.0924 - accuracy: 0.974 - ETA: 11s - loss: 0.0916 - accuracy: 0.975 - ETA: 9s - loss: 0.0912 - accuracy: 0.975 - ETA: 8s - loss: 0.0932 - accuracy: 0.97 - ETA: 6s - loss: 0.0929 - accuracy: 0.97 - ETA: 4s - loss: 0.0927 - accuracy: 0.97 - ETA: 2s - loss: 0.0928 - accuracy: 0.97 - ETA: 1s - loss: 0.0927 - accuracy: 0.97 - 198s 15ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 3.2581 - val_accuracy: 0.3863\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:48 - loss: 0.0487 - accuracy: 0.98 - ETA: 2:56 - loss: 0.0491 - accuracy: 0.98 - ETA: 2:50 - loss: 0.0873 - accuracy: 0.97 - ETA: 2:49 - loss: 0.0782 - accuracy: 0.97 - ETA: 2:48 - loss: 0.0757 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0696 - accuracy: 0.97 - ETA: 2:45 - loss: 0.0668 - accuracy: 0.97 - ETA: 2:43 - loss: 0.0760 - accuracy: 0.97 - ETA: 2:42 - loss: 0.0777 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0785 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0760 - accuracy: 0.97 - ETA: 2:35 - loss: 0.0757 - accuracy: 0.97 - ETA: 2:33 - loss: 0.0808 - accuracy: 0.97 - ETA: 2:31 - loss: 0.0840 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0839 - accuracy: 0.97 - ETA: 2:27 - loss: 0.0863 - accuracy: 0.97 - ETA: 2:25 - loss: 0.0848 - accuracy: 0.97 - ETA: 2:23 - loss: 0.0843 - accuracy: 0.97 - ETA: 2:21 - loss: 0.0880 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0854 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0836 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0830 - accuracy: 0.97 - ETA: 2:14 - loss: 0.0827 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0804 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0857 - accuracy: 0.97 - ETA: 2:09 - loss: 0.0871 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0923 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0910 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0898 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0897 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0896 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0907 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0938 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0927 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0929 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0920 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0912 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0911 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0909 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0904 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0914 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0917 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0925 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0914 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0924 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0937 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0932 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0933 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0939 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0937 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0928 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0932 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0920 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0913 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0915 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0914 - accuracy: 0.97 - ETA: 59s - loss: 0.0913 - accuracy: 0.9747 - ETA: 58s - loss: 0.0917 - accuracy: 0.974 - ETA: 56s - loss: 0.0926 - accuracy: 0.974 - ETA: 54s - loss: 0.0917 - accuracy: 0.974 - ETA: 53s - loss: 0.0918 - accuracy: 0.974 - ETA: 51s - loss: 0.0921 - accuracy: 0.974 - ETA: 49s - loss: 0.0919 - accuracy: 0.974 - ETA: 48s - loss: 0.0911 - accuracy: 0.975 - ETA: 46s - loss: 0.0904 - accuracy: 0.975 - ETA: 44s - loss: 0.0906 - accuracy: 0.975 - ETA: 43s - loss: 0.0907 - accuracy: 0.975 - ETA: 41s - loss: 0.0905 - accuracy: 0.975 - ETA: 39s - loss: 0.0906 - accuracy: 0.975 - ETA: 38s - loss: 0.0916 - accuracy: 0.974 - ETA: 36s - loss: 0.0922 - accuracy: 0.974 - ETA: 34s - loss: 0.0934 - accuracy: 0.974 - ETA: 33s - loss: 0.0930 - accuracy: 0.974 - ETA: 31s - loss: 0.0933 - accuracy: 0.974 - ETA: 29s - loss: 0.0931 - accuracy: 0.974 - ETA: 28s - loss: 0.0925 - accuracy: 0.974 - ETA: 26s - loss: 0.0917 - accuracy: 0.974 - ETA: 24s - loss: 0.0933 - accuracy: 0.974 - ETA: 23s - loss: 0.0927 - accuracy: 0.974 - ETA: 21s - loss: 0.0924 - accuracy: 0.974 - ETA: 19s - loss: 0.0923 - accuracy: 0.974 - ETA: 18s - loss: 0.0929 - accuracy: 0.974 - ETA: 16s - loss: 0.0940 - accuracy: 0.974 - ETA: 14s - loss: 0.0936 - accuracy: 0.974 - ETA: 13s - loss: 0.0932 - accuracy: 0.974 - ETA: 11s - loss: 0.0935 - accuracy: 0.974 - ETA: 9s - loss: 0.0934 - accuracy: 0.974 - ETA: 7s - loss: 0.0933 - accuracy: 0.97 - ETA: 6s - loss: 0.0936 - accuracy: 0.97 - ETA: 4s - loss: 0.0938 - accuracy: 0.97 - ETA: 2s - loss: 0.0933 - accuracy: 0.97 - ETA: 1s - loss: 0.0928 - accuracy: 0.97 - 198s 15ms/step - loss: 0.0922 - accuracy: 0.9746 - val_loss: 3.2706 - val_accuracy: 0.3828\n",
      "Epoch 32/100\n",
      "13022/13022 [==============================] - ETA: 3:17 - loss: 0.1681 - accuracy: 0.96 - ETA: 3:07 - loss: 0.1000 - accuracy: 0.97 - ETA: 2:56 - loss: 0.1107 - accuracy: 0.97 - ETA: 2:54 - loss: 0.1112 - accuracy: 0.97 - ETA: 2:52 - loss: 0.0968 - accuracy: 0.97 - ETA: 2:50 - loss: 0.0843 - accuracy: 0.97 - ETA: 2:47 - loss: 0.0900 - accuracy: 0.97 - ETA: 2:45 - loss: 0.1082 - accuracy: 0.97 - ETA: 2:42 - loss: 0.1021 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0959 - accuracy: 0.97 - ETA: 2:39 - loss: 0.0990 - accuracy: 0.97 - ETA: 2:37 - loss: 0.0971 - accuracy: 0.97 - ETA: 2:36 - loss: 0.0966 - accuracy: 0.97 - ETA: 2:35 - loss: 0.1015 - accuracy: 0.97 - ETA: 2:34 - loss: 0.1131 - accuracy: 0.97 - ETA: 2:32 - loss: 0.1100 - accuracy: 0.97 - ETA: 2:30 - loss: 0.1111 - accuracy: 0.97 - ETA: 2:29 - loss: 0.1107 - accuracy: 0.97 - ETA: 2:27 - loss: 0.1059 - accuracy: 0.97 - ETA: 2:25 - loss: 0.1092 - accuracy: 0.97 - ETA: 2:23 - loss: 0.1136 - accuracy: 0.97 - ETA: 2:21 - loss: 0.1148 - accuracy: 0.97 - ETA: 2:19 - loss: 0.1170 - accuracy: 0.97 - ETA: 2:17 - loss: 0.1159 - accuracy: 0.97 - ETA: 2:15 - loss: 0.1165 - accuracy: 0.97 - ETA: 2:14 - loss: 0.1182 - accuracy: 0.97 - ETA: 2:12 - loss: 0.1171 - accuracy: 0.97 - ETA: 2:10 - loss: 0.1159 - accuracy: 0.97 - ETA: 2:08 - loss: 0.1129 - accuracy: 0.97 - ETA: 2:07 - loss: 0.1159 - accuracy: 0.97 - ETA: 2:05 - loss: 0.1128 - accuracy: 0.97 - ETA: 2:03 - loss: 0.1157 - accuracy: 0.97 - ETA: 2:01 - loss: 0.1155 - accuracy: 0.97 - ETA: 1:59 - loss: 0.1142 - accuracy: 0.97 - ETA: 1:57 - loss: 0.1136 - accuracy: 0.97 - ETA: 1:55 - loss: 0.1148 - accuracy: 0.97 - ETA: 1:54 - loss: 0.1127 - accuracy: 0.97 - ETA: 1:52 - loss: 0.1132 - accuracy: 0.97 - ETA: 1:50 - loss: 0.1119 - accuracy: 0.97 - ETA: 1:47 - loss: 0.1111 - accuracy: 0.97 - ETA: 1:45 - loss: 0.1108 - accuracy: 0.97 - ETA: 1:42 - loss: 0.1108 - accuracy: 0.97 - ETA: 1:40 - loss: 0.1109 - accuracy: 0.97 - ETA: 1:37 - loss: 0.1093 - accuracy: 0.97 - ETA: 1:35 - loss: 0.1092 - accuracy: 0.97 - ETA: 1:33 - loss: 0.1076 - accuracy: 0.97 - ETA: 1:31 - loss: 0.1077 - accuracy: 0.97 - ETA: 1:29 - loss: 0.1061 - accuracy: 0.97 - ETA: 1:27 - loss: 0.1047 - accuracy: 0.97 - ETA: 1:25 - loss: 0.1035 - accuracy: 0.97 - ETA: 1:23 - loss: 0.1020 - accuracy: 0.97 - ETA: 1:21 - loss: 0.1015 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1017 - accuracy: 0.97 - ETA: 1:17 - loss: 0.1006 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0995 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0985 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0973 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0984 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0982 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0973 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0974 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0971 - accuracy: 0.97 - ETA: 59s - loss: 0.0978 - accuracy: 0.9746 - ETA: 58s - loss: 0.0977 - accuracy: 0.974 - ETA: 56s - loss: 0.0969 - accuracy: 0.974 - ETA: 54s - loss: 0.0975 - accuracy: 0.974 - ETA: 52s - loss: 0.0974 - accuracy: 0.974 - ETA: 51s - loss: 0.0962 - accuracy: 0.974 - ETA: 49s - loss: 0.0962 - accuracy: 0.974 - ETA: 47s - loss: 0.0955 - accuracy: 0.974 - ETA: 45s - loss: 0.0956 - accuracy: 0.974 - ETA: 44s - loss: 0.0960 - accuracy: 0.974 - ETA: 42s - loss: 0.0953 - accuracy: 0.974 - ETA: 41s - loss: 0.0969 - accuracy: 0.973 - ETA: 39s - loss: 0.0968 - accuracy: 0.974 - ETA: 37s - loss: 0.0966 - accuracy: 0.974 - ETA: 36s - loss: 0.0966 - accuracy: 0.974 - ETA: 34s - loss: 0.0957 - accuracy: 0.974 - ETA: 33s - loss: 0.0957 - accuracy: 0.974 - ETA: 31s - loss: 0.0949 - accuracy: 0.974 - ETA: 30s - loss: 0.0957 - accuracy: 0.974 - ETA: 28s - loss: 0.0954 - accuracy: 0.974 - ETA: 27s - loss: 0.0948 - accuracy: 0.974 - ETA: 25s - loss: 0.0943 - accuracy: 0.974 - ETA: 24s - loss: 0.0943 - accuracy: 0.974 - ETA: 22s - loss: 0.0942 - accuracy: 0.974 - ETA: 21s - loss: 0.0945 - accuracy: 0.974 - ETA: 19s - loss: 0.0951 - accuracy: 0.975 - ETA: 18s - loss: 0.0946 - accuracy: 0.975 - ETA: 16s - loss: 0.0945 - accuracy: 0.974 - ETA: 15s - loss: 0.0951 - accuracy: 0.974 - ETA: 13s - loss: 0.0953 - accuracy: 0.974 - ETA: 12s - loss: 0.0944 - accuracy: 0.974 - ETA: 10s - loss: 0.0949 - accuracy: 0.974 - ETA: 9s - loss: 0.0948 - accuracy: 0.974 - ETA: 8s - loss: 0.0943 - accuracy: 0.97 - ETA: 6s - loss: 0.0938 - accuracy: 0.97 - ETA: 5s - loss: 0.0934 - accuracy: 0.97 - ETA: 3s - loss: 0.0931 - accuracy: 0.97 - ETA: 2s - loss: 0.0924 - accuracy: 0.97 - ETA: 1s - loss: 0.0917 - accuracy: 0.97 - 154s 12ms/step - loss: 0.0918 - accuracy: 0.9755 - val_loss: 3.2966 - val_accuracy: 0.3776\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:53 - loss: 0.0817 - accuracy: 0.96 - ETA: 1:51 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0605 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0632 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0701 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0690 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0694 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0703 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0722 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0738 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0770 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0803 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0795 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0778 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0754 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0750 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0767 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0796 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0794 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0778 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0779 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0779 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0787 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0771 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0774 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0770 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0777 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0796 - accuracy: 0.97 - ETA: 59s - loss: 0.0795 - accuracy: 0.9774 - ETA: 58s - loss: 0.0825 - accuracy: 0.976 - ETA: 57s - loss: 0.0817 - accuracy: 0.977 - ETA: 56s - loss: 0.0817 - accuracy: 0.976 - ETA: 54s - loss: 0.0814 - accuracy: 0.976 - ETA: 53s - loss: 0.0812 - accuracy: 0.976 - ETA: 52s - loss: 0.0807 - accuracy: 0.976 - ETA: 51s - loss: 0.0813 - accuracy: 0.976 - ETA: 50s - loss: 0.0843 - accuracy: 0.975 - ETA: 49s - loss: 0.0834 - accuracy: 0.976 - ETA: 48s - loss: 0.0832 - accuracy: 0.976 - ETA: 46s - loss: 0.0824 - accuracy: 0.976 - ETA: 45s - loss: 0.0822 - accuracy: 0.976 - ETA: 44s - loss: 0.0818 - accuracy: 0.976 - ETA: 43s - loss: 0.0819 - accuracy: 0.975 - ETA: 42s - loss: 0.0842 - accuracy: 0.975 - ETA: 41s - loss: 0.0837 - accuracy: 0.975 - ETA: 40s - loss: 0.0850 - accuracy: 0.975 - ETA: 39s - loss: 0.0848 - accuracy: 0.976 - ETA: 37s - loss: 0.0844 - accuracy: 0.976 - ETA: 36s - loss: 0.0836 - accuracy: 0.976 - ETA: 35s - loss: 0.0849 - accuracy: 0.976 - ETA: 34s - loss: 0.0850 - accuracy: 0.976 - ETA: 33s - loss: 0.0844 - accuracy: 0.976 - ETA: 32s - loss: 0.0849 - accuracy: 0.976 - ETA: 31s - loss: 0.0859 - accuracy: 0.976 - ETA: 30s - loss: 0.0866 - accuracy: 0.976 - ETA: 29s - loss: 0.0861 - accuracy: 0.976 - ETA: 28s - loss: 0.0860 - accuracy: 0.976 - ETA: 26s - loss: 0.0863 - accuracy: 0.976 - ETA: 25s - loss: 0.0859 - accuracy: 0.976 - ETA: 24s - loss: 0.0881 - accuracy: 0.975 - ETA: 23s - loss: 0.0893 - accuracy: 0.975 - ETA: 22s - loss: 0.0898 - accuracy: 0.975 - ETA: 21s - loss: 0.0897 - accuracy: 0.975 - ETA: 20s - loss: 0.0890 - accuracy: 0.975 - ETA: 18s - loss: 0.0887 - accuracy: 0.975 - ETA: 17s - loss: 0.0893 - accuracy: 0.975 - ETA: 16s - loss: 0.0895 - accuracy: 0.975 - ETA: 15s - loss: 0.0896 - accuracy: 0.975 - ETA: 14s - loss: 0.0892 - accuracy: 0.975 - ETA: 13s - loss: 0.0890 - accuracy: 0.975 - ETA: 12s - loss: 0.0886 - accuracy: 0.975 - ETA: 11s - loss: 0.0883 - accuracy: 0.975 - ETA: 9s - loss: 0.0881 - accuracy: 0.975 - ETA: 8s - loss: 0.0883 - accuracy: 0.97 - ETA: 7s - loss: 0.0885 - accuracy: 0.97 - ETA: 6s - loss: 0.0880 - accuracy: 0.97 - ETA: 5s - loss: 0.0878 - accuracy: 0.97 - ETA: 4s - loss: 0.0874 - accuracy: 0.97 - ETA: 3s - loss: 0.0877 - accuracy: 0.97 - ETA: 1s - loss: 0.0882 - accuracy: 0.97 - ETA: 0s - loss: 0.0892 - accuracy: 0.97 - 127s 10ms/step - loss: 0.0891 - accuracy: 0.9751 - val_loss: 3.3830 - val_accuracy: 0.3745\n",
      "Epoch 34/100\n",
      "13022/13022 [==============================] - ETA: 1:51 - loss: 0.1073 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0794 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0717 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0719 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0732 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0720 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0681 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0785 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0722 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0812 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0803 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0791 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0794 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0811 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0788 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0794 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0788 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0783 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0802 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0783 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0788 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0768 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0762 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0757 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0767 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0756 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0762 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0770 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0818 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0829 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0815 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0811 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0816 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0813 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0822 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0821 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0840 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0829 - accuracy: 0.97 - ETA: 59s - loss: 0.0850 - accuracy: 0.9785 - ETA: 58s - loss: 0.0856 - accuracy: 0.978 - ETA: 57s - loss: 0.0852 - accuracy: 0.978 - ETA: 56s - loss: 0.0845 - accuracy: 0.978 - ETA: 55s - loss: 0.0837 - accuracy: 0.978 - ETA: 54s - loss: 0.0834 - accuracy: 0.978 - ETA: 52s - loss: 0.0836 - accuracy: 0.978 - ETA: 51s - loss: 0.0836 - accuracy: 0.978 - ETA: 50s - loss: 0.0832 - accuracy: 0.978 - ETA: 49s - loss: 0.0835 - accuracy: 0.978 - ETA: 48s - loss: 0.0839 - accuracy: 0.978 - ETA: 47s - loss: 0.0832 - accuracy: 0.978 - ETA: 45s - loss: 0.0837 - accuracy: 0.978 - ETA: 44s - loss: 0.0834 - accuracy: 0.978 - ETA: 43s - loss: 0.0855 - accuracy: 0.978 - ETA: 42s - loss: 0.0852 - accuracy: 0.978 - ETA: 41s - loss: 0.0848 - accuracy: 0.979 - ETA: 40s - loss: 0.0858 - accuracy: 0.978 - ETA: 39s - loss: 0.0857 - accuracy: 0.978 - ETA: 38s - loss: 0.0855 - accuracy: 0.978 - ETA: 37s - loss: 0.0860 - accuracy: 0.978 - ETA: 35s - loss: 0.0865 - accuracy: 0.978 - ETA: 34s - loss: 0.0870 - accuracy: 0.978 - ETA: 33s - loss: 0.0874 - accuracy: 0.978 - ETA: 32s - loss: 0.0879 - accuracy: 0.977 - ETA: 31s - loss: 0.0874 - accuracy: 0.978 - ETA: 30s - loss: 0.0876 - accuracy: 0.978 - ETA: 29s - loss: 0.0875 - accuracy: 0.978 - ETA: 27s - loss: 0.0868 - accuracy: 0.978 - ETA: 26s - loss: 0.0879 - accuracy: 0.977 - ETA: 25s - loss: 0.0885 - accuracy: 0.977 - ETA: 24s - loss: 0.0885 - accuracy: 0.977 - ETA: 23s - loss: 0.0880 - accuracy: 0.977 - ETA: 22s - loss: 0.0878 - accuracy: 0.977 - ETA: 21s - loss: 0.0880 - accuracy: 0.977 - ETA: 20s - loss: 0.0872 - accuracy: 0.977 - ETA: 18s - loss: 0.0880 - accuracy: 0.977 - ETA: 17s - loss: 0.0889 - accuracy: 0.977 - ETA: 16s - loss: 0.0884 - accuracy: 0.977 - ETA: 15s - loss: 0.0890 - accuracy: 0.977 - ETA: 14s - loss: 0.0887 - accuracy: 0.977 - ETA: 13s - loss: 0.0903 - accuracy: 0.977 - ETA: 12s - loss: 0.0905 - accuracy: 0.977 - ETA: 10s - loss: 0.0905 - accuracy: 0.977 - ETA: 9s - loss: 0.0897 - accuracy: 0.977 - ETA: 8s - loss: 0.0892 - accuracy: 0.97 - ETA: 7s - loss: 0.0895 - accuracy: 0.97 - ETA: 6s - loss: 0.0888 - accuracy: 0.97 - ETA: 5s - loss: 0.0889 - accuracy: 0.97 - ETA: 4s - loss: 0.0887 - accuracy: 0.97 - ETA: 3s - loss: 0.0885 - accuracy: 0.97 - ETA: 1s - loss: 0.0885 - accuracy: 0.97 - ETA: 0s - loss: 0.0885 - accuracy: 0.97 - 127s 10ms/step - loss: 0.0881 - accuracy: 0.9774 - val_loss: 3.1160 - val_accuracy: 0.4195\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:54 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0765 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0736 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0684 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0840 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0882 - accuracy: 0.97 - ETA: 1:43 - loss: 0.1165 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1166 - accuracy: 0.97 - ETA: 1:40 - loss: 0.1150 - accuracy: 0.97 - ETA: 1:39 - loss: 0.1159 - accuracy: 0.97 - ETA: 1:37 - loss: 0.1100 - accuracy: 0.97 - ETA: 1:36 - loss: 0.1109 - accuracy: 0.97 - ETA: 1:35 - loss: 0.1109 - accuracy: 0.97 - ETA: 1:34 - loss: 0.1080 - accuracy: 0.97 - ETA: 1:32 - loss: 0.1125 - accuracy: 0.97 - ETA: 1:31 - loss: 0.1127 - accuracy: 0.97 - ETA: 1:30 - loss: 0.1159 - accuracy: 0.97 - ETA: 1:29 - loss: 0.1133 - accuracy: 0.97 - ETA: 1:28 - loss: 0.1151 - accuracy: 0.97 - ETA: 1:27 - loss: 0.1198 - accuracy: 0.97 - ETA: 1:26 - loss: 0.1163 - accuracy: 0.97 - ETA: 1:24 - loss: 0.1156 - accuracy: 0.97 - ETA: 1:23 - loss: 0.1159 - accuracy: 0.97 - ETA: 1:22 - loss: 0.1128 - accuracy: 0.97 - ETA: 1:21 - loss: 0.1119 - accuracy: 0.97 - ETA: 1:20 - loss: 0.1129 - accuracy: 0.97 - ETA: 1:19 - loss: 0.1133 - accuracy: 0.97 - ETA: 1:17 - loss: 0.1113 - accuracy: 0.97 - ETA: 1:16 - loss: 0.1107 - accuracy: 0.97 - ETA: 1:15 - loss: 0.1100 - accuracy: 0.97 - ETA: 1:14 - loss: 0.1106 - accuracy: 0.97 - ETA: 1:13 - loss: 0.1107 - accuracy: 0.97 - ETA: 1:12 - loss: 0.1086 - accuracy: 0.97 - ETA: 1:11 - loss: 0.1077 - accuracy: 0.97 - ETA: 1:10 - loss: 0.1070 - accuracy: 0.97 - ETA: 1:09 - loss: 0.1070 - accuracy: 0.97 - ETA: 1:08 - loss: 0.1050 - accuracy: 0.97 - ETA: 1:06 - loss: 0.1034 - accuracy: 0.97 - ETA: 1:05 - loss: 0.1024 - accuracy: 0.97 - ETA: 1:04 - loss: 0.1033 - accuracy: 0.97 - ETA: 1:03 - loss: 0.1037 - accuracy: 0.97 - ETA: 1:02 - loss: 0.1030 - accuracy: 0.97 - ETA: 1:01 - loss: 0.1012 - accuracy: 0.97 - ETA: 1:00 - loss: 0.1029 - accuracy: 0.97 - ETA: 59s - loss: 0.1025 - accuracy: 0.9742 - ETA: 57s - loss: 0.1061 - accuracy: 0.974 - ETA: 56s - loss: 0.1049 - accuracy: 0.974 - ETA: 55s - loss: 0.1039 - accuracy: 0.974 - ETA: 54s - loss: 0.1061 - accuracy: 0.973 - ETA: 53s - loss: 0.1072 - accuracy: 0.973 - ETA: 52s - loss: 0.1058 - accuracy: 0.974 - ETA: 51s - loss: 0.1059 - accuracy: 0.974 - ETA: 50s - loss: 0.1060 - accuracy: 0.974 - ETA: 48s - loss: 0.1054 - accuracy: 0.974 - ETA: 47s - loss: 0.1083 - accuracy: 0.974 - ETA: 46s - loss: 0.1084 - accuracy: 0.973 - ETA: 45s - loss: 0.1070 - accuracy: 0.974 - ETA: 44s - loss: 0.1069 - accuracy: 0.973 - ETA: 43s - loss: 0.1066 - accuracy: 0.973 - ETA: 42s - loss: 0.1056 - accuracy: 0.973 - ETA: 41s - loss: 0.1061 - accuracy: 0.973 - ETA: 40s - loss: 0.1063 - accuracy: 0.973 - ETA: 39s - loss: 0.1070 - accuracy: 0.973 - ETA: 37s - loss: 0.1069 - accuracy: 0.973 - ETA: 36s - loss: 0.1056 - accuracy: 0.974 - ETA: 35s - loss: 0.1058 - accuracy: 0.973 - ETA: 34s - loss: 0.1054 - accuracy: 0.974 - ETA: 33s - loss: 0.1061 - accuracy: 0.974 - ETA: 32s - loss: 0.1054 - accuracy: 0.974 - ETA: 31s - loss: 0.1042 - accuracy: 0.974 - ETA: 30s - loss: 0.1037 - accuracy: 0.974 - ETA: 28s - loss: 0.1033 - accuracy: 0.974 - ETA: 27s - loss: 0.1028 - accuracy: 0.974 - ETA: 26s - loss: 0.1024 - accuracy: 0.974 - ETA: 25s - loss: 0.1023 - accuracy: 0.974 - ETA: 24s - loss: 0.1033 - accuracy: 0.974 - ETA: 23s - loss: 0.1030 - accuracy: 0.974 - ETA: 22s - loss: 0.1028 - accuracy: 0.974 - ETA: 21s - loss: 0.1027 - accuracy: 0.974 - ETA: 19s - loss: 0.1021 - accuracy: 0.974 - ETA: 18s - loss: 0.1015 - accuracy: 0.974 - ETA: 17s - loss: 0.1008 - accuracy: 0.974 - ETA: 16s - loss: 0.1004 - accuracy: 0.974 - ETA: 15s - loss: 0.0998 - accuracy: 0.974 - ETA: 14s - loss: 0.1000 - accuracy: 0.974 - ETA: 13s - loss: 0.0996 - accuracy: 0.974 - ETA: 12s - loss: 0.0992 - accuracy: 0.974 - ETA: 10s - loss: 0.0992 - accuracy: 0.974 - ETA: 9s - loss: 0.0988 - accuracy: 0.974 - ETA: 8s - loss: 0.0985 - accuracy: 0.97 - ETA: 7s - loss: 0.0987 - accuracy: 0.97 - ETA: 6s - loss: 0.0983 - accuracy: 0.97 - ETA: 5s - loss: 0.0995 - accuracy: 0.97 - ETA: 4s - loss: 0.0993 - accuracy: 0.97 - ETA: 3s - loss: 0.0991 - accuracy: 0.97 - ETA: 1s - loss: 0.0995 - accuracy: 0.97 - ETA: 0s - loss: 0.0992 - accuracy: 0.97 - 126s 10ms/step - loss: 0.0989 - accuracy: 0.9748 - val_loss: 3.4189 - val_accuracy: 0.3679\n",
      "Epoch 36/100\n",
      "13022/13022 [==============================] - ETA: 2:01 - loss: 0.0693 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0659 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0684 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0621 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0723 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0813 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0813 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0786 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0828 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0873 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0928 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0906 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0922 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0902 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0891 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0886 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0868 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0877 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0857 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0861 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0862 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0860 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0846 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0850 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0853 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0845 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0855 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0851 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0840 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0849 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0844 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0831 - accuracy: 0.97 - ETA: 59s - loss: 0.0830 - accuracy: 0.9775 - ETA: 58s - loss: 0.0825 - accuracy: 0.977 - ETA: 57s - loss: 0.0836 - accuracy: 0.977 - ETA: 56s - loss: 0.0837 - accuracy: 0.977 - ETA: 55s - loss: 0.0827 - accuracy: 0.977 - ETA: 54s - loss: 0.0817 - accuracy: 0.978 - ETA: 53s - loss: 0.0822 - accuracy: 0.978 - ETA: 52s - loss: 0.0822 - accuracy: 0.977 - ETA: 51s - loss: 0.0819 - accuracy: 0.977 - ETA: 50s - loss: 0.0829 - accuracy: 0.977 - ETA: 48s - loss: 0.0827 - accuracy: 0.977 - ETA: 47s - loss: 0.0827 - accuracy: 0.977 - ETA: 46s - loss: 0.0829 - accuracy: 0.977 - ETA: 45s - loss: 0.0824 - accuracy: 0.978 - ETA: 44s - loss: 0.0826 - accuracy: 0.977 - ETA: 43s - loss: 0.0819 - accuracy: 0.978 - ETA: 42s - loss: 0.0813 - accuracy: 0.978 - ETA: 41s - loss: 0.0806 - accuracy: 0.978 - ETA: 39s - loss: 0.0812 - accuracy: 0.978 - ETA: 38s - loss: 0.0807 - accuracy: 0.978 - ETA: 37s - loss: 0.0798 - accuracy: 0.978 - ETA: 36s - loss: 0.0796 - accuracy: 0.978 - ETA: 35s - loss: 0.0797 - accuracy: 0.978 - ETA: 34s - loss: 0.0796 - accuracy: 0.978 - ETA: 33s - loss: 0.0800 - accuracy: 0.978 - ETA: 32s - loss: 0.0806 - accuracy: 0.978 - ETA: 31s - loss: 0.0796 - accuracy: 0.978 - ETA: 29s - loss: 0.0794 - accuracy: 0.978 - ETA: 28s - loss: 0.0789 - accuracy: 0.978 - ETA: 27s - loss: 0.0786 - accuracy: 0.978 - ETA: 26s - loss: 0.0793 - accuracy: 0.978 - ETA: 25s - loss: 0.0789 - accuracy: 0.978 - ETA: 24s - loss: 0.0786 - accuracy: 0.978 - ETA: 23s - loss: 0.0787 - accuracy: 0.978 - ETA: 22s - loss: 0.0786 - accuracy: 0.978 - ETA: 20s - loss: 0.0786 - accuracy: 0.978 - ETA: 19s - loss: 0.0784 - accuracy: 0.978 - ETA: 18s - loss: 0.0783 - accuracy: 0.978 - ETA: 17s - loss: 0.0784 - accuracy: 0.978 - ETA: 16s - loss: 0.0779 - accuracy: 0.978 - ETA: 15s - loss: 0.0772 - accuracy: 0.979 - ETA: 14s - loss: 0.0774 - accuracy: 0.978 - ETA: 13s - loss: 0.0771 - accuracy: 0.979 - ETA: 11s - loss: 0.0764 - accuracy: 0.979 - ETA: 10s - loss: 0.0764 - accuracy: 0.979 - ETA: 9s - loss: 0.0760 - accuracy: 0.979 - ETA: 8s - loss: 0.0771 - accuracy: 0.97 - ETA: 7s - loss: 0.0769 - accuracy: 0.97 - ETA: 6s - loss: 0.0768 - accuracy: 0.97 - ETA: 5s - loss: 0.0768 - accuracy: 0.97 - ETA: 4s - loss: 0.0779 - accuracy: 0.97 - ETA: 3s - loss: 0.0780 - accuracy: 0.97 - ETA: 1s - loss: 0.0783 - accuracy: 0.97 - ETA: 0s - loss: 0.0780 - accuracy: 0.97 - 126s 10ms/step - loss: 0.0779 - accuracy: 0.9787 - val_loss: 3.2981 - val_accuracy: 0.4042\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:51 - loss: 0.1513 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0992 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0788 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0905 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0844 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0779 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0841 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0859 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0916 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0844 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0802 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0762 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0691 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0687 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0742 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0763 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0768 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0746 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0812 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0799 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0827 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0814 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0817 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0815 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0816 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0808 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0804 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0805 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0794 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0783 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0781 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0777 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0790 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0778 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0783 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0794 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0810 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0805 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0797 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0792 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0791 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0786 - accuracy: 0.98 - ETA: 59s - loss: 0.0772 - accuracy: 0.9820 - ETA: 58s - loss: 0.0780 - accuracy: 0.981 - ETA: 57s - loss: 0.0780 - accuracy: 0.981 - ETA: 55s - loss: 0.0778 - accuracy: 0.981 - ETA: 54s - loss: 0.0772 - accuracy: 0.981 - ETA: 53s - loss: 0.0764 - accuracy: 0.981 - ETA: 52s - loss: 0.0760 - accuracy: 0.981 - ETA: 51s - loss: 0.0755 - accuracy: 0.981 - ETA: 50s - loss: 0.0747 - accuracy: 0.981 - ETA: 49s - loss: 0.0753 - accuracy: 0.981 - ETA: 48s - loss: 0.0744 - accuracy: 0.981 - ETA: 46s - loss: 0.0736 - accuracy: 0.981 - ETA: 45s - loss: 0.0741 - accuracy: 0.981 - ETA: 44s - loss: 0.0732 - accuracy: 0.981 - ETA: 43s - loss: 0.0728 - accuracy: 0.981 - ETA: 42s - loss: 0.0725 - accuracy: 0.981 - ETA: 41s - loss: 0.0717 - accuracy: 0.981 - ETA: 40s - loss: 0.0720 - accuracy: 0.981 - ETA: 38s - loss: 0.0721 - accuracy: 0.981 - ETA: 37s - loss: 0.0714 - accuracy: 0.981 - ETA: 36s - loss: 0.0707 - accuracy: 0.982 - ETA: 35s - loss: 0.0699 - accuracy: 0.982 - ETA: 34s - loss: 0.0695 - accuracy: 0.982 - ETA: 33s - loss: 0.0703 - accuracy: 0.982 - ETA: 31s - loss: 0.0698 - accuracy: 0.982 - ETA: 30s - loss: 0.0692 - accuracy: 0.982 - ETA: 29s - loss: 0.0685 - accuracy: 0.982 - ETA: 28s - loss: 0.0686 - accuracy: 0.982 - ETA: 27s - loss: 0.0697 - accuracy: 0.982 - ETA: 26s - loss: 0.0695 - accuracy: 0.982 - ETA: 24s - loss: 0.0692 - accuracy: 0.982 - ETA: 23s - loss: 0.0689 - accuracy: 0.982 - ETA: 22s - loss: 0.0701 - accuracy: 0.982 - ETA: 21s - loss: 0.0707 - accuracy: 0.981 - ETA: 20s - loss: 0.0705 - accuracy: 0.981 - ETA: 19s - loss: 0.0702 - accuracy: 0.981 - ETA: 17s - loss: 0.0700 - accuracy: 0.981 - ETA: 16s - loss: 0.0698 - accuracy: 0.981 - ETA: 15s - loss: 0.0709 - accuracy: 0.981 - ETA: 14s - loss: 0.0705 - accuracy: 0.981 - ETA: 13s - loss: 0.0700 - accuracy: 0.981 - ETA: 12s - loss: 0.0722 - accuracy: 0.981 - ETA: 11s - loss: 0.0717 - accuracy: 0.981 - ETA: 9s - loss: 0.0717 - accuracy: 0.981 - ETA: 8s - loss: 0.0728 - accuracy: 0.98 - ETA: 7s - loss: 0.0733 - accuracy: 0.98 - ETA: 6s - loss: 0.0735 - accuracy: 0.98 - ETA: 5s - loss: 0.0738 - accuracy: 0.98 - ETA: 4s - loss: 0.0736 - accuracy: 0.98 - ETA: 3s - loss: 0.0742 - accuracy: 0.98 - ETA: 1s - loss: 0.0738 - accuracy: 0.98 - ETA: 0s - loss: 0.0740 - accuracy: 0.98 - 129s 10ms/step - loss: 0.0746 - accuracy: 0.9805 - val_loss: 3.4351 - val_accuracy: 0.3821\n",
      "Epoch 38/100\n",
      "13022/13022 [==============================] - ETA: 1:54 - loss: 0.0194 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0848 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0645 - accuracy: 0.98 - ETA: 1:49 - loss: 0.1145 - accuracy: 0.98 - ETA: 1:46 - loss: 0.1140 - accuracy: 0.97 - ETA: 1:46 - loss: 0.1004 - accuracy: 0.98 - ETA: 1:44 - loss: 0.1137 - accuracy: 0.97 - ETA: 1:43 - loss: 0.1030 - accuracy: 0.97 - ETA: 1:42 - loss: 0.1026 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1019 - accuracy: 0.97 - ETA: 1:40 - loss: 0.1004 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0939 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0918 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0912 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0895 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0879 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0995 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0962 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0959 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0992 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0982 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0987 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0984 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0991 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0967 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0960 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0980 - accuracy: 0.97 - ETA: 1:22 - loss: 0.1000 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0979 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0950 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0929 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0911 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0931 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0913 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0915 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0906 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0897 - accuracy: 0.97 - ETA: 1:10 - loss: 0.0904 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0904 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0927 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0919 - accuracy: 0.97 - ETA: 1:06 - loss: 0.0939 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0950 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0950 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0943 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0929 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0925 - accuracy: 0.97 - ETA: 59s - loss: 0.0912 - accuracy: 0.9783 - ETA: 57s - loss: 0.0912 - accuracy: 0.978 - ETA: 56s - loss: 0.0901 - accuracy: 0.978 - ETA: 55s - loss: 0.0905 - accuracy: 0.978 - ETA: 54s - loss: 0.0894 - accuracy: 0.978 - ETA: 53s - loss: 0.0890 - accuracy: 0.978 - ETA: 52s - loss: 0.0884 - accuracy: 0.978 - ETA: 51s - loss: 0.0874 - accuracy: 0.978 - ETA: 50s - loss: 0.0886 - accuracy: 0.978 - ETA: 48s - loss: 0.0874 - accuracy: 0.978 - ETA: 47s - loss: 0.0867 - accuracy: 0.978 - ETA: 46s - loss: 0.0860 - accuracy: 0.978 - ETA: 45s - loss: 0.0859 - accuracy: 0.978 - ETA: 44s - loss: 0.0854 - accuracy: 0.979 - ETA: 43s - loss: 0.0857 - accuracy: 0.978 - ETA: 42s - loss: 0.0856 - accuracy: 0.978 - ETA: 41s - loss: 0.0846 - accuracy: 0.979 - ETA: 39s - loss: 0.0838 - accuracy: 0.979 - ETA: 38s - loss: 0.0830 - accuracy: 0.979 - ETA: 37s - loss: 0.0830 - accuracy: 0.979 - ETA: 36s - loss: 0.0823 - accuracy: 0.979 - ETA: 35s - loss: 0.0817 - accuracy: 0.979 - ETA: 34s - loss: 0.0817 - accuracy: 0.979 - ETA: 33s - loss: 0.0814 - accuracy: 0.979 - ETA: 32s - loss: 0.0809 - accuracy: 0.979 - ETA: 31s - loss: 0.0812 - accuracy: 0.979 - ETA: 29s - loss: 0.0823 - accuracy: 0.979 - ETA: 28s - loss: 0.0817 - accuracy: 0.979 - ETA: 27s - loss: 0.0813 - accuracy: 0.979 - ETA: 26s - loss: 0.0806 - accuracy: 0.979 - ETA: 25s - loss: 0.0800 - accuracy: 0.979 - ETA: 24s - loss: 0.0813 - accuracy: 0.979 - ETA: 23s - loss: 0.0818 - accuracy: 0.979 - ETA: 22s - loss: 0.0826 - accuracy: 0.978 - ETA: 20s - loss: 0.0823 - accuracy: 0.978 - ETA: 19s - loss: 0.0816 - accuracy: 0.979 - ETA: 18s - loss: 0.0812 - accuracy: 0.979 - ETA: 17s - loss: 0.0810 - accuracy: 0.979 - ETA: 16s - loss: 0.0814 - accuracy: 0.979 - ETA: 15s - loss: 0.0808 - accuracy: 0.979 - ETA: 14s - loss: 0.0810 - accuracy: 0.979 - ETA: 13s - loss: 0.0805 - accuracy: 0.979 - ETA: 11s - loss: 0.0803 - accuracy: 0.979 - ETA: 10s - loss: 0.0810 - accuracy: 0.979 - ETA: 9s - loss: 0.0810 - accuracy: 0.979 - ETA: 8s - loss: 0.0811 - accuracy: 0.97 - ETA: 7s - loss: 0.0806 - accuracy: 0.97 - ETA: 6s - loss: 0.0811 - accuracy: 0.97 - ETA: 5s - loss: 0.0817 - accuracy: 0.97 - ETA: 4s - loss: 0.0815 - accuracy: 0.97 - ETA: 3s - loss: 0.0813 - accuracy: 0.97 - ETA: 1s - loss: 0.0819 - accuracy: 0.97 - ETA: 0s - loss: 0.0815 - accuracy: 0.97 - 127s 10ms/step - loss: 0.0812 - accuracy: 0.9796 - val_loss: 3.2322 - val_accuracy: 0.4097\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:53 - loss: 0.0627 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0857 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0687 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0764 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0788 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0763 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0842 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0839 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0808 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0791 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0780 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:20 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:19 - loss: 0.0786 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0769 - accuracy: 0.97 - ETA: 1:17 - loss: 0.0767 - accuracy: 0.97 - ETA: 1:16 - loss: 0.0772 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:14 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0747 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0763 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0759 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0766 - accuracy: 0.97 - ETA: 1:09 - loss: 0.0770 - accuracy: 0.97 - ETA: 1:08 - loss: 0.0768 - accuracy: 0.97 - ETA: 1:07 - loss: 0.0787 - accuracy: 0.97 - ETA: 1:05 - loss: 0.0778 - accuracy: 0.97 - ETA: 1:04 - loss: 0.0813 - accuracy: 0.97 - ETA: 1:03 - loss: 0.0799 - accuracy: 0.97 - ETA: 1:02 - loss: 0.0789 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:00 - loss: 0.0767 - accuracy: 0.97 - ETA: 59s - loss: 0.0759 - accuracy: 0.9799 - ETA: 57s - loss: 0.0752 - accuracy: 0.980 - ETA: 56s - loss: 0.0755 - accuracy: 0.979 - ETA: 55s - loss: 0.0745 - accuracy: 0.980 - ETA: 54s - loss: 0.0739 - accuracy: 0.979 - ETA: 53s - loss: 0.0737 - accuracy: 0.979 - ETA: 52s - loss: 0.0757 - accuracy: 0.979 - ETA: 51s - loss: 0.0751 - accuracy: 0.979 - ETA: 50s - loss: 0.0743 - accuracy: 0.979 - ETA: 49s - loss: 0.0749 - accuracy: 0.979 - ETA: 48s - loss: 0.0758 - accuracy: 0.978 - ETA: 47s - loss: 0.0753 - accuracy: 0.979 - ETA: 45s - loss: 0.0745 - accuracy: 0.979 - ETA: 44s - loss: 0.0741 - accuracy: 0.979 - ETA: 43s - loss: 0.0749 - accuracy: 0.979 - ETA: 42s - loss: 0.0767 - accuracy: 0.978 - ETA: 41s - loss: 0.0760 - accuracy: 0.979 - ETA: 40s - loss: 0.0766 - accuracy: 0.978 - ETA: 39s - loss: 0.0764 - accuracy: 0.978 - ETA: 37s - loss: 0.0756 - accuracy: 0.979 - ETA: 36s - loss: 0.0761 - accuracy: 0.979 - ETA: 35s - loss: 0.0768 - accuracy: 0.979 - ETA: 34s - loss: 0.0771 - accuracy: 0.978 - ETA: 33s - loss: 0.0765 - accuracy: 0.978 - ETA: 32s - loss: 0.0764 - accuracy: 0.978 - ETA: 31s - loss: 0.0770 - accuracy: 0.978 - ETA: 30s - loss: 0.0766 - accuracy: 0.978 - ETA: 28s - loss: 0.0769 - accuracy: 0.978 - ETA: 27s - loss: 0.0769 - accuracy: 0.978 - ETA: 26s - loss: 0.0768 - accuracy: 0.978 - ETA: 25s - loss: 0.0774 - accuracy: 0.978 - ETA: 24s - loss: 0.0775 - accuracy: 0.978 - ETA: 23s - loss: 0.0770 - accuracy: 0.978 - ETA: 22s - loss: 0.0782 - accuracy: 0.978 - ETA: 21s - loss: 0.0800 - accuracy: 0.978 - ETA: 19s - loss: 0.0803 - accuracy: 0.978 - ETA: 18s - loss: 0.0803 - accuracy: 0.978 - ETA: 17s - loss: 0.0798 - accuracy: 0.978 - ETA: 16s - loss: 0.0811 - accuracy: 0.978 - ETA: 15s - loss: 0.0805 - accuracy: 0.978 - ETA: 14s - loss: 0.0800 - accuracy: 0.978 - ETA: 13s - loss: 0.0802 - accuracy: 0.978 - ETA: 12s - loss: 0.0807 - accuracy: 0.977 - ETA: 10s - loss: 0.0804 - accuracy: 0.977 - ETA: 9s - loss: 0.0798 - accuracy: 0.978 - ETA: 8s - loss: 0.0799 - accuracy: 0.97 - ETA: 7s - loss: 0.0792 - accuracy: 0.97 - ETA: 6s - loss: 0.0793 - accuracy: 0.97 - ETA: 5s - loss: 0.0790 - accuracy: 0.97 - ETA: 4s - loss: 0.0783 - accuracy: 0.97 - ETA: 3s - loss: 0.0783 - accuracy: 0.97 - ETA: 1s - loss: 0.0782 - accuracy: 0.97 - ETA: 0s - loss: 0.0785 - accuracy: 0.97 - 127s 10ms/step - loss: 0.0793 - accuracy: 0.9781 - val_loss: 3.1909 - val_accuracy: 0.4086\n",
      "Epoch 40/100\n",
      "13022/13022 [==============================] - ETA: 1:53 - loss: 0.0913 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0924 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0717 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0698 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0744 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0776 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0770 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0712 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0748 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0747 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0743 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0778 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0782 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0755 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0775 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0747 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0785 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0794 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0793 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0819 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0828 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0818 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0805 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0790 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0783 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0778 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0762 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0755 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0749 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0760 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0750 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0740 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0729 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0731 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0730 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0720 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0724 - accuracy: 0.98 - ETA: 59s - loss: 0.0716 - accuracy: 0.9821 - ETA: 58s - loss: 0.0710 - accuracy: 0.982 - ETA: 56s - loss: 0.0729 - accuracy: 0.981 - ETA: 55s - loss: 0.0735 - accuracy: 0.981 - ETA: 54s - loss: 0.0737 - accuracy: 0.981 - ETA: 53s - loss: 0.0730 - accuracy: 0.981 - ETA: 52s - loss: 0.0723 - accuracy: 0.981 - ETA: 51s - loss: 0.0716 - accuracy: 0.981 - ETA: 50s - loss: 0.0710 - accuracy: 0.981 - ETA: 49s - loss: 0.0707 - accuracy: 0.982 - ETA: 48s - loss: 0.0717 - accuracy: 0.981 - ETA: 47s - loss: 0.0712 - accuracy: 0.981 - ETA: 46s - loss: 0.0728 - accuracy: 0.981 - ETA: 45s - loss: 0.0730 - accuracy: 0.981 - ETA: 44s - loss: 0.0746 - accuracy: 0.980 - ETA: 43s - loss: 0.0738 - accuracy: 0.981 - ETA: 42s - loss: 0.0741 - accuracy: 0.981 - ETA: 41s - loss: 0.0744 - accuracy: 0.980 - ETA: 40s - loss: 0.0759 - accuracy: 0.980 - ETA: 39s - loss: 0.0755 - accuracy: 0.980 - ETA: 38s - loss: 0.0748 - accuracy: 0.980 - ETA: 37s - loss: 0.0755 - accuracy: 0.980 - ETA: 35s - loss: 0.0756 - accuracy: 0.980 - ETA: 34s - loss: 0.0754 - accuracy: 0.980 - ETA: 33s - loss: 0.0754 - accuracy: 0.980 - ETA: 32s - loss: 0.0754 - accuracy: 0.980 - ETA: 31s - loss: 0.0754 - accuracy: 0.980 - ETA: 30s - loss: 0.0747 - accuracy: 0.980 - ETA: 29s - loss: 0.0741 - accuracy: 0.980 - ETA: 27s - loss: 0.0739 - accuracy: 0.980 - ETA: 26s - loss: 0.0738 - accuracy: 0.980 - ETA: 25s - loss: 0.0736 - accuracy: 0.980 - ETA: 24s - loss: 0.0756 - accuracy: 0.980 - ETA: 23s - loss: 0.0765 - accuracy: 0.980 - ETA: 22s - loss: 0.0775 - accuracy: 0.980 - ETA: 20s - loss: 0.0779 - accuracy: 0.980 - ETA: 19s - loss: 0.0781 - accuracy: 0.980 - ETA: 18s - loss: 0.0775 - accuracy: 0.980 - ETA: 17s - loss: 0.0775 - accuracy: 0.980 - ETA: 16s - loss: 0.0789 - accuracy: 0.980 - ETA: 14s - loss: 0.0791 - accuracy: 0.980 - ETA: 13s - loss: 0.0789 - accuracy: 0.980 - ETA: 12s - loss: 0.0793 - accuracy: 0.980 - ETA: 11s - loss: 0.0787 - accuracy: 0.980 - ETA: 10s - loss: 0.0799 - accuracy: 0.980 - ETA: 9s - loss: 0.0809 - accuracy: 0.980 - ETA: 7s - loss: 0.0806 - accuracy: 0.98 - ETA: 6s - loss: 0.0801 - accuracy: 0.98 - ETA: 5s - loss: 0.0797 - accuracy: 0.98 - ETA: 4s - loss: 0.0799 - accuracy: 0.98 - ETA: 3s - loss: 0.0798 - accuracy: 0.98 - ETA: 2s - loss: 0.0809 - accuracy: 0.98 - ETA: 0s - loss: 0.0809 - accuracy: 0.98 - 132s 10ms/step - loss: 0.0813 - accuracy: 0.9800 - val_loss: 3.2606 - val_accuracy: 0.3848\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:57 - loss: 0.0221 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:50 - loss: 0.1204 - accuracy: 0.97 - ETA: 1:48 - loss: 0.1079 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0914 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0818 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0834 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0873 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0855 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0774 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0798 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0771 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0750 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0671 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0688 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0692 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0685 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0735 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0740 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0751 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0743 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0747 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0761 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0740 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0747 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0740 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0699 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0731 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0730 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0718 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0711 - accuracy: 0.98 - ETA: 59s - loss: 0.0707 - accuracy: 0.9829 - ETA: 58s - loss: 0.0712 - accuracy: 0.982 - ETA: 57s - loss: 0.0709 - accuracy: 0.982 - ETA: 56s - loss: 0.0702 - accuracy: 0.982 - ETA: 55s - loss: 0.0695 - accuracy: 0.982 - ETA: 54s - loss: 0.0690 - accuracy: 0.982 - ETA: 53s - loss: 0.0699 - accuracy: 0.982 - ETA: 52s - loss: 0.0689 - accuracy: 0.983 - ETA: 51s - loss: 0.0687 - accuracy: 0.982 - ETA: 50s - loss: 0.0685 - accuracy: 0.982 - ETA: 48s - loss: 0.0697 - accuracy: 0.982 - ETA: 47s - loss: 0.0692 - accuracy: 0.982 - ETA: 46s - loss: 0.0707 - accuracy: 0.982 - ETA: 45s - loss: 0.0701 - accuracy: 0.982 - ETA: 44s - loss: 0.0691 - accuracy: 0.982 - ETA: 43s - loss: 0.0684 - accuracy: 0.982 - ETA: 42s - loss: 0.0685 - accuracy: 0.982 - ETA: 40s - loss: 0.0679 - accuracy: 0.982 - ETA: 39s - loss: 0.0679 - accuracy: 0.982 - ETA: 38s - loss: 0.0672 - accuracy: 0.982 - ETA: 37s - loss: 0.0664 - accuracy: 0.983 - ETA: 36s - loss: 0.0666 - accuracy: 0.983 - ETA: 35s - loss: 0.0662 - accuracy: 0.983 - ETA: 34s - loss: 0.0656 - accuracy: 0.983 - ETA: 33s - loss: 0.0654 - accuracy: 0.983 - ETA: 32s - loss: 0.0657 - accuracy: 0.983 - ETA: 31s - loss: 0.0655 - accuracy: 0.983 - ETA: 29s - loss: 0.0651 - accuracy: 0.983 - ETA: 28s - loss: 0.0647 - accuracy: 0.983 - ETA: 27s - loss: 0.0646 - accuracy: 0.983 - ETA: 26s - loss: 0.0658 - accuracy: 0.983 - ETA: 25s - loss: 0.0656 - accuracy: 0.983 - ETA: 24s - loss: 0.0654 - accuracy: 0.983 - ETA: 23s - loss: 0.0653 - accuracy: 0.983 - ETA: 22s - loss: 0.0657 - accuracy: 0.983 - ETA: 20s - loss: 0.0652 - accuracy: 0.983 - ETA: 19s - loss: 0.0651 - accuracy: 0.983 - ETA: 18s - loss: 0.0652 - accuracy: 0.983 - ETA: 17s - loss: 0.0650 - accuracy: 0.983 - ETA: 16s - loss: 0.0647 - accuracy: 0.983 - ETA: 15s - loss: 0.0648 - accuracy: 0.983 - ETA: 14s - loss: 0.0644 - accuracy: 0.983 - ETA: 13s - loss: 0.0639 - accuracy: 0.983 - ETA: 12s - loss: 0.0640 - accuracy: 0.983 - ETA: 10s - loss: 0.0636 - accuracy: 0.983 - ETA: 9s - loss: 0.0631 - accuracy: 0.983 - ETA: 8s - loss: 0.0626 - accuracy: 0.98 - ETA: 7s - loss: 0.0625 - accuracy: 0.98 - ETA: 6s - loss: 0.0629 - accuracy: 0.98 - ETA: 5s - loss: 0.0632 - accuracy: 0.98 - ETA: 4s - loss: 0.0630 - accuracy: 0.98 - ETA: 3s - loss: 0.0633 - accuracy: 0.98 - ETA: 1s - loss: 0.0633 - accuracy: 0.98 - ETA: 0s - loss: 0.0630 - accuracy: 0.98 - 125s 10ms/step - loss: 0.0631 - accuracy: 0.9832 - val_loss: 3.5007 - val_accuracy: 0.3727\n",
      "Epoch 42/100\n",
      "13022/13022 [==============================] - ETA: 1:57 - loss: 0.1112 - accuracy: 0.96 - ETA: 1:54 - loss: 0.0857 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0966 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0894 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0898 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0804 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0717 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0704 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0698 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0684 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0704 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0685 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0778 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0773 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0752 - accuracy: 0.97 - ETA: 1:30 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0741 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0753 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0725 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0732 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0688 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0747 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0741 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0708 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0695 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0708 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0744 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0745 - accuracy: 0.98 - ETA: 59s - loss: 0.0752 - accuracy: 0.9808 - ETA: 58s - loss: 0.0749 - accuracy: 0.980 - ETA: 57s - loss: 0.0766 - accuracy: 0.980 - ETA: 56s - loss: 0.0757 - accuracy: 0.980 - ETA: 54s - loss: 0.0764 - accuracy: 0.980 - ETA: 53s - loss: 0.0759 - accuracy: 0.980 - ETA: 52s - loss: 0.0756 - accuracy: 0.980 - ETA: 51s - loss: 0.0754 - accuracy: 0.980 - ETA: 50s - loss: 0.0794 - accuracy: 0.979 - ETA: 49s - loss: 0.0803 - accuracy: 0.979 - ETA: 48s - loss: 0.0792 - accuracy: 0.979 - ETA: 47s - loss: 0.0792 - accuracy: 0.979 - ETA: 46s - loss: 0.0796 - accuracy: 0.979 - ETA: 45s - loss: 0.0798 - accuracy: 0.979 - ETA: 43s - loss: 0.0811 - accuracy: 0.979 - ETA: 42s - loss: 0.0812 - accuracy: 0.978 - ETA: 41s - loss: 0.0803 - accuracy: 0.979 - ETA: 40s - loss: 0.0799 - accuracy: 0.979 - ETA: 39s - loss: 0.0817 - accuracy: 0.979 - ETA: 38s - loss: 0.0808 - accuracy: 0.979 - ETA: 37s - loss: 0.0803 - accuracy: 0.979 - ETA: 36s - loss: 0.0804 - accuracy: 0.979 - ETA: 35s - loss: 0.0798 - accuracy: 0.980 - ETA: 34s - loss: 0.0800 - accuracy: 0.979 - ETA: 33s - loss: 0.0792 - accuracy: 0.980 - ETA: 32s - loss: 0.0783 - accuracy: 0.980 - ETA: 30s - loss: 0.0781 - accuracy: 0.980 - ETA: 29s - loss: 0.0777 - accuracy: 0.980 - ETA: 28s - loss: 0.0771 - accuracy: 0.980 - ETA: 27s - loss: 0.0770 - accuracy: 0.980 - ETA: 26s - loss: 0.0776 - accuracy: 0.980 - ETA: 25s - loss: 0.0785 - accuracy: 0.980 - ETA: 24s - loss: 0.0783 - accuracy: 0.980 - ETA: 23s - loss: 0.0777 - accuracy: 0.980 - ETA: 21s - loss: 0.0774 - accuracy: 0.980 - ETA: 20s - loss: 0.0788 - accuracy: 0.979 - ETA: 19s - loss: 0.0782 - accuracy: 0.979 - ETA: 18s - loss: 0.0788 - accuracy: 0.979 - ETA: 17s - loss: 0.0804 - accuracy: 0.979 - ETA: 16s - loss: 0.0797 - accuracy: 0.979 - ETA: 15s - loss: 0.0796 - accuracy: 0.979 - ETA: 14s - loss: 0.0798 - accuracy: 0.979 - ETA: 13s - loss: 0.0795 - accuracy: 0.979 - ETA: 11s - loss: 0.0792 - accuracy: 0.979 - ETA: 10s - loss: 0.0790 - accuracy: 0.979 - ETA: 9s - loss: 0.0785 - accuracy: 0.979 - ETA: 8s - loss: 0.0783 - accuracy: 0.97 - ETA: 7s - loss: 0.0780 - accuracy: 0.97 - ETA: 6s - loss: 0.0790 - accuracy: 0.97 - ETA: 5s - loss: 0.0786 - accuracy: 0.97 - ETA: 4s - loss: 0.0783 - accuracy: 0.97 - ETA: 3s - loss: 0.0784 - accuracy: 0.97 - ETA: 1s - loss: 0.0782 - accuracy: 0.97 - ETA: 0s - loss: 0.0775 - accuracy: 0.97 - 125s 10ms/step - loss: 0.0794 - accuracy: 0.9798 - val_loss: 3.4548 - val_accuracy: 0.3750\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:53 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0377 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0792 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0797 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0845 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0830 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0809 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0924 - accuracy: 0.97 - ETA: 1:36 - loss: 0.1031 - accuracy: 0.97 - ETA: 1:34 - loss: 0.1004 - accuracy: 0.97 - ETA: 1:33 - loss: 0.1029 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0988 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0955 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0943 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0916 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0896 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0867 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0857 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0839 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0837 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0846 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0841 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0821 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0845 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0823 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0808 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0867 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0857 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0870 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0857 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0855 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0844 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0841 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0826 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0824 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0820 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0810 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0821 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0811 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0814 - accuracy: 0.98 - ETA: 59s - loss: 0.0815 - accuracy: 0.9804 - ETA: 57s - loss: 0.0807 - accuracy: 0.980 - ETA: 56s - loss: 0.0815 - accuracy: 0.980 - ETA: 55s - loss: 0.0812 - accuracy: 0.980 - ETA: 54s - loss: 0.0825 - accuracy: 0.980 - ETA: 53s - loss: 0.0817 - accuracy: 0.980 - ETA: 52s - loss: 0.0824 - accuracy: 0.980 - ETA: 51s - loss: 0.0827 - accuracy: 0.980 - ETA: 50s - loss: 0.0839 - accuracy: 0.980 - ETA: 48s - loss: 0.0848 - accuracy: 0.980 - ETA: 47s - loss: 0.0858 - accuracy: 0.980 - ETA: 46s - loss: 0.0858 - accuracy: 0.979 - ETA: 45s - loss: 0.0849 - accuracy: 0.979 - ETA: 44s - loss: 0.0842 - accuracy: 0.980 - ETA: 43s - loss: 0.0839 - accuracy: 0.980 - ETA: 42s - loss: 0.0844 - accuracy: 0.980 - ETA: 41s - loss: 0.0845 - accuracy: 0.980 - ETA: 40s - loss: 0.0847 - accuracy: 0.980 - ETA: 38s - loss: 0.0843 - accuracy: 0.980 - ETA: 37s - loss: 0.0836 - accuracy: 0.980 - ETA: 36s - loss: 0.0834 - accuracy: 0.980 - ETA: 35s - loss: 0.0842 - accuracy: 0.980 - ETA: 34s - loss: 0.0841 - accuracy: 0.980 - ETA: 33s - loss: 0.0833 - accuracy: 0.980 - ETA: 32s - loss: 0.0826 - accuracy: 0.980 - ETA: 31s - loss: 0.0827 - accuracy: 0.980 - ETA: 29s - loss: 0.0834 - accuracy: 0.979 - ETA: 28s - loss: 0.0830 - accuracy: 0.980 - ETA: 27s - loss: 0.0837 - accuracy: 0.980 - ETA: 26s - loss: 0.0841 - accuracy: 0.980 - ETA: 25s - loss: 0.0838 - accuracy: 0.980 - ETA: 24s - loss: 0.0862 - accuracy: 0.979 - ETA: 23s - loss: 0.0861 - accuracy: 0.979 - ETA: 22s - loss: 0.0855 - accuracy: 0.979 - ETA: 20s - loss: 0.0854 - accuracy: 0.979 - ETA: 19s - loss: 0.0854 - accuracy: 0.979 - ETA: 18s - loss: 0.0847 - accuracy: 0.979 - ETA: 17s - loss: 0.0848 - accuracy: 0.979 - ETA: 16s - loss: 0.0850 - accuracy: 0.979 - ETA: 15s - loss: 0.0845 - accuracy: 0.979 - ETA: 14s - loss: 0.0847 - accuracy: 0.979 - ETA: 13s - loss: 0.0851 - accuracy: 0.979 - ETA: 12s - loss: 0.0853 - accuracy: 0.979 - ETA: 10s - loss: 0.0850 - accuracy: 0.979 - ETA: 9s - loss: 0.0845 - accuracy: 0.979 - ETA: 8s - loss: 0.0847 - accuracy: 0.97 - ETA: 7s - loss: 0.0845 - accuracy: 0.97 - ETA: 6s - loss: 0.0842 - accuracy: 0.97 - ETA: 5s - loss: 0.0848 - accuracy: 0.97 - ETA: 4s - loss: 0.0842 - accuracy: 0.97 - ETA: 3s - loss: 0.0837 - accuracy: 0.97 - ETA: 1s - loss: 0.0835 - accuracy: 0.97 - ETA: 0s - loss: 0.0840 - accuracy: 0.97 - 126s 10ms/step - loss: 0.0835 - accuracy: 0.9795 - val_loss: 3.1943 - val_accuracy: 0.4268\n",
      "Epoch 44/100\n",
      "13022/13022 [==============================] - ETA: 2:03 - loss: 0.1065 - accuracy: 0.96 - ETA: 2:01 - loss: 0.0735 - accuracy: 0.97 - ETA: 1:59 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0814 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0716 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0658 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0654 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0733 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0762 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0757 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0719 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0719 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0697 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0725 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0687 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0720 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0739 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0735 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0725 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0718 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0722 - accuracy: 0.98 - ETA: 59s - loss: 0.0735 - accuracy: 0.9816 - ETA: 58s - loss: 0.0726 - accuracy: 0.981 - ETA: 57s - loss: 0.0724 - accuracy: 0.981 - ETA: 56s - loss: 0.0756 - accuracy: 0.981 - ETA: 55s - loss: 0.0753 - accuracy: 0.981 - ETA: 54s - loss: 0.0759 - accuracy: 0.981 - ETA: 52s - loss: 0.0751 - accuracy: 0.981 - ETA: 51s - loss: 0.0747 - accuracy: 0.981 - ETA: 50s - loss: 0.0743 - accuracy: 0.981 - ETA: 49s - loss: 0.0748 - accuracy: 0.981 - ETA: 48s - loss: 0.0758 - accuracy: 0.981 - ETA: 47s - loss: 0.0763 - accuracy: 0.981 - ETA: 46s - loss: 0.0759 - accuracy: 0.980 - ETA: 45s - loss: 0.0764 - accuracy: 0.980 - ETA: 44s - loss: 0.0760 - accuracy: 0.981 - ETA: 43s - loss: 0.0768 - accuracy: 0.980 - ETA: 42s - loss: 0.0763 - accuracy: 0.980 - ETA: 41s - loss: 0.0761 - accuracy: 0.980 - ETA: 40s - loss: 0.0762 - accuracy: 0.980 - ETA: 39s - loss: 0.0757 - accuracy: 0.980 - ETA: 37s - loss: 0.0755 - accuracy: 0.980 - ETA: 36s - loss: 0.0785 - accuracy: 0.980 - ETA: 35s - loss: 0.0788 - accuracy: 0.980 - ETA: 34s - loss: 0.0824 - accuracy: 0.980 - ETA: 33s - loss: 0.0830 - accuracy: 0.979 - ETA: 32s - loss: 0.0828 - accuracy: 0.979 - ETA: 31s - loss: 0.0823 - accuracy: 0.979 - ETA: 30s - loss: 0.0818 - accuracy: 0.979 - ETA: 28s - loss: 0.0817 - accuracy: 0.979 - ETA: 27s - loss: 0.0817 - accuracy: 0.979 - ETA: 26s - loss: 0.0815 - accuracy: 0.979 - ETA: 25s - loss: 0.0821 - accuracy: 0.979 - ETA: 24s - loss: 0.0816 - accuracy: 0.979 - ETA: 23s - loss: 0.0814 - accuracy: 0.979 - ETA: 22s - loss: 0.0811 - accuracy: 0.979 - ETA: 21s - loss: 0.0808 - accuracy: 0.979 - ETA: 19s - loss: 0.0806 - accuracy: 0.979 - ETA: 18s - loss: 0.0808 - accuracy: 0.979 - ETA: 17s - loss: 0.0814 - accuracy: 0.979 - ETA: 16s - loss: 0.0806 - accuracy: 0.979 - ETA: 15s - loss: 0.0806 - accuracy: 0.979 - ETA: 14s - loss: 0.0811 - accuracy: 0.979 - ETA: 13s - loss: 0.0813 - accuracy: 0.979 - ETA: 12s - loss: 0.0816 - accuracy: 0.979 - ETA: 10s - loss: 0.0818 - accuracy: 0.979 - ETA: 9s - loss: 0.0813 - accuracy: 0.979 - ETA: 8s - loss: 0.0810 - accuracy: 0.97 - ETA: 7s - loss: 0.0813 - accuracy: 0.97 - ETA: 6s - loss: 0.0812 - accuracy: 0.97 - ETA: 5s - loss: 0.0807 - accuracy: 0.97 - ETA: 4s - loss: 0.0808 - accuracy: 0.97 - ETA: 3s - loss: 0.0805 - accuracy: 0.97 - ETA: 1s - loss: 0.0802 - accuracy: 0.97 - ETA: 0s - loss: 0.0798 - accuracy: 0.97 - 128s 10ms/step - loss: 0.0799 - accuracy: 0.9797 - val_loss: 3.1560 - val_accuracy: 0.4115\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:04 - loss: 0.0427 - accuracy: 0.97 - ETA: 1:56 - loss: 0.1437 - accuracy: 0.96 - ETA: 1:54 - loss: 0.1069 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0826 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0901 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0887 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0982 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0910 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0938 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0985 - accuracy: 0.97 - ETA: 1:43 - loss: 0.1069 - accuracy: 0.97 - ETA: 1:42 - loss: 0.1033 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1048 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1053 - accuracy: 0.97 - ETA: 1:41 - loss: 0.1007 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0977 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0953 - accuracy: 0.97 - ETA: 1:42 - loss: 0.0908 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0868 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0893 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0863 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0861 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0847 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0827 - accuracy: 0.97 - ETA: 1:36 - loss: 0.0811 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0793 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0794 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0807 - accuracy: 0.97 - ETA: 1:33 - loss: 0.0838 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0856 - accuracy: 0.97 - ETA: 1:31 - loss: 0.0847 - accuracy: 0.97 - ETA: 1:29 - loss: 0.0835 - accuracy: 0.97 - ETA: 1:28 - loss: 0.0811 - accuracy: 0.97 - ETA: 1:27 - loss: 0.0843 - accuracy: 0.97 - ETA: 1:26 - loss: 0.0828 - accuracy: 0.97 - ETA: 1:25 - loss: 0.0817 - accuracy: 0.97 - ETA: 1:24 - loss: 0.0800 - accuracy: 0.97 - ETA: 1:23 - loss: 0.0811 - accuracy: 0.97 - ETA: 1:22 - loss: 0.0797 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0788 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0776 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0790 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0783 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0778 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0767 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0757 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0762 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0764 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0768 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0767 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0764 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0754 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0758 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0769 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0778 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0774 - accuracy: 0.98 - ETA: 58s - loss: 0.0763 - accuracy: 0.9807 - ETA: 57s - loss: 0.0760 - accuracy: 0.980 - ETA: 56s - loss: 0.0768 - accuracy: 0.980 - ETA: 54s - loss: 0.0795 - accuracy: 0.980 - ETA: 53s - loss: 0.0798 - accuracy: 0.980 - ETA: 52s - loss: 0.0804 - accuracy: 0.980 - ETA: 51s - loss: 0.0803 - accuracy: 0.980 - ETA: 49s - loss: 0.0809 - accuracy: 0.980 - ETA: 48s - loss: 0.0815 - accuracy: 0.980 - ETA: 47s - loss: 0.0816 - accuracy: 0.980 - ETA: 45s - loss: 0.0823 - accuracy: 0.980 - ETA: 44s - loss: 0.0824 - accuracy: 0.980 - ETA: 42s - loss: 0.0837 - accuracy: 0.979 - ETA: 41s - loss: 0.0841 - accuracy: 0.979 - ETA: 40s - loss: 0.0833 - accuracy: 0.979 - ETA: 39s - loss: 0.0829 - accuracy: 0.979 - ETA: 37s - loss: 0.0819 - accuracy: 0.980 - ETA: 36s - loss: 0.0825 - accuracy: 0.979 - ETA: 34s - loss: 0.0816 - accuracy: 0.980 - ETA: 33s - loss: 0.0819 - accuracy: 0.980 - ETA: 32s - loss: 0.0820 - accuracy: 0.979 - ETA: 30s - loss: 0.0817 - accuracy: 0.980 - ETA: 29s - loss: 0.0816 - accuracy: 0.980 - ETA: 28s - loss: 0.0812 - accuracy: 0.980 - ETA: 26s - loss: 0.0810 - accuracy: 0.980 - ETA: 25s - loss: 0.0811 - accuracy: 0.980 - ETA: 24s - loss: 0.0815 - accuracy: 0.980 - ETA: 22s - loss: 0.0811 - accuracy: 0.980 - ETA: 21s - loss: 0.0804 - accuracy: 0.980 - ETA: 20s - loss: 0.0807 - accuracy: 0.980 - ETA: 18s - loss: 0.0804 - accuracy: 0.980 - ETA: 17s - loss: 0.0799 - accuracy: 0.980 - ETA: 16s - loss: 0.0801 - accuracy: 0.980 - ETA: 14s - loss: 0.0802 - accuracy: 0.980 - ETA: 13s - loss: 0.0804 - accuracy: 0.979 - ETA: 11s - loss: 0.0797 - accuracy: 0.980 - ETA: 10s - loss: 0.0794 - accuracy: 0.980 - ETA: 9s - loss: 0.0794 - accuracy: 0.980 - ETA: 7s - loss: 0.0799 - accuracy: 0.98 - ETA: 6s - loss: 0.0800 - accuracy: 0.97 - ETA: 5s - loss: 0.0799 - accuracy: 0.97 - ETA: 3s - loss: 0.0799 - accuracy: 0.97 - ETA: 2s - loss: 0.0799 - accuracy: 0.97 - ETA: 1s - loss: 0.0802 - accuracy: 0.97 - 155s 12ms/step - loss: 0.0803 - accuracy: 0.9796 - val_loss: 3.3454 - val_accuracy: 0.3801\n",
      "Epoch 46/100\n",
      "13022/13022 [==============================] - ETA: 2:19 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0557 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0429 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0485 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0480 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0640 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0630 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0634 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0728 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0693 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0692 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0710 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0731 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0696 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0682 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0702 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0692 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0752 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0702 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0698 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0654 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0699 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0725 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0719 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0709 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0704 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0702 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0733 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0730 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0746 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0742 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0744 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0733 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0730 - accuracy: 0.98 - ETA: 59s - loss: 0.0723 - accuracy: 0.9828 - ETA: 57s - loss: 0.0723 - accuracy: 0.982 - ETA: 56s - loss: 0.0718 - accuracy: 0.983 - ETA: 54s - loss: 0.0725 - accuracy: 0.982 - ETA: 52s - loss: 0.0748 - accuracy: 0.982 - ETA: 51s - loss: 0.0749 - accuracy: 0.982 - ETA: 49s - loss: 0.0751 - accuracy: 0.982 - ETA: 48s - loss: 0.0746 - accuracy: 0.982 - ETA: 46s - loss: 0.0746 - accuracy: 0.982 - ETA: 45s - loss: 0.0750 - accuracy: 0.982 - ETA: 43s - loss: 0.0748 - accuracy: 0.982 - ETA: 42s - loss: 0.0743 - accuracy: 0.982 - ETA: 40s - loss: 0.0747 - accuracy: 0.982 - ETA: 39s - loss: 0.0761 - accuracy: 0.982 - ETA: 37s - loss: 0.0758 - accuracy: 0.981 - ETA: 36s - loss: 0.0767 - accuracy: 0.981 - ETA: 34s - loss: 0.0772 - accuracy: 0.981 - ETA: 33s - loss: 0.0768 - accuracy: 0.981 - ETA: 32s - loss: 0.0771 - accuracy: 0.981 - ETA: 30s - loss: 0.0767 - accuracy: 0.981 - ETA: 29s - loss: 0.0762 - accuracy: 0.981 - ETA: 27s - loss: 0.0755 - accuracy: 0.981 - ETA: 26s - loss: 0.0747 - accuracy: 0.981 - ETA: 24s - loss: 0.0743 - accuracy: 0.981 - ETA: 23s - loss: 0.0745 - accuracy: 0.981 - ETA: 22s - loss: 0.0751 - accuracy: 0.981 - ETA: 20s - loss: 0.0747 - accuracy: 0.981 - ETA: 19s - loss: 0.0751 - accuracy: 0.981 - ETA: 18s - loss: 0.0750 - accuracy: 0.981 - ETA: 16s - loss: 0.0750 - accuracy: 0.981 - ETA: 15s - loss: 0.0744 - accuracy: 0.981 - ETA: 14s - loss: 0.0743 - accuracy: 0.981 - ETA: 12s - loss: 0.0741 - accuracy: 0.981 - ETA: 11s - loss: 0.0736 - accuracy: 0.981 - ETA: 10s - loss: 0.0736 - accuracy: 0.981 - ETA: 8s - loss: 0.0735 - accuracy: 0.981 - ETA: 7s - loss: 0.0729 - accuracy: 0.98 - ETA: 6s - loss: 0.0728 - accuracy: 0.98 - ETA: 4s - loss: 0.0729 - accuracy: 0.98 - ETA: 3s - loss: 0.0727 - accuracy: 0.98 - ETA: 2s - loss: 0.0724 - accuracy: 0.98 - ETA: 0s - loss: 0.0724 - accuracy: 0.98 - 150s 11ms/step - loss: 0.0722 - accuracy: 0.9816 - val_loss: 3.2794 - val_accuracy: 0.4086\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:31 - loss: 0.1132 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0758 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0779 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0815 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0883 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0893 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0810 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0789 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0738 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0741 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0708 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0741 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0732 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0713 - accuracy: 0.97 - ETA: 1:57 - loss: 0.0758 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0739 - accuracy: 0.97 - ETA: 1:54 - loss: 0.0722 - accuracy: 0.97 - ETA: 1:53 - loss: 0.0700 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0695 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0690 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0691 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0662 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0646 - accuracy: 0.98 - ETA: 59s - loss: 0.0655 - accuracy: 0.9825 - ETA: 57s - loss: 0.0649 - accuracy: 0.982 - ETA: 56s - loss: 0.0644 - accuracy: 0.982 - ETA: 54s - loss: 0.0638 - accuracy: 0.983 - ETA: 53s - loss: 0.0629 - accuracy: 0.983 - ETA: 52s - loss: 0.0633 - accuracy: 0.983 - ETA: 50s - loss: 0.0641 - accuracy: 0.983 - ETA: 49s - loss: 0.0646 - accuracy: 0.983 - ETA: 47s - loss: 0.0650 - accuracy: 0.983 - ETA: 46s - loss: 0.0649 - accuracy: 0.983 - ETA: 44s - loss: 0.0649 - accuracy: 0.983 - ETA: 43s - loss: 0.0654 - accuracy: 0.982 - ETA: 41s - loss: 0.0647 - accuracy: 0.983 - ETA: 40s - loss: 0.0640 - accuracy: 0.983 - ETA: 38s - loss: 0.0637 - accuracy: 0.983 - ETA: 37s - loss: 0.0636 - accuracy: 0.983 - ETA: 36s - loss: 0.0628 - accuracy: 0.983 - ETA: 34s - loss: 0.0628 - accuracy: 0.983 - ETA: 33s - loss: 0.0628 - accuracy: 0.983 - ETA: 32s - loss: 0.0622 - accuracy: 0.983 - ETA: 30s - loss: 0.0619 - accuracy: 0.983 - ETA: 29s - loss: 0.0620 - accuracy: 0.983 - ETA: 28s - loss: 0.0619 - accuracy: 0.983 - ETA: 26s - loss: 0.0622 - accuracy: 0.983 - ETA: 25s - loss: 0.0618 - accuracy: 0.983 - ETA: 24s - loss: 0.0616 - accuracy: 0.983 - ETA: 23s - loss: 0.0620 - accuracy: 0.983 - ETA: 21s - loss: 0.0645 - accuracy: 0.983 - ETA: 20s - loss: 0.0643 - accuracy: 0.983 - ETA: 19s - loss: 0.0645 - accuracy: 0.983 - ETA: 18s - loss: 0.0642 - accuracy: 0.983 - ETA: 16s - loss: 0.0636 - accuracy: 0.983 - ETA: 15s - loss: 0.0632 - accuracy: 0.983 - ETA: 14s - loss: 0.0627 - accuracy: 0.983 - ETA: 12s - loss: 0.0628 - accuracy: 0.983 - ETA: 11s - loss: 0.0630 - accuracy: 0.983 - ETA: 10s - loss: 0.0626 - accuracy: 0.983 - ETA: 8s - loss: 0.0623 - accuracy: 0.983 - ETA: 7s - loss: 0.0618 - accuracy: 0.98 - ETA: 6s - loss: 0.0666 - accuracy: 0.98 - ETA: 4s - loss: 0.0673 - accuracy: 0.98 - ETA: 3s - loss: 0.0673 - accuracy: 0.98 - ETA: 2s - loss: 0.0669 - accuracy: 0.98 - ETA: 0s - loss: 0.0671 - accuracy: 0.98 - 150s 12ms/step - loss: 0.0670 - accuracy: 0.9834 - val_loss: 3.4873 - val_accuracy: 0.3908\n",
      "Epoch 48/100\n",
      "13022/13022 [==============================] - ETA: 2:28 - loss: 0.0799 - accuracy: 0.96 - ETA: 2:22 - loss: 0.0476 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0507 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0543 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0482 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0568 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0650 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0614 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0615 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0635 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0685 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0707 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0720 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0749 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0813 - accuracy: 0.97 - ETA: 1:15 - loss: 0.0802 - accuracy: 0.97 - ETA: 1:13 - loss: 0.0791 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0782 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0784 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0782 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0774 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0787 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0785 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0781 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0784 - accuracy: 0.97 - ETA: 1:01 - loss: 0.0785 - accuracy: 0.98 - ETA: 59s - loss: 0.0781 - accuracy: 0.9801 - ETA: 58s - loss: 0.0783 - accuracy: 0.979 - ETA: 56s - loss: 0.0776 - accuracy: 0.979 - ETA: 55s - loss: 0.0769 - accuracy: 0.979 - ETA: 54s - loss: 0.0793 - accuracy: 0.979 - ETA: 52s - loss: 0.0799 - accuracy: 0.979 - ETA: 51s - loss: 0.0791 - accuracy: 0.979 - ETA: 49s - loss: 0.0784 - accuracy: 0.979 - ETA: 48s - loss: 0.0797 - accuracy: 0.979 - ETA: 46s - loss: 0.0796 - accuracy: 0.979 - ETA: 45s - loss: 0.0795 - accuracy: 0.979 - ETA: 43s - loss: 0.0787 - accuracy: 0.979 - ETA: 42s - loss: 0.0783 - accuracy: 0.979 - ETA: 40s - loss: 0.0780 - accuracy: 0.979 - ETA: 39s - loss: 0.0778 - accuracy: 0.979 - ETA: 38s - loss: 0.0776 - accuracy: 0.979 - ETA: 36s - loss: 0.0781 - accuracy: 0.979 - ETA: 35s - loss: 0.0779 - accuracy: 0.979 - ETA: 33s - loss: 0.0772 - accuracy: 0.979 - ETA: 32s - loss: 0.0772 - accuracy: 0.979 - ETA: 30s - loss: 0.0799 - accuracy: 0.979 - ETA: 29s - loss: 0.0801 - accuracy: 0.979 - ETA: 27s - loss: 0.0798 - accuracy: 0.979 - ETA: 26s - loss: 0.0794 - accuracy: 0.979 - ETA: 25s - loss: 0.0790 - accuracy: 0.979 - ETA: 23s - loss: 0.0783 - accuracy: 0.979 - ETA: 22s - loss: 0.0782 - accuracy: 0.979 - ETA: 20s - loss: 0.0789 - accuracy: 0.979 - ETA: 19s - loss: 0.0789 - accuracy: 0.979 - ETA: 18s - loss: 0.0797 - accuracy: 0.979 - ETA: 16s - loss: 0.0799 - accuracy: 0.979 - ETA: 15s - loss: 0.0798 - accuracy: 0.979 - ETA: 13s - loss: 0.0799 - accuracy: 0.979 - ETA: 12s - loss: 0.0800 - accuracy: 0.979 - ETA: 10s - loss: 0.0802 - accuracy: 0.979 - ETA: 9s - loss: 0.0809 - accuracy: 0.979 - ETA: 8s - loss: 0.0817 - accuracy: 0.97 - ETA: 6s - loss: 0.0812 - accuracy: 0.97 - ETA: 5s - loss: 0.0810 - accuracy: 0.97 - ETA: 3s - loss: 0.0806 - accuracy: 0.97 - ETA: 2s - loss: 0.0802 - accuracy: 0.97 - ETA: 1s - loss: 0.0812 - accuracy: 0.97 - 160s 12ms/step - loss: 0.0810 - accuracy: 0.9787 - val_loss: 3.4535 - val_accuracy: 0.3859\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:18 - loss: 0.1123 - accuracy: 0.98 - ETA: 2:14 - loss: 0.1141 - accuracy: 0.97 - ETA: 2:13 - loss: 0.1128 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0936 - accuracy: 0.98 - ETA: 2:10 - loss: 0.1045 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0909 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0836 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0793 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0752 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0776 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0738 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0700 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0710 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0720 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0779 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0764 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0788 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0807 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0853 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0847 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0831 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0930 - accuracy: 0.97 - ETA: 1:47 - loss: 0.0917 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0937 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0925 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0901 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0878 - accuracy: 0.97 - ETA: 1:40 - loss: 0.0869 - accuracy: 0.97 - ETA: 1:39 - loss: 0.0852 - accuracy: 0.97 - ETA: 1:38 - loss: 0.0843 - accuracy: 0.97 - ETA: 1:37 - loss: 0.0827 - accuracy: 0.97 - ETA: 1:35 - loss: 0.0815 - accuracy: 0.97 - ETA: 1:34 - loss: 0.0806 - accuracy: 0.97 - ETA: 1:32 - loss: 0.0786 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0775 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0775 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0767 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0767 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0758 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0762 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0757 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0751 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0753 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0751 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0745 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0745 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0749 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0737 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0735 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0731 - accuracy: 0.98 - ETA: 59s - loss: 0.0733 - accuracy: 0.9807 - ETA: 57s - loss: 0.0723 - accuracy: 0.980 - ETA: 56s - loss: 0.0717 - accuracy: 0.981 - ETA: 54s - loss: 0.0710 - accuracy: 0.981 - ETA: 53s - loss: 0.0706 - accuracy: 0.981 - ETA: 52s - loss: 0.0701 - accuracy: 0.981 - ETA: 50s - loss: 0.0724 - accuracy: 0.981 - ETA: 49s - loss: 0.0716 - accuracy: 0.981 - ETA: 47s - loss: 0.0709 - accuracy: 0.982 - ETA: 46s - loss: 0.0725 - accuracy: 0.981 - ETA: 45s - loss: 0.0720 - accuracy: 0.981 - ETA: 43s - loss: 0.0716 - accuracy: 0.981 - ETA: 42s - loss: 0.0728 - accuracy: 0.981 - ETA: 40s - loss: 0.0727 - accuracy: 0.981 - ETA: 39s - loss: 0.0734 - accuracy: 0.981 - ETA: 37s - loss: 0.0730 - accuracy: 0.981 - ETA: 36s - loss: 0.0725 - accuracy: 0.981 - ETA: 35s - loss: 0.0734 - accuracy: 0.981 - ETA: 33s - loss: 0.0730 - accuracy: 0.981 - ETA: 32s - loss: 0.0729 - accuracy: 0.981 - ETA: 30s - loss: 0.0722 - accuracy: 0.981 - ETA: 29s - loss: 0.0715 - accuracy: 0.981 - ETA: 27s - loss: 0.0717 - accuracy: 0.981 - ETA: 26s - loss: 0.0718 - accuracy: 0.981 - ETA: 25s - loss: 0.0712 - accuracy: 0.981 - ETA: 23s - loss: 0.0709 - accuracy: 0.981 - ETA: 22s - loss: 0.0708 - accuracy: 0.981 - ETA: 20s - loss: 0.0708 - accuracy: 0.981 - ETA: 19s - loss: 0.0702 - accuracy: 0.982 - ETA: 18s - loss: 0.0703 - accuracy: 0.981 - ETA: 16s - loss: 0.0716 - accuracy: 0.981 - ETA: 15s - loss: 0.0719 - accuracy: 0.981 - ETA: 13s - loss: 0.0728 - accuracy: 0.981 - ETA: 12s - loss: 0.0726 - accuracy: 0.981 - ETA: 10s - loss: 0.0730 - accuracy: 0.981 - ETA: 9s - loss: 0.0723 - accuracy: 0.981 - ETA: 8s - loss: 0.0724 - accuracy: 0.98 - ETA: 6s - loss: 0.0722 - accuracy: 0.98 - ETA: 5s - loss: 0.0718 - accuracy: 0.98 - ETA: 3s - loss: 0.0715 - accuracy: 0.98 - ETA: 2s - loss: 0.0717 - accuracy: 0.98 - ETA: 1s - loss: 0.0717 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0715 - accuracy: 0.9813 - val_loss: 3.5421 - val_accuracy: 0.3652\n",
      "Epoch 50/100\n",
      "13022/13022 [==============================] - ETA: 2:21 - loss: 0.0890 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0518 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0429 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0409 - accuracy: 0.99 - ETA: 2:27 - loss: 0.0338 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0357 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0408 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0393 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0455 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0454 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0436 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0512 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0729 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0720 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0718 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0707 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0718 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0711 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0709 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0735 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0736 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0739 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0752 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0781 - accuracy: 0.97 - ETA: 1:12 - loss: 0.0781 - accuracy: 0.97 - ETA: 1:11 - loss: 0.0767 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0772 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0772 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0761 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0771 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0769 - accuracy: 0.97 - ETA: 59s - loss: 0.0769 - accuracy: 0.9798 - ETA: 58s - loss: 0.0761 - accuracy: 0.980 - ETA: 56s - loss: 0.0756 - accuracy: 0.980 - ETA: 55s - loss: 0.0758 - accuracy: 0.980 - ETA: 54s - loss: 0.0752 - accuracy: 0.980 - ETA: 52s - loss: 0.0753 - accuracy: 0.979 - ETA: 51s - loss: 0.0748 - accuracy: 0.979 - ETA: 49s - loss: 0.0743 - accuracy: 0.979 - ETA: 48s - loss: 0.0738 - accuracy: 0.979 - ETA: 47s - loss: 0.0737 - accuracy: 0.979 - ETA: 45s - loss: 0.0740 - accuracy: 0.979 - ETA: 44s - loss: 0.0737 - accuracy: 0.979 - ETA: 43s - loss: 0.0738 - accuracy: 0.979 - ETA: 42s - loss: 0.0740 - accuracy: 0.979 - ETA: 40s - loss: 0.0738 - accuracy: 0.979 - ETA: 39s - loss: 0.0730 - accuracy: 0.979 - ETA: 37s - loss: 0.0730 - accuracy: 0.979 - ETA: 36s - loss: 0.0730 - accuracy: 0.979 - ETA: 35s - loss: 0.0726 - accuracy: 0.979 - ETA: 33s - loss: 0.0728 - accuracy: 0.979 - ETA: 32s - loss: 0.0729 - accuracy: 0.979 - ETA: 31s - loss: 0.0727 - accuracy: 0.979 - ETA: 29s - loss: 0.0722 - accuracy: 0.980 - ETA: 28s - loss: 0.0721 - accuracy: 0.980 - ETA: 27s - loss: 0.0720 - accuracy: 0.980 - ETA: 25s - loss: 0.0714 - accuracy: 0.980 - ETA: 24s - loss: 0.0725 - accuracy: 0.980 - ETA: 22s - loss: 0.0728 - accuracy: 0.979 - ETA: 21s - loss: 0.0723 - accuracy: 0.980 - ETA: 20s - loss: 0.0725 - accuracy: 0.980 - ETA: 18s - loss: 0.0720 - accuracy: 0.980 - ETA: 17s - loss: 0.0714 - accuracy: 0.980 - ETA: 16s - loss: 0.0709 - accuracy: 0.980 - ETA: 14s - loss: 0.0713 - accuracy: 0.980 - ETA: 13s - loss: 0.0713 - accuracy: 0.980 - ETA: 12s - loss: 0.0723 - accuracy: 0.980 - ETA: 10s - loss: 0.0717 - accuracy: 0.980 - ETA: 9s - loss: 0.0713 - accuracy: 0.980 - ETA: 7s - loss: 0.0711 - accuracy: 0.98 - ETA: 6s - loss: 0.0710 - accuracy: 0.98 - ETA: 5s - loss: 0.0706 - accuracy: 0.98 - ETA: 3s - loss: 0.0706 - accuracy: 0.98 - ETA: 2s - loss: 0.0711 - accuracy: 0.98 - ETA: 1s - loss: 0.0708 - accuracy: 0.98 - 156s 12ms/step - loss: 0.0704 - accuracy: 0.9804 - val_loss: 3.4218 - val_accuracy: 0.3923\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:22 - loss: 0.0414 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0340 - accuracy: 0.98 - ETA: 2:26 - loss: 0.0269 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0282 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0341 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0725 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0658 - accuracy: 0.98 - ETA: 2:14 - loss: 0.1003 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0918 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0929 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0918 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0888 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0865 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0836 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0812 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0787 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0867 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0896 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0868 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0840 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0824 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0830 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0876 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0870 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0850 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0828 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0828 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0803 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0805 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0785 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0778 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0755 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0738 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0750 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0744 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0729 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0722 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0709 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0684 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0653 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0673 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0660 - accuracy: 0.98 - ETA: 59s - loss: 0.0656 - accuracy: 0.9846 - ETA: 57s - loss: 0.0655 - accuracy: 0.984 - ETA: 56s - loss: 0.0659 - accuracy: 0.984 - ETA: 55s - loss: 0.0655 - accuracy: 0.984 - ETA: 53s - loss: 0.0650 - accuracy: 0.984 - ETA: 52s - loss: 0.0660 - accuracy: 0.984 - ETA: 50s - loss: 0.0655 - accuracy: 0.984 - ETA: 49s - loss: 0.0649 - accuracy: 0.984 - ETA: 47s - loss: 0.0653 - accuracy: 0.984 - ETA: 46s - loss: 0.0655 - accuracy: 0.984 - ETA: 45s - loss: 0.0664 - accuracy: 0.983 - ETA: 43s - loss: 0.0665 - accuracy: 0.983 - ETA: 42s - loss: 0.0661 - accuracy: 0.983 - ETA: 40s - loss: 0.0659 - accuracy: 0.983 - ETA: 39s - loss: 0.0655 - accuracy: 0.983 - ETA: 37s - loss: 0.0654 - accuracy: 0.983 - ETA: 36s - loss: 0.0648 - accuracy: 0.983 - ETA: 34s - loss: 0.0651 - accuracy: 0.983 - ETA: 33s - loss: 0.0665 - accuracy: 0.983 - ETA: 32s - loss: 0.0663 - accuracy: 0.983 - ETA: 30s - loss: 0.0664 - accuracy: 0.983 - ETA: 29s - loss: 0.0668 - accuracy: 0.983 - ETA: 27s - loss: 0.0670 - accuracy: 0.983 - ETA: 26s - loss: 0.0670 - accuracy: 0.983 - ETA: 25s - loss: 0.0663 - accuracy: 0.983 - ETA: 23s - loss: 0.0662 - accuracy: 0.983 - ETA: 22s - loss: 0.0658 - accuracy: 0.983 - ETA: 21s - loss: 0.0652 - accuracy: 0.983 - ETA: 19s - loss: 0.0651 - accuracy: 0.983 - ETA: 18s - loss: 0.0646 - accuracy: 0.983 - ETA: 16s - loss: 0.0649 - accuracy: 0.983 - ETA: 15s - loss: 0.0645 - accuracy: 0.983 - ETA: 13s - loss: 0.0645 - accuracy: 0.983 - ETA: 12s - loss: 0.0645 - accuracy: 0.983 - ETA: 11s - loss: 0.0665 - accuracy: 0.983 - ETA: 9s - loss: 0.0672 - accuracy: 0.983 - ETA: 8s - loss: 0.0675 - accuracy: 0.98 - ETA: 6s - loss: 0.0681 - accuracy: 0.98 - ETA: 5s - loss: 0.0675 - accuracy: 0.98 - ETA: 3s - loss: 0.0671 - accuracy: 0.98 - ETA: 2s - loss: 0.0676 - accuracy: 0.98 - ETA: 1s - loss: 0.0673 - accuracy: 0.98 - 161s 12ms/step - loss: 0.0676 - accuracy: 0.9830 - val_loss: 3.5313 - val_accuracy: 0.3672\n",
      "Epoch 52/100\n",
      "13022/13022 [==============================] - ETA: 2:29 - loss: 0.0561 - accuracy: 0.97 - ETA: 2:29 - loss: 0.0887 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0666 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0985 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0978 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0884 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0850 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0848 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0849 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0823 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0777 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0766 - accuracy: 0.97 - ETA: 2:04 - loss: 0.0741 - accuracy: 0.97 - ETA: 2:02 - loss: 0.0777 - accuracy: 0.97 - ETA: 2:01 - loss: 0.0741 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0746 - accuracy: 0.97 - ETA: 1:58 - loss: 0.0729 - accuracy: 0.97 - ETA: 1:56 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0660 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0531 - accuracy: 0.98 - ETA: 58s - loss: 0.0525 - accuracy: 0.9852 - ETA: 57s - loss: 0.0524 - accuracy: 0.985 - ETA: 55s - loss: 0.0518 - accuracy: 0.985 - ETA: 54s - loss: 0.0512 - accuracy: 0.985 - ETA: 53s - loss: 0.0510 - accuracy: 0.985 - ETA: 51s - loss: 0.0507 - accuracy: 0.985 - ETA: 50s - loss: 0.0509 - accuracy: 0.985 - ETA: 48s - loss: 0.0515 - accuracy: 0.985 - ETA: 47s - loss: 0.0514 - accuracy: 0.985 - ETA: 46s - loss: 0.0514 - accuracy: 0.985 - ETA: 44s - loss: 0.0524 - accuracy: 0.985 - ETA: 43s - loss: 0.0531 - accuracy: 0.984 - ETA: 41s - loss: 0.0531 - accuracy: 0.984 - ETA: 40s - loss: 0.0530 - accuracy: 0.984 - ETA: 39s - loss: 0.0525 - accuracy: 0.984 - ETA: 37s - loss: 0.0534 - accuracy: 0.984 - ETA: 36s - loss: 0.0542 - accuracy: 0.984 - ETA: 34s - loss: 0.0548 - accuracy: 0.984 - ETA: 33s - loss: 0.0546 - accuracy: 0.984 - ETA: 32s - loss: 0.0542 - accuracy: 0.984 - ETA: 30s - loss: 0.0538 - accuracy: 0.984 - ETA: 29s - loss: 0.0538 - accuracy: 0.984 - ETA: 27s - loss: 0.0539 - accuracy: 0.984 - ETA: 26s - loss: 0.0536 - accuracy: 0.984 - ETA: 25s - loss: 0.0533 - accuracy: 0.984 - ETA: 23s - loss: 0.0535 - accuracy: 0.984 - ETA: 22s - loss: 0.0531 - accuracy: 0.985 - ETA: 20s - loss: 0.0529 - accuracy: 0.985 - ETA: 19s - loss: 0.0525 - accuracy: 0.985 - ETA: 18s - loss: 0.0526 - accuracy: 0.985 - ETA: 16s - loss: 0.0526 - accuracy: 0.985 - ETA: 15s - loss: 0.0526 - accuracy: 0.985 - ETA: 13s - loss: 0.0524 - accuracy: 0.985 - ETA: 12s - loss: 0.0529 - accuracy: 0.985 - ETA: 10s - loss: 0.0525 - accuracy: 0.985 - ETA: 9s - loss: 0.0532 - accuracy: 0.985 - ETA: 8s - loss: 0.0533 - accuracy: 0.98 - ETA: 6s - loss: 0.0541 - accuracy: 0.98 - ETA: 5s - loss: 0.0546 - accuracy: 0.98 - ETA: 3s - loss: 0.0547 - accuracy: 0.98 - ETA: 2s - loss: 0.0542 - accuracy: 0.98 - ETA: 1s - loss: 0.0543 - accuracy: 0.98 - 159s 12ms/step - loss: 0.0541 - accuracy: 0.9853 - val_loss: 3.2850 - val_accuracy: 0.4268\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:21 - loss: 0.0213 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0725 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0618 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0646 - accuracy: 0.97 - ETA: 2:17 - loss: 0.0562 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0521 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0561 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0587 - accuracy: 0.98 - ETA: 58s - loss: 0.0584 - accuracy: 0.9845 - ETA: 57s - loss: 0.0598 - accuracy: 0.984 - ETA: 55s - loss: 0.0591 - accuracy: 0.984 - ETA: 54s - loss: 0.0592 - accuracy: 0.984 - ETA: 52s - loss: 0.0585 - accuracy: 0.984 - ETA: 51s - loss: 0.0580 - accuracy: 0.984 - ETA: 49s - loss: 0.0577 - accuracy: 0.984 - ETA: 48s - loss: 0.0578 - accuracy: 0.984 - ETA: 46s - loss: 0.0577 - accuracy: 0.984 - ETA: 45s - loss: 0.0573 - accuracy: 0.984 - ETA: 44s - loss: 0.0599 - accuracy: 0.984 - ETA: 42s - loss: 0.0596 - accuracy: 0.984 - ETA: 41s - loss: 0.0590 - accuracy: 0.984 - ETA: 39s - loss: 0.0595 - accuracy: 0.984 - ETA: 38s - loss: 0.0601 - accuracy: 0.984 - ETA: 36s - loss: 0.0620 - accuracy: 0.983 - ETA: 35s - loss: 0.0618 - accuracy: 0.984 - ETA: 33s - loss: 0.0617 - accuracy: 0.984 - ETA: 32s - loss: 0.0613 - accuracy: 0.984 - ETA: 31s - loss: 0.0608 - accuracy: 0.984 - ETA: 29s - loss: 0.0609 - accuracy: 0.984 - ETA: 28s - loss: 0.0611 - accuracy: 0.983 - ETA: 26s - loss: 0.0612 - accuracy: 0.983 - ETA: 25s - loss: 0.0609 - accuracy: 0.983 - ETA: 23s - loss: 0.0604 - accuracy: 0.983 - ETA: 22s - loss: 0.0602 - accuracy: 0.983 - ETA: 20s - loss: 0.0601 - accuracy: 0.983 - ETA: 19s - loss: 0.0598 - accuracy: 0.983 - ETA: 18s - loss: 0.0599 - accuracy: 0.983 - ETA: 16s - loss: 0.0593 - accuracy: 0.984 - ETA: 15s - loss: 0.0593 - accuracy: 0.983 - ETA: 13s - loss: 0.0596 - accuracy: 0.984 - ETA: 12s - loss: 0.0595 - accuracy: 0.984 - ETA: 11s - loss: 0.0595 - accuracy: 0.983 - ETA: 9s - loss: 0.0602 - accuracy: 0.983 - ETA: 8s - loss: 0.0601 - accuracy: 0.98 - ETA: 6s - loss: 0.0597 - accuracy: 0.98 - ETA: 5s - loss: 0.0603 - accuracy: 0.98 - ETA: 3s - loss: 0.0604 - accuracy: 0.98 - ETA: 2s - loss: 0.0618 - accuracy: 0.98 - ETA: 1s - loss: 0.0620 - accuracy: 0.98 - 159s 12ms/step - loss: 0.0617 - accuracy: 0.9838 - val_loss: 3.3672 - val_accuracy: 0.3993\n",
      "Epoch 54/100\n",
      "13022/13022 [==============================] - ETA: 2:14 - loss: 0.1001 - accuracy: 0.96 - ETA: 2:19 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0485 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0467 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0497 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0477 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0525 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0508 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0529 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0523 - accuracy: 0.98 - ETA: 59s - loss: 0.0532 - accuracy: 0.9858 - ETA: 58s - loss: 0.0534 - accuracy: 0.985 - ETA: 56s - loss: 0.0533 - accuracy: 0.985 - ETA: 55s - loss: 0.0530 - accuracy: 0.985 - ETA: 53s - loss: 0.0523 - accuracy: 0.985 - ETA: 52s - loss: 0.0518 - accuracy: 0.986 - ETA: 51s - loss: 0.0514 - accuracy: 0.986 - ETA: 50s - loss: 0.0510 - accuracy: 0.986 - ETA: 48s - loss: 0.0509 - accuracy: 0.986 - ETA: 47s - loss: 0.0505 - accuracy: 0.986 - ETA: 46s - loss: 0.0507 - accuracy: 0.986 - ETA: 44s - loss: 0.0508 - accuracy: 0.986 - ETA: 43s - loss: 0.0515 - accuracy: 0.986 - ETA: 41s - loss: 0.0515 - accuracy: 0.986 - ETA: 40s - loss: 0.0511 - accuracy: 0.986 - ETA: 38s - loss: 0.0512 - accuracy: 0.986 - ETA: 37s - loss: 0.0512 - accuracy: 0.986 - ETA: 36s - loss: 0.0514 - accuracy: 0.985 - ETA: 34s - loss: 0.0511 - accuracy: 0.986 - ETA: 33s - loss: 0.0517 - accuracy: 0.985 - ETA: 31s - loss: 0.0512 - accuracy: 0.986 - ETA: 30s - loss: 0.0518 - accuracy: 0.986 - ETA: 29s - loss: 0.0518 - accuracy: 0.986 - ETA: 27s - loss: 0.0512 - accuracy: 0.986 - ETA: 26s - loss: 0.0511 - accuracy: 0.986 - ETA: 24s - loss: 0.0511 - accuracy: 0.986 - ETA: 23s - loss: 0.0513 - accuracy: 0.985 - ETA: 22s - loss: 0.0519 - accuracy: 0.985 - ETA: 20s - loss: 0.0517 - accuracy: 0.985 - ETA: 19s - loss: 0.0524 - accuracy: 0.985 - ETA: 17s - loss: 0.0550 - accuracy: 0.985 - ETA: 16s - loss: 0.0545 - accuracy: 0.985 - ETA: 15s - loss: 0.0543 - accuracy: 0.985 - ETA: 13s - loss: 0.0542 - accuracy: 0.985 - ETA: 12s - loss: 0.0540 - accuracy: 0.985 - ETA: 10s - loss: 0.0540 - accuracy: 0.985 - ETA: 9s - loss: 0.0539 - accuracy: 0.985 - ETA: 8s - loss: 0.0545 - accuracy: 0.98 - ETA: 6s - loss: 0.0541 - accuracy: 0.98 - ETA: 5s - loss: 0.0547 - accuracy: 0.98 - ETA: 3s - loss: 0.0543 - accuracy: 0.98 - ETA: 2s - loss: 0.0543 - accuracy: 0.98 - ETA: 1s - loss: 0.0546 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0546 - accuracy: 0.9854 - val_loss: 3.5500 - val_accuracy: 0.3865\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 3:00 - loss: 0.0487 - accuracy: 0.97 - ETA: 2:40 - loss: 0.0397 - accuracy: 0.98 - ETA: 2:30 - loss: 0.0356 - accuracy: 0.98 - ETA: 2:28 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0402 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0506 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0542 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0514 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0451 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0529 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0545 - accuracy: 0.98 - ETA: 59s - loss: 0.0544 - accuracy: 0.9858 - ETA: 57s - loss: 0.0538 - accuracy: 0.986 - ETA: 56s - loss: 0.0539 - accuracy: 0.986 - ETA: 55s - loss: 0.0556 - accuracy: 0.986 - ETA: 53s - loss: 0.0559 - accuracy: 0.986 - ETA: 52s - loss: 0.0582 - accuracy: 0.985 - ETA: 50s - loss: 0.0592 - accuracy: 0.985 - ETA: 49s - loss: 0.0585 - accuracy: 0.985 - ETA: 47s - loss: 0.0579 - accuracy: 0.985 - ETA: 46s - loss: 0.0582 - accuracy: 0.985 - ETA: 44s - loss: 0.0577 - accuracy: 0.985 - ETA: 43s - loss: 0.0575 - accuracy: 0.985 - ETA: 42s - loss: 0.0601 - accuracy: 0.985 - ETA: 40s - loss: 0.0616 - accuracy: 0.985 - ETA: 39s - loss: 0.0609 - accuracy: 0.985 - ETA: 37s - loss: 0.0617 - accuracy: 0.985 - ETA: 36s - loss: 0.0616 - accuracy: 0.985 - ETA: 35s - loss: 0.0609 - accuracy: 0.985 - ETA: 33s - loss: 0.0613 - accuracy: 0.985 - ETA: 32s - loss: 0.0614 - accuracy: 0.985 - ETA: 30s - loss: 0.0636 - accuracy: 0.985 - ETA: 29s - loss: 0.0631 - accuracy: 0.985 - ETA: 27s - loss: 0.0637 - accuracy: 0.985 - ETA: 26s - loss: 0.0641 - accuracy: 0.985 - ETA: 25s - loss: 0.0643 - accuracy: 0.985 - ETA: 23s - loss: 0.0640 - accuracy: 0.985 - ETA: 22s - loss: 0.0638 - accuracy: 0.985 - ETA: 20s - loss: 0.0635 - accuracy: 0.985 - ETA: 19s - loss: 0.0633 - accuracy: 0.985 - ETA: 17s - loss: 0.0633 - accuracy: 0.985 - ETA: 16s - loss: 0.0628 - accuracy: 0.985 - ETA: 15s - loss: 0.0622 - accuracy: 0.985 - ETA: 13s - loss: 0.0619 - accuracy: 0.985 - ETA: 12s - loss: 0.0625 - accuracy: 0.985 - ETA: 10s - loss: 0.0622 - accuracy: 0.985 - ETA: 9s - loss: 0.0620 - accuracy: 0.985 - ETA: 8s - loss: 0.0614 - accuracy: 0.98 - ETA: 6s - loss: 0.0615 - accuracy: 0.98 - ETA: 5s - loss: 0.0625 - accuracy: 0.98 - ETA: 3s - loss: 0.0620 - accuracy: 0.98 - ETA: 2s - loss: 0.0618 - accuracy: 0.98 - ETA: 1s - loss: 0.0630 - accuracy: 0.98 - 158s 12ms/step - loss: 0.0629 - accuracy: 0.9856 - val_loss: 3.4327 - val_accuracy: 0.3797\n",
      "Epoch 56/100\n",
      "13022/13022 [==============================] - ETA: 2:17 - loss: 0.0675 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0370 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0312 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0387 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0416 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0555 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0590 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0696 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0686 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0659 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0730 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0718 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0654 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0571 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0571 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0592 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0591 - accuracy: 0.98 - ETA: 59s - loss: 0.0592 - accuracy: 0.9866 - ETA: 58s - loss: 0.0596 - accuracy: 0.986 - ETA: 56s - loss: 0.0597 - accuracy: 0.986 - ETA: 55s - loss: 0.0591 - accuracy: 0.986 - ETA: 53s - loss: 0.0589 - accuracy: 0.986 - ETA: 52s - loss: 0.0600 - accuracy: 0.986 - ETA: 50s - loss: 0.0592 - accuracy: 0.986 - ETA: 49s - loss: 0.0589 - accuracy: 0.986 - ETA: 47s - loss: 0.0620 - accuracy: 0.986 - ETA: 46s - loss: 0.0618 - accuracy: 0.986 - ETA: 44s - loss: 0.0610 - accuracy: 0.986 - ETA: 43s - loss: 0.0605 - accuracy: 0.986 - ETA: 41s - loss: 0.0604 - accuracy: 0.986 - ETA: 40s - loss: 0.0598 - accuracy: 0.986 - ETA: 38s - loss: 0.0597 - accuracy: 0.986 - ETA: 37s - loss: 0.0605 - accuracy: 0.986 - ETA: 35s - loss: 0.0601 - accuracy: 0.986 - ETA: 34s - loss: 0.0603 - accuracy: 0.986 - ETA: 32s - loss: 0.0608 - accuracy: 0.986 - ETA: 31s - loss: 0.0604 - accuracy: 0.986 - ETA: 30s - loss: 0.0604 - accuracy: 0.986 - ETA: 28s - loss: 0.0601 - accuracy: 0.986 - ETA: 27s - loss: 0.0595 - accuracy: 0.986 - ETA: 25s - loss: 0.0596 - accuracy: 0.986 - ETA: 24s - loss: 0.0592 - accuracy: 0.986 - ETA: 22s - loss: 0.0585 - accuracy: 0.986 - ETA: 21s - loss: 0.0583 - accuracy: 0.986 - ETA: 19s - loss: 0.0583 - accuracy: 0.986 - ETA: 18s - loss: 0.0580 - accuracy: 0.986 - ETA: 16s - loss: 0.0577 - accuracy: 0.986 - ETA: 15s - loss: 0.0571 - accuracy: 0.986 - ETA: 14s - loss: 0.0573 - accuracy: 0.986 - ETA: 12s - loss: 0.0571 - accuracy: 0.986 - ETA: 11s - loss: 0.0566 - accuracy: 0.986 - ETA: 9s - loss: 0.0564 - accuracy: 0.986 - ETA: 8s - loss: 0.0580 - accuracy: 0.98 - ETA: 6s - loss: 0.0584 - accuracy: 0.98 - ETA: 5s - loss: 0.0579 - accuracy: 0.98 - ETA: 3s - loss: 0.0580 - accuracy: 0.98 - ETA: 2s - loss: 0.0575 - accuracy: 0.98 - ETA: 1s - loss: 0.0573 - accuracy: 0.98 - 163s 12ms/step - loss: 0.0577 - accuracy: 0.9863 - val_loss: 3.4502 - val_accuracy: 0.3808\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:15 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0328 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0256 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0325 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0344 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0371 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0343 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0311 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0439 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0417 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0447 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0550 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0568 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0571 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0568 - accuracy: 0.98 - ETA: 59s - loss: 0.0572 - accuracy: 0.9848 - ETA: 57s - loss: 0.0569 - accuracy: 0.984 - ETA: 56s - loss: 0.0562 - accuracy: 0.985 - ETA: 55s - loss: 0.0556 - accuracy: 0.985 - ETA: 53s - loss: 0.0553 - accuracy: 0.985 - ETA: 52s - loss: 0.0570 - accuracy: 0.985 - ETA: 51s - loss: 0.0564 - accuracy: 0.985 - ETA: 49s - loss: 0.0568 - accuracy: 0.985 - ETA: 48s - loss: 0.0567 - accuracy: 0.985 - ETA: 46s - loss: 0.0562 - accuracy: 0.985 - ETA: 45s - loss: 0.0570 - accuracy: 0.985 - ETA: 44s - loss: 0.0563 - accuracy: 0.985 - ETA: 42s - loss: 0.0558 - accuracy: 0.985 - ETA: 41s - loss: 0.0555 - accuracy: 0.985 - ETA: 40s - loss: 0.0557 - accuracy: 0.985 - ETA: 38s - loss: 0.0564 - accuracy: 0.985 - ETA: 37s - loss: 0.0559 - accuracy: 0.985 - ETA: 35s - loss: 0.0557 - accuracy: 0.985 - ETA: 34s - loss: 0.0560 - accuracy: 0.985 - ETA: 33s - loss: 0.0568 - accuracy: 0.985 - ETA: 31s - loss: 0.0568 - accuracy: 0.985 - ETA: 30s - loss: 0.0575 - accuracy: 0.985 - ETA: 28s - loss: 0.0574 - accuracy: 0.985 - ETA: 27s - loss: 0.0576 - accuracy: 0.985 - ETA: 26s - loss: 0.0570 - accuracy: 0.985 - ETA: 24s - loss: 0.0566 - accuracy: 0.985 - ETA: 23s - loss: 0.0570 - accuracy: 0.985 - ETA: 22s - loss: 0.0573 - accuracy: 0.985 - ETA: 20s - loss: 0.0573 - accuracy: 0.985 - ETA: 19s - loss: 0.0571 - accuracy: 0.985 - ETA: 17s - loss: 0.0571 - accuracy: 0.985 - ETA: 16s - loss: 0.0568 - accuracy: 0.985 - ETA: 15s - loss: 0.0567 - accuracy: 0.985 - ETA: 13s - loss: 0.0576 - accuracy: 0.985 - ETA: 12s - loss: 0.0579 - accuracy: 0.985 - ETA: 10s - loss: 0.0589 - accuracy: 0.984 - ETA: 9s - loss: 0.0590 - accuracy: 0.984 - ETA: 8s - loss: 0.0600 - accuracy: 0.98 - ETA: 6s - loss: 0.0615 - accuracy: 0.98 - ETA: 5s - loss: 0.0611 - accuracy: 0.98 - ETA: 3s - loss: 0.0607 - accuracy: 0.98 - ETA: 2s - loss: 0.0612 - accuracy: 0.98 - ETA: 1s - loss: 0.0610 - accuracy: 0.98 - 158s 12ms/step - loss: 0.0609 - accuracy: 0.9846 - val_loss: 3.4124 - val_accuracy: 0.3754\n",
      "Epoch 58/100\n",
      "13022/13022 [==============================] - ETA: 2:15 - loss: 0.0833 - accuracy: 0.97 - ETA: 2:13 - loss: 0.1175 - accuracy: 0.97 - ETA: 2:12 - loss: 0.0837 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0721 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0682 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0786 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0716 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0714 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0597 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0560 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0549 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0552 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0562 - accuracy: 0.98 - ETA: 59s - loss: 0.0560 - accuracy: 0.9853 - ETA: 58s - loss: 0.0556 - accuracy: 0.985 - ETA: 57s - loss: 0.0570 - accuracy: 0.984 - ETA: 55s - loss: 0.0565 - accuracy: 0.985 - ETA: 54s - loss: 0.0575 - accuracy: 0.984 - ETA: 52s - loss: 0.0582 - accuracy: 0.984 - ETA: 51s - loss: 0.0576 - accuracy: 0.984 - ETA: 50s - loss: 0.0573 - accuracy: 0.984 - ETA: 48s - loss: 0.0579 - accuracy: 0.984 - ETA: 47s - loss: 0.0579 - accuracy: 0.984 - ETA: 45s - loss: 0.0575 - accuracy: 0.984 - ETA: 44s - loss: 0.0574 - accuracy: 0.984 - ETA: 42s - loss: 0.0567 - accuracy: 0.984 - ETA: 41s - loss: 0.0561 - accuracy: 0.984 - ETA: 40s - loss: 0.0555 - accuracy: 0.984 - ETA: 38s - loss: 0.0555 - accuracy: 0.984 - ETA: 37s - loss: 0.0553 - accuracy: 0.984 - ETA: 36s - loss: 0.0557 - accuracy: 0.984 - ETA: 34s - loss: 0.0554 - accuracy: 0.984 - ETA: 33s - loss: 0.0554 - accuracy: 0.984 - ETA: 31s - loss: 0.0548 - accuracy: 0.985 - ETA: 30s - loss: 0.0551 - accuracy: 0.984 - ETA: 29s - loss: 0.0558 - accuracy: 0.984 - ETA: 27s - loss: 0.0554 - accuracy: 0.985 - ETA: 26s - loss: 0.0555 - accuracy: 0.985 - ETA: 24s - loss: 0.0552 - accuracy: 0.985 - ETA: 23s - loss: 0.0554 - accuracy: 0.985 - ETA: 22s - loss: 0.0551 - accuracy: 0.985 - ETA: 20s - loss: 0.0549 - accuracy: 0.985 - ETA: 19s - loss: 0.0554 - accuracy: 0.985 - ETA: 17s - loss: 0.0550 - accuracy: 0.985 - ETA: 16s - loss: 0.0551 - accuracy: 0.985 - ETA: 15s - loss: 0.0554 - accuracy: 0.985 - ETA: 13s - loss: 0.0554 - accuracy: 0.985 - ETA: 12s - loss: 0.0569 - accuracy: 0.985 - ETA: 10s - loss: 0.0573 - accuracy: 0.985 - ETA: 9s - loss: 0.0569 - accuracy: 0.985 - ETA: 8s - loss: 0.0570 - accuracy: 0.98 - ETA: 6s - loss: 0.0569 - accuracy: 0.98 - ETA: 5s - loss: 0.0566 - accuracy: 0.98 - ETA: 3s - loss: 0.0571 - accuracy: 0.98 - ETA: 2s - loss: 0.0568 - accuracy: 0.98 - ETA: 1s - loss: 0.0570 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0569 - accuracy: 0.9851 - val_loss: 3.5309 - val_accuracy: 0.3752\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:20 - loss: 0.0505 - accuracy: 0.97 - ETA: 2:15 - loss: 0.1089 - accuracy: 0.96 - ETA: 2:13 - loss: 0.0761 - accuracy: 0.97 - ETA: 2:11 - loss: 0.0835 - accuracy: 0.97 - ETA: 2:10 - loss: 0.0740 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0752 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0727 - accuracy: 0.97 - ETA: 2:08 - loss: 0.0721 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0649 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0667 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0645 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0604 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0623 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0792 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0786 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0758 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0745 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0703 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0702 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0707 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0687 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0621 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0622 - accuracy: 0.98 - ETA: 59s - loss: 0.0622 - accuracy: 0.9860 - ETA: 58s - loss: 0.0615 - accuracy: 0.985 - ETA: 56s - loss: 0.0616 - accuracy: 0.986 - ETA: 55s - loss: 0.0615 - accuracy: 0.986 - ETA: 53s - loss: 0.0624 - accuracy: 0.985 - ETA: 52s - loss: 0.0624 - accuracy: 0.985 - ETA: 51s - loss: 0.0620 - accuracy: 0.985 - ETA: 49s - loss: 0.0611 - accuracy: 0.985 - ETA: 48s - loss: 0.0612 - accuracy: 0.985 - ETA: 46s - loss: 0.0613 - accuracy: 0.985 - ETA: 45s - loss: 0.0607 - accuracy: 0.985 - ETA: 44s - loss: 0.0607 - accuracy: 0.985 - ETA: 42s - loss: 0.0605 - accuracy: 0.985 - ETA: 41s - loss: 0.0639 - accuracy: 0.985 - ETA: 39s - loss: 0.0631 - accuracy: 0.985 - ETA: 38s - loss: 0.0637 - accuracy: 0.985 - ETA: 37s - loss: 0.0634 - accuracy: 0.985 - ETA: 35s - loss: 0.0639 - accuracy: 0.985 - ETA: 34s - loss: 0.0633 - accuracy: 0.985 - ETA: 32s - loss: 0.0634 - accuracy: 0.985 - ETA: 31s - loss: 0.0635 - accuracy: 0.985 - ETA: 30s - loss: 0.0631 - accuracy: 0.985 - ETA: 28s - loss: 0.0627 - accuracy: 0.985 - ETA: 27s - loss: 0.0624 - accuracy: 0.985 - ETA: 25s - loss: 0.0622 - accuracy: 0.985 - ETA: 24s - loss: 0.0620 - accuracy: 0.985 - ETA: 23s - loss: 0.0624 - accuracy: 0.984 - ETA: 21s - loss: 0.0636 - accuracy: 0.984 - ETA: 20s - loss: 0.0633 - accuracy: 0.984 - ETA: 19s - loss: 0.0632 - accuracy: 0.984 - ETA: 17s - loss: 0.0629 - accuracy: 0.984 - ETA: 16s - loss: 0.0651 - accuracy: 0.984 - ETA: 14s - loss: 0.0649 - accuracy: 0.984 - ETA: 13s - loss: 0.0643 - accuracy: 0.984 - ETA: 12s - loss: 0.0647 - accuracy: 0.984 - ETA: 10s - loss: 0.0646 - accuracy: 0.984 - ETA: 9s - loss: 0.0653 - accuracy: 0.983 - ETA: 7s - loss: 0.0651 - accuracy: 0.98 - ETA: 6s - loss: 0.0653 - accuracy: 0.98 - ETA: 5s - loss: 0.0653 - accuracy: 0.98 - ETA: 3s - loss: 0.0655 - accuracy: 0.98 - ETA: 2s - loss: 0.0655 - accuracy: 0.98 - ETA: 1s - loss: 0.0660 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0659 - accuracy: 0.9835 - val_loss: 3.2959 - val_accuracy: 0.4146\n",
      "Epoch 60/100\n",
      "13022/13022 [==============================] - ETA: 2:16 - loss: 0.0420 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0541 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0483 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0642 - accuracy: 0.97 - ETA: 2:07 - loss: 0.0699 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0715 - accuracy: 0.97 - ETA: 2:05 - loss: 0.1050 - accuracy: 0.97 - ETA: 2:05 - loss: 0.0964 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0921 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0871 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0827 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0775 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0803 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0769 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0742 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0756 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0782 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0772 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0807 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0827 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0842 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0844 - accuracy: 0.97 - ETA: 1:48 - loss: 0.0815 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0794 - accuracy: 0.97 - ETA: 1:45 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:44 - loss: 0.0789 - accuracy: 0.97 - ETA: 1:43 - loss: 0.0780 - accuracy: 0.97 - ETA: 1:41 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0744 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0738 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0731 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0744 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0724 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0732 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0699 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0687 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0695 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0687 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0691 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0638 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0648 - accuracy: 0.98 - ETA: 58s - loss: 0.0649 - accuracy: 0.9832 - ETA: 57s - loss: 0.0645 - accuracy: 0.983 - ETA: 55s - loss: 0.0639 - accuracy: 0.983 - ETA: 54s - loss: 0.0635 - accuracy: 0.983 - ETA: 53s - loss: 0.0641 - accuracy: 0.983 - ETA: 51s - loss: 0.0637 - accuracy: 0.983 - ETA: 50s - loss: 0.0629 - accuracy: 0.983 - ETA: 49s - loss: 0.0627 - accuracy: 0.983 - ETA: 47s - loss: 0.0634 - accuracy: 0.983 - ETA: 46s - loss: 0.0640 - accuracy: 0.983 - ETA: 45s - loss: 0.0641 - accuracy: 0.983 - ETA: 43s - loss: 0.0646 - accuracy: 0.983 - ETA: 42s - loss: 0.0644 - accuracy: 0.983 - ETA: 40s - loss: 0.0652 - accuracy: 0.983 - ETA: 39s - loss: 0.0665 - accuracy: 0.983 - ETA: 38s - loss: 0.0658 - accuracy: 0.983 - ETA: 36s - loss: 0.0655 - accuracy: 0.983 - ETA: 35s - loss: 0.0665 - accuracy: 0.983 - ETA: 33s - loss: 0.0661 - accuracy: 0.983 - ETA: 32s - loss: 0.0655 - accuracy: 0.983 - ETA: 31s - loss: 0.0647 - accuracy: 0.983 - ETA: 29s - loss: 0.0662 - accuracy: 0.983 - ETA: 28s - loss: 0.0660 - accuracy: 0.983 - ETA: 26s - loss: 0.0662 - accuracy: 0.983 - ETA: 25s - loss: 0.0666 - accuracy: 0.983 - ETA: 23s - loss: 0.0661 - accuracy: 0.983 - ETA: 22s - loss: 0.0662 - accuracy: 0.983 - ETA: 21s - loss: 0.0657 - accuracy: 0.984 - ETA: 19s - loss: 0.0657 - accuracy: 0.984 - ETA: 18s - loss: 0.0654 - accuracy: 0.983 - ETA: 16s - loss: 0.0655 - accuracy: 0.983 - ETA: 15s - loss: 0.0649 - accuracy: 0.983 - ETA: 13s - loss: 0.0652 - accuracy: 0.984 - ETA: 12s - loss: 0.0653 - accuracy: 0.984 - ETA: 11s - loss: 0.0661 - accuracy: 0.984 - ETA: 9s - loss: 0.0668 - accuracy: 0.984 - ETA: 8s - loss: 0.0666 - accuracy: 0.98 - ETA: 6s - loss: 0.0666 - accuracy: 0.98 - ETA: 5s - loss: 0.0670 - accuracy: 0.98 - ETA: 3s - loss: 0.0665 - accuracy: 0.98 - ETA: 2s - loss: 0.0663 - accuracy: 0.98 - ETA: 1s - loss: 0.0660 - accuracy: 0.98 - 161s 12ms/step - loss: 0.0657 - accuracy: 0.9839 - val_loss: 3.4398 - val_accuracy: 0.3999\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:21 - loss: 0.0203 - accuracy: 1.00 - ETA: 2:19 - loss: 0.0592 - accuracy: 0.99 - ETA: 2:20 - loss: 0.0582 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0494 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0466 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0805 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0723 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0770 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0731 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0729 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0846 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0803 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0782 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0768 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0719 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0773 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0753 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0698 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0659 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0651 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0641 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0651 - accuracy: 0.98 - ETA: 59s - loss: 0.0643 - accuracy: 0.9851 - ETA: 57s - loss: 0.0641 - accuracy: 0.985 - ETA: 56s - loss: 0.0656 - accuracy: 0.984 - ETA: 55s - loss: 0.0656 - accuracy: 0.984 - ETA: 53s - loss: 0.0648 - accuracy: 0.984 - ETA: 52s - loss: 0.0656 - accuracy: 0.984 - ETA: 51s - loss: 0.0662 - accuracy: 0.984 - ETA: 49s - loss: 0.0666 - accuracy: 0.984 - ETA: 48s - loss: 0.0672 - accuracy: 0.984 - ETA: 47s - loss: 0.0677 - accuracy: 0.984 - ETA: 46s - loss: 0.0671 - accuracy: 0.984 - ETA: 44s - loss: 0.0667 - accuracy: 0.984 - ETA: 43s - loss: 0.0668 - accuracy: 0.984 - ETA: 42s - loss: 0.0667 - accuracy: 0.984 - ETA: 41s - loss: 0.0671 - accuracy: 0.983 - ETA: 39s - loss: 0.0673 - accuracy: 0.983 - ETA: 38s - loss: 0.0677 - accuracy: 0.983 - ETA: 37s - loss: 0.0676 - accuracy: 0.983 - ETA: 36s - loss: 0.0667 - accuracy: 0.983 - ETA: 34s - loss: 0.0672 - accuracy: 0.983 - ETA: 33s - loss: 0.0664 - accuracy: 0.983 - ETA: 32s - loss: 0.0670 - accuracy: 0.983 - ETA: 31s - loss: 0.0671 - accuracy: 0.983 - ETA: 29s - loss: 0.0684 - accuracy: 0.983 - ETA: 28s - loss: 0.0677 - accuracy: 0.983 - ETA: 27s - loss: 0.0678 - accuracy: 0.983 - ETA: 26s - loss: 0.0687 - accuracy: 0.983 - ETA: 24s - loss: 0.0688 - accuracy: 0.983 - ETA: 23s - loss: 0.0684 - accuracy: 0.983 - ETA: 22s - loss: 0.0680 - accuracy: 0.983 - ETA: 21s - loss: 0.0696 - accuracy: 0.983 - ETA: 20s - loss: 0.0693 - accuracy: 0.983 - ETA: 18s - loss: 0.0692 - accuracy: 0.983 - ETA: 17s - loss: 0.0695 - accuracy: 0.983 - ETA: 16s - loss: 0.0691 - accuracy: 0.983 - ETA: 15s - loss: 0.0690 - accuracy: 0.983 - ETA: 14s - loss: 0.0692 - accuracy: 0.983 - ETA: 12s - loss: 0.0693 - accuracy: 0.983 - ETA: 11s - loss: 0.0687 - accuracy: 0.983 - ETA: 10s - loss: 0.0693 - accuracy: 0.983 - ETA: 9s - loss: 0.0693 - accuracy: 0.983 - ETA: 8s - loss: 0.0690 - accuracy: 0.98 - ETA: 6s - loss: 0.0697 - accuracy: 0.98 - ETA: 5s - loss: 0.0703 - accuracy: 0.98 - ETA: 4s - loss: 0.0697 - accuracy: 0.98 - ETA: 3s - loss: 0.0694 - accuracy: 0.98 - ETA: 2s - loss: 0.0701 - accuracy: 0.98 - ETA: 0s - loss: 0.0697 - accuracy: 0.98 - 133s 10ms/step - loss: 0.0712 - accuracy: 0.9832 - val_loss: 3.3948 - val_accuracy: 0.3948\n",
      "Epoch 62/100\n",
      "13022/13022 [==============================] - ETA: 1:55 - loss: 0.0491 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0498 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0545 - accuracy: 0.98 - ETA: 59s - loss: 0.0544 - accuracy: 0.9861 - ETA: 58s - loss: 0.0534 - accuracy: 0.986 - ETA: 57s - loss: 0.0542 - accuracy: 0.986 - ETA: 55s - loss: 0.0542 - accuracy: 0.986 - ETA: 54s - loss: 0.0547 - accuracy: 0.986 - ETA: 53s - loss: 0.0549 - accuracy: 0.986 - ETA: 52s - loss: 0.0562 - accuracy: 0.986 - ETA: 51s - loss: 0.0563 - accuracy: 0.986 - ETA: 50s - loss: 0.0556 - accuracy: 0.986 - ETA: 49s - loss: 0.0566 - accuracy: 0.986 - ETA: 47s - loss: 0.0560 - accuracy: 0.986 - ETA: 46s - loss: 0.0554 - accuracy: 0.986 - ETA: 45s - loss: 0.0564 - accuracy: 0.986 - ETA: 44s - loss: 0.0558 - accuracy: 0.986 - ETA: 43s - loss: 0.0565 - accuracy: 0.986 - ETA: 42s - loss: 0.0582 - accuracy: 0.986 - ETA: 41s - loss: 0.0582 - accuracy: 0.985 - ETA: 40s - loss: 0.0579 - accuracy: 0.985 - ETA: 39s - loss: 0.0572 - accuracy: 0.985 - ETA: 37s - loss: 0.0587 - accuracy: 0.985 - ETA: 36s - loss: 0.0591 - accuracy: 0.985 - ETA: 35s - loss: 0.0589 - accuracy: 0.985 - ETA: 34s - loss: 0.0595 - accuracy: 0.985 - ETA: 33s - loss: 0.0596 - accuracy: 0.985 - ETA: 32s - loss: 0.0603 - accuracy: 0.985 - ETA: 31s - loss: 0.0613 - accuracy: 0.984 - ETA: 30s - loss: 0.0611 - accuracy: 0.984 - ETA: 28s - loss: 0.0609 - accuracy: 0.984 - ETA: 27s - loss: 0.0619 - accuracy: 0.984 - ETA: 26s - loss: 0.0616 - accuracy: 0.984 - ETA: 25s - loss: 0.0614 - accuracy: 0.984 - ETA: 24s - loss: 0.0612 - accuracy: 0.984 - ETA: 23s - loss: 0.0628 - accuracy: 0.984 - ETA: 22s - loss: 0.0628 - accuracy: 0.984 - ETA: 21s - loss: 0.0621 - accuracy: 0.984 - ETA: 19s - loss: 0.0616 - accuracy: 0.984 - ETA: 18s - loss: 0.0612 - accuracy: 0.984 - ETA: 17s - loss: 0.0620 - accuracy: 0.984 - ETA: 16s - loss: 0.0640 - accuracy: 0.984 - ETA: 15s - loss: 0.0641 - accuracy: 0.984 - ETA: 14s - loss: 0.0648 - accuracy: 0.983 - ETA: 13s - loss: 0.0644 - accuracy: 0.983 - ETA: 12s - loss: 0.0639 - accuracy: 0.983 - ETA: 10s - loss: 0.0633 - accuracy: 0.984 - ETA: 9s - loss: 0.0631 - accuracy: 0.984 - ETA: 8s - loss: 0.0630 - accuracy: 0.98 - ETA: 7s - loss: 0.0629 - accuracy: 0.98 - ETA: 6s - loss: 0.0626 - accuracy: 0.98 - ETA: 5s - loss: 0.0627 - accuracy: 0.98 - ETA: 4s - loss: 0.0633 - accuracy: 0.98 - ETA: 3s - loss: 0.0627 - accuracy: 0.98 - ETA: 1s - loss: 0.0622 - accuracy: 0.98 - ETA: 0s - loss: 0.0621 - accuracy: 0.98 - 127s 10ms/step - loss: 0.0618 - accuracy: 0.9845 - val_loss: 3.6379 - val_accuracy: 0.3598\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:49 - loss: 0.0664 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:50 - loss: 0.1139 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0903 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0829 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0741 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0705 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0554 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0499 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0489 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0483 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0493 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0473 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0456 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0456 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0462 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0461 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0462 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0471 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0462 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0463 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0476 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0493 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0488 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0486 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0484 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0474 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0467 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0495 - accuracy: 0.98 - ETA: 59s - loss: 0.0490 - accuracy: 0.9884 - ETA: 58s - loss: 0.0487 - accuracy: 0.988 - ETA: 57s - loss: 0.0481 - accuracy: 0.988 - ETA: 56s - loss: 0.0474 - accuracy: 0.988 - ETA: 55s - loss: 0.0474 - accuracy: 0.988 - ETA: 53s - loss: 0.0479 - accuracy: 0.988 - ETA: 52s - loss: 0.0479 - accuracy: 0.988 - ETA: 51s - loss: 0.0486 - accuracy: 0.988 - ETA: 50s - loss: 0.0480 - accuracy: 0.988 - ETA: 49s - loss: 0.0476 - accuracy: 0.988 - ETA: 48s - loss: 0.0473 - accuracy: 0.988 - ETA: 46s - loss: 0.0489 - accuracy: 0.988 - ETA: 45s - loss: 0.0487 - accuracy: 0.988 - ETA: 44s - loss: 0.0497 - accuracy: 0.988 - ETA: 43s - loss: 0.0491 - accuracy: 0.988 - ETA: 42s - loss: 0.0491 - accuracy: 0.988 - ETA: 41s - loss: 0.0489 - accuracy: 0.988 - ETA: 40s - loss: 0.0489 - accuracy: 0.988 - ETA: 39s - loss: 0.0493 - accuracy: 0.988 - ETA: 38s - loss: 0.0490 - accuracy: 0.988 - ETA: 36s - loss: 0.0486 - accuracy: 0.988 - ETA: 35s - loss: 0.0487 - accuracy: 0.988 - ETA: 34s - loss: 0.0486 - accuracy: 0.988 - ETA: 33s - loss: 0.0487 - accuracy: 0.988 - ETA: 32s - loss: 0.0486 - accuracy: 0.987 - ETA: 31s - loss: 0.0488 - accuracy: 0.987 - ETA: 30s - loss: 0.0483 - accuracy: 0.988 - ETA: 28s - loss: 0.0478 - accuracy: 0.988 - ETA: 27s - loss: 0.0503 - accuracy: 0.987 - ETA: 26s - loss: 0.0499 - accuracy: 0.987 - ETA: 25s - loss: 0.0499 - accuracy: 0.987 - ETA: 24s - loss: 0.0494 - accuracy: 0.987 - ETA: 23s - loss: 0.0491 - accuracy: 0.987 - ETA: 22s - loss: 0.0489 - accuracy: 0.987 - ETA: 21s - loss: 0.0499 - accuracy: 0.987 - ETA: 19s - loss: 0.0498 - accuracy: 0.987 - ETA: 18s - loss: 0.0498 - accuracy: 0.987 - ETA: 17s - loss: 0.0498 - accuracy: 0.987 - ETA: 16s - loss: 0.0526 - accuracy: 0.987 - ETA: 15s - loss: 0.0528 - accuracy: 0.987 - ETA: 14s - loss: 0.0527 - accuracy: 0.987 - ETA: 13s - loss: 0.0523 - accuracy: 0.987 - ETA: 12s - loss: 0.0518 - accuracy: 0.987 - ETA: 10s - loss: 0.0540 - accuracy: 0.987 - ETA: 9s - loss: 0.0535 - accuracy: 0.987 - ETA: 8s - loss: 0.0534 - accuracy: 0.98 - ETA: 7s - loss: 0.0529 - accuracy: 0.98 - ETA: 6s - loss: 0.0527 - accuracy: 0.98 - ETA: 5s - loss: 0.0523 - accuracy: 0.98 - ETA: 4s - loss: 0.0522 - accuracy: 0.98 - ETA: 3s - loss: 0.0522 - accuracy: 0.98 - ETA: 1s - loss: 0.0520 - accuracy: 0.98 - ETA: 0s - loss: 0.0517 - accuracy: 0.98 - 127s 10ms/step - loss: 0.0517 - accuracy: 0.9879 - val_loss: 3.5319 - val_accuracy: 0.3890\n",
      "Epoch 64/100\n",
      "13022/13022 [==============================] - ETA: 1:50 - loss: 0.0475 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0288 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0214 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0397 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0520 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0514 - accuracy: 0.98 - ETA: 59s - loss: 0.0506 - accuracy: 0.9879 - ETA: 58s - loss: 0.0516 - accuracy: 0.987 - ETA: 57s - loss: 0.0513 - accuracy: 0.987 - ETA: 56s - loss: 0.0509 - accuracy: 0.987 - ETA: 54s - loss: 0.0506 - accuracy: 0.987 - ETA: 53s - loss: 0.0500 - accuracy: 0.987 - ETA: 52s - loss: 0.0504 - accuracy: 0.987 - ETA: 51s - loss: 0.0496 - accuracy: 0.987 - ETA: 50s - loss: 0.0496 - accuracy: 0.987 - ETA: 49s - loss: 0.0492 - accuracy: 0.987 - ETA: 48s - loss: 0.0484 - accuracy: 0.988 - ETA: 46s - loss: 0.0492 - accuracy: 0.987 - ETA: 45s - loss: 0.0490 - accuracy: 0.988 - ETA: 44s - loss: 0.0499 - accuracy: 0.987 - ETA: 43s - loss: 0.0492 - accuracy: 0.987 - ETA: 42s - loss: 0.0497 - accuracy: 0.987 - ETA: 41s - loss: 0.0509 - accuracy: 0.987 - ETA: 40s - loss: 0.0503 - accuracy: 0.987 - ETA: 39s - loss: 0.0507 - accuracy: 0.987 - ETA: 37s - loss: 0.0518 - accuracy: 0.987 - ETA: 36s - loss: 0.0520 - accuracy: 0.987 - ETA: 35s - loss: 0.0519 - accuracy: 0.986 - ETA: 34s - loss: 0.0512 - accuracy: 0.987 - ETA: 33s - loss: 0.0513 - accuracy: 0.987 - ETA: 32s - loss: 0.0519 - accuracy: 0.986 - ETA: 31s - loss: 0.0527 - accuracy: 0.986 - ETA: 30s - loss: 0.0527 - accuracy: 0.986 - ETA: 28s - loss: 0.0537 - accuracy: 0.986 - ETA: 27s - loss: 0.0532 - accuracy: 0.986 - ETA: 26s - loss: 0.0549 - accuracy: 0.986 - ETA: 25s - loss: 0.0551 - accuracy: 0.986 - ETA: 24s - loss: 0.0547 - accuracy: 0.986 - ETA: 23s - loss: 0.0545 - accuracy: 0.986 - ETA: 22s - loss: 0.0548 - accuracy: 0.985 - ETA: 21s - loss: 0.0548 - accuracy: 0.986 - ETA: 19s - loss: 0.0571 - accuracy: 0.986 - ETA: 18s - loss: 0.0593 - accuracy: 0.985 - ETA: 17s - loss: 0.0600 - accuracy: 0.985 - ETA: 16s - loss: 0.0611 - accuracy: 0.985 - ETA: 15s - loss: 0.0609 - accuracy: 0.985 - ETA: 14s - loss: 0.0618 - accuracy: 0.985 - ETA: 13s - loss: 0.0612 - accuracy: 0.985 - ETA: 12s - loss: 0.0613 - accuracy: 0.985 - ETA: 10s - loss: 0.0612 - accuracy: 0.985 - ETA: 9s - loss: 0.0609 - accuracy: 0.985 - ETA: 8s - loss: 0.0607 - accuracy: 0.98 - ETA: 7s - loss: 0.0604 - accuracy: 0.98 - ETA: 6s - loss: 0.0598 - accuracy: 0.98 - ETA: 5s - loss: 0.0598 - accuracy: 0.98 - ETA: 4s - loss: 0.0600 - accuracy: 0.98 - ETA: 3s - loss: 0.0597 - accuracy: 0.98 - ETA: 1s - loss: 0.0608 - accuracy: 0.98 - ETA: 0s - loss: 0.0613 - accuracy: 0.98 - 127s 10ms/step - loss: 0.0609 - accuracy: 0.9855 - val_loss: 3.5336 - val_accuracy: 0.4033\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:51 - loss: 0.0242 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0503 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0437 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0427 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0707 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0708 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0776 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0764 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0730 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0737 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0702 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0717 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0695 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0685 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0691 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0666 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0648 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0632 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0612 - accuracy: 0.98 - ETA: 59s - loss: 0.0610 - accuracy: 0.9853 - ETA: 58s - loss: 0.0614 - accuracy: 0.985 - ETA: 57s - loss: 0.0617 - accuracy: 0.985 - ETA: 56s - loss: 0.0664 - accuracy: 0.984 - ETA: 55s - loss: 0.0664 - accuracy: 0.984 - ETA: 54s - loss: 0.0657 - accuracy: 0.984 - ETA: 52s - loss: 0.0655 - accuracy: 0.984 - ETA: 51s - loss: 0.0652 - accuracy: 0.984 - ETA: 50s - loss: 0.0660 - accuracy: 0.984 - ETA: 49s - loss: 0.0653 - accuracy: 0.984 - ETA: 48s - loss: 0.0659 - accuracy: 0.984 - ETA: 47s - loss: 0.0655 - accuracy: 0.984 - ETA: 46s - loss: 0.0646 - accuracy: 0.984 - ETA: 44s - loss: 0.0666 - accuracy: 0.984 - ETA: 43s - loss: 0.0661 - accuracy: 0.984 - ETA: 42s - loss: 0.0657 - accuracy: 0.984 - ETA: 41s - loss: 0.0650 - accuracy: 0.984 - ETA: 40s - loss: 0.0647 - accuracy: 0.984 - ETA: 39s - loss: 0.0661 - accuracy: 0.984 - ETA: 38s - loss: 0.0657 - accuracy: 0.985 - ETA: 37s - loss: 0.0655 - accuracy: 0.984 - ETA: 35s - loss: 0.0654 - accuracy: 0.984 - ETA: 34s - loss: 0.0651 - accuracy: 0.984 - ETA: 33s - loss: 0.0647 - accuracy: 0.985 - ETA: 32s - loss: 0.0644 - accuracy: 0.985 - ETA: 31s - loss: 0.0642 - accuracy: 0.985 - ETA: 30s - loss: 0.0636 - accuracy: 0.985 - ETA: 29s - loss: 0.0633 - accuracy: 0.985 - ETA: 28s - loss: 0.0648 - accuracy: 0.985 - ETA: 26s - loss: 0.0644 - accuracy: 0.985 - ETA: 25s - loss: 0.0643 - accuracy: 0.985 - ETA: 24s - loss: 0.0637 - accuracy: 0.985 - ETA: 23s - loss: 0.0633 - accuracy: 0.985 - ETA: 22s - loss: 0.0632 - accuracy: 0.985 - ETA: 21s - loss: 0.0631 - accuracy: 0.985 - ETA: 20s - loss: 0.0626 - accuracy: 0.985 - ETA: 18s - loss: 0.0629 - accuracy: 0.985 - ETA: 17s - loss: 0.0624 - accuracy: 0.985 - ETA: 16s - loss: 0.0625 - accuracy: 0.985 - ETA: 15s - loss: 0.0642 - accuracy: 0.985 - ETA: 14s - loss: 0.0637 - accuracy: 0.985 - ETA: 13s - loss: 0.0631 - accuracy: 0.985 - ETA: 12s - loss: 0.0636 - accuracy: 0.985 - ETA: 11s - loss: 0.0632 - accuracy: 0.985 - ETA: 9s - loss: 0.0643 - accuracy: 0.984 - ETA: 8s - loss: 0.0639 - accuracy: 0.98 - ETA: 7s - loss: 0.0635 - accuracy: 0.98 - ETA: 6s - loss: 0.0638 - accuracy: 0.98 - ETA: 5s - loss: 0.0640 - accuracy: 0.98 - ETA: 4s - loss: 0.0637 - accuracy: 0.98 - ETA: 3s - loss: 0.0643 - accuracy: 0.98 - ETA: 1s - loss: 0.0643 - accuracy: 0.98 - ETA: 0s - loss: 0.0641 - accuracy: 0.98 - 128s 10ms/step - loss: 0.0638 - accuracy: 0.9843 - val_loss: 3.6178 - val_accuracy: 0.3589\n",
      "Epoch 66/100\n",
      "13022/13022 [==============================] - ETA: 1:55 - loss: 0.1659 - accuracy: 0.95 - ETA: 1:54 - loss: 0.1024 - accuracy: 0.96 - ETA: 1:52 - loss: 0.1074 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0978 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0815 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0684 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0745 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0668 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0792 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0768 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0759 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0751 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0786 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0736 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0735 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0760 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0740 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0755 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0815 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0790 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0760 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0743 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0733 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0721 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0733 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0754 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0733 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0725 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0738 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0732 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0712 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0714 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0703 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0746 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0734 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0716 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0731 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0718 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0708 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0684 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0688 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0715 - accuracy: 0.98 - ETA: 59s - loss: 0.0722 - accuracy: 0.9825 - ETA: 57s - loss: 0.0717 - accuracy: 0.982 - ETA: 56s - loss: 0.0733 - accuracy: 0.982 - ETA: 55s - loss: 0.0731 - accuracy: 0.982 - ETA: 54s - loss: 0.0722 - accuracy: 0.982 - ETA: 53s - loss: 0.0743 - accuracy: 0.982 - ETA: 51s - loss: 0.0746 - accuracy: 0.982 - ETA: 50s - loss: 0.0735 - accuracy: 0.982 - ETA: 49s - loss: 0.0735 - accuracy: 0.982 - ETA: 48s - loss: 0.0736 - accuracy: 0.982 - ETA: 46s - loss: 0.0728 - accuracy: 0.982 - ETA: 45s - loss: 0.0742 - accuracy: 0.982 - ETA: 44s - loss: 0.0733 - accuracy: 0.982 - ETA: 43s - loss: 0.0745 - accuracy: 0.982 - ETA: 41s - loss: 0.0812 - accuracy: 0.982 - ETA: 40s - loss: 0.0830 - accuracy: 0.982 - ETA: 39s - loss: 0.0831 - accuracy: 0.982 - ETA: 38s - loss: 0.0826 - accuracy: 0.982 - ETA: 36s - loss: 0.0820 - accuracy: 0.982 - ETA: 35s - loss: 0.0823 - accuracy: 0.982 - ETA: 34s - loss: 0.0815 - accuracy: 0.982 - ETA: 33s - loss: 0.0808 - accuracy: 0.982 - ETA: 31s - loss: 0.0808 - accuracy: 0.982 - ETA: 30s - loss: 0.0809 - accuracy: 0.982 - ETA: 29s - loss: 0.0808 - accuracy: 0.982 - ETA: 28s - loss: 0.0798 - accuracy: 0.982 - ETA: 27s - loss: 0.0802 - accuracy: 0.982 - ETA: 25s - loss: 0.0794 - accuracy: 0.982 - ETA: 24s - loss: 0.0792 - accuracy: 0.982 - ETA: 23s - loss: 0.0788 - accuracy: 0.982 - ETA: 22s - loss: 0.0784 - accuracy: 0.982 - ETA: 21s - loss: 0.0792 - accuracy: 0.982 - ETA: 19s - loss: 0.0792 - accuracy: 0.982 - ETA: 18s - loss: 0.0788 - accuracy: 0.982 - ETA: 17s - loss: 0.0787 - accuracy: 0.982 - ETA: 16s - loss: 0.0784 - accuracy: 0.982 - ETA: 15s - loss: 0.0780 - accuracy: 0.982 - ETA: 13s - loss: 0.0775 - accuracy: 0.982 - ETA: 12s - loss: 0.0769 - accuracy: 0.982 - ETA: 11s - loss: 0.0763 - accuracy: 0.982 - ETA: 10s - loss: 0.0768 - accuracy: 0.982 - ETA: 9s - loss: 0.0765 - accuracy: 0.982 - ETA: 7s - loss: 0.0761 - accuracy: 0.98 - ETA: 6s - loss: 0.0759 - accuracy: 0.98 - ETA: 5s - loss: 0.0753 - accuracy: 0.98 - ETA: 4s - loss: 0.0748 - accuracy: 0.98 - ETA: 3s - loss: 0.0753 - accuracy: 0.98 - ETA: 2s - loss: 0.0747 - accuracy: 0.98 - ETA: 0s - loss: 0.0743 - accuracy: 0.98 - 132s 10ms/step - loss: 0.0748 - accuracy: 0.9831 - val_loss: 3.4324 - val_accuracy: 0.3803\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:53 - loss: 0.1249 - accuracy: 0.97 - ETA: 1:50 - loss: 0.0807 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0681 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0683 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0702 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0689 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0707 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0731 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0723 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0661 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0610 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0715 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0727 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0716 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0690 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0716 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0782 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0769 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0753 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0741 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0732 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0706 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0696 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0697 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0686 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0675 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0685 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0679 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0674 - accuracy: 0.98 - ETA: 59s - loss: 0.0668 - accuracy: 0.9834 - ETA: 58s - loss: 0.0666 - accuracy: 0.983 - ETA: 57s - loss: 0.0656 - accuracy: 0.983 - ETA: 56s - loss: 0.0645 - accuracy: 0.983 - ETA: 55s - loss: 0.0653 - accuracy: 0.983 - ETA: 54s - loss: 0.0656 - accuracy: 0.983 - ETA: 53s - loss: 0.0654 - accuracy: 0.983 - ETA: 52s - loss: 0.0658 - accuracy: 0.983 - ETA: 51s - loss: 0.0650 - accuracy: 0.984 - ETA: 49s - loss: 0.0651 - accuracy: 0.984 - ETA: 48s - loss: 0.0650 - accuracy: 0.984 - ETA: 47s - loss: 0.0653 - accuracy: 0.984 - ETA: 46s - loss: 0.0658 - accuracy: 0.984 - ETA: 45s - loss: 0.0663 - accuracy: 0.983 - ETA: 44s - loss: 0.0656 - accuracy: 0.983 - ETA: 43s - loss: 0.0657 - accuracy: 0.983 - ETA: 42s - loss: 0.0649 - accuracy: 0.983 - ETA: 41s - loss: 0.0655 - accuracy: 0.983 - ETA: 39s - loss: 0.0647 - accuracy: 0.984 - ETA: 38s - loss: 0.0638 - accuracy: 0.984 - ETA: 37s - loss: 0.0632 - accuracy: 0.984 - ETA: 36s - loss: 0.0627 - accuracy: 0.984 - ETA: 35s - loss: 0.0625 - accuracy: 0.984 - ETA: 34s - loss: 0.0618 - accuracy: 0.984 - ETA: 33s - loss: 0.0620 - accuracy: 0.984 - ETA: 32s - loss: 0.0615 - accuracy: 0.984 - ETA: 30s - loss: 0.0618 - accuracy: 0.984 - ETA: 29s - loss: 0.0621 - accuracy: 0.984 - ETA: 28s - loss: 0.0615 - accuracy: 0.984 - ETA: 27s - loss: 0.0627 - accuracy: 0.984 - ETA: 26s - loss: 0.0623 - accuracy: 0.984 - ETA: 25s - loss: 0.0636 - accuracy: 0.984 - ETA: 24s - loss: 0.0631 - accuracy: 0.984 - ETA: 23s - loss: 0.0626 - accuracy: 0.984 - ETA: 22s - loss: 0.0624 - accuracy: 0.984 - ETA: 20s - loss: 0.0628 - accuracy: 0.984 - ETA: 19s - loss: 0.0626 - accuracy: 0.984 - ETA: 18s - loss: 0.0622 - accuracy: 0.984 - ETA: 17s - loss: 0.0620 - accuracy: 0.984 - ETA: 16s - loss: 0.0616 - accuracy: 0.984 - ETA: 15s - loss: 0.0612 - accuracy: 0.984 - ETA: 14s - loss: 0.0606 - accuracy: 0.984 - ETA: 13s - loss: 0.0602 - accuracy: 0.984 - ETA: 11s - loss: 0.0600 - accuracy: 0.984 - ETA: 10s - loss: 0.0605 - accuracy: 0.984 - ETA: 9s - loss: 0.0602 - accuracy: 0.984 - ETA: 8s - loss: 0.0604 - accuracy: 0.98 - ETA: 7s - loss: 0.0605 - accuracy: 0.98 - ETA: 6s - loss: 0.0616 - accuracy: 0.98 - ETA: 5s - loss: 0.0616 - accuracy: 0.98 - ETA: 4s - loss: 0.0613 - accuracy: 0.98 - ETA: 3s - loss: 0.0617 - accuracy: 0.98 - ETA: 1s - loss: 0.0613 - accuracy: 0.98 - ETA: 0s - loss: 0.0616 - accuracy: 0.98 - 126s 10ms/step - loss: 0.0624 - accuracy: 0.9846 - val_loss: 3.4513 - val_accuracy: 0.3845\n",
      "Epoch 68/100\n",
      "13022/13022 [==============================] - ETA: 1:50 - loss: 0.0234 - accuracy: 1.00 - ETA: 1:48 - loss: 0.0901 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0528 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0445 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0520 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0496 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0747 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0888 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0804 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0842 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0853 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0846 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0836 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0787 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0766 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0739 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0775 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0779 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0751 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0731 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0708 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0733 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0690 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0637 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0621 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0596 - accuracy: 0.98 - ETA: 59s - loss: 0.0602 - accuracy: 0.9867 - ETA: 58s - loss: 0.0595 - accuracy: 0.986 - ETA: 57s - loss: 0.0590 - accuracy: 0.986 - ETA: 56s - loss: 0.0581 - accuracy: 0.987 - ETA: 55s - loss: 0.0579 - accuracy: 0.987 - ETA: 54s - loss: 0.0568 - accuracy: 0.987 - ETA: 53s - loss: 0.0564 - accuracy: 0.987 - ETA: 52s - loss: 0.0573 - accuracy: 0.987 - ETA: 51s - loss: 0.0582 - accuracy: 0.987 - ETA: 49s - loss: 0.0576 - accuracy: 0.987 - ETA: 48s - loss: 0.0575 - accuracy: 0.987 - ETA: 47s - loss: 0.0571 - accuracy: 0.987 - ETA: 46s - loss: 0.0566 - accuracy: 0.987 - ETA: 45s - loss: 0.0567 - accuracy: 0.987 - ETA: 44s - loss: 0.0567 - accuracy: 0.987 - ETA: 43s - loss: 0.0560 - accuracy: 0.987 - ETA: 42s - loss: 0.0561 - accuracy: 0.987 - ETA: 40s - loss: 0.0554 - accuracy: 0.987 - ETA: 39s - loss: 0.0555 - accuracy: 0.987 - ETA: 38s - loss: 0.0550 - accuracy: 0.987 - ETA: 37s - loss: 0.0551 - accuracy: 0.987 - ETA: 36s - loss: 0.0553 - accuracy: 0.987 - ETA: 35s - loss: 0.0549 - accuracy: 0.987 - ETA: 34s - loss: 0.0544 - accuracy: 0.987 - ETA: 33s - loss: 0.0545 - accuracy: 0.987 - ETA: 32s - loss: 0.0539 - accuracy: 0.987 - ETA: 30s - loss: 0.0537 - accuracy: 0.987 - ETA: 29s - loss: 0.0544 - accuracy: 0.987 - ETA: 28s - loss: 0.0551 - accuracy: 0.987 - ETA: 27s - loss: 0.0550 - accuracy: 0.987 - ETA: 26s - loss: 0.0546 - accuracy: 0.987 - ETA: 25s - loss: 0.0544 - accuracy: 0.987 - ETA: 24s - loss: 0.0549 - accuracy: 0.987 - ETA: 23s - loss: 0.0545 - accuracy: 0.987 - ETA: 21s - loss: 0.0547 - accuracy: 0.987 - ETA: 20s - loss: 0.0544 - accuracy: 0.987 - ETA: 19s - loss: 0.0548 - accuracy: 0.987 - ETA: 18s - loss: 0.0554 - accuracy: 0.987 - ETA: 17s - loss: 0.0552 - accuracy: 0.987 - ETA: 16s - loss: 0.0555 - accuracy: 0.987 - ETA: 15s - loss: 0.0560 - accuracy: 0.987 - ETA: 14s - loss: 0.0568 - accuracy: 0.987 - ETA: 13s - loss: 0.0568 - accuracy: 0.987 - ETA: 11s - loss: 0.0565 - accuracy: 0.987 - ETA: 10s - loss: 0.0562 - accuracy: 0.987 - ETA: 9s - loss: 0.0557 - accuracy: 0.987 - ETA: 8s - loss: 0.0567 - accuracy: 0.98 - ETA: 7s - loss: 0.0569 - accuracy: 0.98 - ETA: 6s - loss: 0.0568 - accuracy: 0.98 - ETA: 5s - loss: 0.0563 - accuracy: 0.98 - ETA: 4s - loss: 0.0563 - accuracy: 0.98 - ETA: 3s - loss: 0.0568 - accuracy: 0.98 - ETA: 1s - loss: 0.0579 - accuracy: 0.98 - ETA: 0s - loss: 0.0588 - accuracy: 0.98 - 127s 10ms/step - loss: 0.0588 - accuracy: 0.9873 - val_loss: 3.4609 - val_accuracy: 0.3952\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:51 - loss: 0.0832 - accuracy: 0.97 - ETA: 1:52 - loss: 0.0695 - accuracy: 0.97 - ETA: 1:49 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0369 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0380 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0361 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0340 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0337 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0313 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0341 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0357 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0344 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0335 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0348 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0449 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0435 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0438 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0432 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0432 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0425 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0575 - accuracy: 0.98 - ETA: 59s - loss: 0.0566 - accuracy: 0.9878 - ETA: 58s - loss: 0.0560 - accuracy: 0.987 - ETA: 57s - loss: 0.0575 - accuracy: 0.987 - ETA: 56s - loss: 0.0593 - accuracy: 0.987 - ETA: 55s - loss: 0.0585 - accuracy: 0.987 - ETA: 54s - loss: 0.0582 - accuracy: 0.987 - ETA: 53s - loss: 0.0574 - accuracy: 0.987 - ETA: 52s - loss: 0.0592 - accuracy: 0.986 - ETA: 50s - loss: 0.0585 - accuracy: 0.987 - ETA: 49s - loss: 0.0582 - accuracy: 0.987 - ETA: 48s - loss: 0.0640 - accuracy: 0.986 - ETA: 47s - loss: 0.0645 - accuracy: 0.986 - ETA: 46s - loss: 0.0637 - accuracy: 0.986 - ETA: 45s - loss: 0.0629 - accuracy: 0.986 - ETA: 44s - loss: 0.0631 - accuracy: 0.986 - ETA: 43s - loss: 0.0631 - accuracy: 0.986 - ETA: 41s - loss: 0.0624 - accuracy: 0.986 - ETA: 40s - loss: 0.0619 - accuracy: 0.986 - ETA: 39s - loss: 0.0612 - accuracy: 0.986 - ETA: 38s - loss: 0.0617 - accuracy: 0.986 - ETA: 37s - loss: 0.0627 - accuracy: 0.985 - ETA: 36s - loss: 0.0634 - accuracy: 0.985 - ETA: 35s - loss: 0.0639 - accuracy: 0.985 - ETA: 34s - loss: 0.0639 - accuracy: 0.985 - ETA: 33s - loss: 0.0631 - accuracy: 0.985 - ETA: 31s - loss: 0.0634 - accuracy: 0.985 - ETA: 30s - loss: 0.0631 - accuracy: 0.985 - ETA: 29s - loss: 0.0642 - accuracy: 0.985 - ETA: 28s - loss: 0.0634 - accuracy: 0.985 - ETA: 27s - loss: 0.0632 - accuracy: 0.985 - ETA: 26s - loss: 0.0627 - accuracy: 0.985 - ETA: 25s - loss: 0.0621 - accuracy: 0.985 - ETA: 24s - loss: 0.0621 - accuracy: 0.985 - ETA: 23s - loss: 0.0633 - accuracy: 0.985 - ETA: 21s - loss: 0.0632 - accuracy: 0.985 - ETA: 20s - loss: 0.0630 - accuracy: 0.985 - ETA: 19s - loss: 0.0625 - accuracy: 0.985 - ETA: 18s - loss: 0.0661 - accuracy: 0.985 - ETA: 17s - loss: 0.0656 - accuracy: 0.985 - ETA: 16s - loss: 0.0654 - accuracy: 0.985 - ETA: 15s - loss: 0.0651 - accuracy: 0.985 - ETA: 14s - loss: 0.0649 - accuracy: 0.985 - ETA: 13s - loss: 0.0648 - accuracy: 0.985 - ETA: 11s - loss: 0.0646 - accuracy: 0.985 - ETA: 10s - loss: 0.0642 - accuracy: 0.985 - ETA: 9s - loss: 0.0637 - accuracy: 0.985 - ETA: 8s - loss: 0.0631 - accuracy: 0.98 - ETA: 7s - loss: 0.0630 - accuracy: 0.98 - ETA: 6s - loss: 0.0628 - accuracy: 0.98 - ETA: 5s - loss: 0.0635 - accuracy: 0.98 - ETA: 4s - loss: 0.0635 - accuracy: 0.98 - ETA: 3s - loss: 0.0637 - accuracy: 0.98 - ETA: 1s - loss: 0.0632 - accuracy: 0.98 - ETA: 0s - loss: 0.0626 - accuracy: 0.98 - 126s 10ms/step - loss: 0.0624 - accuracy: 0.9854 - val_loss: 3.4588 - val_accuracy: 0.3739\n",
      "Epoch 70/100\n",
      "13022/13022 [==============================] - ETA: 1:51 - loss: 0.0507 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0302 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0209 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0212 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0328 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0328 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0332 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0432 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0452 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0447 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0424 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0417 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0466 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0463 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0471 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0455 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0448 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0454 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0427 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0592 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0584 - accuracy: 0.98 - ETA: 59s - loss: 0.0574 - accuracy: 0.9878 - ETA: 58s - loss: 0.0565 - accuracy: 0.988 - ETA: 57s - loss: 0.0558 - accuracy: 0.988 - ETA: 56s - loss: 0.0581 - accuracy: 0.987 - ETA: 54s - loss: 0.0575 - accuracy: 0.987 - ETA: 53s - loss: 0.0584 - accuracy: 0.987 - ETA: 52s - loss: 0.0575 - accuracy: 0.987 - ETA: 51s - loss: 0.0569 - accuracy: 0.987 - ETA: 50s - loss: 0.0566 - accuracy: 0.988 - ETA: 49s - loss: 0.0565 - accuracy: 0.988 - ETA: 48s - loss: 0.0562 - accuracy: 0.988 - ETA: 47s - loss: 0.0554 - accuracy: 0.988 - ETA: 46s - loss: 0.0557 - accuracy: 0.988 - ETA: 45s - loss: 0.0569 - accuracy: 0.987 - ETA: 43s - loss: 0.0564 - accuracy: 0.987 - ETA: 42s - loss: 0.0560 - accuracy: 0.987 - ETA: 41s - loss: 0.0568 - accuracy: 0.987 - ETA: 40s - loss: 0.0562 - accuracy: 0.987 - ETA: 39s - loss: 0.0558 - accuracy: 0.987 - ETA: 38s - loss: 0.0551 - accuracy: 0.987 - ETA: 37s - loss: 0.0549 - accuracy: 0.987 - ETA: 36s - loss: 0.0546 - accuracy: 0.987 - ETA: 35s - loss: 0.0556 - accuracy: 0.987 - ETA: 33s - loss: 0.0552 - accuracy: 0.987 - ETA: 32s - loss: 0.0546 - accuracy: 0.987 - ETA: 31s - loss: 0.0549 - accuracy: 0.987 - ETA: 30s - loss: 0.0550 - accuracy: 0.987 - ETA: 29s - loss: 0.0550 - accuracy: 0.987 - ETA: 28s - loss: 0.0545 - accuracy: 0.987 - ETA: 27s - loss: 0.0555 - accuracy: 0.987 - ETA: 26s - loss: 0.0555 - accuracy: 0.987 - ETA: 25s - loss: 0.0562 - accuracy: 0.987 - ETA: 23s - loss: 0.0556 - accuracy: 0.987 - ETA: 22s - loss: 0.0550 - accuracy: 0.987 - ETA: 21s - loss: 0.0546 - accuracy: 0.987 - ETA: 20s - loss: 0.0544 - accuracy: 0.987 - ETA: 19s - loss: 0.0539 - accuracy: 0.987 - ETA: 18s - loss: 0.0535 - accuracy: 0.987 - ETA: 17s - loss: 0.0533 - accuracy: 0.987 - ETA: 16s - loss: 0.0530 - accuracy: 0.987 - ETA: 15s - loss: 0.0529 - accuracy: 0.987 - ETA: 14s - loss: 0.0525 - accuracy: 0.988 - ETA: 12s - loss: 0.0524 - accuracy: 0.988 - ETA: 11s - loss: 0.0519 - accuracy: 0.988 - ETA: 10s - loss: 0.0528 - accuracy: 0.987 - ETA: 9s - loss: 0.0537 - accuracy: 0.988 - ETA: 8s - loss: 0.0537 - accuracy: 0.98 - ETA: 7s - loss: 0.0543 - accuracy: 0.98 - ETA: 6s - loss: 0.0539 - accuracy: 0.98 - ETA: 5s - loss: 0.0535 - accuracy: 0.98 - ETA: 4s - loss: 0.0531 - accuracy: 0.98 - ETA: 3s - loss: 0.0527 - accuracy: 0.98 - ETA: 1s - loss: 0.0525 - accuracy: 0.98 - ETA: 0s - loss: 0.0529 - accuracy: 0.98 - 125s 10ms/step - loss: 0.0526 - accuracy: 0.9880 - val_loss: 3.4616 - val_accuracy: 0.4042\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:52 - loss: 0.0191 - accuracy: 1.00 - ETA: 1:51 - loss: 0.0388 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0320 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0302 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0278 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0258 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0223 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0204 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0201 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0189 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0228 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0250 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0310 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0310 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0322 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0307 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0302 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0324 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0342 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0329 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0346 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0376 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0365 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0360 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0364 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0353 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0348 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0347 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0351 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0353 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0342 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0414 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0437 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0493 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0482 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0492 - accuracy: 0.98 - ETA: 59s - loss: 0.0498 - accuracy: 0.9880 - ETA: 58s - loss: 0.0499 - accuracy: 0.987 - ETA: 57s - loss: 0.0509 - accuracy: 0.988 - ETA: 56s - loss: 0.0507 - accuracy: 0.988 - ETA: 55s - loss: 0.0528 - accuracy: 0.988 - ETA: 54s - loss: 0.0556 - accuracy: 0.987 - ETA: 52s - loss: 0.0550 - accuracy: 0.988 - ETA: 51s - loss: 0.0556 - accuracy: 0.987 - ETA: 50s - loss: 0.0563 - accuracy: 0.987 - ETA: 49s - loss: 0.0571 - accuracy: 0.987 - ETA: 48s - loss: 0.0562 - accuracy: 0.987 - ETA: 47s - loss: 0.0560 - accuracy: 0.988 - ETA: 46s - loss: 0.0560 - accuracy: 0.987 - ETA: 45s - loss: 0.0578 - accuracy: 0.987 - ETA: 44s - loss: 0.0577 - accuracy: 0.987 - ETA: 42s - loss: 0.0584 - accuracy: 0.987 - ETA: 41s - loss: 0.0578 - accuracy: 0.987 - ETA: 40s - loss: 0.0570 - accuracy: 0.988 - ETA: 39s - loss: 0.0563 - accuracy: 0.988 - ETA: 38s - loss: 0.0558 - accuracy: 0.988 - ETA: 37s - loss: 0.0568 - accuracy: 0.987 - ETA: 36s - loss: 0.0569 - accuracy: 0.988 - ETA: 35s - loss: 0.0567 - accuracy: 0.987 - ETA: 34s - loss: 0.0565 - accuracy: 0.987 - ETA: 32s - loss: 0.0563 - accuracy: 0.987 - ETA: 31s - loss: 0.0559 - accuracy: 0.987 - ETA: 30s - loss: 0.0563 - accuracy: 0.987 - ETA: 29s - loss: 0.0556 - accuracy: 0.987 - ETA: 28s - loss: 0.0550 - accuracy: 0.988 - ETA: 27s - loss: 0.0549 - accuracy: 0.987 - ETA: 26s - loss: 0.0545 - accuracy: 0.988 - ETA: 25s - loss: 0.0543 - accuracy: 0.987 - ETA: 24s - loss: 0.0538 - accuracy: 0.988 - ETA: 22s - loss: 0.0538 - accuracy: 0.988 - ETA: 21s - loss: 0.0535 - accuracy: 0.988 - ETA: 20s - loss: 0.0535 - accuracy: 0.988 - ETA: 19s - loss: 0.0542 - accuracy: 0.987 - ETA: 18s - loss: 0.0544 - accuracy: 0.987 - ETA: 17s - loss: 0.0540 - accuracy: 0.988 - ETA: 16s - loss: 0.0535 - accuracy: 0.988 - ETA: 15s - loss: 0.0529 - accuracy: 0.988 - ETA: 14s - loss: 0.0529 - accuracy: 0.987 - ETA: 12s - loss: 0.0529 - accuracy: 0.987 - ETA: 11s - loss: 0.0526 - accuracy: 0.988 - ETA: 10s - loss: 0.0527 - accuracy: 0.987 - ETA: 9s - loss: 0.0525 - accuracy: 0.987 - ETA: 8s - loss: 0.0520 - accuracy: 0.98 - ETA: 7s - loss: 0.0539 - accuracy: 0.98 - ETA: 6s - loss: 0.0535 - accuracy: 0.98 - ETA: 5s - loss: 0.0537 - accuracy: 0.98 - ETA: 4s - loss: 0.0542 - accuracy: 0.98 - ETA: 3s - loss: 0.0538 - accuracy: 0.98 - ETA: 1s - loss: 0.0533 - accuracy: 0.98 - ETA: 0s - loss: 0.0529 - accuracy: 0.98 - 125s 10ms/step - loss: 0.0535 - accuracy: 0.9878 - val_loss: 3.5615 - val_accuracy: 0.3905\n",
      "Epoch 72/100\n",
      "13022/13022 [==============================] - ETA: 1:55 - loss: 0.0300 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0327 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0331 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0304 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0330 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0517 - accuracy: 0.98 - ETA: 59s - loss: 0.0532 - accuracy: 0.9858 - ETA: 58s - loss: 0.0529 - accuracy: 0.986 - ETA: 57s - loss: 0.0532 - accuracy: 0.985 - ETA: 55s - loss: 0.0538 - accuracy: 0.985 - ETA: 54s - loss: 0.0539 - accuracy: 0.985 - ETA: 53s - loss: 0.0544 - accuracy: 0.985 - ETA: 52s - loss: 0.0536 - accuracy: 0.985 - ETA: 51s - loss: 0.0543 - accuracy: 0.985 - ETA: 50s - loss: 0.0549 - accuracy: 0.985 - ETA: 49s - loss: 0.0544 - accuracy: 0.985 - ETA: 48s - loss: 0.0545 - accuracy: 0.985 - ETA: 47s - loss: 0.0552 - accuracy: 0.985 - ETA: 46s - loss: 0.0545 - accuracy: 0.985 - ETA: 44s - loss: 0.0563 - accuracy: 0.985 - ETA: 43s - loss: 0.0582 - accuracy: 0.985 - ETA: 42s - loss: 0.0583 - accuracy: 0.985 - ETA: 41s - loss: 0.0581 - accuracy: 0.985 - ETA: 40s - loss: 0.0578 - accuracy: 0.985 - ETA: 39s - loss: 0.0581 - accuracy: 0.984 - ETA: 38s - loss: 0.0580 - accuracy: 0.984 - ETA: 37s - loss: 0.0582 - accuracy: 0.984 - ETA: 36s - loss: 0.0587 - accuracy: 0.984 - ETA: 34s - loss: 0.0587 - accuracy: 0.984 - ETA: 33s - loss: 0.0592 - accuracy: 0.984 - ETA: 32s - loss: 0.0598 - accuracy: 0.984 - ETA: 31s - loss: 0.0591 - accuracy: 0.984 - ETA: 30s - loss: 0.0586 - accuracy: 0.984 - ETA: 29s - loss: 0.0582 - accuracy: 0.984 - ETA: 28s - loss: 0.0584 - accuracy: 0.984 - ETA: 27s - loss: 0.0578 - accuracy: 0.985 - ETA: 26s - loss: 0.0584 - accuracy: 0.985 - ETA: 25s - loss: 0.0587 - accuracy: 0.985 - ETA: 23s - loss: 0.0583 - accuracy: 0.985 - ETA: 22s - loss: 0.0579 - accuracy: 0.985 - ETA: 21s - loss: 0.0577 - accuracy: 0.985 - ETA: 20s - loss: 0.0578 - accuracy: 0.985 - ETA: 19s - loss: 0.0579 - accuracy: 0.985 - ETA: 18s - loss: 0.0581 - accuracy: 0.985 - ETA: 17s - loss: 0.0577 - accuracy: 0.985 - ETA: 16s - loss: 0.0593 - accuracy: 0.985 - ETA: 15s - loss: 0.0596 - accuracy: 0.985 - ETA: 14s - loss: 0.0591 - accuracy: 0.985 - ETA: 12s - loss: 0.0596 - accuracy: 0.985 - ETA: 11s - loss: 0.0598 - accuracy: 0.985 - ETA: 10s - loss: 0.0594 - accuracy: 0.985 - ETA: 9s - loss: 0.0593 - accuracy: 0.985 - ETA: 8s - loss: 0.0588 - accuracy: 0.98 - ETA: 7s - loss: 0.0596 - accuracy: 0.98 - ETA: 6s - loss: 0.0597 - accuracy: 0.98 - ETA: 5s - loss: 0.0596 - accuracy: 0.98 - ETA: 4s - loss: 0.0598 - accuracy: 0.98 - ETA: 3s - loss: 0.0594 - accuracy: 0.98 - ETA: 1s - loss: 0.0599 - accuracy: 0.98 - ETA: 0s - loss: 0.0601 - accuracy: 0.98 - 125s 10ms/step - loss: 0.0606 - accuracy: 0.9853 - val_loss: 3.5671 - val_accuracy: 0.3797\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:55 - loss: 0.0374 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0698 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0737 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0676 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0646 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0687 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0713 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0805 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0776 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0767 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0825 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0824 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0807 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0775 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0832 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0829 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0813 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0800 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0791 - accuracy: 0.97 - ETA: 1:21 - loss: 0.0770 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0771 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0793 - accuracy: 0.97 - ETA: 1:18 - loss: 0.0777 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0763 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0755 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0741 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0742 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0736 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0748 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0737 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0726 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0709 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0693 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0680 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0685 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0677 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0684 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0672 - accuracy: 0.98 - ETA: 59s - loss: 0.0664 - accuracy: 0.9834 - ETA: 58s - loss: 0.0675 - accuracy: 0.983 - ETA: 57s - loss: 0.0668 - accuracy: 0.983 - ETA: 56s - loss: 0.0671 - accuracy: 0.983 - ETA: 55s - loss: 0.0669 - accuracy: 0.983 - ETA: 53s - loss: 0.0658 - accuracy: 0.983 - ETA: 52s - loss: 0.0648 - accuracy: 0.983 - ETA: 51s - loss: 0.0644 - accuracy: 0.983 - ETA: 50s - loss: 0.0651 - accuracy: 0.983 - ETA: 49s - loss: 0.0646 - accuracy: 0.983 - ETA: 48s - loss: 0.0640 - accuracy: 0.983 - ETA: 47s - loss: 0.0631 - accuracy: 0.984 - ETA: 46s - loss: 0.0630 - accuracy: 0.983 - ETA: 44s - loss: 0.0637 - accuracy: 0.983 - ETA: 43s - loss: 0.0631 - accuracy: 0.983 - ETA: 42s - loss: 0.0635 - accuracy: 0.983 - ETA: 41s - loss: 0.0633 - accuracy: 0.983 - ETA: 40s - loss: 0.0633 - accuracy: 0.983 - ETA: 39s - loss: 0.0634 - accuracy: 0.983 - ETA: 38s - loss: 0.0635 - accuracy: 0.983 - ETA: 37s - loss: 0.0628 - accuracy: 0.983 - ETA: 36s - loss: 0.0634 - accuracy: 0.983 - ETA: 35s - loss: 0.0626 - accuracy: 0.983 - ETA: 33s - loss: 0.0636 - accuracy: 0.983 - ETA: 32s - loss: 0.0646 - accuracy: 0.983 - ETA: 31s - loss: 0.0642 - accuracy: 0.983 - ETA: 30s - loss: 0.0638 - accuracy: 0.983 - ETA: 29s - loss: 0.0634 - accuracy: 0.983 - ETA: 28s - loss: 0.0627 - accuracy: 0.983 - ETA: 27s - loss: 0.0642 - accuracy: 0.983 - ETA: 26s - loss: 0.0641 - accuracy: 0.983 - ETA: 25s - loss: 0.0640 - accuracy: 0.983 - ETA: 24s - loss: 0.0648 - accuracy: 0.983 - ETA: 22s - loss: 0.0650 - accuracy: 0.983 - ETA: 21s - loss: 0.0649 - accuracy: 0.983 - ETA: 20s - loss: 0.0646 - accuracy: 0.983 - ETA: 19s - loss: 0.0643 - accuracy: 0.983 - ETA: 18s - loss: 0.0637 - accuracy: 0.983 - ETA: 17s - loss: 0.0635 - accuracy: 0.983 - ETA: 16s - loss: 0.0631 - accuracy: 0.983 - ETA: 15s - loss: 0.0636 - accuracy: 0.983 - ETA: 14s - loss: 0.0638 - accuracy: 0.983 - ETA: 12s - loss: 0.0631 - accuracy: 0.983 - ETA: 11s - loss: 0.0633 - accuracy: 0.983 - ETA: 10s - loss: 0.0633 - accuracy: 0.983 - ETA: 9s - loss: 0.0627 - accuracy: 0.983 - ETA: 8s - loss: 0.0632 - accuracy: 0.98 - ETA: 7s - loss: 0.0633 - accuracy: 0.98 - ETA: 6s - loss: 0.0631 - accuracy: 0.98 - ETA: 5s - loss: 0.0636 - accuracy: 0.98 - ETA: 4s - loss: 0.0633 - accuracy: 0.98 - ETA: 3s - loss: 0.0628 - accuracy: 0.98 - ETA: 1s - loss: 0.0622 - accuracy: 0.98 - ETA: 0s - loss: 0.0617 - accuracy: 0.98 - 125s 10ms/step - loss: 0.0615 - accuracy: 0.9843 - val_loss: 3.2690 - val_accuracy: 0.4211\n",
      "Epoch 74/100\n",
      "13022/13022 [==============================] - ETA: 1:56 - loss: 0.0499 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0302 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0253 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0200 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0235 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0577 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0605 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0593 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0545 - accuracy: 0.98 - ETA: 59s - loss: 0.0543 - accuracy: 0.9863 - ETA: 58s - loss: 0.0544 - accuracy: 0.986 - ETA: 57s - loss: 0.0549 - accuracy: 0.986 - ETA: 56s - loss: 0.0544 - accuracy: 0.986 - ETA: 55s - loss: 0.0547 - accuracy: 0.986 - ETA: 53s - loss: 0.0544 - accuracy: 0.986 - ETA: 52s - loss: 0.0537 - accuracy: 0.986 - ETA: 51s - loss: 0.0532 - accuracy: 0.986 - ETA: 50s - loss: 0.0526 - accuracy: 0.986 - ETA: 49s - loss: 0.0517 - accuracy: 0.987 - ETA: 48s - loss: 0.0525 - accuracy: 0.986 - ETA: 47s - loss: 0.0525 - accuracy: 0.986 - ETA: 46s - loss: 0.0518 - accuracy: 0.987 - ETA: 45s - loss: 0.0514 - accuracy: 0.987 - ETA: 44s - loss: 0.0508 - accuracy: 0.987 - ETA: 43s - loss: 0.0514 - accuracy: 0.987 - ETA: 41s - loss: 0.0510 - accuracy: 0.987 - ETA: 40s - loss: 0.0509 - accuracy: 0.987 - ETA: 39s - loss: 0.0543 - accuracy: 0.987 - ETA: 38s - loss: 0.0542 - accuracy: 0.987 - ETA: 37s - loss: 0.0542 - accuracy: 0.987 - ETA: 36s - loss: 0.0540 - accuracy: 0.986 - ETA: 35s - loss: 0.0542 - accuracy: 0.986 - ETA: 34s - loss: 0.0536 - accuracy: 0.986 - ETA: 32s - loss: 0.0536 - accuracy: 0.986 - ETA: 31s - loss: 0.0529 - accuracy: 0.986 - ETA: 30s - loss: 0.0522 - accuracy: 0.987 - ETA: 29s - loss: 0.0518 - accuracy: 0.987 - ETA: 28s - loss: 0.0519 - accuracy: 0.986 - ETA: 27s - loss: 0.0515 - accuracy: 0.987 - ETA: 26s - loss: 0.0520 - accuracy: 0.986 - ETA: 25s - loss: 0.0514 - accuracy: 0.987 - ETA: 24s - loss: 0.0508 - accuracy: 0.987 - ETA: 23s - loss: 0.0505 - accuracy: 0.987 - ETA: 21s - loss: 0.0508 - accuracy: 0.987 - ETA: 20s - loss: 0.0503 - accuracy: 0.987 - ETA: 19s - loss: 0.0498 - accuracy: 0.987 - ETA: 18s - loss: 0.0493 - accuracy: 0.987 - ETA: 17s - loss: 0.0490 - accuracy: 0.987 - ETA: 16s - loss: 0.0494 - accuracy: 0.987 - ETA: 15s - loss: 0.0493 - accuracy: 0.987 - ETA: 14s - loss: 0.0491 - accuracy: 0.987 - ETA: 12s - loss: 0.0488 - accuracy: 0.987 - ETA: 11s - loss: 0.0483 - accuracy: 0.987 - ETA: 10s - loss: 0.0481 - accuracy: 0.987 - ETA: 9s - loss: 0.0483 - accuracy: 0.986 - ETA: 8s - loss: 0.0494 - accuracy: 0.98 - ETA: 7s - loss: 0.0490 - accuracy: 0.98 - ETA: 6s - loss: 0.0490 - accuracy: 0.98 - ETA: 5s - loss: 0.0486 - accuracy: 0.98 - ETA: 4s - loss: 0.0484 - accuracy: 0.98 - ETA: 3s - loss: 0.0488 - accuracy: 0.98 - ETA: 1s - loss: 0.0484 - accuracy: 0.98 - ETA: 0s - loss: 0.0485 - accuracy: 0.98 - 126s 10ms/step - loss: 0.0490 - accuracy: 0.9869 - val_loss: 3.4589 - val_accuracy: 0.4220\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:55 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0566 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0749 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0701 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0592 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0585 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0657 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0656 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0629 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0650 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0633 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0605 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0592 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0605 - accuracy: 0.98 - ETA: 59s - loss: 0.0607 - accuracy: 0.9854 - ETA: 58s - loss: 0.0598 - accuracy: 0.985 - ETA: 57s - loss: 0.0590 - accuracy: 0.985 - ETA: 56s - loss: 0.0585 - accuracy: 0.985 - ETA: 54s - loss: 0.0583 - accuracy: 0.985 - ETA: 53s - loss: 0.0585 - accuracy: 0.985 - ETA: 52s - loss: 0.0580 - accuracy: 0.985 - ETA: 51s - loss: 0.0580 - accuracy: 0.985 - ETA: 50s - loss: 0.0577 - accuracy: 0.985 - ETA: 49s - loss: 0.0571 - accuracy: 0.985 - ETA: 48s - loss: 0.0565 - accuracy: 0.985 - ETA: 47s - loss: 0.0558 - accuracy: 0.986 - ETA: 46s - loss: 0.0562 - accuracy: 0.985 - ETA: 45s - loss: 0.0554 - accuracy: 0.986 - ETA: 43s - loss: 0.0553 - accuracy: 0.985 - ETA: 42s - loss: 0.0546 - accuracy: 0.986 - ETA: 41s - loss: 0.0542 - accuracy: 0.986 - ETA: 40s - loss: 0.0539 - accuracy: 0.986 - ETA: 39s - loss: 0.0549 - accuracy: 0.986 - ETA: 38s - loss: 0.0549 - accuracy: 0.986 - ETA: 37s - loss: 0.0550 - accuracy: 0.985 - ETA: 36s - loss: 0.0553 - accuracy: 0.985 - ETA: 35s - loss: 0.0552 - accuracy: 0.985 - ETA: 34s - loss: 0.0547 - accuracy: 0.985 - ETA: 32s - loss: 0.0548 - accuracy: 0.985 - ETA: 31s - loss: 0.0545 - accuracy: 0.985 - ETA: 30s - loss: 0.0558 - accuracy: 0.985 - ETA: 29s - loss: 0.0553 - accuracy: 0.985 - ETA: 28s - loss: 0.0551 - accuracy: 0.985 - ETA: 27s - loss: 0.0581 - accuracy: 0.985 - ETA: 26s - loss: 0.0577 - accuracy: 0.986 - ETA: 25s - loss: 0.0575 - accuracy: 0.986 - ETA: 24s - loss: 0.0596 - accuracy: 0.985 - ETA: 22s - loss: 0.0596 - accuracy: 0.985 - ETA: 21s - loss: 0.0598 - accuracy: 0.985 - ETA: 20s - loss: 0.0591 - accuracy: 0.986 - ETA: 19s - loss: 0.0590 - accuracy: 0.986 - ETA: 18s - loss: 0.0585 - accuracy: 0.986 - ETA: 17s - loss: 0.0583 - accuracy: 0.986 - ETA: 16s - loss: 0.0586 - accuracy: 0.986 - ETA: 15s - loss: 0.0583 - accuracy: 0.986 - ETA: 14s - loss: 0.0585 - accuracy: 0.985 - ETA: 13s - loss: 0.0583 - accuracy: 0.985 - ETA: 12s - loss: 0.0585 - accuracy: 0.985 - ETA: 10s - loss: 0.0580 - accuracy: 0.985 - ETA: 9s - loss: 0.0574 - accuracy: 0.986 - ETA: 8s - loss: 0.0579 - accuracy: 0.98 - ETA: 7s - loss: 0.0580 - accuracy: 0.98 - ETA: 6s - loss: 0.0576 - accuracy: 0.98 - ETA: 5s - loss: 0.0570 - accuracy: 0.98 - ETA: 4s - loss: 0.0568 - accuracy: 0.98 - ETA: 3s - loss: 0.0565 - accuracy: 0.98 - ETA: 1s - loss: 0.0565 - accuracy: 0.98 - ETA: 0s - loss: 0.0566 - accuracy: 0.98 - 130s 10ms/step - loss: 0.0563 - accuracy: 0.9864 - val_loss: 3.7116 - val_accuracy: 0.3696\n",
      "Epoch 76/100\n",
      "13022/13022 [==============================] - ETA: 2:19 - loss: 0.0871 - accuracy: 0.97 - ETA: 2:06 - loss: 0.0552 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0301 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0411 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0370 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0336 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0308 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0306 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0310 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0293 - accuracy: 0.99 - ETA: 1:59 - loss: 0.0313 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0367 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0362 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0411 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0427 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0461 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0502 - accuracy: 0.98 - ETA: 58s - loss: 0.0507 - accuracy: 0.9878 - ETA: 57s - loss: 0.0521 - accuracy: 0.987 - ETA: 56s - loss: 0.0513 - accuracy: 0.987 - ETA: 55s - loss: 0.0513 - accuracy: 0.987 - ETA: 53s - loss: 0.0513 - accuracy: 0.987 - ETA: 52s - loss: 0.0508 - accuracy: 0.987 - ETA: 51s - loss: 0.0513 - accuracy: 0.987 - ETA: 49s - loss: 0.0507 - accuracy: 0.987 - ETA: 48s - loss: 0.0511 - accuracy: 0.987 - ETA: 47s - loss: 0.0504 - accuracy: 0.987 - ETA: 45s - loss: 0.0522 - accuracy: 0.987 - ETA: 44s - loss: 0.0532 - accuracy: 0.987 - ETA: 43s - loss: 0.0532 - accuracy: 0.987 - ETA: 41s - loss: 0.0528 - accuracy: 0.987 - ETA: 40s - loss: 0.0522 - accuracy: 0.987 - ETA: 39s - loss: 0.0520 - accuracy: 0.987 - ETA: 37s - loss: 0.0520 - accuracy: 0.987 - ETA: 36s - loss: 0.0517 - accuracy: 0.987 - ETA: 35s - loss: 0.0510 - accuracy: 0.987 - ETA: 34s - loss: 0.0506 - accuracy: 0.988 - ETA: 32s - loss: 0.0504 - accuracy: 0.988 - ETA: 31s - loss: 0.0515 - accuracy: 0.987 - ETA: 30s - loss: 0.0509 - accuracy: 0.987 - ETA: 29s - loss: 0.0509 - accuracy: 0.988 - ETA: 27s - loss: 0.0504 - accuracy: 0.988 - ETA: 26s - loss: 0.0511 - accuracy: 0.988 - ETA: 25s - loss: 0.0506 - accuracy: 0.988 - ETA: 24s - loss: 0.0509 - accuracy: 0.988 - ETA: 22s - loss: 0.0505 - accuracy: 0.988 - ETA: 21s - loss: 0.0505 - accuracy: 0.988 - ETA: 20s - loss: 0.0500 - accuracy: 0.988 - ETA: 19s - loss: 0.0496 - accuracy: 0.988 - ETA: 17s - loss: 0.0491 - accuracy: 0.988 - ETA: 16s - loss: 0.0490 - accuracy: 0.988 - ETA: 15s - loss: 0.0486 - accuracy: 0.988 - ETA: 14s - loss: 0.0482 - accuracy: 0.988 - ETA: 12s - loss: 0.0483 - accuracy: 0.988 - ETA: 11s - loss: 0.0488 - accuracy: 0.988 - ETA: 10s - loss: 0.0485 - accuracy: 0.988 - ETA: 9s - loss: 0.0484 - accuracy: 0.988 - ETA: 8s - loss: 0.0479 - accuracy: 0.98 - ETA: 6s - loss: 0.0484 - accuracy: 0.98 - ETA: 5s - loss: 0.0485 - accuracy: 0.98 - ETA: 4s - loss: 0.0484 - accuracy: 0.98 - ETA: 3s - loss: 0.0483 - accuracy: 0.98 - ETA: 2s - loss: 0.0483 - accuracy: 0.98 - ETA: 0s - loss: 0.0479 - accuracy: 0.98 - 134s 10ms/step - loss: 0.0479 - accuracy: 0.9885 - val_loss: 3.7391 - val_accuracy: 0.3859\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:54 - loss: 0.1145 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0976 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0686 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0642 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0606 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0513 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0492 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0537 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0512 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0504 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0468 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0443 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0427 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0424 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0409 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0396 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0376 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0361 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0370 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0354 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0343 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0353 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0342 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0354 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0365 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0400 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0386 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0380 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0375 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0378 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0370 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0365 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0382 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0384 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0413 - accuracy: 0.98 - ETA: 59s - loss: 0.0407 - accuracy: 0.9896 - ETA: 58s - loss: 0.0414 - accuracy: 0.989 - ETA: 57s - loss: 0.0419 - accuracy: 0.988 - ETA: 56s - loss: 0.0418 - accuracy: 0.988 - ETA: 55s - loss: 0.0413 - accuracy: 0.988 - ETA: 54s - loss: 0.0418 - accuracy: 0.988 - ETA: 52s - loss: 0.0415 - accuracy: 0.988 - ETA: 51s - loss: 0.0430 - accuracy: 0.987 - ETA: 50s - loss: 0.0456 - accuracy: 0.987 - ETA: 49s - loss: 0.0450 - accuracy: 0.987 - ETA: 48s - loss: 0.0444 - accuracy: 0.987 - ETA: 47s - loss: 0.0447 - accuracy: 0.987 - ETA: 46s - loss: 0.0446 - accuracy: 0.987 - ETA: 45s - loss: 0.0450 - accuracy: 0.987 - ETA: 44s - loss: 0.0446 - accuracy: 0.987 - ETA: 42s - loss: 0.0445 - accuracy: 0.987 - ETA: 41s - loss: 0.0443 - accuracy: 0.987 - ETA: 40s - loss: 0.0446 - accuracy: 0.987 - ETA: 39s - loss: 0.0440 - accuracy: 0.987 - ETA: 38s - loss: 0.0436 - accuracy: 0.987 - ETA: 37s - loss: 0.0445 - accuracy: 0.987 - ETA: 36s - loss: 0.0450 - accuracy: 0.987 - ETA: 35s - loss: 0.0453 - accuracy: 0.987 - ETA: 34s - loss: 0.0460 - accuracy: 0.987 - ETA: 32s - loss: 0.0461 - accuracy: 0.987 - ETA: 31s - loss: 0.0466 - accuracy: 0.986 - ETA: 30s - loss: 0.0460 - accuracy: 0.987 - ETA: 29s - loss: 0.0466 - accuracy: 0.987 - ETA: 28s - loss: 0.0472 - accuracy: 0.987 - ETA: 27s - loss: 0.0468 - accuracy: 0.987 - ETA: 26s - loss: 0.0469 - accuracy: 0.987 - ETA: 25s - loss: 0.0490 - accuracy: 0.986 - ETA: 24s - loss: 0.0484 - accuracy: 0.987 - ETA: 23s - loss: 0.0490 - accuracy: 0.986 - ETA: 21s - loss: 0.0494 - accuracy: 0.986 - ETA: 20s - loss: 0.0489 - accuracy: 0.987 - ETA: 19s - loss: 0.0486 - accuracy: 0.987 - ETA: 18s - loss: 0.0483 - accuracy: 0.987 - ETA: 17s - loss: 0.0481 - accuracy: 0.987 - ETA: 16s - loss: 0.0479 - accuracy: 0.987 - ETA: 15s - loss: 0.0475 - accuracy: 0.987 - ETA: 14s - loss: 0.0472 - accuracy: 0.987 - ETA: 13s - loss: 0.0467 - accuracy: 0.987 - ETA: 11s - loss: 0.0488 - accuracy: 0.987 - ETA: 10s - loss: 0.0493 - accuracy: 0.987 - ETA: 9s - loss: 0.0496 - accuracy: 0.987 - ETA: 8s - loss: 0.0499 - accuracy: 0.98 - ETA: 7s - loss: 0.0498 - accuracy: 0.98 - ETA: 6s - loss: 0.0494 - accuracy: 0.98 - ETA: 5s - loss: 0.0491 - accuracy: 0.98 - ETA: 4s - loss: 0.0487 - accuracy: 0.98 - ETA: 3s - loss: 0.0486 - accuracy: 0.98 - ETA: 1s - loss: 0.0485 - accuracy: 0.98 - ETA: 0s - loss: 0.0481 - accuracy: 0.98 - 125s 10ms/step - loss: 0.0487 - accuracy: 0.9873 - val_loss: 3.5446 - val_accuracy: 0.3914\n",
      "Epoch 78/100\n",
      "13022/13022 [==============================] - ETA: 1:53 - loss: 0.0147 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0137 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0689 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0716 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0674 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0519 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0503 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0604 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0644 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0605 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0568 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0572 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0543 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0509 - accuracy: 0.98 - ETA: 59s - loss: 0.0519 - accuracy: 0.9872 - ETA: 58s - loss: 0.0556 - accuracy: 0.987 - ETA: 57s - loss: 0.0553 - accuracy: 0.987 - ETA: 56s - loss: 0.0545 - accuracy: 0.987 - ETA: 55s - loss: 0.0545 - accuracy: 0.987 - ETA: 53s - loss: 0.0536 - accuracy: 0.987 - ETA: 52s - loss: 0.0530 - accuracy: 0.987 - ETA: 51s - loss: 0.0545 - accuracy: 0.987 - ETA: 50s - loss: 0.0537 - accuracy: 0.987 - ETA: 49s - loss: 0.0529 - accuracy: 0.987 - ETA: 48s - loss: 0.0543 - accuracy: 0.987 - ETA: 46s - loss: 0.0550 - accuracy: 0.987 - ETA: 45s - loss: 0.0558 - accuracy: 0.987 - ETA: 44s - loss: 0.0563 - accuracy: 0.987 - ETA: 43s - loss: 0.0560 - accuracy: 0.987 - ETA: 42s - loss: 0.0552 - accuracy: 0.987 - ETA: 41s - loss: 0.0557 - accuracy: 0.987 - ETA: 40s - loss: 0.0551 - accuracy: 0.987 - ETA: 39s - loss: 0.0547 - accuracy: 0.987 - ETA: 38s - loss: 0.0547 - accuracy: 0.987 - ETA: 36s - loss: 0.0544 - accuracy: 0.987 - ETA: 35s - loss: 0.0548 - accuracy: 0.987 - ETA: 34s - loss: 0.0540 - accuracy: 0.987 - ETA: 33s - loss: 0.0535 - accuracy: 0.987 - ETA: 32s - loss: 0.0533 - accuracy: 0.987 - ETA: 31s - loss: 0.0527 - accuracy: 0.987 - ETA: 30s - loss: 0.0557 - accuracy: 0.987 - ETA: 28s - loss: 0.0551 - accuracy: 0.987 - ETA: 27s - loss: 0.0547 - accuracy: 0.987 - ETA: 26s - loss: 0.0547 - accuracy: 0.987 - ETA: 25s - loss: 0.0560 - accuracy: 0.987 - ETA: 24s - loss: 0.0553 - accuracy: 0.987 - ETA: 23s - loss: 0.0550 - accuracy: 0.987 - ETA: 22s - loss: 0.0553 - accuracy: 0.987 - ETA: 21s - loss: 0.0547 - accuracy: 0.987 - ETA: 19s - loss: 0.0547 - accuracy: 0.987 - ETA: 18s - loss: 0.0542 - accuracy: 0.987 - ETA: 17s - loss: 0.0537 - accuracy: 0.987 - ETA: 16s - loss: 0.0544 - accuracy: 0.987 - ETA: 15s - loss: 0.0540 - accuracy: 0.987 - ETA: 14s - loss: 0.0541 - accuracy: 0.987 - ETA: 13s - loss: 0.0537 - accuracy: 0.987 - ETA: 12s - loss: 0.0549 - accuracy: 0.987 - ETA: 11s - loss: 0.0549 - accuracy: 0.987 - ETA: 9s - loss: 0.0546 - accuracy: 0.987 - ETA: 8s - loss: 0.0546 - accuracy: 0.98 - ETA: 7s - loss: 0.0543 - accuracy: 0.98 - ETA: 6s - loss: 0.0543 - accuracy: 0.98 - ETA: 5s - loss: 0.0546 - accuracy: 0.98 - ETA: 4s - loss: 0.0544 - accuracy: 0.98 - ETA: 3s - loss: 0.0552 - accuracy: 0.98 - ETA: 2s - loss: 0.0552 - accuracy: 0.98 - ETA: 0s - loss: 0.0564 - accuracy: 0.98 - 133s 10ms/step - loss: 0.0565 - accuracy: 0.9877 - val_loss: 3.4870 - val_accuracy: 0.3919\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:37 - loss: 0.0081 - accuracy: 1.00 - ETA: 2:34 - loss: 0.0101 - accuracy: 1.00 - ETA: 2:34 - loss: 0.0233 - accuracy: 0.99 - ETA: 2:30 - loss: 0.0319 - accuracy: 0.99 - ETA: 2:28 - loss: 0.0362 - accuracy: 0.98 - ETA: 2:25 - loss: 0.0332 - accuracy: 0.98 - ETA: 2:24 - loss: 0.0343 - accuracy: 0.98 - ETA: 2:23 - loss: 0.0327 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0302 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0352 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0348 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0324 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0405 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0419 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0407 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0393 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0448 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0461 - accuracy: 0.98 - ETA: 58s - loss: 0.0458 - accuracy: 0.9876 - ETA: 57s - loss: 0.0460 - accuracy: 0.987 - ETA: 55s - loss: 0.0456 - accuracy: 0.987 - ETA: 54s - loss: 0.0453 - accuracy: 0.987 - ETA: 52s - loss: 0.0451 - accuracy: 0.987 - ETA: 51s - loss: 0.0446 - accuracy: 0.987 - ETA: 50s - loss: 0.0445 - accuracy: 0.987 - ETA: 48s - loss: 0.0444 - accuracy: 0.987 - ETA: 47s - loss: 0.0452 - accuracy: 0.988 - ETA: 46s - loss: 0.0448 - accuracy: 0.988 - ETA: 44s - loss: 0.0469 - accuracy: 0.988 - ETA: 43s - loss: 0.0471 - accuracy: 0.988 - ETA: 41s - loss: 0.0477 - accuracy: 0.988 - ETA: 40s - loss: 0.0475 - accuracy: 0.988 - ETA: 38s - loss: 0.0475 - accuracy: 0.987 - ETA: 37s - loss: 0.0469 - accuracy: 0.988 - ETA: 35s - loss: 0.0474 - accuracy: 0.987 - ETA: 34s - loss: 0.0469 - accuracy: 0.988 - ETA: 32s - loss: 0.0463 - accuracy: 0.988 - ETA: 31s - loss: 0.0463 - accuracy: 0.988 - ETA: 29s - loss: 0.0471 - accuracy: 0.988 - ETA: 28s - loss: 0.0473 - accuracy: 0.988 - ETA: 26s - loss: 0.0470 - accuracy: 0.988 - ETA: 25s - loss: 0.0468 - accuracy: 0.988 - ETA: 23s - loss: 0.0471 - accuracy: 0.988 - ETA: 22s - loss: 0.0468 - accuracy: 0.988 - ETA: 20s - loss: 0.0473 - accuracy: 0.988 - ETA: 19s - loss: 0.0469 - accuracy: 0.988 - ETA: 17s - loss: 0.0466 - accuracy: 0.988 - ETA: 16s - loss: 0.0464 - accuracy: 0.988 - ETA: 15s - loss: 0.0466 - accuracy: 0.988 - ETA: 13s - loss: 0.0464 - accuracy: 0.988 - ETA: 12s - loss: 0.0460 - accuracy: 0.988 - ETA: 10s - loss: 0.0458 - accuracy: 0.988 - ETA: 9s - loss: 0.0461 - accuracy: 0.988 - ETA: 7s - loss: 0.0464 - accuracy: 0.98 - ETA: 6s - loss: 0.0460 - accuracy: 0.98 - ETA: 5s - loss: 0.0458 - accuracy: 0.98 - ETA: 3s - loss: 0.0454 - accuracy: 0.98 - ETA: 2s - loss: 0.0455 - accuracy: 0.98 - ETA: 1s - loss: 0.0454 - accuracy: 0.98 - 152s 12ms/step - loss: 0.0451 - accuracy: 0.9885 - val_loss: 3.4998 - val_accuracy: 0.4231\n",
      "Epoch 80/100\n",
      "13022/13022 [==============================] - ETA: 1:53 - loss: 0.0292 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0380 - accuracy: 0.97 - ETA: 1:46 - loss: 0.0299 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0281 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0354 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0318 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0316 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0303 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0293 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0299 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0320 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0305 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0306 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0334 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0353 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0364 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0359 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0347 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0341 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0336 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0350 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0343 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0410 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0425 - accuracy: 0.98 - ETA: 58s - loss: 0.0428 - accuracy: 0.9881 - ETA: 57s - loss: 0.0427 - accuracy: 0.987 - ETA: 56s - loss: 0.0435 - accuracy: 0.987 - ETA: 54s - loss: 0.0428 - accuracy: 0.988 - ETA: 53s - loss: 0.0436 - accuracy: 0.987 - ETA: 51s - loss: 0.0443 - accuracy: 0.987 - ETA: 50s - loss: 0.0437 - accuracy: 0.987 - ETA: 49s - loss: 0.0439 - accuracy: 0.987 - ETA: 48s - loss: 0.0436 - accuracy: 0.987 - ETA: 47s - loss: 0.0435 - accuracy: 0.987 - ETA: 45s - loss: 0.0430 - accuracy: 0.987 - ETA: 44s - loss: 0.0427 - accuracy: 0.987 - ETA: 43s - loss: 0.0422 - accuracy: 0.988 - ETA: 42s - loss: 0.0416 - accuracy: 0.988 - ETA: 41s - loss: 0.0410 - accuracy: 0.988 - ETA: 39s - loss: 0.0415 - accuracy: 0.988 - ETA: 38s - loss: 0.0425 - accuracy: 0.988 - ETA: 37s - loss: 0.0429 - accuracy: 0.988 - ETA: 35s - loss: 0.0430 - accuracy: 0.987 - ETA: 34s - loss: 0.0435 - accuracy: 0.987 - ETA: 33s - loss: 0.0432 - accuracy: 0.987 - ETA: 32s - loss: 0.0437 - accuracy: 0.987 - ETA: 30s - loss: 0.0433 - accuracy: 0.987 - ETA: 29s - loss: 0.0431 - accuracy: 0.988 - ETA: 28s - loss: 0.0427 - accuracy: 0.988 - ETA: 26s - loss: 0.0424 - accuracy: 0.988 - ETA: 25s - loss: 0.0424 - accuracy: 0.988 - ETA: 24s - loss: 0.0431 - accuracy: 0.987 - ETA: 22s - loss: 0.0432 - accuracy: 0.987 - ETA: 21s - loss: 0.0432 - accuracy: 0.987 - ETA: 20s - loss: 0.0427 - accuracy: 0.988 - ETA: 18s - loss: 0.0423 - accuracy: 0.988 - ETA: 17s - loss: 0.0425 - accuracy: 0.988 - ETA: 16s - loss: 0.0421 - accuracy: 0.988 - ETA: 14s - loss: 0.0427 - accuracy: 0.988 - ETA: 13s - loss: 0.0431 - accuracy: 0.988 - ETA: 12s - loss: 0.0430 - accuracy: 0.988 - ETA: 10s - loss: 0.0435 - accuracy: 0.988 - ETA: 9s - loss: 0.0446 - accuracy: 0.988 - ETA: 7s - loss: 0.0445 - accuracy: 0.98 - ETA: 6s - loss: 0.0460 - accuracy: 0.98 - ETA: 5s - loss: 0.0458 - accuracy: 0.98 - ETA: 3s - loss: 0.0455 - accuracy: 0.98 - ETA: 2s - loss: 0.0456 - accuracy: 0.98 - ETA: 1s - loss: 0.0459 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0459 - accuracy: 0.9882 - val_loss: 3.7065 - val_accuracy: 0.3848\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:23 - loss: 0.1108 - accuracy: 0.95 - ETA: 2:22 - loss: 0.0868 - accuracy: 0.96 - ETA: 2:20 - loss: 0.0593 - accuracy: 0.97 - ETA: 2:19 - loss: 0.0681 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0503 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0478 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0460 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0438 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0405 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0383 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0433 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0461 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0483 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0500 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0493 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0499 - accuracy: 0.98 - ETA: 59s - loss: 0.0498 - accuracy: 0.9876 - ETA: 58s - loss: 0.0504 - accuracy: 0.987 - ETA: 56s - loss: 0.0513 - accuracy: 0.987 - ETA: 55s - loss: 0.0506 - accuracy: 0.987 - ETA: 53s - loss: 0.0500 - accuracy: 0.987 - ETA: 52s - loss: 0.0496 - accuracy: 0.987 - ETA: 50s - loss: 0.0496 - accuracy: 0.987 - ETA: 49s - loss: 0.0498 - accuracy: 0.987 - ETA: 47s - loss: 0.0495 - accuracy: 0.987 - ETA: 45s - loss: 0.0507 - accuracy: 0.987 - ETA: 44s - loss: 0.0511 - accuracy: 0.987 - ETA: 43s - loss: 0.0506 - accuracy: 0.987 - ETA: 41s - loss: 0.0505 - accuracy: 0.987 - ETA: 40s - loss: 0.0501 - accuracy: 0.987 - ETA: 38s - loss: 0.0494 - accuracy: 0.987 - ETA: 37s - loss: 0.0496 - accuracy: 0.987 - ETA: 35s - loss: 0.0507 - accuracy: 0.987 - ETA: 34s - loss: 0.0502 - accuracy: 0.987 - ETA: 32s - loss: 0.0497 - accuracy: 0.987 - ETA: 31s - loss: 0.0502 - accuracy: 0.987 - ETA: 29s - loss: 0.0513 - accuracy: 0.987 - ETA: 28s - loss: 0.0515 - accuracy: 0.987 - ETA: 27s - loss: 0.0521 - accuracy: 0.987 - ETA: 25s - loss: 0.0520 - accuracy: 0.987 - ETA: 24s - loss: 0.0518 - accuracy: 0.987 - ETA: 23s - loss: 0.0513 - accuracy: 0.987 - ETA: 21s - loss: 0.0509 - accuracy: 0.987 - ETA: 20s - loss: 0.0511 - accuracy: 0.987 - ETA: 18s - loss: 0.0509 - accuracy: 0.987 - ETA: 17s - loss: 0.0503 - accuracy: 0.987 - ETA: 16s - loss: 0.0499 - accuracy: 0.987 - ETA: 14s - loss: 0.0510 - accuracy: 0.987 - ETA: 13s - loss: 0.0508 - accuracy: 0.987 - ETA: 11s - loss: 0.0505 - accuracy: 0.987 - ETA: 10s - loss: 0.0503 - accuracy: 0.987 - ETA: 9s - loss: 0.0498 - accuracy: 0.987 - ETA: 7s - loss: 0.0500 - accuracy: 0.98 - ETA: 6s - loss: 0.0521 - accuracy: 0.98 - ETA: 5s - loss: 0.0523 - accuracy: 0.98 - ETA: 3s - loss: 0.0521 - accuracy: 0.98 - ETA: 2s - loss: 0.0525 - accuracy: 0.98 - ETA: 0s - loss: 0.0529 - accuracy: 0.98 - 150s 12ms/step - loss: 0.0532 - accuracy: 0.9869 - val_loss: 3.6000 - val_accuracy: 0.4010\n",
      "Epoch 82/100\n",
      "13022/13022 [==============================] - ETA: 2:09 - loss: 0.0019 - accuracy: 1.00 - ETA: 2:02 - loss: 0.0363 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0351 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0300 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0324 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0304 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0346 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0337 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0351 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0321 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0316 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0417 - accuracy: 0.99 - ETA: 1:50 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0456 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0428 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0461 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0449 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0467 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0497 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0506 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0540 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0529 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0519 - accuracy: 0.98 - ETA: 59s - loss: 0.0514 - accuracy: 0.9881 - ETA: 57s - loss: 0.0520 - accuracy: 0.987 - ETA: 56s - loss: 0.0514 - accuracy: 0.987 - ETA: 55s - loss: 0.0515 - accuracy: 0.987 - ETA: 54s - loss: 0.0545 - accuracy: 0.987 - ETA: 53s - loss: 0.0544 - accuracy: 0.987 - ETA: 51s - loss: 0.0537 - accuracy: 0.987 - ETA: 50s - loss: 0.0534 - accuracy: 0.987 - ETA: 49s - loss: 0.0528 - accuracy: 0.987 - ETA: 48s - loss: 0.0520 - accuracy: 0.988 - ETA: 47s - loss: 0.0513 - accuracy: 0.988 - ETA: 45s - loss: 0.0519 - accuracy: 0.987 - ETA: 44s - loss: 0.0512 - accuracy: 0.987 - ETA: 43s - loss: 0.0519 - accuracy: 0.987 - ETA: 42s - loss: 0.0517 - accuracy: 0.987 - ETA: 41s - loss: 0.0515 - accuracy: 0.988 - ETA: 40s - loss: 0.0512 - accuracy: 0.988 - ETA: 38s - loss: 0.0520 - accuracy: 0.988 - ETA: 37s - loss: 0.0513 - accuracy: 0.988 - ETA: 36s - loss: 0.0506 - accuracy: 0.988 - ETA: 35s - loss: 0.0502 - accuracy: 0.988 - ETA: 34s - loss: 0.0502 - accuracy: 0.988 - ETA: 32s - loss: 0.0501 - accuracy: 0.988 - ETA: 31s - loss: 0.0502 - accuracy: 0.988 - ETA: 30s - loss: 0.0504 - accuracy: 0.988 - ETA: 29s - loss: 0.0499 - accuracy: 0.988 - ETA: 28s - loss: 0.0497 - accuracy: 0.988 - ETA: 26s - loss: 0.0495 - accuracy: 0.988 - ETA: 25s - loss: 0.0492 - accuracy: 0.988 - ETA: 24s - loss: 0.0490 - accuracy: 0.988 - ETA: 23s - loss: 0.0499 - accuracy: 0.988 - ETA: 22s - loss: 0.0495 - accuracy: 0.988 - ETA: 20s - loss: 0.0494 - accuracy: 0.988 - ETA: 19s - loss: 0.0491 - accuracy: 0.988 - ETA: 18s - loss: 0.0489 - accuracy: 0.988 - ETA: 17s - loss: 0.0490 - accuracy: 0.988 - ETA: 16s - loss: 0.0486 - accuracy: 0.988 - ETA: 14s - loss: 0.0486 - accuracy: 0.988 - ETA: 13s - loss: 0.0499 - accuracy: 0.988 - ETA: 12s - loss: 0.0500 - accuracy: 0.988 - ETA: 11s - loss: 0.0501 - accuracy: 0.988 - ETA: 10s - loss: 0.0497 - accuracy: 0.988 - ETA: 9s - loss: 0.0493 - accuracy: 0.988 - ETA: 7s - loss: 0.0490 - accuracy: 0.98 - ETA: 6s - loss: 0.0496 - accuracy: 0.98 - ETA: 5s - loss: 0.0497 - accuracy: 0.98 - ETA: 4s - loss: 0.0493 - accuracy: 0.98 - ETA: 3s - loss: 0.0488 - accuracy: 0.98 - ETA: 2s - loss: 0.0500 - accuracy: 0.98 - ETA: 0s - loss: 0.0500 - accuracy: 0.98 - 132s 10ms/step - loss: 0.0504 - accuracy: 0.9886 - val_loss: 3.6812 - val_accuracy: 0.3806\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:01 - loss: 0.0096 - accuracy: 1.00 - ETA: 1:56 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0989 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0962 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0959 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0860 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0813 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0818 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0791 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0756 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0741 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0710 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0667 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0621 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0628 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0590 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0541 - accuracy: 0.98 - ETA: 59s - loss: 0.0542 - accuracy: 0.9859 - ETA: 58s - loss: 0.0542 - accuracy: 0.986 - ETA: 57s - loss: 0.0556 - accuracy: 0.986 - ETA: 56s - loss: 0.0557 - accuracy: 0.986 - ETA: 54s - loss: 0.0547 - accuracy: 0.986 - ETA: 53s - loss: 0.0546 - accuracy: 0.986 - ETA: 52s - loss: 0.0546 - accuracy: 0.986 - ETA: 51s - loss: 0.0540 - accuracy: 0.986 - ETA: 50s - loss: 0.0537 - accuracy: 0.986 - ETA: 49s - loss: 0.0539 - accuracy: 0.986 - ETA: 47s - loss: 0.0534 - accuracy: 0.986 - ETA: 46s - loss: 0.0526 - accuracy: 0.986 - ETA: 45s - loss: 0.0531 - accuracy: 0.986 - ETA: 44s - loss: 0.0537 - accuracy: 0.986 - ETA: 43s - loss: 0.0557 - accuracy: 0.986 - ETA: 42s - loss: 0.0553 - accuracy: 0.986 - ETA: 40s - loss: 0.0550 - accuracy: 0.986 - ETA: 39s - loss: 0.0551 - accuracy: 0.986 - ETA: 38s - loss: 0.0547 - accuracy: 0.986 - ETA: 37s - loss: 0.0546 - accuracy: 0.986 - ETA: 36s - loss: 0.0552 - accuracy: 0.986 - ETA: 35s - loss: 0.0555 - accuracy: 0.985 - ETA: 34s - loss: 0.0551 - accuracy: 0.986 - ETA: 32s - loss: 0.0553 - accuracy: 0.986 - ETA: 31s - loss: 0.0546 - accuracy: 0.986 - ETA: 30s - loss: 0.0542 - accuracy: 0.986 - ETA: 29s - loss: 0.0540 - accuracy: 0.986 - ETA: 28s - loss: 0.0535 - accuracy: 0.986 - ETA: 27s - loss: 0.0532 - accuracy: 0.986 - ETA: 25s - loss: 0.0533 - accuracy: 0.986 - ETA: 24s - loss: 0.0545 - accuracy: 0.986 - ETA: 23s - loss: 0.0539 - accuracy: 0.986 - ETA: 22s - loss: 0.0537 - accuracy: 0.986 - ETA: 21s - loss: 0.0543 - accuracy: 0.986 - ETA: 20s - loss: 0.0541 - accuracy: 0.986 - ETA: 19s - loss: 0.0539 - accuracy: 0.986 - ETA: 17s - loss: 0.0536 - accuracy: 0.986 - ETA: 16s - loss: 0.0544 - accuracy: 0.986 - ETA: 15s - loss: 0.0539 - accuracy: 0.986 - ETA: 14s - loss: 0.0550 - accuracy: 0.986 - ETA: 13s - loss: 0.0547 - accuracy: 0.986 - ETA: 12s - loss: 0.0543 - accuracy: 0.986 - ETA: 11s - loss: 0.0541 - accuracy: 0.986 - ETA: 9s - loss: 0.0555 - accuracy: 0.986 - ETA: 8s - loss: 0.0551 - accuracy: 0.98 - ETA: 7s - loss: 0.0549 - accuracy: 0.98 - ETA: 6s - loss: 0.0549 - accuracy: 0.98 - ETA: 5s - loss: 0.0547 - accuracy: 0.98 - ETA: 4s - loss: 0.0544 - accuracy: 0.98 - ETA: 3s - loss: 0.0542 - accuracy: 0.98 - ETA: 1s - loss: 0.0536 - accuracy: 0.98 - ETA: 0s - loss: 0.0545 - accuracy: 0.98 - 128s 10ms/step - loss: 0.0541 - accuracy: 0.9866 - val_loss: 3.9821 - val_accuracy: 0.3581\n",
      "Epoch 84/100\n",
      "13022/13022 [==============================] - ETA: 2:02 - loss: 0.0265 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0410 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0363 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0346 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0332 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0362 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0440 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0423 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0383 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0368 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0373 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0361 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0390 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0399 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0384 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0378 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0382 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0368 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0358 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0347 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0348 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0363 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0348 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0342 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0348 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0341 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0360 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0353 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0350 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0342 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0336 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0332 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0344 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0362 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0382 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0378 - accuracy: 0.99 - ETA: 59s - loss: 0.0381 - accuracy: 0.9901 - ETA: 58s - loss: 0.0377 - accuracy: 0.990 - ETA: 57s - loss: 0.0389 - accuracy: 0.990 - ETA: 55s - loss: 0.0383 - accuracy: 0.990 - ETA: 54s - loss: 0.0398 - accuracy: 0.990 - ETA: 53s - loss: 0.0398 - accuracy: 0.990 - ETA: 52s - loss: 0.0392 - accuracy: 0.990 - ETA: 51s - loss: 0.0419 - accuracy: 0.989 - ETA: 50s - loss: 0.0414 - accuracy: 0.989 - ETA: 49s - loss: 0.0411 - accuracy: 0.989 - ETA: 47s - loss: 0.0422 - accuracy: 0.989 - ETA: 46s - loss: 0.0429 - accuracy: 0.989 - ETA: 45s - loss: 0.0426 - accuracy: 0.989 - ETA: 44s - loss: 0.0419 - accuracy: 0.989 - ETA: 43s - loss: 0.0418 - accuracy: 0.989 - ETA: 42s - loss: 0.0420 - accuracy: 0.989 - ETA: 41s - loss: 0.0433 - accuracy: 0.989 - ETA: 40s - loss: 0.0428 - accuracy: 0.989 - ETA: 38s - loss: 0.0455 - accuracy: 0.989 - ETA: 37s - loss: 0.0454 - accuracy: 0.989 - ETA: 36s - loss: 0.0453 - accuracy: 0.989 - ETA: 35s - loss: 0.0455 - accuracy: 0.989 - ETA: 34s - loss: 0.0459 - accuracy: 0.989 - ETA: 33s - loss: 0.0456 - accuracy: 0.989 - ETA: 32s - loss: 0.0452 - accuracy: 0.989 - ETA: 31s - loss: 0.0452 - accuracy: 0.988 - ETA: 29s - loss: 0.0466 - accuracy: 0.988 - ETA: 28s - loss: 0.0473 - accuracy: 0.988 - ETA: 27s - loss: 0.0473 - accuracy: 0.988 - ETA: 26s - loss: 0.0470 - accuracy: 0.988 - ETA: 25s - loss: 0.0467 - accuracy: 0.988 - ETA: 24s - loss: 0.0463 - accuracy: 0.988 - ETA: 23s - loss: 0.0468 - accuracy: 0.988 - ETA: 22s - loss: 0.0464 - accuracy: 0.988 - ETA: 20s - loss: 0.0472 - accuracy: 0.988 - ETA: 19s - loss: 0.0476 - accuracy: 0.988 - ETA: 18s - loss: 0.0475 - accuracy: 0.988 - ETA: 17s - loss: 0.0471 - accuracy: 0.988 - ETA: 16s - loss: 0.0472 - accuracy: 0.988 - ETA: 15s - loss: 0.0472 - accuracy: 0.988 - ETA: 14s - loss: 0.0470 - accuracy: 0.988 - ETA: 13s - loss: 0.0477 - accuracy: 0.988 - ETA: 12s - loss: 0.0478 - accuracy: 0.988 - ETA: 10s - loss: 0.0476 - accuracy: 0.988 - ETA: 9s - loss: 0.0471 - accuracy: 0.988 - ETA: 8s - loss: 0.0467 - accuracy: 0.98 - ETA: 7s - loss: 0.0466 - accuracy: 0.98 - ETA: 6s - loss: 0.0472 - accuracy: 0.98 - ETA: 5s - loss: 0.0475 - accuracy: 0.98 - ETA: 4s - loss: 0.0475 - accuracy: 0.98 - ETA: 3s - loss: 0.0472 - accuracy: 0.98 - ETA: 1s - loss: 0.0471 - accuracy: 0.98 - ETA: 0s - loss: 0.0475 - accuracy: 0.98 - 127s 10ms/step - loss: 0.0474 - accuracy: 0.9885 - val_loss: 3.8617 - val_accuracy: 0.3710\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:57 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0374 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0303 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0331 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0286 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0278 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0328 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0359 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0412 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0397 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0393 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0384 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0375 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0370 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0369 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0366 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0364 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0379 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0379 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0397 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0391 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0374 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0371 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0378 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0378 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0376 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0371 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0368 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0359 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0364 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0370 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0376 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0372 - accuracy: 0.99 - ETA: 59s - loss: 0.0388 - accuracy: 0.9901 - ETA: 58s - loss: 0.0381 - accuracy: 0.990 - ETA: 56s - loss: 0.0376 - accuracy: 0.990 - ETA: 55s - loss: 0.0372 - accuracy: 0.990 - ETA: 54s - loss: 0.0366 - accuracy: 0.990 - ETA: 53s - loss: 0.0366 - accuracy: 0.990 - ETA: 52s - loss: 0.0362 - accuracy: 0.990 - ETA: 51s - loss: 0.0408 - accuracy: 0.990 - ETA: 50s - loss: 0.0406 - accuracy: 0.990 - ETA: 49s - loss: 0.0400 - accuracy: 0.990 - ETA: 47s - loss: 0.0399 - accuracy: 0.990 - ETA: 46s - loss: 0.0396 - accuracy: 0.990 - ETA: 45s - loss: 0.0390 - accuracy: 0.990 - ETA: 44s - loss: 0.0389 - accuracy: 0.990 - ETA: 43s - loss: 0.0400 - accuracy: 0.990 - ETA: 42s - loss: 0.0412 - accuracy: 0.990 - ETA: 41s - loss: 0.0410 - accuracy: 0.990 - ETA: 40s - loss: 0.0414 - accuracy: 0.990 - ETA: 39s - loss: 0.0426 - accuracy: 0.989 - ETA: 38s - loss: 0.0432 - accuracy: 0.989 - ETA: 36s - loss: 0.0425 - accuracy: 0.989 - ETA: 35s - loss: 0.0420 - accuracy: 0.989 - ETA: 34s - loss: 0.0420 - accuracy: 0.989 - ETA: 33s - loss: 0.0417 - accuracy: 0.989 - ETA: 32s - loss: 0.0415 - accuracy: 0.989 - ETA: 31s - loss: 0.0420 - accuracy: 0.989 - ETA: 30s - loss: 0.0417 - accuracy: 0.989 - ETA: 29s - loss: 0.0417 - accuracy: 0.989 - ETA: 28s - loss: 0.0416 - accuracy: 0.989 - ETA: 27s - loss: 0.0412 - accuracy: 0.989 - ETA: 25s - loss: 0.0420 - accuracy: 0.989 - ETA: 24s - loss: 0.0416 - accuracy: 0.989 - ETA: 23s - loss: 0.0418 - accuracy: 0.989 - ETA: 22s - loss: 0.0418 - accuracy: 0.989 - ETA: 21s - loss: 0.0416 - accuracy: 0.989 - ETA: 20s - loss: 0.0415 - accuracy: 0.989 - ETA: 19s - loss: 0.0412 - accuracy: 0.989 - ETA: 18s - loss: 0.0410 - accuracy: 0.989 - ETA: 17s - loss: 0.0406 - accuracy: 0.989 - ETA: 15s - loss: 0.0413 - accuracy: 0.989 - ETA: 14s - loss: 0.0412 - accuracy: 0.989 - ETA: 13s - loss: 0.0414 - accuracy: 0.989 - ETA: 12s - loss: 0.0414 - accuracy: 0.989 - ETA: 11s - loss: 0.0417 - accuracy: 0.989 - ETA: 10s - loss: 0.0414 - accuracy: 0.989 - ETA: 8s - loss: 0.0413 - accuracy: 0.989 - ETA: 7s - loss: 0.0413 - accuracy: 0.98 - ETA: 6s - loss: 0.0413 - accuracy: 0.98 - ETA: 5s - loss: 0.0411 - accuracy: 0.98 - ETA: 4s - loss: 0.0408 - accuracy: 0.99 - ETA: 3s - loss: 0.0408 - accuracy: 0.98 - ETA: 2s - loss: 0.0404 - accuracy: 0.99 - ETA: 0s - loss: 0.0413 - accuracy: 0.98 - 132s 10ms/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 3.9133 - val_accuracy: 0.3814\n",
      "Epoch 86/100\n",
      "13022/13022 [==============================] - ETA: 1:55 - loss: 0.0448 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0596 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0402 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0379 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0320 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0330 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0293 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0258 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0279 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0406 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0421 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0393 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0415 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0401 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0385 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0395 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0379 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0392 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0406 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0406 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0416 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0406 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0396 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0388 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0396 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0412 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0426 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0414 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0416 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0433 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0395 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0404 - accuracy: 0.98 - ETA: 59s - loss: 0.0401 - accuracy: 0.9898 - ETA: 58s - loss: 0.0406 - accuracy: 0.989 - ETA: 57s - loss: 0.0406 - accuracy: 0.989 - ETA: 55s - loss: 0.0405 - accuracy: 0.989 - ETA: 54s - loss: 0.0404 - accuracy: 0.989 - ETA: 53s - loss: 0.0404 - accuracy: 0.989 - ETA: 51s - loss: 0.0407 - accuracy: 0.989 - ETA: 50s - loss: 0.0404 - accuracy: 0.989 - ETA: 49s - loss: 0.0413 - accuracy: 0.989 - ETA: 47s - loss: 0.0408 - accuracy: 0.989 - ETA: 46s - loss: 0.0417 - accuracy: 0.989 - ETA: 45s - loss: 0.0418 - accuracy: 0.989 - ETA: 43s - loss: 0.0413 - accuracy: 0.989 - ETA: 42s - loss: 0.0409 - accuracy: 0.989 - ETA: 40s - loss: 0.0419 - accuracy: 0.989 - ETA: 39s - loss: 0.0420 - accuracy: 0.989 - ETA: 38s - loss: 0.0422 - accuracy: 0.989 - ETA: 36s - loss: 0.0418 - accuracy: 0.989 - ETA: 35s - loss: 0.0414 - accuracy: 0.989 - ETA: 33s - loss: 0.0414 - accuracy: 0.989 - ETA: 32s - loss: 0.0410 - accuracy: 0.989 - ETA: 31s - loss: 0.0408 - accuracy: 0.989 - ETA: 29s - loss: 0.0414 - accuracy: 0.989 - ETA: 28s - loss: 0.0410 - accuracy: 0.989 - ETA: 27s - loss: 0.0406 - accuracy: 0.989 - ETA: 25s - loss: 0.0409 - accuracy: 0.989 - ETA: 24s - loss: 0.0427 - accuracy: 0.989 - ETA: 22s - loss: 0.0429 - accuracy: 0.989 - ETA: 21s - loss: 0.0424 - accuracy: 0.989 - ETA: 20s - loss: 0.0436 - accuracy: 0.989 - ETA: 18s - loss: 0.0439 - accuracy: 0.989 - ETA: 17s - loss: 0.0438 - accuracy: 0.989 - ETA: 16s - loss: 0.0441 - accuracy: 0.989 - ETA: 14s - loss: 0.0448 - accuracy: 0.989 - ETA: 13s - loss: 0.0447 - accuracy: 0.989 - ETA: 12s - loss: 0.0444 - accuracy: 0.989 - ETA: 10s - loss: 0.0441 - accuracy: 0.989 - ETA: 9s - loss: 0.0437 - accuracy: 0.989 - ETA: 7s - loss: 0.0440 - accuracy: 0.98 - ETA: 6s - loss: 0.0436 - accuracy: 0.98 - ETA: 5s - loss: 0.0437 - accuracy: 0.98 - ETA: 3s - loss: 0.0436 - accuracy: 0.98 - ETA: 2s - loss: 0.0433 - accuracy: 0.98 - ETA: 1s - loss: 0.0438 - accuracy: 0.98 - 155s 12ms/step - loss: 0.0436 - accuracy: 0.9894 - val_loss: 3.6476 - val_accuracy: 0.3910\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:22 - loss: 0.0180 - accuracy: 0.99 - ETA: 2:23 - loss: 0.0229 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0332 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0456 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0524 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0551 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0569 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0518 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0505 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0546 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0551 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0694 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0690 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0655 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0591 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0561 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0559 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0586 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0589 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0567 - accuracy: 0.98 - ETA: 59s - loss: 0.0563 - accuracy: 0.9876 - ETA: 58s - loss: 0.0557 - accuracy: 0.987 - ETA: 56s - loss: 0.0550 - accuracy: 0.987 - ETA: 55s - loss: 0.0548 - accuracy: 0.987 - ETA: 54s - loss: 0.0541 - accuracy: 0.988 - ETA: 52s - loss: 0.0581 - accuracy: 0.987 - ETA: 51s - loss: 0.0573 - accuracy: 0.988 - ETA: 49s - loss: 0.0566 - accuracy: 0.988 - ETA: 48s - loss: 0.0581 - accuracy: 0.988 - ETA: 47s - loss: 0.0583 - accuracy: 0.988 - ETA: 45s - loss: 0.0588 - accuracy: 0.987 - ETA: 44s - loss: 0.0595 - accuracy: 0.987 - ETA: 42s - loss: 0.0595 - accuracy: 0.987 - ETA: 41s - loss: 0.0604 - accuracy: 0.987 - ETA: 40s - loss: 0.0619 - accuracy: 0.987 - ETA: 38s - loss: 0.0617 - accuracy: 0.987 - ETA: 37s - loss: 0.0610 - accuracy: 0.987 - ETA: 35s - loss: 0.0606 - accuracy: 0.987 - ETA: 34s - loss: 0.0599 - accuracy: 0.987 - ETA: 33s - loss: 0.0601 - accuracy: 0.987 - ETA: 31s - loss: 0.0603 - accuracy: 0.987 - ETA: 30s - loss: 0.0596 - accuracy: 0.987 - ETA: 29s - loss: 0.0597 - accuracy: 0.987 - ETA: 27s - loss: 0.0591 - accuracy: 0.987 - ETA: 26s - loss: 0.0585 - accuracy: 0.987 - ETA: 24s - loss: 0.0599 - accuracy: 0.987 - ETA: 23s - loss: 0.0595 - accuracy: 0.987 - ETA: 22s - loss: 0.0598 - accuracy: 0.987 - ETA: 20s - loss: 0.0601 - accuracy: 0.987 - ETA: 19s - loss: 0.0599 - accuracy: 0.987 - ETA: 17s - loss: 0.0594 - accuracy: 0.987 - ETA: 16s - loss: 0.0589 - accuracy: 0.987 - ETA: 14s - loss: 0.0594 - accuracy: 0.987 - ETA: 13s - loss: 0.0589 - accuracy: 0.987 - ETA: 12s - loss: 0.0583 - accuracy: 0.987 - ETA: 10s - loss: 0.0580 - accuracy: 0.987 - ETA: 9s - loss: 0.0578 - accuracy: 0.987 - ETA: 8s - loss: 0.0576 - accuracy: 0.98 - ETA: 6s - loss: 0.0595 - accuracy: 0.98 - ETA: 5s - loss: 0.0592 - accuracy: 0.98 - ETA: 3s - loss: 0.0591 - accuracy: 0.98 - ETA: 2s - loss: 0.0592 - accuracy: 0.98 - ETA: 1s - loss: 0.0587 - accuracy: 0.98 - 156s 12ms/step - loss: 0.0585 - accuracy: 0.9876 - val_loss: 3.6003 - val_accuracy: 0.3743\n",
      "Epoch 88/100\n",
      "13022/13022 [==============================] - ETA: 2:17 - loss: 0.0151 - accuracy: 1.00 - ETA: 2:14 - loss: 0.0221 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0209 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0547 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0636 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0587 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0569 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0554 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0550 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0516 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0474 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0452 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0421 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0450 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0431 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0386 - accuracy: 0.99 - ETA: 1:41 - loss: 0.0375 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0365 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0361 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0356 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0353 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0352 - accuracy: 0.99 - ETA: 1:31 - loss: 0.0356 - accuracy: 0.99 - ETA: 1:30 - loss: 0.0348 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0343 - accuracy: 0.99 - ETA: 1:27 - loss: 0.0335 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0332 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0325 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:22 - loss: 0.0312 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0317 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0322 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0322 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0319 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0314 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0310 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0318 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0336 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0331 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0334 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0330 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0337 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0333 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0337 - accuracy: 0.99 - ETA: 59s - loss: 0.0339 - accuracy: 0.9913 - ETA: 58s - loss: 0.0337 - accuracy: 0.991 - ETA: 56s - loss: 0.0340 - accuracy: 0.991 - ETA: 55s - loss: 0.0340 - accuracy: 0.990 - ETA: 54s - loss: 0.0337 - accuracy: 0.991 - ETA: 52s - loss: 0.0357 - accuracy: 0.991 - ETA: 51s - loss: 0.0359 - accuracy: 0.991 - ETA: 49s - loss: 0.0356 - accuracy: 0.991 - ETA: 48s - loss: 0.0377 - accuracy: 0.990 - ETA: 46s - loss: 0.0378 - accuracy: 0.990 - ETA: 45s - loss: 0.0382 - accuracy: 0.990 - ETA: 44s - loss: 0.0378 - accuracy: 0.990 - ETA: 42s - loss: 0.0377 - accuracy: 0.990 - ETA: 41s - loss: 0.0374 - accuracy: 0.990 - ETA: 39s - loss: 0.0375 - accuracy: 0.990 - ETA: 38s - loss: 0.0375 - accuracy: 0.990 - ETA: 37s - loss: 0.0384 - accuracy: 0.990 - ETA: 35s - loss: 0.0384 - accuracy: 0.990 - ETA: 34s - loss: 0.0385 - accuracy: 0.990 - ETA: 33s - loss: 0.0385 - accuracy: 0.990 - ETA: 31s - loss: 0.0384 - accuracy: 0.990 - ETA: 30s - loss: 0.0381 - accuracy: 0.990 - ETA: 28s - loss: 0.0378 - accuracy: 0.990 - ETA: 27s - loss: 0.0375 - accuracy: 0.990 - ETA: 26s - loss: 0.0371 - accuracy: 0.990 - ETA: 24s - loss: 0.0388 - accuracy: 0.990 - ETA: 23s - loss: 0.0384 - accuracy: 0.990 - ETA: 21s - loss: 0.0381 - accuracy: 0.990 - ETA: 20s - loss: 0.0383 - accuracy: 0.990 - ETA: 19s - loss: 0.0383 - accuracy: 0.990 - ETA: 17s - loss: 0.0386 - accuracy: 0.990 - ETA: 16s - loss: 0.0384 - accuracy: 0.990 - ETA: 14s - loss: 0.0389 - accuracy: 0.990 - ETA: 13s - loss: 0.0387 - accuracy: 0.990 - ETA: 12s - loss: 0.0393 - accuracy: 0.990 - ETA: 10s - loss: 0.0402 - accuracy: 0.990 - ETA: 9s - loss: 0.0400 - accuracy: 0.990 - ETA: 7s - loss: 0.0398 - accuracy: 0.99 - ETA: 6s - loss: 0.0402 - accuracy: 0.99 - ETA: 5s - loss: 0.0404 - accuracy: 0.99 - ETA: 3s - loss: 0.0404 - accuracy: 0.99 - ETA: 2s - loss: 0.0403 - accuracy: 0.99 - ETA: 1s - loss: 0.0410 - accuracy: 0.99 - 156s 12ms/step - loss: 0.0425 - accuracy: 0.9900 - val_loss: 3.9833 - val_accuracy: 0.3581\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:15 - loss: 0.0570 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0604 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0339 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0368 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0486 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0440 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0509 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0519 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0501 - accuracy: 0.99 - ETA: 2:05 - loss: 0.0466 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0467 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0489 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0470 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0478 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0465 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0475 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0483 - accuracy: 0.99 - ETA: 1:43 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0504 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0642 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0635 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0622 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0624 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0630 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0621 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0615 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0626 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0617 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0619 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0612 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0602 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0598 - accuracy: 0.98 - ETA: 58s - loss: 0.0592 - accuracy: 0.9878 - ETA: 57s - loss: 0.0595 - accuracy: 0.987 - ETA: 55s - loss: 0.0596 - accuracy: 0.987 - ETA: 54s - loss: 0.0593 - accuracy: 0.987 - ETA: 53s - loss: 0.0590 - accuracy: 0.987 - ETA: 51s - loss: 0.0587 - accuracy: 0.987 - ETA: 50s - loss: 0.0599 - accuracy: 0.987 - ETA: 48s - loss: 0.0596 - accuracy: 0.987 - ETA: 47s - loss: 0.0610 - accuracy: 0.987 - ETA: 46s - loss: 0.0604 - accuracy: 0.987 - ETA: 44s - loss: 0.0601 - accuracy: 0.986 - ETA: 43s - loss: 0.0599 - accuracy: 0.986 - ETA: 41s - loss: 0.0607 - accuracy: 0.986 - ETA: 40s - loss: 0.0601 - accuracy: 0.986 - ETA: 38s - loss: 0.0601 - accuracy: 0.986 - ETA: 37s - loss: 0.0599 - accuracy: 0.986 - ETA: 36s - loss: 0.0594 - accuracy: 0.986 - ETA: 34s - loss: 0.0598 - accuracy: 0.986 - ETA: 33s - loss: 0.0604 - accuracy: 0.986 - ETA: 31s - loss: 0.0597 - accuracy: 0.986 - ETA: 30s - loss: 0.0593 - accuracy: 0.986 - ETA: 29s - loss: 0.0601 - accuracy: 0.986 - ETA: 27s - loss: 0.0595 - accuracy: 0.986 - ETA: 26s - loss: 0.0598 - accuracy: 0.986 - ETA: 24s - loss: 0.0594 - accuracy: 0.986 - ETA: 23s - loss: 0.0594 - accuracy: 0.986 - ETA: 21s - loss: 0.0592 - accuracy: 0.986 - ETA: 20s - loss: 0.0600 - accuracy: 0.986 - ETA: 19s - loss: 0.0609 - accuracy: 0.986 - ETA: 17s - loss: 0.0617 - accuracy: 0.986 - ETA: 16s - loss: 0.0615 - accuracy: 0.986 - ETA: 14s - loss: 0.0623 - accuracy: 0.985 - ETA: 13s - loss: 0.0617 - accuracy: 0.986 - ETA: 12s - loss: 0.0627 - accuracy: 0.986 - ETA: 10s - loss: 0.0626 - accuracy: 0.986 - ETA: 9s - loss: 0.0627 - accuracy: 0.986 - ETA: 7s - loss: 0.0621 - accuracy: 0.98 - ETA: 6s - loss: 0.0619 - accuracy: 0.98 - ETA: 5s - loss: 0.0628 - accuracy: 0.98 - ETA: 3s - loss: 0.0623 - accuracy: 0.98 - ETA: 2s - loss: 0.0619 - accuracy: 0.98 - ETA: 1s - loss: 0.0617 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0621 - accuracy: 0.9861 - val_loss: 3.4459 - val_accuracy: 0.4320\n",
      "Epoch 90/100\n",
      "13022/13022 [==============================] - ETA: 2:16 - loss: 0.0105 - accuracy: 1.00 - ETA: 2:13 - loss: 0.1089 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0854 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0918 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0750 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0654 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0668 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0578 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0538 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0533 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0578 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0542 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0536 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0467 - accuracy: 0.99 - ETA: 1:51 - loss: 0.0471 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0537 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0580 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0531 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0474 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0475 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0470 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0454 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0431 - accuracy: 0.98 - ETA: 59s - loss: 0.0425 - accuracy: 0.9891 - ETA: 58s - loss: 0.0444 - accuracy: 0.988 - ETA: 56s - loss: 0.0455 - accuracy: 0.988 - ETA: 55s - loss: 0.0465 - accuracy: 0.988 - ETA: 53s - loss: 0.0463 - accuracy: 0.988 - ETA: 52s - loss: 0.0469 - accuracy: 0.988 - ETA: 51s - loss: 0.0467 - accuracy: 0.988 - ETA: 49s - loss: 0.0465 - accuracy: 0.988 - ETA: 48s - loss: 0.0461 - accuracy: 0.988 - ETA: 47s - loss: 0.0462 - accuracy: 0.988 - ETA: 45s - loss: 0.0460 - accuracy: 0.988 - ETA: 44s - loss: 0.0461 - accuracy: 0.988 - ETA: 43s - loss: 0.0457 - accuracy: 0.988 - ETA: 41s - loss: 0.0462 - accuracy: 0.988 - ETA: 40s - loss: 0.0478 - accuracy: 0.988 - ETA: 39s - loss: 0.0473 - accuracy: 0.988 - ETA: 37s - loss: 0.0474 - accuracy: 0.988 - ETA: 36s - loss: 0.0482 - accuracy: 0.988 - ETA: 34s - loss: 0.0480 - accuracy: 0.988 - ETA: 33s - loss: 0.0481 - accuracy: 0.988 - ETA: 32s - loss: 0.0482 - accuracy: 0.988 - ETA: 30s - loss: 0.0479 - accuracy: 0.988 - ETA: 29s - loss: 0.0481 - accuracy: 0.988 - ETA: 28s - loss: 0.0477 - accuracy: 0.988 - ETA: 26s - loss: 0.0482 - accuracy: 0.988 - ETA: 25s - loss: 0.0477 - accuracy: 0.988 - ETA: 24s - loss: 0.0478 - accuracy: 0.988 - ETA: 22s - loss: 0.0476 - accuracy: 0.988 - ETA: 21s - loss: 0.0471 - accuracy: 0.988 - ETA: 20s - loss: 0.0474 - accuracy: 0.988 - ETA: 18s - loss: 0.0473 - accuracy: 0.988 - ETA: 17s - loss: 0.0470 - accuracy: 0.988 - ETA: 15s - loss: 0.0475 - accuracy: 0.988 - ETA: 14s - loss: 0.0470 - accuracy: 0.988 - ETA: 13s - loss: 0.0469 - accuracy: 0.988 - ETA: 11s - loss: 0.0465 - accuracy: 0.988 - ETA: 10s - loss: 0.0466 - accuracy: 0.988 - ETA: 9s - loss: 0.0466 - accuracy: 0.988 - ETA: 7s - loss: 0.0469 - accuracy: 0.98 - ETA: 6s - loss: 0.0470 - accuracy: 0.98 - ETA: 5s - loss: 0.0466 - accuracy: 0.98 - ETA: 3s - loss: 0.0465 - accuracy: 0.98 - ETA: 2s - loss: 0.0463 - accuracy: 0.98 - ETA: 1s - loss: 0.0461 - accuracy: 0.98 - 154s 12ms/step - loss: 0.0459 - accuracy: 0.9883 - val_loss: 3.7157 - val_accuracy: 0.3973\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:19 - loss: 0.0191 - accuracy: 0.99 - ETA: 2:17 - loss: 0.0270 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0268 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0596 - accuracy: 0.97 - ETA: 2:18 - loss: 0.0525 - accuracy: 0.97 - ETA: 2:16 - loss: 0.0440 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0375 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0357 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0418 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0464 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0453 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0479 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0468 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0450 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0401 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0394 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0388 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0477 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0492 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0486 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0489 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0452 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0473 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0466 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0485 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0483 - accuracy: 0.98 - ETA: 59s - loss: 0.0483 - accuracy: 0.9878 - ETA: 58s - loss: 0.0476 - accuracy: 0.988 - ETA: 57s - loss: 0.0489 - accuracy: 0.987 - ETA: 55s - loss: 0.0493 - accuracy: 0.987 - ETA: 54s - loss: 0.0490 - accuracy: 0.987 - ETA: 53s - loss: 0.0490 - accuracy: 0.987 - ETA: 52s - loss: 0.0492 - accuracy: 0.987 - ETA: 50s - loss: 0.0487 - accuracy: 0.987 - ETA: 49s - loss: 0.0483 - accuracy: 0.987 - ETA: 48s - loss: 0.0478 - accuracy: 0.988 - ETA: 47s - loss: 0.0473 - accuracy: 0.988 - ETA: 45s - loss: 0.0467 - accuracy: 0.988 - ETA: 44s - loss: 0.0467 - accuracy: 0.988 - ETA: 43s - loss: 0.0472 - accuracy: 0.988 - ETA: 42s - loss: 0.0467 - accuracy: 0.988 - ETA: 40s - loss: 0.0463 - accuracy: 0.988 - ETA: 39s - loss: 0.0462 - accuracy: 0.988 - ETA: 38s - loss: 0.0457 - accuracy: 0.988 - ETA: 37s - loss: 0.0452 - accuracy: 0.988 - ETA: 36s - loss: 0.0458 - accuracy: 0.988 - ETA: 35s - loss: 0.0452 - accuracy: 0.988 - ETA: 33s - loss: 0.0448 - accuracy: 0.989 - ETA: 32s - loss: 0.0452 - accuracy: 0.988 - ETA: 31s - loss: 0.0447 - accuracy: 0.989 - ETA: 30s - loss: 0.0447 - accuracy: 0.989 - ETA: 29s - loss: 0.0443 - accuracy: 0.989 - ETA: 27s - loss: 0.0450 - accuracy: 0.989 - ETA: 26s - loss: 0.0452 - accuracy: 0.989 - ETA: 25s - loss: 0.0454 - accuracy: 0.989 - ETA: 24s - loss: 0.0457 - accuracy: 0.989 - ETA: 23s - loss: 0.0463 - accuracy: 0.988 - ETA: 21s - loss: 0.0460 - accuracy: 0.989 - ETA: 20s - loss: 0.0465 - accuracy: 0.988 - ETA: 19s - loss: 0.0469 - accuracy: 0.989 - ETA: 18s - loss: 0.0468 - accuracy: 0.988 - ETA: 17s - loss: 0.0467 - accuracy: 0.988 - ETA: 16s - loss: 0.0463 - accuracy: 0.989 - ETA: 14s - loss: 0.0464 - accuracy: 0.988 - ETA: 13s - loss: 0.0460 - accuracy: 0.989 - ETA: 12s - loss: 0.0459 - accuracy: 0.989 - ETA: 11s - loss: 0.0464 - accuracy: 0.989 - ETA: 10s - loss: 0.0459 - accuracy: 0.989 - ETA: 9s - loss: 0.0456 - accuracy: 0.989 - ETA: 7s - loss: 0.0455 - accuracy: 0.98 - ETA: 6s - loss: 0.0452 - accuracy: 0.98 - ETA: 5s - loss: 0.0454 - accuracy: 0.98 - ETA: 4s - loss: 0.0456 - accuracy: 0.98 - ETA: 3s - loss: 0.0459 - accuracy: 0.98 - ETA: 2s - loss: 0.0459 - accuracy: 0.98 - ETA: 0s - loss: 0.0459 - accuracy: 0.98 - 130s 10ms/step - loss: 0.0461 - accuracy: 0.9892 - val_loss: 3.8037 - val_accuracy: 0.3765\n",
      "Epoch 92/100\n",
      "13022/13022 [==============================] - ETA: 2:03 - loss: 0.0061 - accuracy: 1.00 - ETA: 2:00 - loss: 0.0083 - accuracy: 1.00 - ETA: 1:55 - loss: 0.0145 - accuracy: 0.99 - ETA: 1:52 - loss: 0.0176 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0185 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0169 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0180 - accuracy: 0.99 - ETA: 1:44 - loss: 0.0205 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0218 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0230 - accuracy: 0.99 - ETA: 1:42 - loss: 0.0360 - accuracy: 0.99 - ETA: 1:40 - loss: 0.0356 - accuracy: 0.99 - ETA: 1:39 - loss: 0.0331 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0342 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0387 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0491 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0476 - accuracy: 0.99 - ETA: 1:34 - loss: 0.0488 - accuracy: 0.99 - ETA: 1:33 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0522 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0529 - accuracy: 0.99 - ETA: 1:29 - loss: 0.0506 - accuracy: 0.99 - ETA: 1:28 - loss: 0.0487 - accuracy: 0.99 - ETA: 1:26 - loss: 0.0477 - accuracy: 0.99 - ETA: 1:25 - loss: 0.0488 - accuracy: 0.99 - ETA: 1:24 - loss: 0.0473 - accuracy: 0.99 - ETA: 1:23 - loss: 0.0485 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0479 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0465 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0464 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0455 - accuracy: 0.99 - ETA: 1:17 - loss: 0.0443 - accuracy: 0.99 - ETA: 1:16 - loss: 0.0452 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0444 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0439 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0437 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0428 - accuracy: 0.99 - ETA: 1:10 - loss: 0.0420 - accuracy: 0.99 - ETA: 1:09 - loss: 0.0436 - accuracy: 0.99 - ETA: 1:08 - loss: 0.0426 - accuracy: 0.99 - ETA: 1:07 - loss: 0.0421 - accuracy: 0.99 - ETA: 1:06 - loss: 0.0435 - accuracy: 0.99 - ETA: 1:05 - loss: 0.0430 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0452 - accuracy: 0.99 - ETA: 1:02 - loss: 0.0444 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0436 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0429 - accuracy: 0.99 - ETA: 59s - loss: 0.0435 - accuracy: 0.9910 - ETA: 58s - loss: 0.0451 - accuracy: 0.990 - ETA: 57s - loss: 0.0457 - accuracy: 0.990 - ETA: 56s - loss: 0.0470 - accuracy: 0.990 - ETA: 55s - loss: 0.0471 - accuracy: 0.990 - ETA: 54s - loss: 0.0477 - accuracy: 0.990 - ETA: 52s - loss: 0.0473 - accuracy: 0.990 - ETA: 51s - loss: 0.0466 - accuracy: 0.990 - ETA: 50s - loss: 0.0460 - accuracy: 0.990 - ETA: 49s - loss: 0.0463 - accuracy: 0.990 - ETA: 48s - loss: 0.0455 - accuracy: 0.990 - ETA: 47s - loss: 0.0450 - accuracy: 0.990 - ETA: 46s - loss: 0.0445 - accuracy: 0.990 - ETA: 45s - loss: 0.0442 - accuracy: 0.990 - ETA: 44s - loss: 0.0447 - accuracy: 0.990 - ETA: 42s - loss: 0.0441 - accuracy: 0.990 - ETA: 41s - loss: 0.0436 - accuracy: 0.990 - ETA: 40s - loss: 0.0439 - accuracy: 0.990 - ETA: 39s - loss: 0.0452 - accuracy: 0.990 - ETA: 38s - loss: 0.0447 - accuracy: 0.990 - ETA: 37s - loss: 0.0460 - accuracy: 0.990 - ETA: 36s - loss: 0.0456 - accuracy: 0.990 - ETA: 35s - loss: 0.0452 - accuracy: 0.990 - ETA: 34s - loss: 0.0446 - accuracy: 0.990 - ETA: 32s - loss: 0.0471 - accuracy: 0.990 - ETA: 31s - loss: 0.0469 - accuracy: 0.990 - ETA: 30s - loss: 0.0470 - accuracy: 0.989 - ETA: 29s - loss: 0.0481 - accuracy: 0.989 - ETA: 28s - loss: 0.0482 - accuracy: 0.989 - ETA: 27s - loss: 0.0476 - accuracy: 0.989 - ETA: 26s - loss: 0.0497 - accuracy: 0.989 - ETA: 25s - loss: 0.0506 - accuracy: 0.989 - ETA: 24s - loss: 0.0505 - accuracy: 0.989 - ETA: 22s - loss: 0.0502 - accuracy: 0.989 - ETA: 21s - loss: 0.0497 - accuracy: 0.989 - ETA: 20s - loss: 0.0499 - accuracy: 0.989 - ETA: 19s - loss: 0.0495 - accuracy: 0.989 - ETA: 18s - loss: 0.0501 - accuracy: 0.989 - ETA: 17s - loss: 0.0498 - accuracy: 0.989 - ETA: 16s - loss: 0.0502 - accuracy: 0.989 - ETA: 15s - loss: 0.0497 - accuracy: 0.989 - ETA: 14s - loss: 0.0493 - accuracy: 0.989 - ETA: 13s - loss: 0.0489 - accuracy: 0.989 - ETA: 11s - loss: 0.0491 - accuracy: 0.989 - ETA: 10s - loss: 0.0487 - accuracy: 0.989 - ETA: 9s - loss: 0.0484 - accuracy: 0.989 - ETA: 8s - loss: 0.0484 - accuracy: 0.98 - ETA: 7s - loss: 0.0486 - accuracy: 0.98 - ETA: 6s - loss: 0.0486 - accuracy: 0.98 - ETA: 5s - loss: 0.0490 - accuracy: 0.98 - ETA: 4s - loss: 0.0496 - accuracy: 0.98 - ETA: 3s - loss: 0.0499 - accuracy: 0.98 - ETA: 1s - loss: 0.0499 - accuracy: 0.98 - ETA: 0s - loss: 0.0499 - accuracy: 0.98 - 125s 10ms/step - loss: 0.0500 - accuracy: 0.9894 - val_loss: 3.6595 - val_accuracy: 0.3750\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:51 - loss: 0.1141 - accuracy: 0.97 - ETA: 1:51 - loss: 0.0601 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0625 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0809 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0745 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0728 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0725 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0729 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0672 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0665 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0618 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0670 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0663 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0640 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0598 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0568 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0534 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0567 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0535 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0555 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0549 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0560 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0570 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0581 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0575 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0584 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0576 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0573 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0585 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0579 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0558 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0564 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0565 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0557 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0552 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0538 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0553 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0547 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0540 - accuracy: 0.98 - ETA: 59s - loss: 0.0531 - accuracy: 0.9871 - ETA: 58s - loss: 0.0536 - accuracy: 0.986 - ETA: 57s - loss: 0.0530 - accuracy: 0.986 - ETA: 55s - loss: 0.0523 - accuracy: 0.987 - ETA: 54s - loss: 0.0523 - accuracy: 0.987 - ETA: 53s - loss: 0.0524 - accuracy: 0.987 - ETA: 52s - loss: 0.0518 - accuracy: 0.987 - ETA: 51s - loss: 0.0514 - accuracy: 0.987 - ETA: 49s - loss: 0.0506 - accuracy: 0.987 - ETA: 48s - loss: 0.0499 - accuracy: 0.987 - ETA: 47s - loss: 0.0505 - accuracy: 0.987 - ETA: 46s - loss: 0.0499 - accuracy: 0.987 - ETA: 45s - loss: 0.0495 - accuracy: 0.987 - ETA: 43s - loss: 0.0504 - accuracy: 0.987 - ETA: 42s - loss: 0.0504 - accuracy: 0.987 - ETA: 41s - loss: 0.0498 - accuracy: 0.987 - ETA: 40s - loss: 0.0498 - accuracy: 0.987 - ETA: 39s - loss: 0.0493 - accuracy: 0.987 - ETA: 37s - loss: 0.0491 - accuracy: 0.988 - ETA: 36s - loss: 0.0494 - accuracy: 0.987 - ETA: 35s - loss: 0.0491 - accuracy: 0.988 - ETA: 34s - loss: 0.0489 - accuracy: 0.987 - ETA: 32s - loss: 0.0483 - accuracy: 0.988 - ETA: 31s - loss: 0.0493 - accuracy: 0.988 - ETA: 30s - loss: 0.0493 - accuracy: 0.988 - ETA: 29s - loss: 0.0487 - accuracy: 0.988 - ETA: 27s - loss: 0.0484 - accuracy: 0.988 - ETA: 26s - loss: 0.0486 - accuracy: 0.988 - ETA: 25s - loss: 0.0483 - accuracy: 0.988 - ETA: 24s - loss: 0.0481 - accuracy: 0.988 - ETA: 22s - loss: 0.0477 - accuracy: 0.988 - ETA: 21s - loss: 0.0473 - accuracy: 0.988 - ETA: 20s - loss: 0.0483 - accuracy: 0.988 - ETA: 18s - loss: 0.0492 - accuracy: 0.988 - ETA: 17s - loss: 0.0489 - accuracy: 0.988 - ETA: 16s - loss: 0.0486 - accuracy: 0.988 - ETA: 15s - loss: 0.0484 - accuracy: 0.988 - ETA: 13s - loss: 0.0487 - accuracy: 0.988 - ETA: 12s - loss: 0.0483 - accuracy: 0.988 - ETA: 11s - loss: 0.0479 - accuracy: 0.988 - ETA: 10s - loss: 0.0480 - accuracy: 0.988 - ETA: 8s - loss: 0.0488 - accuracy: 0.987 - ETA: 7s - loss: 0.0486 - accuracy: 0.98 - ETA: 6s - loss: 0.0484 - accuracy: 0.98 - ETA: 4s - loss: 0.0482 - accuracy: 0.98 - ETA: 3s - loss: 0.0479 - accuracy: 0.98 - ETA: 2s - loss: 0.0477 - accuracy: 0.98 - ETA: 0s - loss: 0.0477 - accuracy: 0.98 - 147s 11ms/step - loss: 0.0489 - accuracy: 0.9876 - val_loss: 3.6651 - val_accuracy: 0.3745\n",
      "Epoch 94/100\n",
      "13022/13022 [==============================] - ETA: 2:19 - loss: 0.0223 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0563 - accuracy: 0.98 - ETA: 2:18 - loss: 0.0553 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0610 - accuracy: 0.98 - ETA: 2:13 - loss: 0.0522 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0651 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0596 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0571 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0531 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0551 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0528 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0499 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0501 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0476 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0458 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0468 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0463 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0479 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0480 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0481 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0502 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0494 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0488 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0503 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0510 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0526 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0521 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0513 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0508 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0526 - accuracy: 0.98 - ETA: 58s - loss: 0.0520 - accuracy: 0.9870 - ETA: 57s - loss: 0.0518 - accuracy: 0.987 - ETA: 56s - loss: 0.0518 - accuracy: 0.986 - ETA: 54s - loss: 0.0514 - accuracy: 0.987 - ETA: 53s - loss: 0.0524 - accuracy: 0.987 - ETA: 52s - loss: 0.0520 - accuracy: 0.987 - ETA: 50s - loss: 0.0524 - accuracy: 0.987 - ETA: 49s - loss: 0.0525 - accuracy: 0.987 - ETA: 47s - loss: 0.0519 - accuracy: 0.987 - ETA: 46s - loss: 0.0512 - accuracy: 0.987 - ETA: 45s - loss: 0.0512 - accuracy: 0.987 - ETA: 43s - loss: 0.0510 - accuracy: 0.987 - ETA: 42s - loss: 0.0511 - accuracy: 0.987 - ETA: 41s - loss: 0.0508 - accuracy: 0.987 - ETA: 39s - loss: 0.0507 - accuracy: 0.987 - ETA: 38s - loss: 0.0512 - accuracy: 0.987 - ETA: 36s - loss: 0.0512 - accuracy: 0.987 - ETA: 35s - loss: 0.0521 - accuracy: 0.987 - ETA: 34s - loss: 0.0520 - accuracy: 0.987 - ETA: 32s - loss: 0.0516 - accuracy: 0.987 - ETA: 31s - loss: 0.0518 - accuracy: 0.987 - ETA: 30s - loss: 0.0521 - accuracy: 0.987 - ETA: 28s - loss: 0.0518 - accuracy: 0.987 - ETA: 27s - loss: 0.0515 - accuracy: 0.987 - ETA: 25s - loss: 0.0510 - accuracy: 0.987 - ETA: 24s - loss: 0.0518 - accuracy: 0.987 - ETA: 23s - loss: 0.0514 - accuracy: 0.987 - ETA: 21s - loss: 0.0509 - accuracy: 0.987 - ETA: 20s - loss: 0.0522 - accuracy: 0.987 - ETA: 18s - loss: 0.0522 - accuracy: 0.987 - ETA: 17s - loss: 0.0517 - accuracy: 0.987 - ETA: 16s - loss: 0.0513 - accuracy: 0.987 - ETA: 14s - loss: 0.0529 - accuracy: 0.987 - ETA: 13s - loss: 0.0528 - accuracy: 0.987 - ETA: 12s - loss: 0.0525 - accuracy: 0.987 - ETA: 10s - loss: 0.0521 - accuracy: 0.987 - ETA: 9s - loss: 0.0525 - accuracy: 0.987 - ETA: 7s - loss: 0.0521 - accuracy: 0.98 - ETA: 6s - loss: 0.0517 - accuracy: 0.98 - ETA: 5s - loss: 0.0512 - accuracy: 0.98 - ETA: 3s - loss: 0.0511 - accuracy: 0.98 - ETA: 2s - loss: 0.0511 - accuracy: 0.98 - ETA: 1s - loss: 0.0507 - accuracy: 0.98 - 155s 12ms/step - loss: 0.0507 - accuracy: 0.9878 - val_loss: 3.5985 - val_accuracy: 0.3830\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:14 - loss: 0.0376 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0575 - accuracy: 0.98 - ETA: 2:15 - loss: 0.0499 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0396 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0546 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0465 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0427 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0441 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0425 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0442 - accuracy: 0.98 - ETA: 2:03 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0423 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0365 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0446 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0438 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0420 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0400 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0406 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0396 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0390 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0389 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0378 - accuracy: 0.99 - ETA: 1:15 - loss: 0.0374 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0376 - accuracy: 0.99 - ETA: 1:12 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:11 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0437 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0441 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0445 - accuracy: 0.98 - ETA: 59s - loss: 0.0440 - accuracy: 0.9889 - ETA: 57s - loss: 0.0435 - accuracy: 0.988 - ETA: 56s - loss: 0.0429 - accuracy: 0.989 - ETA: 54s - loss: 0.0428 - accuracy: 0.989 - ETA: 53s - loss: 0.0429 - accuracy: 0.988 - ETA: 52s - loss: 0.0430 - accuracy: 0.988 - ETA: 50s - loss: 0.0428 - accuracy: 0.988 - ETA: 49s - loss: 0.0437 - accuracy: 0.988 - ETA: 47s - loss: 0.0445 - accuracy: 0.988 - ETA: 46s - loss: 0.0447 - accuracy: 0.988 - ETA: 45s - loss: 0.0444 - accuracy: 0.988 - ETA: 43s - loss: 0.0439 - accuracy: 0.988 - ETA: 42s - loss: 0.0458 - accuracy: 0.988 - ETA: 40s - loss: 0.0478 - accuracy: 0.988 - ETA: 39s - loss: 0.0473 - accuracy: 0.988 - ETA: 38s - loss: 0.0467 - accuracy: 0.989 - ETA: 36s - loss: 0.0464 - accuracy: 0.989 - ETA: 35s - loss: 0.0464 - accuracy: 0.989 - ETA: 34s - loss: 0.0459 - accuracy: 0.989 - ETA: 32s - loss: 0.0471 - accuracy: 0.989 - ETA: 31s - loss: 0.0472 - accuracy: 0.988 - ETA: 29s - loss: 0.0467 - accuracy: 0.989 - ETA: 28s - loss: 0.0467 - accuracy: 0.989 - ETA: 27s - loss: 0.0464 - accuracy: 0.989 - ETA: 25s - loss: 0.0462 - accuracy: 0.989 - ETA: 24s - loss: 0.0461 - accuracy: 0.989 - ETA: 23s - loss: 0.0457 - accuracy: 0.989 - ETA: 21s - loss: 0.0454 - accuracy: 0.989 - ETA: 20s - loss: 0.0452 - accuracy: 0.989 - ETA: 18s - loss: 0.0448 - accuracy: 0.989 - ETA: 17s - loss: 0.0452 - accuracy: 0.989 - ETA: 16s - loss: 0.0463 - accuracy: 0.989 - ETA: 14s - loss: 0.0467 - accuracy: 0.989 - ETA: 13s - loss: 0.0471 - accuracy: 0.989 - ETA: 12s - loss: 0.0471 - accuracy: 0.989 - ETA: 10s - loss: 0.0467 - accuracy: 0.989 - ETA: 9s - loss: 0.0465 - accuracy: 0.989 - ETA: 7s - loss: 0.0463 - accuracy: 0.98 - ETA: 6s - loss: 0.0459 - accuracy: 0.98 - ETA: 5s - loss: 0.0465 - accuracy: 0.98 - ETA: 3s - loss: 0.0461 - accuracy: 0.98 - ETA: 2s - loss: 0.0465 - accuracy: 0.98 - ETA: 1s - loss: 0.0464 - accuracy: 0.98 - 155s 12ms/step - loss: 0.0472 - accuracy: 0.9892 - val_loss: 3.6871 - val_accuracy: 0.4106\n",
      "Epoch 96/100\n",
      "13022/13022 [==============================] - ETA: 2:15 - loss: 0.0328 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0449 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0472 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0475 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0413 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0371 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0390 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0498 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0471 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0445 - accuracy: 0.98 - ETA: 2:01 - loss: 0.0444 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0412 - accuracy: 0.99 - ETA: 1:57 - loss: 0.0408 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0390 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0407 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0398 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:49 - loss: 0.0370 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0371 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0367 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0356 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0414 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0409 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0405 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0392 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0379 - accuracy: 0.99 - ETA: 1:38 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0393 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0391 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0381 - accuracy: 0.99 - ETA: 1:32 - loss: 0.0388 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0397 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0408 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0453 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0437 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0432 - accuracy: 0.99 - ETA: 1:18 - loss: 0.0472 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0465 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0458 - accuracy: 0.99 - ETA: 1:14 - loss: 0.0452 - accuracy: 0.99 - ETA: 1:13 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0456 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0464 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0467 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0487 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0484 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0490 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0482 - accuracy: 0.98 - ETA: 58s - loss: 0.0481 - accuracy: 0.9886 - ETA: 57s - loss: 0.0473 - accuracy: 0.988 - ETA: 55s - loss: 0.0482 - accuracy: 0.988 - ETA: 54s - loss: 0.0485 - accuracy: 0.988 - ETA: 53s - loss: 0.0497 - accuracy: 0.988 - ETA: 51s - loss: 0.0492 - accuracy: 0.988 - ETA: 50s - loss: 0.0486 - accuracy: 0.988 - ETA: 49s - loss: 0.0481 - accuracy: 0.988 - ETA: 47s - loss: 0.0477 - accuracy: 0.988 - ETA: 46s - loss: 0.0484 - accuracy: 0.988 - ETA: 45s - loss: 0.0477 - accuracy: 0.988 - ETA: 43s - loss: 0.0471 - accuracy: 0.989 - ETA: 42s - loss: 0.0467 - accuracy: 0.989 - ETA: 40s - loss: 0.0480 - accuracy: 0.989 - ETA: 39s - loss: 0.0474 - accuracy: 0.989 - ETA: 38s - loss: 0.0473 - accuracy: 0.989 - ETA: 36s - loss: 0.0485 - accuracy: 0.989 - ETA: 35s - loss: 0.0481 - accuracy: 0.989 - ETA: 33s - loss: 0.0476 - accuracy: 0.989 - ETA: 32s - loss: 0.0470 - accuracy: 0.989 - ETA: 31s - loss: 0.0471 - accuracy: 0.989 - ETA: 29s - loss: 0.0466 - accuracy: 0.989 - ETA: 28s - loss: 0.0461 - accuracy: 0.989 - ETA: 27s - loss: 0.0459 - accuracy: 0.989 - ETA: 25s - loss: 0.0460 - accuracy: 0.989 - ETA: 24s - loss: 0.0467 - accuracy: 0.989 - ETA: 23s - loss: 0.0462 - accuracy: 0.989 - ETA: 21s - loss: 0.0462 - accuracy: 0.989 - ETA: 20s - loss: 0.0462 - accuracy: 0.989 - ETA: 18s - loss: 0.0461 - accuracy: 0.989 - ETA: 17s - loss: 0.0464 - accuracy: 0.989 - ETA: 16s - loss: 0.0469 - accuracy: 0.988 - ETA: 14s - loss: 0.0469 - accuracy: 0.988 - ETA: 13s - loss: 0.0485 - accuracy: 0.988 - ETA: 11s - loss: 0.0483 - accuracy: 0.988 - ETA: 10s - loss: 0.0482 - accuracy: 0.988 - ETA: 9s - loss: 0.0490 - accuracy: 0.988 - ETA: 7s - loss: 0.0489 - accuracy: 0.98 - ETA: 6s - loss: 0.0486 - accuracy: 0.98 - ETA: 5s - loss: 0.0482 - accuracy: 0.98 - ETA: 3s - loss: 0.0478 - accuracy: 0.98 - ETA: 2s - loss: 0.0484 - accuracy: 0.98 - ETA: 1s - loss: 0.0489 - accuracy: 0.98 - 154s 12ms/step - loss: 0.0490 - accuracy: 0.9886 - val_loss: 3.5723 - val_accuracy: 0.4404\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:22 - loss: 0.0225 - accuracy: 0.99 - ETA: 2:24 - loss: 0.0217 - accuracy: 0.99 - ETA: 2:22 - loss: 0.0201 - accuracy: 0.99 - ETA: 2:18 - loss: 0.0211 - accuracy: 0.99 - ETA: 2:16 - loss: 0.0250 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0285 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0385 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0352 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0391 - accuracy: 0.98 - ETA: 2:05 - loss: 0.0359 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0371 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0395 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0383 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0386 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0367 - accuracy: 0.99 - ETA: 1:55 - loss: 0.0358 - accuracy: 0.99 - ETA: 1:54 - loss: 0.0366 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0379 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0649 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0700 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0678 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0669 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0652 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0647 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0634 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0639 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0627 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0614 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0643 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0631 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0623 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0613 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0606 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0620 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0616 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0609 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0600 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0595 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0599 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0594 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0588 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0587 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0583 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0574 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0582 - accuracy: 0.98 - ETA: 59s - loss: 0.0576 - accuracy: 0.9870 - ETA: 58s - loss: 0.0579 - accuracy: 0.987 - ETA: 56s - loss: 0.0571 - accuracy: 0.987 - ETA: 55s - loss: 0.0589 - accuracy: 0.986 - ETA: 53s - loss: 0.0587 - accuracy: 0.986 - ETA: 52s - loss: 0.0595 - accuracy: 0.986 - ETA: 51s - loss: 0.0598 - accuracy: 0.986 - ETA: 49s - loss: 0.0590 - accuracy: 0.987 - ETA: 48s - loss: 0.0591 - accuracy: 0.987 - ETA: 46s - loss: 0.0583 - accuracy: 0.987 - ETA: 45s - loss: 0.0588 - accuracy: 0.987 - ETA: 44s - loss: 0.0584 - accuracy: 0.987 - ETA: 42s - loss: 0.0578 - accuracy: 0.987 - ETA: 41s - loss: 0.0577 - accuracy: 0.987 - ETA: 39s - loss: 0.0592 - accuracy: 0.986 - ETA: 38s - loss: 0.0585 - accuracy: 0.987 - ETA: 37s - loss: 0.0579 - accuracy: 0.987 - ETA: 35s - loss: 0.0580 - accuracy: 0.987 - ETA: 34s - loss: 0.0577 - accuracy: 0.987 - ETA: 32s - loss: 0.0583 - accuracy: 0.987 - ETA: 31s - loss: 0.0576 - accuracy: 0.987 - ETA: 30s - loss: 0.0592 - accuracy: 0.986 - ETA: 28s - loss: 0.0612 - accuracy: 0.986 - ETA: 27s - loss: 0.0609 - accuracy: 0.986 - ETA: 25s - loss: 0.0608 - accuracy: 0.986 - ETA: 24s - loss: 0.0604 - accuracy: 0.986 - ETA: 23s - loss: 0.0604 - accuracy: 0.986 - ETA: 21s - loss: 0.0599 - accuracy: 0.986 - ETA: 20s - loss: 0.0594 - accuracy: 0.986 - ETA: 19s - loss: 0.0592 - accuracy: 0.986 - ETA: 17s - loss: 0.0587 - accuracy: 0.986 - ETA: 16s - loss: 0.0597 - accuracy: 0.986 - ETA: 14s - loss: 0.0593 - accuracy: 0.986 - ETA: 13s - loss: 0.0592 - accuracy: 0.986 - ETA: 12s - loss: 0.0588 - accuracy: 0.986 - ETA: 10s - loss: 0.0582 - accuracy: 0.986 - ETA: 9s - loss: 0.0582 - accuracy: 0.986 - ETA: 7s - loss: 0.0579 - accuracy: 0.98 - ETA: 6s - loss: 0.0575 - accuracy: 0.98 - ETA: 5s - loss: 0.0571 - accuracy: 0.98 - ETA: 3s - loss: 0.0580 - accuracy: 0.98 - ETA: 2s - loss: 0.0576 - accuracy: 0.98 - ETA: 1s - loss: 0.0575 - accuracy: 0.98 - 156s 12ms/step - loss: 0.0572 - accuracy: 0.9869 - val_loss: 3.6658 - val_accuracy: 0.3759\n",
      "Epoch 98/100\n",
      "13022/13022 [==============================] - ETA: 2:16 - loss: 0.0735 - accuracy: 0.99 - ETA: 2:14 - loss: 0.0416 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0414 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0322 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0375 - accuracy: 0.99 - ETA: 2:12 - loss: 0.0481 - accuracy: 0.99 - ETA: 2:10 - loss: 0.0780 - accuracy: 0.99 - ETA: 2:09 - loss: 0.0728 - accuracy: 0.99 - ETA: 2:08 - loss: 0.0664 - accuracy: 0.99 - ETA: 2:07 - loss: 0.0606 - accuracy: 0.99 - ETA: 2:06 - loss: 0.0577 - accuracy: 0.99 - ETA: 2:04 - loss: 0.0580 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0538 - accuracy: 0.99 - ETA: 2:02 - loss: 0.0525 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0520 - accuracy: 0.99 - ETA: 2:03 - loss: 0.0508 - accuracy: 0.99 - ETA: 2:01 - loss: 0.0495 - accuracy: 0.99 - ETA: 2:00 - loss: 0.0579 - accuracy: 0.99 - ETA: 1:58 - loss: 0.0605 - accuracy: 0.99 - ETA: 1:56 - loss: 0.0636 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0611 - accuracy: 0.99 - ETA: 1:53 - loss: 0.0608 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0611 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0607 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0597 - accuracy: 0.98 - ETA: 1:47 - loss: 0.0582 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:44 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0563 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0545 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0562 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0548 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0539 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0530 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0515 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0551 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0554 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0544 - accuracy: 0.98 - ETA: 1:21 - loss: 0.0533 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0525 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0517 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0514 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0524 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0516 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0511 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0509 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0507 - accuracy: 0.98 - ETA: 1:04 - loss: 0.0527 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0523 - accuracy: 0.98 - ETA: 1:01 - loss: 0.0519 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0515 - accuracy: 0.98 - ETA: 58s - loss: 0.0507 - accuracy: 0.9889 - ETA: 57s - loss: 0.0502 - accuracy: 0.989 - ETA: 56s - loss: 0.0504 - accuracy: 0.989 - ETA: 54s - loss: 0.0503 - accuracy: 0.989 - ETA: 53s - loss: 0.0508 - accuracy: 0.988 - ETA: 51s - loss: 0.0510 - accuracy: 0.988 - ETA: 50s - loss: 0.0504 - accuracy: 0.988 - ETA: 48s - loss: 0.0497 - accuracy: 0.989 - ETA: 47s - loss: 0.0495 - accuracy: 0.988 - ETA: 45s - loss: 0.0494 - accuracy: 0.988 - ETA: 44s - loss: 0.0491 - accuracy: 0.989 - ETA: 43s - loss: 0.0493 - accuracy: 0.989 - ETA: 41s - loss: 0.0512 - accuracy: 0.988 - ETA: 40s - loss: 0.0511 - accuracy: 0.988 - ETA: 38s - loss: 0.0511 - accuracy: 0.988 - ETA: 37s - loss: 0.0509 - accuracy: 0.988 - ETA: 36s - loss: 0.0503 - accuracy: 0.989 - ETA: 34s - loss: 0.0498 - accuracy: 0.989 - ETA: 33s - loss: 0.0521 - accuracy: 0.989 - ETA: 31s - loss: 0.0517 - accuracy: 0.989 - ETA: 30s - loss: 0.0519 - accuracy: 0.988 - ETA: 29s - loss: 0.0521 - accuracy: 0.988 - ETA: 27s - loss: 0.0530 - accuracy: 0.988 - ETA: 26s - loss: 0.0536 - accuracy: 0.988 - ETA: 24s - loss: 0.0531 - accuracy: 0.988 - ETA: 23s - loss: 0.0528 - accuracy: 0.988 - ETA: 22s - loss: 0.0528 - accuracy: 0.988 - ETA: 20s - loss: 0.0525 - accuracy: 0.988 - ETA: 19s - loss: 0.0535 - accuracy: 0.988 - ETA: 17s - loss: 0.0537 - accuracy: 0.988 - ETA: 16s - loss: 0.0536 - accuracy: 0.988 - ETA: 15s - loss: 0.0539 - accuracy: 0.988 - ETA: 13s - loss: 0.0536 - accuracy: 0.988 - ETA: 12s - loss: 0.0532 - accuracy: 0.988 - ETA: 10s - loss: 0.0527 - accuracy: 0.988 - ETA: 9s - loss: 0.0523 - accuracy: 0.988 - ETA: 8s - loss: 0.0523 - accuracy: 0.98 - ETA: 6s - loss: 0.0521 - accuracy: 0.98 - ETA: 5s - loss: 0.0519 - accuracy: 0.98 - ETA: 3s - loss: 0.0516 - accuracy: 0.98 - ETA: 2s - loss: 0.0518 - accuracy: 0.98 - ETA: 1s - loss: 0.0516 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0514 - accuracy: 0.9884 - val_loss: 3.7725 - val_accuracy: 0.3870\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 2:15 - loss: 0.0383 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0946 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0895 - accuracy: 0.97 - ETA: 2:13 - loss: 0.0775 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0627 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0640 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0699 - accuracy: 0.98 - ETA: 2:09 - loss: 0.0631 - accuracy: 0.98 - ETA: 2:07 - loss: 0.0601 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0574 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0598 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0599 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0569 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0556 - accuracy: 0.98 - ETA: 1:58 - loss: 0.0541 - accuracy: 0.98 - ETA: 1:56 - loss: 0.0529 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0505 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0482 - accuracy: 0.98 - ETA: 1:52 - loss: 0.0496 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0528 - accuracy: 0.98 - ETA: 1:49 - loss: 0.0546 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0532 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0518 - accuracy: 0.98 - ETA: 1:45 - loss: 0.0512 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0495 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0478 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0469 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0462 - accuracy: 0.98 - ETA: 1:38 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:37 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:36 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:35 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:34 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0455 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0443 - accuracy: 0.98 - ETA: 1:31 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0431 - accuracy: 0.98 - ETA: 1:28 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0425 - accuracy: 0.98 - ETA: 1:24 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0428 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:17 - loss: 0.0457 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0460 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0459 - accuracy: 0.98 - ETA: 1:13 - loss: 0.0451 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:10 - loss: 0.0440 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0442 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:06 - loss: 0.0436 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0430 - accuracy: 0.98 - ETA: 1:03 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:02 - loss: 0.0445 - accuracy: 0.98 - ETA: 1:00 - loss: 0.0444 - accuracy: 0.98 - ETA: 59s - loss: 0.0438 - accuracy: 0.9889 - ETA: 58s - loss: 0.0435 - accuracy: 0.988 - ETA: 56s - loss: 0.0444 - accuracy: 0.989 - ETA: 55s - loss: 0.0442 - accuracy: 0.989 - ETA: 53s - loss: 0.0466 - accuracy: 0.988 - ETA: 52s - loss: 0.0461 - accuracy: 0.988 - ETA: 51s - loss: 0.0476 - accuracy: 0.988 - ETA: 49s - loss: 0.0501 - accuracy: 0.988 - ETA: 48s - loss: 0.0507 - accuracy: 0.988 - ETA: 46s - loss: 0.0504 - accuracy: 0.988 - ETA: 45s - loss: 0.0503 - accuracy: 0.988 - ETA: 44s - loss: 0.0503 - accuracy: 0.988 - ETA: 42s - loss: 0.0496 - accuracy: 0.988 - ETA: 41s - loss: 0.0501 - accuracy: 0.988 - ETA: 39s - loss: 0.0498 - accuracy: 0.988 - ETA: 38s - loss: 0.0499 - accuracy: 0.988 - ETA: 37s - loss: 0.0498 - accuracy: 0.988 - ETA: 35s - loss: 0.0493 - accuracy: 0.988 - ETA: 34s - loss: 0.0488 - accuracy: 0.988 - ETA: 33s - loss: 0.0485 - accuracy: 0.988 - ETA: 31s - loss: 0.0489 - accuracy: 0.988 - ETA: 30s - loss: 0.0492 - accuracy: 0.988 - ETA: 28s - loss: 0.0492 - accuracy: 0.988 - ETA: 27s - loss: 0.0522 - accuracy: 0.988 - ETA: 25s - loss: 0.0525 - accuracy: 0.988 - ETA: 24s - loss: 0.0523 - accuracy: 0.988 - ETA: 23s - loss: 0.0519 - accuracy: 0.988 - ETA: 21s - loss: 0.0524 - accuracy: 0.988 - ETA: 20s - loss: 0.0520 - accuracy: 0.988 - ETA: 19s - loss: 0.0516 - accuracy: 0.988 - ETA: 17s - loss: 0.0514 - accuracy: 0.988 - ETA: 16s - loss: 0.0514 - accuracy: 0.988 - ETA: 14s - loss: 0.0521 - accuracy: 0.988 - ETA: 13s - loss: 0.0523 - accuracy: 0.988 - ETA: 12s - loss: 0.0523 - accuracy: 0.988 - ETA: 10s - loss: 0.0525 - accuracy: 0.988 - ETA: 9s - loss: 0.0520 - accuracy: 0.988 - ETA: 7s - loss: 0.0517 - accuracy: 0.98 - ETA: 6s - loss: 0.0515 - accuracy: 0.98 - ETA: 5s - loss: 0.0514 - accuracy: 0.98 - ETA: 3s - loss: 0.0513 - accuracy: 0.98 - ETA: 2s - loss: 0.0510 - accuracy: 0.98 - ETA: 1s - loss: 0.0507 - accuracy: 0.98 - 157s 12ms/step - loss: 0.0507 - accuracy: 0.9884 - val_loss: 3.7946 - val_accuracy: 0.3578\n",
      "Epoch 100/100\n",
      "13022/13022 [==============================] - ETA: 2:22 - loss: 0.0491 - accuracy: 0.98 - ETA: 2:20 - loss: 0.0481 - accuracy: 0.98 - ETA: 2:17 - loss: 0.0428 - accuracy: 0.98 - ETA: 2:22 - loss: 0.0463 - accuracy: 0.98 - ETA: 2:19 - loss: 0.0495 - accuracy: 0.98 - ETA: 2:16 - loss: 0.0492 - accuracy: 0.98 - ETA: 2:14 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0510 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0502 - accuracy: 0.98 - ETA: 2:11 - loss: 0.0459 - accuracy: 0.98 - ETA: 2:10 - loss: 0.0424 - accuracy: 0.98 - ETA: 2:08 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0398 - accuracy: 0.98 - ETA: 2:04 - loss: 0.0384 - accuracy: 0.98 - ETA: 2:02 - loss: 0.0408 - accuracy: 0.98 - ETA: 2:00 - loss: 0.0404 - accuracy: 0.98 - ETA: 1:59 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:57 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:55 - loss: 0.0385 - accuracy: 0.98 - ETA: 1:54 - loss: 0.0368 - accuracy: 0.98 - ETA: 1:53 - loss: 0.0367 - accuracy: 0.98 - ETA: 1:51 - loss: 0.0357 - accuracy: 0.98 - ETA: 1:50 - loss: 0.0345 - accuracy: 0.98 - ETA: 1:48 - loss: 0.0333 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0345 - accuracy: 0.99 - ETA: 1:45 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:43 - loss: 0.0447 - accuracy: 0.98 - ETA: 1:42 - loss: 0.0449 - accuracy: 0.98 - ETA: 1:40 - loss: 0.0435 - accuracy: 0.98 - ETA: 1:39 - loss: 0.0422 - accuracy: 0.99 - ETA: 1:37 - loss: 0.0414 - accuracy: 0.99 - ETA: 1:36 - loss: 0.0413 - accuracy: 0.99 - ETA: 1:35 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:33 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:32 - loss: 0.0415 - accuracy: 0.98 - ETA: 1:30 - loss: 0.0412 - accuracy: 0.98 - ETA: 1:29 - loss: 0.0419 - accuracy: 0.98 - ETA: 1:27 - loss: 0.0422 - accuracy: 0.98 - ETA: 1:26 - loss: 0.0424 - accuracy: 0.98 - ETA: 1:25 - loss: 0.0421 - accuracy: 0.98 - ETA: 1:23 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:22 - loss: 0.0413 - accuracy: 0.98 - ETA: 1:20 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0429 - accuracy: 0.98 - ETA: 1:18 - loss: 0.0427 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0439 - accuracy: 0.98 - ETA: 1:15 - loss: 0.0434 - accuracy: 0.98 - ETA: 1:14 - loss: 0.0432 - accuracy: 0.98 - ETA: 1:12 - loss: 0.0423 - accuracy: 0.98 - ETA: 1:11 - loss: 0.0416 - accuracy: 0.98 - ETA: 1:09 - loss: 0.0417 - accuracy: 0.98 - ETA: 1:08 - loss: 0.0411 - accuracy: 0.98 - ETA: 1:07 - loss: 0.0403 - accuracy: 0.98 - ETA: 1:05 - loss: 0.0398 - accuracy: 0.99 - ETA: 1:04 - loss: 0.0397 - accuracy: 0.99 - ETA: 1:03 - loss: 0.0394 - accuracy: 0.99 - ETA: 1:01 - loss: 0.0389 - accuracy: 0.99 - ETA: 1:00 - loss: 0.0388 - accuracy: 0.99 - ETA: 59s - loss: 0.0388 - accuracy: 0.9903 - ETA: 57s - loss: 0.0383 - accuracy: 0.990 - ETA: 56s - loss: 0.0377 - accuracy: 0.990 - ETA: 54s - loss: 0.0383 - accuracy: 0.990 - ETA: 53s - loss: 0.0379 - accuracy: 0.990 - ETA: 51s - loss: 0.0381 - accuracy: 0.990 - ETA: 50s - loss: 0.0378 - accuracy: 0.990 - ETA: 49s - loss: 0.0377 - accuracy: 0.990 - ETA: 47s - loss: 0.0398 - accuracy: 0.990 - ETA: 46s - loss: 0.0403 - accuracy: 0.989 - ETA: 45s - loss: 0.0397 - accuracy: 0.989 - ETA: 43s - loss: 0.0400 - accuracy: 0.989 - ETA: 42s - loss: 0.0400 - accuracy: 0.989 - ETA: 40s - loss: 0.0395 - accuracy: 0.989 - ETA: 39s - loss: 0.0392 - accuracy: 0.989 - ETA: 38s - loss: 0.0388 - accuracy: 0.990 - ETA: 36s - loss: 0.0395 - accuracy: 0.989 - ETA: 35s - loss: 0.0391 - accuracy: 0.989 - ETA: 33s - loss: 0.0390 - accuracy: 0.989 - ETA: 32s - loss: 0.0389 - accuracy: 0.989 - ETA: 31s - loss: 0.0392 - accuracy: 0.989 - ETA: 29s - loss: 0.0388 - accuracy: 0.989 - ETA: 28s - loss: 0.0389 - accuracy: 0.989 - ETA: 27s - loss: 0.0384 - accuracy: 0.990 - ETA: 25s - loss: 0.0388 - accuracy: 0.990 - ETA: 24s - loss: 0.0386 - accuracy: 0.990 - ETA: 22s - loss: 0.0386 - accuracy: 0.990 - ETA: 21s - loss: 0.0382 - accuracy: 0.990 - ETA: 20s - loss: 0.0381 - accuracy: 0.990 - ETA: 18s - loss: 0.0377 - accuracy: 0.990 - ETA: 17s - loss: 0.0377 - accuracy: 0.990 - ETA: 16s - loss: 0.0375 - accuracy: 0.990 - ETA: 14s - loss: 0.0377 - accuracy: 0.990 - ETA: 13s - loss: 0.0374 - accuracy: 0.990 - ETA: 12s - loss: 0.0374 - accuracy: 0.990 - ETA: 10s - loss: 0.0376 - accuracy: 0.989 - ETA: 9s - loss: 0.0374 - accuracy: 0.990 - ETA: 7s - loss: 0.0372 - accuracy: 0.99 - ETA: 6s - loss: 0.0378 - accuracy: 0.98 - ETA: 5s - loss: 0.0375 - accuracy: 0.99 - ETA: 3s - loss: 0.0372 - accuracy: 0.99 - ETA: 2s - loss: 0.0369 - accuracy: 0.99 - ETA: 1s - loss: 0.0379 - accuracy: 0.98 - 155s 12ms/step - loss: 0.0393 - accuracy: 0.9899 - val_loss: 3.9474 - val_accuracy: 0.3699\n",
      "2020-03-17 22:31:30.249234\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "t5=datetime.datetime.now()\n",
    "print(t5)\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n",
    "t6=datetime.datetime.now()\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/ResNet101V2_history.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(history, '../Pickle/ResNet101V2_history.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "history = joblib.load('../Pickle/ResNet101V2_history.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [3.60519562864243, 3.0541984528589863, 2.601169247141679, 2.4988821312355074, 2.3356116134385965, 2.4186972375140257, 2.396009043700294, 2.479581240691038, 2.5550798570034314, 2.663008583151379, 2.651784669386754, 2.7935403822786817, 2.6590236655314228, 2.8262572974686098, 2.8137411583809393, 2.711368801579066, 2.7884819522228876, 3.054042640864514, 3.0265293214984075, 2.8107082785294337, 3.1259209776158925, 2.856011883392362, 3.200396652055005, 2.91364125176327, 3.1183776975524666, 2.8952190964037263, 3.0507330907944725, 3.1134035459816465, 3.0359945641504287, 3.258111719565118, 3.270598342326605, 3.296594813604021, 3.3829866608642014, 3.116018660835493, 3.418910217112, 3.2981452653165304, 3.4350933839804894, 3.2321686880586284, 3.1908509758287384, 3.2606142057394307, 3.5007112736031507, 3.4548304305197344, 3.194320634248188, 3.155965643361641, 3.3453547374958523, 3.2794353075664953, 3.4872732030938316, 3.45349770487687, 3.5421225961626055, 3.4218200365812104, 3.5313115421210237, 3.2850131779608596, 3.367193799664698, 3.549953263831104, 3.4327032813066296, 3.4501567281387717, 3.4124038752231307, 3.5308736443456112, 3.295892272030613, 3.439817732995598, 3.3948028668366343, 3.637944011510348, 3.5319474620916513, 3.5336207268858675, 3.6178491823277175, 3.4324086557841818, 3.4512796263812477, 3.4609178358553367, 3.4587914650757012, 3.4615953170705738, 3.5615193287571993, 3.567051346542442, 3.2689985436211373, 3.4589423491426974, 3.7116090873218117, 3.7390869808924094, 3.5445830161421394, 3.4869797914966, 3.499808319719205, 3.7065233882187982, 3.6000233598785125, 3.6812228843208654, 3.9821475163672035, 3.8617188007296765, 3.9133380941382594, 3.647596190533592, 3.600279354296096, 3.983342001390102, 3.4459206051860773, 3.7157174915881357, 3.8036664622656784, 3.6595067629442877, 3.6650873438878984, 3.598453606518936, 3.6871258578876724, 3.5722794643362192, 3.6658359523524493, 3.772454992317099, 3.7946287908334027, 3.9474433758055594], 'val_accuracy': [0.11163550615310669, 0.21310582756996155, 0.36431294679641724, 0.3450717031955719, 0.3944454491138458, 0.37447813153266907, 0.3815574645996094, 0.3839172124862671, 0.40261390805244446, 0.37175530195236206, 0.39081501960754395, 0.3806498348712921, 0.41604647040367126, 0.3813759386539459, 0.3993465304374695, 0.4100562632083893, 0.3897258937358856, 0.3712107539176941, 0.38609549403190613, 0.4320203363895416, 0.3759303092956543, 0.41205301880836487, 0.39154112339019775, 0.40896713733673096, 0.3877291679382324, 0.42711925506591797, 0.4027954339981079, 0.3548738360404968, 0.39154112339019775, 0.3862769901752472, 0.38282808661460876, 0.3775639832019806, 0.37447813153266907, 0.4194953739643097, 0.3679433763027191, 0.40424758195877075, 0.38210201263427734, 0.40969324111938477, 0.40860411524772644, 0.38482484221458435, 0.37266290187835693, 0.37502267956733704, 0.42675620317459106, 0.4115084409713745, 0.38010528683662415, 0.40860411524772644, 0.39081501960754395, 0.3859139680862427, 0.3652205467224121, 0.3922671973705292, 0.3672172725200653, 0.42675620317459106, 0.3993465304374695, 0.38645851612091064, 0.37974223494529724, 0.38083136081695557, 0.37538573145866394, 0.3752042055130005, 0.41459429264068604, 0.39989107847213745, 0.39480850100517273, 0.3597749173641205, 0.3889998197555542, 0.4033399820327759, 0.3588673174381256, 0.3802868127822876, 0.38446179032325745, 0.39517152309417725, 0.3739335536956787, 0.40424758195877075, 0.39045199751853943, 0.37974223494529724, 0.421129047870636, 0.42203667759895325, 0.3695770502090454, 0.3859139680862427, 0.3913595974445343, 0.39190414547920227, 0.4231258034706116, 0.38482484221458435, 0.4009802043437958, 0.3806498348712921, 0.3581412136554718, 0.37102922797203064, 0.3813759386539459, 0.3909965455532074, 0.3742966055870056, 0.3581412136554718, 0.4320203363895416, 0.3973498046398163, 0.37647485733032227, 0.37502267956733704, 0.37447813153266907, 0.3830096125602722, 0.41060084104537964, 0.4403702914714813, 0.3759303092956543, 0.387003093957901, 0.3577781915664673, 0.3699401021003723], 'loss': [3.570107350424859, 2.5213769385569695, 1.7929710723199963, 1.3615101670874665, 1.0846749205795088, 0.8698246303726646, 0.6878446192716494, 0.5664102358123048, 0.49961397343380554, 0.4142161545308939, 0.35940012452954284, 0.3054766778919558, 0.2851503686299981, 0.2472564537364791, 0.21978886601031788, 0.20020249352543387, 0.18417514698367352, 0.17592834701755597, 0.16685976960580848, 0.14275189914579417, 0.14571738940329068, 0.1387489205465176, 0.1363248056888745, 0.12050038605420349, 0.10867244877851498, 0.10734988896070656, 0.1082844947490654, 0.10451956723023259, 0.10343948368001984, 0.0924820802840352, 0.092202643010061, 0.09184172426481581, 0.08907294611862372, 0.08810245830779104, 0.09888253638538287, 0.07788451978425573, 0.07461909678807696, 0.08115852220266292, 0.07925119907730388, 0.08125956136360822, 0.06312197976179376, 0.07943141372993673, 0.0834543483434501, 0.0798960741471446, 0.08032913974967902, 0.07223466940417558, 0.06698022889795253, 0.08096336776591212, 0.07149773142056666, 0.0703656696390479, 0.06761854228231329, 0.05407973396404605, 0.06166523164977833, 0.054630835056121846, 0.06286939359129143, 0.057731694977709344, 0.06088943376214873, 0.056876216733159055, 0.06587009009582036, 0.06568564415994171, 0.07119416618169572, 0.06175463107052514, 0.051658514707438354, 0.06089175075825834, 0.06378365366820792, 0.07475140284116945, 0.06238057797011134, 0.05875113153822446, 0.062390865692549854, 0.05262197636472952, 0.053485278832603025, 0.060620632360761866, 0.06146270806300825, 0.04901147417860305, 0.05625187197430945, 0.04790518168692416, 0.048670259739896374, 0.056465130464682066, 0.04512807589486033, 0.04593034134784376, 0.05318745566671335, 0.050419667944245725, 0.05409407094365575, 0.04741439851828525, 0.041162323033300675, 0.04360524518122103, 0.05853889810358795, 0.04249084242302744, 0.062056101738463675, 0.04585012469566286, 0.046062163557760584, 0.050047917507509906, 0.04885101414709995, 0.05067637799051093, 0.047215501328544345, 0.049034698220775746, 0.057176751936991135, 0.05135908027940074, 0.05070507718355145, 0.03927348166099984], 'accuracy': [0.11027492, 0.3371986, 0.5059131, 0.6097374, 0.67754567, 0.7377515, 0.7859776, 0.8269851, 0.8471817, 0.87682384, 0.88980186, 0.9101521, 0.91468287, 0.92551064, 0.939871, 0.94171405, 0.94801104, 0.95177394, 0.95384735, 0.95937645, 0.95937645, 0.96283215, 0.9622946, 0.9665182, 0.9707418, 0.9697435, 0.9709722, 0.9707418, 0.9731992, 0.9750422, 0.9745815, 0.97550297, 0.97511905, 0.97742283, 0.97481185, 0.9787283, 0.98049456, 0.97964984, 0.97811395, 0.979957, 0.9831823, 0.9798034, 0.97949624, 0.9797266, 0.97964984, 0.98156965, 0.9834127, 0.9787283, 0.9813393, 0.9804177, 0.9830287, 0.9853325, 0.98379666, 0.9854093, 0.9855629, 0.98625404, 0.9845646, 0.9851021, 0.98348945, 0.9838734, 0.9831823, 0.9844878, 0.9879435, 0.9854861, 0.9842574, 0.98310554, 0.9845646, 0.98725235, 0.9854093, 0.9880203, 0.98778987, 0.9852557, 0.9842574, 0.9868684, 0.98640764, 0.98848104, 0.98725235, 0.9877131, 0.98848104, 0.98817384, 0.98694515, 0.9885578, 0.986638, 0.98848104, 0.9897865, 0.98940253, 0.9876363, 0.9900169, 0.98610044, 0.9882507, 0.989249, 0.98940253, 0.9876363, 0.98778987, 0.98917216, 0.9885578, 0.98694515, 0.9884042, 0.9884042, 0.98986334]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochResNet101V2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
