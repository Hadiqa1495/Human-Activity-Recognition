{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\HH TRADERS\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13017</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13018</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13019</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13020</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13021</th>\n",
       "      <td>winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image class\n",
       "13017  winKen_wave_u_cm_np1_ri_bad_1_frame0.jpg  wave\n",
       "13018  winKen_wave_u_cm_np1_ri_bad_1_frame1.jpg  wave\n",
       "13019  winKen_wave_u_cm_np1_ri_bad_1_frame2.jpg  wave\n",
       "13020  winKen_wave_u_cm_np1_ri_bad_1_frame3.jpg  wave\n",
       "13021  winKen_wave_u_cm_np1_ri_bad_1_frame4.jpg  wave"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "train.sort_values(by=['class', 'image'])\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13022/13022 [01:23<00:00, 156.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/train_frame/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13022, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X_train = np.array(train_image,np.float16)\n",
    "\n",
    "# shape of the array\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...</td>\n",
       "      <td>wave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image class\n",
       "5504  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5505  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5506  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5507  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave\n",
       "5508  prelinger_LetsBeGo1953_wave_u_cm_np10_ba_med_3...  wave"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = pd.read_csv('../data/val.csv')\n",
    "val.sort_values(by=['class', 'image'])\n",
    "val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5509/5509 [00:41<00:00, 133.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an empty list\n",
    "val_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(val.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('../data/val_frame/'+val['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    val_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5509, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list to numpy array\n",
    "X_test = np.array(val_image,np.float16)\n",
    "\n",
    "# shape of the array\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13022,)\n",
      "(5509,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image    5509\n",
       "class      51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating the target\n",
    "y_train = train['class']\n",
    "y_test = val['class']\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "train.nunique()\n",
    "val.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13022, 51)\n",
      "(5509, 51)\n"
     ]
    }
   ],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained VGG16 model\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, None, 1536)\n"
     ]
    }
   ],
   "source": [
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_resnet_v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 9 18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 6 12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 9 288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 6 192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 9 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 6 0           batch_normalization_12[0][0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, None, None, 3 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 3 96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 3 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 4 13824       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 3 96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 4 144         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 3 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 4 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 3 9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 6 27648       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 3 96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 3 96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 6 192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 3 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 3 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 6 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, None, None, 1 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, None, None, 3 41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, None, None, 3 0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, None, None, 3 0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 3 96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 3 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 4 13824       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 3 96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 4 144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 3 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 4 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 3 9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 6 27648       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 3 96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 3 96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 6 192         conv2d_24[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 3 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 3 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 6 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, None, None, 1 0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, None, None, 3 41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, None, None, 3 0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, None, None, 3 0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 3 96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 3 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 4 13824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 3 96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 4 144         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 3 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 4 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 6 27648       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 3 96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 6 192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 3 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 6 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, None, None, 1 0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, None, None, 3 41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, None, None, 3 0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, None, None, 3 0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 3 96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 3 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 4 13824       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 3 96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 4 144         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 3 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 4 0           batch_normalization_35[0][0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 3 9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 6 27648       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 3 96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 3 96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 6 192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 3 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 3 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 6 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, None, None, 1 0           activation_31[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, None, None, 3 41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, None, None, 3 0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, None, None, 3 0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 3 96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 3 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 4 13824       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 3 96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 4 144         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 3 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 4 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 3 9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 6 27648       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 3 96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 3 96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 6 192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 3 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 3 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 6 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, None, None, 1 0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, None, None, 3 41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, None, None, 3 0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, None, None, 3 0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 3 96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 3 0           batch_normalization_46[0][0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 4 13824       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 3 96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 4 144         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 3 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 4 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 3 9216        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 6 27648       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 3 96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 3 96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 6 192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 3 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 3 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 6 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, None, None, 1 0           activation_43[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, None, None, 3 41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, None, None, 3 0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, None, None, 3 0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 3 96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 3 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 4 13824       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 3 96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 4 144         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 3 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 4 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 3 9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 6 27648       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 3 96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 3 96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 6 192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 3 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 3 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 6 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, None, None, 1 0           activation_49[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block35_7_conv (Conv2D)         (None, None, None, 3 41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, None, None, 3 0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, None, None, 3 0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 3 96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 3 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 4 13824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 3 96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 4 144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 3 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 4 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 3 9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 6 27648       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 3 96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 3 96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 6 192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 3 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 3 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 6 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, None, None, 1 0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, None, None, 3 41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, None, None, 3 0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, None, None, 3 0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 3 96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 3 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 4 13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 3 96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 4 144         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 3 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 4 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 3 9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 6 27648       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 3 96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 3 96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_66 (BatchNo (None, None, None, 6 192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 3 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 3 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 6 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, None, None, 1 0           activation_61[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, None, None, 3 41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, None, None, 3 0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, None, None, 3 0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 3 96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 3 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 4 13824       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 3 96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 4 144         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 3 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 4 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 3 9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 6 27648       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 3 96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 3 96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 6 192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 3 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 3 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 6 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, None, None, 1 0           activation_67[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, None, None, 3 41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, None, None, 3 0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, None, None, 3 0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 2 81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 2 768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 2 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 2 589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 2 768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 2 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 3 1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 3 884736      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_73 (BatchNo (None, None, None, 3 1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 3 1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 3 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 3 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 3 0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, None, None, 1 0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 1 139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 1 384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 1 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 1 143360      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 1 480         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 1 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 1 208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 1 215040      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 1 576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 1 576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 1 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 1 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, None, None, 3 0           activation_77[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, None, None, 1 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, None, None, 1 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, None, None, 1 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 1 139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 1 384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 1 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 1 143360      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 1 480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 1 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 1 208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 1 215040      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 1 576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 1 576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 1 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 1 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, None, None, 3 0           activation_81[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, None, None, 1 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, None, None, 1 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, None, None, 1 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_86 (Conv2D)              (None, None, None, 1 139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 1 384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 1 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 1 143360      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 1 480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 1 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 1 215040      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 1 576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 1 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, None, None, 3 0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, None, None, 1 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, None, None, 1 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, None, None, 1 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 1 139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 1 384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 1 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 1 143360      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 1 480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 1 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 1 208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 1 215040      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 1 576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 1 576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 1 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 1 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, None, None, 3 0           activation_89[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, None, None, 1 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, None, None, 1 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, None, None, 1 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 1 143360      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 1 480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 1 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 1 208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_96 (Conv2D)              (None, None, None, 1 215040      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 1 576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 1 576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 1 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 1 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, None, None, 3 0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, None, None, 1 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, None, None, 1 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, None, None, 1 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 1 139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 1 384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 1 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, None, None, 1 143360      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, None, 1 480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 1 208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, None, None, 1 215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 1 576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, None, 1 576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 1 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 1 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, None, None, 3 0           activation_97[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, None, None, 1 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, None, None, 1 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, None, None, 1 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, None, None, 1 139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, None, 1 384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 1 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, None, None, 1 143360      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, None, 1 480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 1 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, None, None, 1 208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, None, None, 1 215040      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, None, 1 576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, None, 1 576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 1 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 1 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, None, None, 3 0           activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, None, None, 1 418880      block17_7_mixed[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, None, None, 1 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, None, None, 1 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, None, None, 1 139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, None, 1 384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 1 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, None, None, 1 143360      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, None, 1 480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 1 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, None, None, 1 208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, None, None, 1 215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, None, 1 576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, None, 1 576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 1 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 1 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, None, None, 3 0           activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, None, None, 1 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, None, None, 1 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, None, None, 1 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, None, None, 1 139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, None, 1 384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 1 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, None, None, 1 143360      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, None, 1 480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 1 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, None, None, 1 208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, None, None, 1 215040      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, None, 1 576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, None, 1 576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 1 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 1 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, None, None, 3 0           activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, None, None, 1 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, None, None, 1 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, None, None, 1 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, None, None, 1 139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, None, 1 384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 1 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, None, None, 1 143360      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_115 (BatchN (None, None, None, 1 480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 1 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, None, None, 1 208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, None, None, 1 215040      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, None, 1 576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, None, 1 576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 1 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 1 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, None, None, 3 0           activation_113[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, None, None, 1 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, None, None, 1 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, None, None, 1 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, None, None, 1 139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, None, 1 384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 1 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, None, None, 1 143360      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, None, 1 480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 1 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, None, None, 1 208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, None, None, 1 215040      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, None, 1 576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, None, 1 576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 1 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 1 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, None, None, 3 0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, None, None, 1 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, None, None, 1 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, None, None, 1 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, None, None, 1 139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, None, 1 384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 1 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, None, None, 1 143360      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, None, None, 1 480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 1 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, None, None, 1 208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, None, None, 1 215040      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, None, 1 576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, None, None, 1 576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 1 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_124 (Activation)     (None, None, None, 1 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, None, None, 3 0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, None, None, 1 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, None, None, 1 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, None, None, 1 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, None, None, 1 139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, None, None, 1 384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, None, None, 1 143360      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, None, None, 1 480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, None, None, 1 208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, None, None, 1 215040      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, None, None, 1 576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, None, None, 1 576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, None, None, 3 0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, None, None, 1 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, None, None, 1 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, None, None, 1 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, None, None, 1 139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, None, None, 1 384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, None, None, 1 143360      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, None, None, 1 480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, None, None, 1 208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, None, None, 1 215040      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, None, None, 1 576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, None, None, 1 576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, None, None, 3 0           activation_129[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, None, None, 1 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, None, None, 1 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, None, None, 1 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 1 139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_134 (BatchN (None, None, None, 1 384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 1 143360      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, None, None, 1 480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 1 208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 1 215040      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, None, None, 1 576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, None, None, 1 576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, None, None, 3 0           activation_133[0][0]             \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, None, None, 1 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, None, None, 1 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, None, None, 1 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 1 139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, None, None, 1 384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 1 143360      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, None, None, 1 480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 1 208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 1 215040      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, None, None, 1 576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, None, None, 1 576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, None, None, 3 0           activation_137[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, None, None, 1 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, None, None, 1 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, None, None, 1 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 1 139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, None, None, 1 384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, None, 1 143360      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, None, None, 1 480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 1 208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_141 (BatchN (None, None, None, 1 576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, None, None, 3 0           activation_141[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, None, None, 1 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, None, None, 1 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, None, None, 1 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 1 139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, None, None, 1 384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 1 143360      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, None, None, 1 480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, None, None, 1 208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 1 215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, None, None, 1 576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, None, None, 1 576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, None, None, 3 0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, None, None, 1 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, None, None, 1 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, None, None, 1 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 1 139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, None, None, 1 384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 1 143360      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, None, None, 1 480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 1 208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 1 215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, None, None, 1 576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, None, None, 1 576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, None, None, 3 0           activation_149[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, None, None, 1 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, None, None, 1 0           block17_18_ac[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, None, None, 1 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 1 139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, None, None, 1 384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 1 143360      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, None, None, 1 480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 1 208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, None, None, 1 215040      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, None, None, 1 576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, None, None, 1 576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 1 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, None, None, 3 0           activation_153[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, None, None, 1 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, None, None, 1 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, None, None, 1 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, None, None, 2 768         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 2 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, None, None, 2 663552      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, None, None, 2 768         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, None, None, 2 768         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, None, None, 2 864         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 2 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 2 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 2 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, None, None, 3 884736      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, None, None, 2 663552      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, None, None, 3 829440      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, None, None, 3 1152        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, None, None, 2 864         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, None, None, 3 960         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 3 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 2 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 3 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 1 0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed_7a (Concatenate)          (None, None, None, 2 0           activation_158[0][0]             \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, None, None, 1 576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 1 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, None, None, 2 129024      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, None, None, 2 672         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 2 0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, None, None, 2 172032      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, None, None, 2 768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 2 0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, None, None, 4 0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, None, None, 2 933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, None, None, 2 0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, None, None, 2 0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, None, None, 1 576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 1 0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, None, None, 2 129024      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, None, None, 2 672         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 2 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, None, None, 2 172032      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, None, None, 2 768         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 2 0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, None, None, 4 0           activation_168[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, None, None, 2 933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, None, None, 2 0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, None, None, 2 0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, None, None, 1 576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 1 0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, None, None, 2 129024      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, None, None, 2 672         conv2d_174[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 2 0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, None, None, 2 172032      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, None, None, 1 576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, None, None, 2 768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 1 0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 2 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, None, None, 4 0           activation_172[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, None, None, 2 933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, None, None, 2 0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, None, None, 2 0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, None, 1 576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 1 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, None, None, 2 129024      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, None, 2 672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 2 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, None, None, 2 172032      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, None, None, 1 576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, None, 2 768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 1 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 2 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, None, None, 4 0           activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, None, None, 2 933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, None, None, 2 0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, None, None, 2 0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, None, 1 576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 1 0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, None, None, 2 129024      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, None, 2 672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 2 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, None, None, 2 172032      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, None, 1 576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, None, 2 768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 1 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 2 0           batch_normalization_183[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, None, None, 4 0           activation_180[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, None, None, 2 933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, None, None, 2 0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, None, None, 2 0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, None, 1 576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 1 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, None, None, 2 129024      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, None, 2 672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 2 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, None, None, 2 172032      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, None, 1 576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, None, 2 768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 1 0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 2 0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, None, None, 4 0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, None, None, 2 933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, None, None, 2 0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, None, None, 2 0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, None, None, 1 576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, None, None, 1 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, None, None, 2 129024      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, None, None, 2 672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, None, None, 2 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, None, None, 2 172032      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, None, 1 576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, None, None, 2 768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 1 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, None, None, 2 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, None, None, 4 0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, None, None, 2 933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, None, None, 2 0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, None, None, 2 0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, None, None, 1 576         conv2d_193[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, None, None, 1 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, None, None, 2 129024      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, None, None, 2 672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, None, None, 2 0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, None, None, 2 172032      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, None, None, 1 576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, None, None, 2 768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, None, None, 1 0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, None, None, 2 0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, None, None, 4 0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, None, None, 2 933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, None, None, 2 0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, None, None, 2 0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, None, None, 1 576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 1 0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, None, None, 2 129024      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, None, None, 2 672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 2 0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, None, None, 2 172032      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, None, None, 1 576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, None, None, 2 768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, None, None, 1 0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 2 0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, None, None, 4 0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, None, None, 2 933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, None, None, 2 0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, None, None, 2 0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, None, None, 1 576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 1 0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, None, None, 2 129024      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, None, None, 2 672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 2 0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, None, None, 2 172032      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, None, None, 1 576         conv2d_200[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, None, None, 2 768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 1 0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, None, None, 2 0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, None, None, 4 0           activation_200[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, None, None, 2 933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, None, None, 2 0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, None, None, 1 3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, None, None, 1 4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, None, None, 1 0           conv_7b_bn[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 54,336,736\n",
      "Trainable params: 54,276,192\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'inception_resnet_v2',\n",
       " 'layers': [{'name': 'input_1',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None, None, 3),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'input_1'},\n",
       "   'inbound_nodes': []},\n",
       "  {'name': 'conv2d_1',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_1',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_1', 0, 0, {}]]]},\n",
       "  {'name': 'activation_1',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_2',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_1', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_2',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_2', 0, 0, {}]]]},\n",
       "  {'name': 'activation_2',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_3',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_2', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_3',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_3', 0, 0, {}]]]},\n",
       "  {'name': 'activation_3',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_3', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_1',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['activation_3', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_4',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 80,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['max_pooling2d_1', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_4',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_4', 0, 0, {}]]]},\n",
       "  {'name': 'activation_4',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_4', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_5',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_4', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_5',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_5', 0, 0, {}]]]},\n",
       "  {'name': 'activation_5',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_5', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_2',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['activation_5', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_9',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_9',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_9',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_9',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_9', 0, 0, {}]]]},\n",
       "  {'name': 'activation_9',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_9',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_9', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_7',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_10',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 96,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_9', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_7',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_7', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_10',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_10', 0, 0, {}]]]},\n",
       "  {'name': 'activation_7',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_7', 0, 0, {}]]]},\n",
       "  {'name': 'activation_10',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_10', 0, 0, {}]]]},\n",
       "  {'name': 'average_pooling2d_1',\n",
       "   'class_name': 'AveragePooling2D',\n",
       "   'config': {'name': 'average_pooling2d_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'same',\n",
       "    'strides': (1, 1),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_6',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 96,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['max_pooling2d_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_8',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_8',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (5, 5),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_7', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_11',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_11',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 96,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_10', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_12',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_12',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['average_pooling2d_1', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_6',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_6', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_8',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_8',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_8', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_11',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_11',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_11', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_12',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_12',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_12', 0, 0, {}]]]},\n",
       "  {'name': 'activation_6',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_6', 0, 0, {}]]]},\n",
       "  {'name': 'activation_8',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_8',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_8', 0, 0, {}]]]},\n",
       "  {'name': 'activation_11',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_11',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_11', 0, 0, {}]]]},\n",
       "  {'name': 'activation_12',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_12',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_12', 0, 0, {}]]]},\n",
       "  {'name': 'mixed_5b',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'mixed_5b',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_6', 0, 0, {}],\n",
       "     ['activation_8', 0, 0, {}],\n",
       "     ['activation_11', 0, 0, {}],\n",
       "     ['activation_12', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_16',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_16',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['mixed_5b', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_16',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_16',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_16', 0, 0, {}]]]},\n",
       "  {'name': 'activation_16',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_16',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_16', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_14',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_14',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['mixed_5b', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_17',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_17',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_16', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_14',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_14',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_14', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_17',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_17',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_17', 0, 0, {}]]]},\n",
       "  {'name': 'activation_14',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_14',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_14', 0, 0, {}]]]},\n",
       "  {'name': 'activation_17',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_17',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_17', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_13',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_13',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['mixed_5b', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_15',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_15',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_14', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_18',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_18',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_17', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_13',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_13',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_13', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_15',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_15',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_15', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_18',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_18',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_18', 0, 0, {}]]]},\n",
       "  {'name': 'activation_13',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_13',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_13', 0, 0, {}]]]},\n",
       "  {'name': 'activation_15',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_15',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_15', 0, 0, {}]]]},\n",
       "  {'name': 'activation_18',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_18',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_18', 0, 0, {}]]]},\n",
       "  {'name': 'block35_1_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_1_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_13', 0, 0, {}],\n",
       "     ['activation_15', 0, 0, {}],\n",
       "     ['activation_18', 0, 0, {}]]]},\n",
       "  {'name': 'block35_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_1_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_1',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['mixed_5b', 0, 0, {}], ['block35_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_1_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_1_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_22',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_22',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_1_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_22',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_22',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_22', 0, 0, {}]]]},\n",
       "  {'name': 'activation_22',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_22',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_22', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_20',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_20',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_1_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_23',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_23',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_22', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_20',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_20',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_20', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_23',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_23',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_23', 0, 0, {}]]]},\n",
       "  {'name': 'activation_20',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_20',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_20', 0, 0, {}]]]},\n",
       "  {'name': 'activation_23',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_23',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_23', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_19',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_19',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_1_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_21',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_21',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_20', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_24',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_24',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_23', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_19',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_19',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_19', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_21',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_21',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_21', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_24',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_24',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_24', 0, 0, {}]]]},\n",
       "  {'name': 'activation_19',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_19',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_19', 0, 0, {}]]]},\n",
       "  {'name': 'activation_21',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_21',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_21', 0, 0, {}]]]},\n",
       "  {'name': 'activation_24',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_24',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_24', 0, 0, {}]]]},\n",
       "  {'name': 'block35_2_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_2_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_19', 0, 0, {}],\n",
       "     ['activation_21', 0, 0, {}],\n",
       "     ['activation_24', 0, 0, {}]]]},\n",
       "  {'name': 'block35_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_2_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_2',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_1_ac', 0, 0, {}],\n",
       "     ['block35_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_2_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_2_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_28',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_28',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_2_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_28',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_28',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_28', 0, 0, {}]]]},\n",
       "  {'name': 'activation_28',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_28',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_28', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_26',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_26',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_2_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_29',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_29',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_28', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_26',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_26',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_26', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_29',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_29',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_29', 0, 0, {}]]]},\n",
       "  {'name': 'activation_26',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_26',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_26', 0, 0, {}]]]},\n",
       "  {'name': 'activation_29',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_29',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_29', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_25',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_25',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_2_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_27',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_27',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_26', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_30',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_30',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_29', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_25',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_25',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_25', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_27',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_27',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_27', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_30',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_30',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_30', 0, 0, {}]]]},\n",
       "  {'name': 'activation_25',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_25',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_25', 0, 0, {}]]]},\n",
       "  {'name': 'activation_27',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_27',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_27', 0, 0, {}]]]},\n",
       "  {'name': 'activation_30',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_30',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_30', 0, 0, {}]]]},\n",
       "  {'name': 'block35_3_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_3_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_25', 0, 0, {}],\n",
       "     ['activation_27', 0, 0, {}],\n",
       "     ['activation_30', 0, 0, {}]]]},\n",
       "  {'name': 'block35_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_3_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_3',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_2_ac', 0, 0, {}],\n",
       "     ['block35_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_3_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_3_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_3', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_34',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_34',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_3_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_34',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_34',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_34', 0, 0, {}]]]},\n",
       "  {'name': 'activation_34',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_34',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_34', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_32',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_32',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_3_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_35',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_35',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_34', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_32',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_32',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_32', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_35',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_35',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_35', 0, 0, {}]]]},\n",
       "  {'name': 'activation_32',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_32',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_32', 0, 0, {}]]]},\n",
       "  {'name': 'activation_35',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_35',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_35', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_31',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_31',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_3_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_33',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_33',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_32', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_36',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_36',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_35', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_31',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_31',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_31', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_33',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_33',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_33', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_36',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_36',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_36', 0, 0, {}]]]},\n",
       "  {'name': 'activation_31',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_31',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_31', 0, 0, {}]]]},\n",
       "  {'name': 'activation_33',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_33',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_33', 0, 0, {}]]]},\n",
       "  {'name': 'activation_36',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_36',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_36', 0, 0, {}]]]},\n",
       "  {'name': 'block35_4_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_4_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_31', 0, 0, {}],\n",
       "     ['activation_33', 0, 0, {}],\n",
       "     ['activation_36', 0, 0, {}]]]},\n",
       "  {'name': 'block35_4_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_4_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_4_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_4',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_3_ac', 0, 0, {}],\n",
       "     ['block35_4_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_4_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_4_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_4', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_40',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_40',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_4_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_40',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_40',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_40', 0, 0, {}]]]},\n",
       "  {'name': 'activation_40',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_40',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_40', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_38',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_38',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_4_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_41',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_41',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_40', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_38',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_38',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_38', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_41',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_41',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_41', 0, 0, {}]]]},\n",
       "  {'name': 'activation_38',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_38',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_38', 0, 0, {}]]]},\n",
       "  {'name': 'activation_41',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_41',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_41', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_37',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_37',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_4_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_39',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_39',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_38', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_42',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_42',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_41', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_37',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_37',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_37', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_39',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_39',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_39', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_42',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_42',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_42', 0, 0, {}]]]},\n",
       "  {'name': 'activation_37',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_37',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_37', 0, 0, {}]]]},\n",
       "  {'name': 'activation_39',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_39',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_39', 0, 0, {}]]]},\n",
       "  {'name': 'activation_42',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_42',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_42', 0, 0, {}]]]},\n",
       "  {'name': 'block35_5_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_5_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_37', 0, 0, {}],\n",
       "     ['activation_39', 0, 0, {}],\n",
       "     ['activation_42', 0, 0, {}]]]},\n",
       "  {'name': 'block35_5_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_5_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_5_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_5',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_4_ac', 0, 0, {}],\n",
       "     ['block35_5_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_5_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_5_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_5', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_46',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_46',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_5_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_46',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_46',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_46', 0, 0, {}]]]},\n",
       "  {'name': 'activation_46',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_46',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_46', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_44',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_44',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_5_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_47',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_47',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_46', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_44',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_44',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_44', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_47',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_47',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_47', 0, 0, {}]]]},\n",
       "  {'name': 'activation_44',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_44',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_44', 0, 0, {}]]]},\n",
       "  {'name': 'activation_47',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_47',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_47', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_43',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_43',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_5_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_45',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_45',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_44', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_48',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_48',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_47', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_43',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_43',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_43', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_45',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_45',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_45', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_48',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_48',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_48', 0, 0, {}]]]},\n",
       "  {'name': 'activation_43',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_43',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_43', 0, 0, {}]]]},\n",
       "  {'name': 'activation_45',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_45',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_45', 0, 0, {}]]]},\n",
       "  {'name': 'activation_48',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_48',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_48', 0, 0, {}]]]},\n",
       "  {'name': 'block35_6_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_6_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_43', 0, 0, {}],\n",
       "     ['activation_45', 0, 0, {}],\n",
       "     ['activation_48', 0, 0, {}]]]},\n",
       "  {'name': 'block35_6_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_6_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_6_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_6',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_5_ac', 0, 0, {}],\n",
       "     ['block35_6_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_6_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_6_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_6', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_52',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_52',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_6_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_52',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_52',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_52', 0, 0, {}]]]},\n",
       "  {'name': 'activation_52',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_52',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_52', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_50',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_50',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_6_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_53',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_53',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_52', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_50',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_50',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_50', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_53',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_53',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_53', 0, 0, {}]]]},\n",
       "  {'name': 'activation_50',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_50',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_50', 0, 0, {}]]]},\n",
       "  {'name': 'activation_53',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_53',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_53', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_49',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_49',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_6_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_51',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_51',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_50', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_54',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_54',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_53', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_49',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_49',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_49', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_51',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_51',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_51', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_54',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_54',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_54', 0, 0, {}]]]},\n",
       "  {'name': 'activation_49',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_49',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_49', 0, 0, {}]]]},\n",
       "  {'name': 'activation_51',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_51',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_51', 0, 0, {}]]]},\n",
       "  {'name': 'activation_54',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_54',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_54', 0, 0, {}]]]},\n",
       "  {'name': 'block35_7_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_7_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_49', 0, 0, {}],\n",
       "     ['activation_51', 0, 0, {}],\n",
       "     ['activation_54', 0, 0, {}]]]},\n",
       "  {'name': 'block35_7_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_7_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_7_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_7',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_6_ac', 0, 0, {}],\n",
       "     ['block35_7_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_7_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_7_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_7', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_58',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_58',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_7_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_58',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_58',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_58', 0, 0, {}]]]},\n",
       "  {'name': 'activation_58',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_58',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_58', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_56',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_56',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_7_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_59',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_59',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_58', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_56',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_56',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_56', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_59',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_59',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_59', 0, 0, {}]]]},\n",
       "  {'name': 'activation_56',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_56',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_56', 0, 0, {}]]]},\n",
       "  {'name': 'activation_59',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_59',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_59', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_55',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_55',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_7_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_57',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_57',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_56', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_60',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_60',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_59', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_55',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_55',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_55', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_57',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_57',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_57', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_60',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_60',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_60', 0, 0, {}]]]},\n",
       "  {'name': 'activation_55',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_55',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_55', 0, 0, {}]]]},\n",
       "  {'name': 'activation_57',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_57',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_57', 0, 0, {}]]]},\n",
       "  {'name': 'activation_60',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_60',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_60', 0, 0, {}]]]},\n",
       "  {'name': 'block35_8_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_8_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_55', 0, 0, {}],\n",
       "     ['activation_57', 0, 0, {}],\n",
       "     ['activation_60', 0, 0, {}]]]},\n",
       "  {'name': 'block35_8_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_8_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_8_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_8',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_8',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_7_ac', 0, 0, {}],\n",
       "     ['block35_8_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_8_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_8_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_8', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_64',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_64',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_8_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_64',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_64',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_64', 0, 0, {}]]]},\n",
       "  {'name': 'activation_64',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_64',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_64', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_62',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_62',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_8_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_65',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_65',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_64', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_62',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_62',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_62', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_65',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_65',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_65', 0, 0, {}]]]},\n",
       "  {'name': 'activation_62',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_62',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_62', 0, 0, {}]]]},\n",
       "  {'name': 'activation_65',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_65',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_65', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_61',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_61',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_8_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_63',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_63',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_62', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_66',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_66',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_65', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_61',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_61',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_61', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_63',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_63',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_63', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_66',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_66',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_66', 0, 0, {}]]]},\n",
       "  {'name': 'activation_61',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_61',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_61', 0, 0, {}]]]},\n",
       "  {'name': 'activation_63',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_63',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_63', 0, 0, {}]]]},\n",
       "  {'name': 'activation_66',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_66',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_66', 0, 0, {}]]]},\n",
       "  {'name': 'block35_9_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_9_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_61', 0, 0, {}],\n",
       "     ['activation_63', 0, 0, {}],\n",
       "     ['activation_66', 0, 0, {}]]]},\n",
       "  {'name': 'block35_9_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_9_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_9_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_9',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_9',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_8_ac', 0, 0, {}],\n",
       "     ['block35_9_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_9_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_9_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_9', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_70',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_70',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_9_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_70',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_70',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_70', 0, 0, {}]]]},\n",
       "  {'name': 'activation_70',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_70',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_70', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_68',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_68',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_9_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_71',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_71',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 48,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_70', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_68',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_68',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_68', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_71',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_71',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_71', 0, 0, {}]]]},\n",
       "  {'name': 'activation_68',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_68',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_68', 0, 0, {}]]]},\n",
       "  {'name': 'activation_71',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_71',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_71', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_67',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_67',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_9_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_69',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_69',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 32,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_68', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_72',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_72',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 64,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_71', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_67',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_67',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_67', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_69',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_69',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_69', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_72',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_72',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_72', 0, 0, {}]]]},\n",
       "  {'name': 'activation_67',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_67',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_67', 0, 0, {}]]]},\n",
       "  {'name': 'activation_69',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_69',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_69', 0, 0, {}]]]},\n",
       "  {'name': 'activation_72',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_72',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_72', 0, 0, {}]]]},\n",
       "  {'name': 'block35_10_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block35_10_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_67', 0, 0, {}],\n",
       "     ['activation_69', 0, 0, {}],\n",
       "     ['activation_72', 0, 0, {}]]]},\n",
       "  {'name': 'block35_10_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block35_10_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_10_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block35_10',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block35_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 320),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.17}},\n",
       "   'inbound_nodes': [[['block35_9_ac', 0, 0, {}],\n",
       "     ['block35_10_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block35_10_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block35_10_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block35_10', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_74',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_74',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_10_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_74',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_74',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_74', 0, 0, {}]]]},\n",
       "  {'name': 'activation_74',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_74',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_74', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_75',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_75',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_74', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_75',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_75',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_75', 0, 0, {}]]]},\n",
       "  {'name': 'activation_75',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_75',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_75', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_73',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_73',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 384,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block35_10_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_76',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_76',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 384,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_75', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_73',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_73',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_73', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_76',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_76',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_76', 0, 0, {}]]]},\n",
       "  {'name': 'activation_73',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_73',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_73', 0, 0, {}]]]},\n",
       "  {'name': 'activation_76',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_76',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_76', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_3',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['block35_10_ac', 0, 0, {}]]]},\n",
       "  {'name': 'mixed_6a',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'mixed_6a',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_73', 0, 0, {}],\n",
       "     ['activation_76', 0, 0, {}],\n",
       "     ['max_pooling2d_3', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_78',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_78',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['mixed_6a', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_78',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_78',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_78', 0, 0, {}]]]},\n",
       "  {'name': 'activation_78',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_78',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_78', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_79',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_79',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_78', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_79',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_79',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_79', 0, 0, {}]]]},\n",
       "  {'name': 'activation_79',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_79',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_79', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_77',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_77',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['mixed_6a', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_80',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_80',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_79', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_77',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_77',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_77', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_80',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_80',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_80', 0, 0, {}]]]},\n",
       "  {'name': 'activation_77',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_77',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_77', 0, 0, {}]]]},\n",
       "  {'name': 'activation_80',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_80',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_80', 0, 0, {}]]]},\n",
       "  {'name': 'block17_1_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_1_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_77', 0, 0, {}],\n",
       "     ['activation_80', 0, 0, {}]]]},\n",
       "  {'name': 'block17_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_1_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_1',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['mixed_6a', 0, 0, {}], ['block17_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_1_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_1_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_82',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_82',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_1_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_82',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_82',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_82', 0, 0, {}]]]},\n",
       "  {'name': 'activation_82',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_82',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_82', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_83',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_83',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_82', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_83',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_83',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_83', 0, 0, {}]]]},\n",
       "  {'name': 'activation_83',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_83',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_83', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_81',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_81',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_1_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_84',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_84',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_83', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_81',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_81',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_81', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_84',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_84',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_84', 0, 0, {}]]]},\n",
       "  {'name': 'activation_81',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_81',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_81', 0, 0, {}]]]},\n",
       "  {'name': 'activation_84',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_84',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_84', 0, 0, {}]]]},\n",
       "  {'name': 'block17_2_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_2_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_81', 0, 0, {}],\n",
       "     ['activation_84', 0, 0, {}]]]},\n",
       "  {'name': 'block17_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_2_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_2',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_1_ac', 0, 0, {}],\n",
       "     ['block17_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_2_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_2_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_86',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_86',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_2_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_86',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_86',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_86', 0, 0, {}]]]},\n",
       "  {'name': 'activation_86',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_86',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_86', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_87',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_87',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_86', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_87',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_87',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_87', 0, 0, {}]]]},\n",
       "  {'name': 'activation_87',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_87',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_87', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_85',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_85',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_2_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_88',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_88',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_87', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_85',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_85',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_85', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_88',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_88',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_88', 0, 0, {}]]]},\n",
       "  {'name': 'activation_85',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_85',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_85', 0, 0, {}]]]},\n",
       "  {'name': 'activation_88',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_88',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_88', 0, 0, {}]]]},\n",
       "  {'name': 'block17_3_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_3_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_85', 0, 0, {}],\n",
       "     ['activation_88', 0, 0, {}]]]},\n",
       "  {'name': 'block17_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_3_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_3',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_2_ac', 0, 0, {}],\n",
       "     ['block17_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_3_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_3_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_3', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_90',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_90',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_3_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_90',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_90',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_90', 0, 0, {}]]]},\n",
       "  {'name': 'activation_90',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_90',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_90', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_91',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_91',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_90', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_91',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_91',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_91', 0, 0, {}]]]},\n",
       "  {'name': 'activation_91',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_91',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_91', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_89',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_89',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_3_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_92',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_92',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_91', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_89',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_89',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_89', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_92',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_92',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_92', 0, 0, {}]]]},\n",
       "  {'name': 'activation_89',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_89',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_89', 0, 0, {}]]]},\n",
       "  {'name': 'activation_92',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_92',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_92', 0, 0, {}]]]},\n",
       "  {'name': 'block17_4_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_4_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_89', 0, 0, {}],\n",
       "     ['activation_92', 0, 0, {}]]]},\n",
       "  {'name': 'block17_4_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_4_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_4_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_4',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_3_ac', 0, 0, {}],\n",
       "     ['block17_4_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_4_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_4_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_4', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_94',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_94',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_4_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_94',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_94',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_94', 0, 0, {}]]]},\n",
       "  {'name': 'activation_94',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_94',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_94', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_95',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_95',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_94', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_95',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_95',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_95', 0, 0, {}]]]},\n",
       "  {'name': 'activation_95',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_95',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_95', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_93',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_93',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_4_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_96',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_96',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_95', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_93',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_93',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_93', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_96',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_96',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_96', 0, 0, {}]]]},\n",
       "  {'name': 'activation_93',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_93',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_93', 0, 0, {}]]]},\n",
       "  {'name': 'activation_96',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_96',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_96', 0, 0, {}]]]},\n",
       "  {'name': 'block17_5_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_5_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_93', 0, 0, {}],\n",
       "     ['activation_96', 0, 0, {}]]]},\n",
       "  {'name': 'block17_5_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_5_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_5_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_5',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_4_ac', 0, 0, {}],\n",
       "     ['block17_5_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_5_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_5_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_5', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_98',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_98',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_5_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_98',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_98',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_98', 0, 0, {}]]]},\n",
       "  {'name': 'activation_98',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_98',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_98', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_99',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_99',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_98', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_99',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_99',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_99', 0, 0, {}]]]},\n",
       "  {'name': 'activation_99',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_99',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_99', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_97',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_97',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_5_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_100',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_100',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_99', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_97',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_97',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_97', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_100',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_100',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_100', 0, 0, {}]]]},\n",
       "  {'name': 'activation_97',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_97',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_97', 0, 0, {}]]]},\n",
       "  {'name': 'activation_100',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_100',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_100', 0, 0, {}]]]},\n",
       "  {'name': 'block17_6_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_6_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_97', 0, 0, {}],\n",
       "     ['activation_100', 0, 0, {}]]]},\n",
       "  {'name': 'block17_6_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_6_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_6_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_6',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_5_ac', 0, 0, {}],\n",
       "     ['block17_6_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_6_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_6_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_6', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_102',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_102',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_6_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_102',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_102',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_102', 0, 0, {}]]]},\n",
       "  {'name': 'activation_102',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_102',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_102', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_103',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_103',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_102', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_103',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_103',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_103', 0, 0, {}]]]},\n",
       "  {'name': 'activation_103',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_103',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_103', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_101',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_101',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_6_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_104',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_104',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_103', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_101',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_101',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_101', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_104',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_104',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_104', 0, 0, {}]]]},\n",
       "  {'name': 'activation_101',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_101',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_101', 0, 0, {}]]]},\n",
       "  {'name': 'activation_104',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_104',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_104', 0, 0, {}]]]},\n",
       "  {'name': 'block17_7_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_7_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_101', 0, 0, {}],\n",
       "     ['activation_104', 0, 0, {}]]]},\n",
       "  {'name': 'block17_7_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_7_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_7_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_7',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_6_ac', 0, 0, {}],\n",
       "     ['block17_7_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_7_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_7_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_7', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_106',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_106',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_7_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_106',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_106',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_106', 0, 0, {}]]]},\n",
       "  {'name': 'activation_106',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_106',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_106', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_107',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_107',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_106', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_107',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_107',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_107', 0, 0, {}]]]},\n",
       "  {'name': 'activation_107',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_107',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_107', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_105',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_105',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_7_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_108',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_108',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_107', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_105',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_105',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_105', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_108',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_108',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_108', 0, 0, {}]]]},\n",
       "  {'name': 'activation_105',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_105',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_105', 0, 0, {}]]]},\n",
       "  {'name': 'activation_108',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_108',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_108', 0, 0, {}]]]},\n",
       "  {'name': 'block17_8_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_8_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_105', 0, 0, {}],\n",
       "     ['activation_108', 0, 0, {}]]]},\n",
       "  {'name': 'block17_8_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_8_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_8_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_8',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_8',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_7_ac', 0, 0, {}],\n",
       "     ['block17_8_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_8_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_8_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_8', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_110',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_110',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_8_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_110',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_110',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_110', 0, 0, {}]]]},\n",
       "  {'name': 'activation_110',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_110',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_110', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_111',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_111',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_110', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_111',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_111',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_111', 0, 0, {}]]]},\n",
       "  {'name': 'activation_111',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_111',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_111', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_109',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_109',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_8_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_112',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_112',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_111', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_109',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_109',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_109', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_112',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_112',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_112', 0, 0, {}]]]},\n",
       "  {'name': 'activation_109',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_109',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_109', 0, 0, {}]]]},\n",
       "  {'name': 'activation_112',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_112',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_112', 0, 0, {}]]]},\n",
       "  {'name': 'block17_9_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_9_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_109', 0, 0, {}],\n",
       "     ['activation_112', 0, 0, {}]]]},\n",
       "  {'name': 'block17_9_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_9_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_9_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_9',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_9',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_8_ac', 0, 0, {}],\n",
       "     ['block17_9_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_9_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_9_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_9', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_114',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_114',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_9_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_114',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_114',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_114', 0, 0, {}]]]},\n",
       "  {'name': 'activation_114',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_114',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_114', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_115',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_115',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_114', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_115',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_115',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_115', 0, 0, {}]]]},\n",
       "  {'name': 'activation_115',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_115',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_115', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_113',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_113',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_9_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_116',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_116',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_115', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_113',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_113',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_113', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_116',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_116',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_116', 0, 0, {}]]]},\n",
       "  {'name': 'activation_113',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_113',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_113', 0, 0, {}]]]},\n",
       "  {'name': 'activation_116',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_116',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_116', 0, 0, {}]]]},\n",
       "  {'name': 'block17_10_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_10_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_113', 0, 0, {}],\n",
       "     ['activation_116', 0, 0, {}]]]},\n",
       "  {'name': 'block17_10_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_10_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_10_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_10',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_9_ac', 0, 0, {}],\n",
       "     ['block17_10_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_10_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_10_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_10', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_118',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_118',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_10_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_118',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_118',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_118', 0, 0, {}]]]},\n",
       "  {'name': 'activation_118',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_118',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_118', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_119',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_119',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_118', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_119',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_119',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_119', 0, 0, {}]]]},\n",
       "  {'name': 'activation_119',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_119',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_119', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_117',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_117',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_10_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_120',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_120',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_119', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_117',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_117',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_117', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_120',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_120',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_120', 0, 0, {}]]]},\n",
       "  {'name': 'activation_117',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_117',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_117', 0, 0, {}]]]},\n",
       "  {'name': 'activation_120',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_120',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_120', 0, 0, {}]]]},\n",
       "  {'name': 'block17_11_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_11_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_117', 0, 0, {}],\n",
       "     ['activation_120', 0, 0, {}]]]},\n",
       "  {'name': 'block17_11_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_11_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_11_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_11',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_11',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_10_ac', 0, 0, {}],\n",
       "     ['block17_11_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_11_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_11_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_11', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_122',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_122',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_11_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_122',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_122',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_122', 0, 0, {}]]]},\n",
       "  {'name': 'activation_122',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_122',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_122', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_123',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_123',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_122', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_123',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_123',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_123', 0, 0, {}]]]},\n",
       "  {'name': 'activation_123',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_123',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_123', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_121',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_121',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_11_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_124',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_124',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_123', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_121',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_121',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_121', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_124',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_124',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_124', 0, 0, {}]]]},\n",
       "  {'name': 'activation_121',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_121',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_121', 0, 0, {}]]]},\n",
       "  {'name': 'activation_124',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_124',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_124', 0, 0, {}]]]},\n",
       "  {'name': 'block17_12_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_12_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_121', 0, 0, {}],\n",
       "     ['activation_124', 0, 0, {}]]]},\n",
       "  {'name': 'block17_12_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_12_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_12_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_12',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_12',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_11_ac', 0, 0, {}],\n",
       "     ['block17_12_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_12_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_12_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_12', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_126',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_126',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_12_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_126',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_126',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_126', 0, 0, {}]]]},\n",
       "  {'name': 'activation_126',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_126',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_126', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_127',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_127',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_126', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_127',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_127',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_127', 0, 0, {}]]]},\n",
       "  {'name': 'activation_127',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_127',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_127', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_125',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_125',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_12_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_128',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_128',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_127', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_125',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_125',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_125', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_128',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_128',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_128', 0, 0, {}]]]},\n",
       "  {'name': 'activation_125',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_125',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_125', 0, 0, {}]]]},\n",
       "  {'name': 'activation_128',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_128',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_128', 0, 0, {}]]]},\n",
       "  {'name': 'block17_13_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_13_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_125', 0, 0, {}],\n",
       "     ['activation_128', 0, 0, {}]]]},\n",
       "  {'name': 'block17_13_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_13_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_13_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_13',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_13',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_12_ac', 0, 0, {}],\n",
       "     ['block17_13_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_13_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_13_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_13', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_130',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_130',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_13_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_130',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_130',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_130', 0, 0, {}]]]},\n",
       "  {'name': 'activation_130',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_130',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_130', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_131',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_131',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_130', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_131',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_131',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_131', 0, 0, {}]]]},\n",
       "  {'name': 'activation_131',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_131',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_131', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_129',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_129',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_13_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_132',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_132',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_131', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_129',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_129',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_129', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_132',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_132',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_132', 0, 0, {}]]]},\n",
       "  {'name': 'activation_129',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_129',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_129', 0, 0, {}]]]},\n",
       "  {'name': 'activation_132',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_132',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_132', 0, 0, {}]]]},\n",
       "  {'name': 'block17_14_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_14_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_129', 0, 0, {}],\n",
       "     ['activation_132', 0, 0, {}]]]},\n",
       "  {'name': 'block17_14_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_14_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_14_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_14',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_14',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_13_ac', 0, 0, {}],\n",
       "     ['block17_14_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_14_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_14_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_14', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_134',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_134',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_14_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_134',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_134',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_134', 0, 0, {}]]]},\n",
       "  {'name': 'activation_134',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_134',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_134', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_135',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_135',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_134', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_135',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_135',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_135', 0, 0, {}]]]},\n",
       "  {'name': 'activation_135',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_135',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_135', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_133',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_133',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_14_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_136',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_136',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_135', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_133',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_133',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_133', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_136',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_136',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_136', 0, 0, {}]]]},\n",
       "  {'name': 'activation_133',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_133',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_133', 0, 0, {}]]]},\n",
       "  {'name': 'activation_136',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_136',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_136', 0, 0, {}]]]},\n",
       "  {'name': 'block17_15_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_15_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_133', 0, 0, {}],\n",
       "     ['activation_136', 0, 0, {}]]]},\n",
       "  {'name': 'block17_15_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_15_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_15_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_15',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_15',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_14_ac', 0, 0, {}],\n",
       "     ['block17_15_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_15_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_15_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_15', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_138',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_138',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_15_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_138',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_138',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_138', 0, 0, {}]]]},\n",
       "  {'name': 'activation_138',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_138',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_138', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_139',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_139',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_138', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_139',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_139',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_139', 0, 0, {}]]]},\n",
       "  {'name': 'activation_139',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_139',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_139', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_137',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_137',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_15_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_140',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_140',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_139', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_137',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_137',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_137', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_140',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_140',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_140', 0, 0, {}]]]},\n",
       "  {'name': 'activation_137',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_137',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_137', 0, 0, {}]]]},\n",
       "  {'name': 'activation_140',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_140',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_140', 0, 0, {}]]]},\n",
       "  {'name': 'block17_16_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_16_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_137', 0, 0, {}],\n",
       "     ['activation_140', 0, 0, {}]]]},\n",
       "  {'name': 'block17_16_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_16_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_16_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_16',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_16',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_15_ac', 0, 0, {}],\n",
       "     ['block17_16_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_16_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_16_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_16', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_142',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_142',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_16_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_142',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_142',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_142', 0, 0, {}]]]},\n",
       "  {'name': 'activation_142',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_142',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_142', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_143',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_143',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_142', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_143',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_143',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_143', 0, 0, {}]]]},\n",
       "  {'name': 'activation_143',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_143',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_143', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_141',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_141',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_16_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_144',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_144',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_143', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_141',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_141',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_141', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_144',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_144',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_144', 0, 0, {}]]]},\n",
       "  {'name': 'activation_141',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_141',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_141', 0, 0, {}]]]},\n",
       "  {'name': 'activation_144',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_144',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_144', 0, 0, {}]]]},\n",
       "  {'name': 'block17_17_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_17_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_141', 0, 0, {}],\n",
       "     ['activation_144', 0, 0, {}]]]},\n",
       "  {'name': 'block17_17_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_17_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_17_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_17',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_17',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_16_ac', 0, 0, {}],\n",
       "     ['block17_17_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_17_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_17_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_17', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_146',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_146',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_17_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_146',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_146',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_146', 0, 0, {}]]]},\n",
       "  {'name': 'activation_146',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_146',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_146', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_147',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_147',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_146', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_147',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_147',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_147', 0, 0, {}]]]},\n",
       "  {'name': 'activation_147',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_147',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_147', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_145',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_145',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_17_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_148',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_148',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_147', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_145',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_145',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_145', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_148',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_148',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_148', 0, 0, {}]]]},\n",
       "  {'name': 'activation_145',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_145',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_145', 0, 0, {}]]]},\n",
       "  {'name': 'activation_148',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_148',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_148', 0, 0, {}]]]},\n",
       "  {'name': 'block17_18_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_18_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_145', 0, 0, {}],\n",
       "     ['activation_148', 0, 0, {}]]]},\n",
       "  {'name': 'block17_18_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_18_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_18_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_18',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_18',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_17_ac', 0, 0, {}],\n",
       "     ['block17_18_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_18_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_18_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_18', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_150',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_150',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_18_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_150',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_150',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_150', 0, 0, {}]]]},\n",
       "  {'name': 'activation_150',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_150',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_150', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_151',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_151',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_150', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_151',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_151',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_151', 0, 0, {}]]]},\n",
       "  {'name': 'activation_151',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_151',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_151', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_149',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_149',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_18_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_152',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_152',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_151', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_149',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_149',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_149', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_152',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_152',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_152', 0, 0, {}]]]},\n",
       "  {'name': 'activation_149',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_149',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_149', 0, 0, {}]]]},\n",
       "  {'name': 'activation_152',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_152',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_152', 0, 0, {}]]]},\n",
       "  {'name': 'block17_19_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_19_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_149', 0, 0, {}],\n",
       "     ['activation_152', 0, 0, {}]]]},\n",
       "  {'name': 'block17_19_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_19_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_19_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_19',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_19',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_18_ac', 0, 0, {}],\n",
       "     ['block17_19_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_19_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_19_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_19', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_154',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_154',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 128,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_19_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_154',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_154',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_154', 0, 0, {}]]]},\n",
       "  {'name': 'activation_154',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_154',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_154', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_155',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_155',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 160,\n",
       "    'kernel_size': (1, 7),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_154', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_155',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_155',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_155', 0, 0, {}]]]},\n",
       "  {'name': 'activation_155',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_155',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_155', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_153',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_153',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_19_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_156',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_156',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (7, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_155', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_153',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_153',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_153', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_156',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_156',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_156', 0, 0, {}]]]},\n",
       "  {'name': 'activation_153',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_153',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_153', 0, 0, {}]]]},\n",
       "  {'name': 'activation_156',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_156',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_156', 0, 0, {}]]]},\n",
       "  {'name': 'block17_20_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block17_20_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_153', 0, 0, {}],\n",
       "     ['activation_156', 0, 0, {}]]]},\n",
       "  {'name': 'block17_20_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block17_20_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1088,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_20_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block17_20',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block17_20',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 1088),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.1}},\n",
       "   'inbound_nodes': [[['block17_19_ac', 0, 0, {}],\n",
       "     ['block17_20_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block17_20_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block17_20_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block17_20', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_161',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_161',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_20_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_161',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_161',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_161', 0, 0, {}]]]},\n",
       "  {'name': 'activation_161',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_161',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_161', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_157',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_157',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_20_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_159',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_159',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block17_20_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_162',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_162',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 288,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_161', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_157',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_157',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_157', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_159',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_159',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_159', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_162',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_162',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_162', 0, 0, {}]]]},\n",
       "  {'name': 'activation_157',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_157',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_157', 0, 0, {}]]]},\n",
       "  {'name': 'activation_159',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_159',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_159', 0, 0, {}]]]},\n",
       "  {'name': 'activation_162',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_162',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_162', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_158',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_158',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 384,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_157', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_160',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_160',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 288,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_159', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_163',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_163',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 320,\n",
       "    'kernel_size': (3, 3),\n",
       "    'strides': (2, 2),\n",
       "    'padding': 'valid',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_162', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_158',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_158',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_158', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_160',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_160',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_160', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_163',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_163',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_163', 0, 0, {}]]]},\n",
       "  {'name': 'activation_158',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_158',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_158', 0, 0, {}]]]},\n",
       "  {'name': 'activation_160',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_160',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_160', 0, 0, {}]]]},\n",
       "  {'name': 'activation_163',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_163',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_163', 0, 0, {}]]]},\n",
       "  {'name': 'max_pooling2d_4',\n",
       "   'class_name': 'MaxPooling2D',\n",
       "   'config': {'name': 'max_pooling2d_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'pool_size': (3, 3),\n",
       "    'padding': 'valid',\n",
       "    'strides': (2, 2),\n",
       "    'data_format': 'channels_last'},\n",
       "   'inbound_nodes': [[['block17_20_ac', 0, 0, {}]]]},\n",
       "  {'name': 'mixed_7a',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'mixed_7a',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_158', 0, 0, {}],\n",
       "     ['activation_160', 0, 0, {}],\n",
       "     ['activation_163', 0, 0, {}],\n",
       "     ['max_pooling2d_4', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_165',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_165',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['mixed_7a', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_165',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_165',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_165', 0, 0, {}]]]},\n",
       "  {'name': 'activation_165',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_165',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_165', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_166',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_166',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_165', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_166',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_166',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_166', 0, 0, {}]]]},\n",
       "  {'name': 'activation_166',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_166',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_166', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_164',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_164',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['mixed_7a', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_167',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_167',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_166', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_164',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_164',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_164', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_167',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_167',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_167', 0, 0, {}]]]},\n",
       "  {'name': 'activation_164',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_164',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_164', 0, 0, {}]]]},\n",
       "  {'name': 'activation_167',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_167',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_167', 0, 0, {}]]]},\n",
       "  {'name': 'block8_1_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_1_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_164', 0, 0, {}],\n",
       "     ['activation_167', 0, 0, {}]]]},\n",
       "  {'name': 'block8_1_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_1_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_1_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_1',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['mixed_7a', 0, 0, {}], ['block8_1_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_1_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_1_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_1', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_169',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_169',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_1_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_169',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_169',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_169', 0, 0, {}]]]},\n",
       "  {'name': 'activation_169',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_169',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_169', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_170',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_170',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_169', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_170',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_170',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_170', 0, 0, {}]]]},\n",
       "  {'name': 'activation_170',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_170',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_170', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_168',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_168',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_1_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_171',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_171',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_170', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_168',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_168',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_168', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_171',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_171',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_171', 0, 0, {}]]]},\n",
       "  {'name': 'activation_168',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_168',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_168', 0, 0, {}]]]},\n",
       "  {'name': 'activation_171',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_171',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_171', 0, 0, {}]]]},\n",
       "  {'name': 'block8_2_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_2_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_168', 0, 0, {}],\n",
       "     ['activation_171', 0, 0, {}]]]},\n",
       "  {'name': 'block8_2_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_2_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_2_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_2',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_1_ac', 0, 0, {}],\n",
       "     ['block8_2_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_2_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_2_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_2', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_173',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_173',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_2_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_173',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_173',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_173', 0, 0, {}]]]},\n",
       "  {'name': 'activation_173',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_173',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_173', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_174',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_174',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_173', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_174',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_174',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_174', 0, 0, {}]]]},\n",
       "  {'name': 'activation_174',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_174',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_174', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_172',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_172',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_2_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_175',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_175',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_174', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_172',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_172',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_172', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_175',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_175',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_175', 0, 0, {}]]]},\n",
       "  {'name': 'activation_172',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_172',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_172', 0, 0, {}]]]},\n",
       "  {'name': 'activation_175',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_175',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_175', 0, 0, {}]]]},\n",
       "  {'name': 'block8_3_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_3_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_172', 0, 0, {}],\n",
       "     ['activation_175', 0, 0, {}]]]},\n",
       "  {'name': 'block8_3_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_3_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_3_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_3',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_2_ac', 0, 0, {}],\n",
       "     ['block8_3_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_3_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_3_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_3', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_177',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_177',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_3_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_177',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_177',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_177', 0, 0, {}]]]},\n",
       "  {'name': 'activation_177',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_177',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_177', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_178',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_178',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_177', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_178',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_178',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_178', 0, 0, {}]]]},\n",
       "  {'name': 'activation_178',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_178',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_178', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_176',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_176',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_3_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_179',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_179',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_178', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_176',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_176',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_176', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_179',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_179',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_179', 0, 0, {}]]]},\n",
       "  {'name': 'activation_176',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_176',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_176', 0, 0, {}]]]},\n",
       "  {'name': 'activation_179',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_179',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_179', 0, 0, {}]]]},\n",
       "  {'name': 'block8_4_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_4_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_176', 0, 0, {}],\n",
       "     ['activation_179', 0, 0, {}]]]},\n",
       "  {'name': 'block8_4_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_4_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_4_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_4',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_3_ac', 0, 0, {}],\n",
       "     ['block8_4_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_4_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_4_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_4', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_181',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_181',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_4_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_181',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_181',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_181', 0, 0, {}]]]},\n",
       "  {'name': 'activation_181',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_181',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_181', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_182',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_182',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_181', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_182',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_182',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_182', 0, 0, {}]]]},\n",
       "  {'name': 'activation_182',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_182',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_182', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_180',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_180',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_4_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_183',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_183',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_182', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_180',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_180',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_180', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_183',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_183',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_183', 0, 0, {}]]]},\n",
       "  {'name': 'activation_180',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_180',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_180', 0, 0, {}]]]},\n",
       "  {'name': 'activation_183',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_183',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_183', 0, 0, {}]]]},\n",
       "  {'name': 'block8_5_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_5_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_180', 0, 0, {}],\n",
       "     ['activation_183', 0, 0, {}]]]},\n",
       "  {'name': 'block8_5_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_5_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_5_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_5',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_4_ac', 0, 0, {}],\n",
       "     ['block8_5_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_5_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_5_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_5', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_185',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_185',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_5_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_185',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_185',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_185', 0, 0, {}]]]},\n",
       "  {'name': 'activation_185',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_185',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_185', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_186',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_186',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_185', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_186',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_186',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_186', 0, 0, {}]]]},\n",
       "  {'name': 'activation_186',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_186',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_186', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_184',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_184',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_5_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_187',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_187',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_186', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_184',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_184',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_184', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_187',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_187',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_187', 0, 0, {}]]]},\n",
       "  {'name': 'activation_184',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_184',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_184', 0, 0, {}]]]},\n",
       "  {'name': 'activation_187',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_187',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_187', 0, 0, {}]]]},\n",
       "  {'name': 'block8_6_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_6_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_184', 0, 0, {}],\n",
       "     ['activation_187', 0, 0, {}]]]},\n",
       "  {'name': 'block8_6_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_6_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_6_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_6',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_6',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_5_ac', 0, 0, {}],\n",
       "     ['block8_6_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_6_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_6_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_6', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_189',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_189',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_6_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_189',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_189',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_189', 0, 0, {}]]]},\n",
       "  {'name': 'activation_189',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_189',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_189', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_190',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_190',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_189', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_190',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_190',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_190', 0, 0, {}]]]},\n",
       "  {'name': 'activation_190',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_190',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_190', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_188',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_188',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_6_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_191',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_191',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_190', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_188',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_188',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_188', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_191',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_191',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_191', 0, 0, {}]]]},\n",
       "  {'name': 'activation_188',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_188',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_188', 0, 0, {}]]]},\n",
       "  {'name': 'activation_191',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_191',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_191', 0, 0, {}]]]},\n",
       "  {'name': 'block8_7_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_7_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_188', 0, 0, {}],\n",
       "     ['activation_191', 0, 0, {}]]]},\n",
       "  {'name': 'block8_7_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_7_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_7_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_7',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_7',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_6_ac', 0, 0, {}],\n",
       "     ['block8_7_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_7_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_7_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_7', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_193',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_193',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_7_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_193',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_193',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_193', 0, 0, {}]]]},\n",
       "  {'name': 'activation_193',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_193',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_193', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_194',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_194',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_193', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_194',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_194',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_194', 0, 0, {}]]]},\n",
       "  {'name': 'activation_194',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_194',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_194', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_192',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_192',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_7_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_195',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_195',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_194', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_192',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_192',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_192', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_195',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_195',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_195', 0, 0, {}]]]},\n",
       "  {'name': 'activation_192',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_192',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_192', 0, 0, {}]]]},\n",
       "  {'name': 'activation_195',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_195',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_195', 0, 0, {}]]]},\n",
       "  {'name': 'block8_8_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_8_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_192', 0, 0, {}],\n",
       "     ['activation_195', 0, 0, {}]]]},\n",
       "  {'name': 'block8_8_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_8_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_8_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_8',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_8',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_7_ac', 0, 0, {}],\n",
       "     ['block8_8_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_8_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_8_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_8', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_197',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_197',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_8_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_197',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_197',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_197', 0, 0, {}]]]},\n",
       "  {'name': 'activation_197',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_197',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_197', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_198',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_198',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_197', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_198',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_198',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_198', 0, 0, {}]]]},\n",
       "  {'name': 'activation_198',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_198',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_198', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_196',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_196',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_8_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_199',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_199',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_198', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_196',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_196',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_196', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_199',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_199',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_199', 0, 0, {}]]]},\n",
       "  {'name': 'activation_196',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_196',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_196', 0, 0, {}]]]},\n",
       "  {'name': 'activation_199',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_199',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_199', 0, 0, {}]]]},\n",
       "  {'name': 'block8_9_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_9_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_196', 0, 0, {}],\n",
       "     ['activation_199', 0, 0, {}]]]},\n",
       "  {'name': 'block8_9_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_9_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_9_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_9',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_9',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 0.2}},\n",
       "   'inbound_nodes': [[['block8_8_ac', 0, 0, {}],\n",
       "     ['block8_9_conv', 0, 0, {}]]]},\n",
       "  {'name': 'block8_9_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'block8_9_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['block8_9', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_201',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_201',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_9_ac', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_201',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_201',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_201', 0, 0, {}]]]},\n",
       "  {'name': 'activation_201',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_201',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_201', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_202',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_202',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 224,\n",
       "    'kernel_size': (1, 3),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_201', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_202',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_202',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_202', 0, 0, {}]]]},\n",
       "  {'name': 'activation_202',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_202',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_202', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_200',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_200',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 192,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_9_ac', 0, 0, {}]]]},\n",
       "  {'name': 'conv2d_203',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv2d_203',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 256,\n",
       "    'kernel_size': (3, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['activation_202', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_200',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_200',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_200', 0, 0, {}]]]},\n",
       "  {'name': 'batch_normalization_203',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'batch_normalization_203',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv2d_203', 0, 0, {}]]]},\n",
       "  {'name': 'activation_200',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_200',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_200', 0, 0, {}]]]},\n",
       "  {'name': 'activation_203',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'activation_203',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['batch_normalization_203', 0, 0, {}]]]},\n",
       "  {'name': 'block8_10_mixed',\n",
       "   'class_name': 'Concatenate',\n",
       "   'config': {'name': 'block8_10_mixed',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3},\n",
       "   'inbound_nodes': [[['activation_200', 0, 0, {}],\n",
       "     ['activation_203', 0, 0, {}]]]},\n",
       "  {'name': 'block8_10_conv',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'block8_10_conv',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 2080,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_10_mixed', 0, 0, {}]]]},\n",
       "  {'name': 'block8_10',\n",
       "   'class_name': 'Lambda',\n",
       "   'config': {'name': 'block8_10',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'function': ('4wIAAAAAAAAAAgAAAAMAAABTAAAAcxQAAAB8AGQBGQB8AGQCGQB8ARQAFwBTACkDTukAAAAA6QEA\\nAACpACkC2gZpbnB1dHPaBXNjYWxlcgMAAAByAwAAAPpZQzpcVXNlcnNcSEggVFJBREVSU1xBbmFj\\nb25kYTNcbGliXHNpdGUtcGFja2FnZXNca2VyYXNfYXBwbGljYXRpb25zXGluY2VwdGlvbl9yZXNu\\nZXRfdjIucHnaCDxsYW1iZGE+qAAAAPMAAAAA\\n',\n",
       "     None,\n",
       "     None),\n",
       "    'function_type': 'lambda',\n",
       "    'output_shape': (None, None, 2080),\n",
       "    'output_shape_type': 'raw',\n",
       "    'arguments': {'scale': 1.0}},\n",
       "   'inbound_nodes': [[['block8_9_ac', 0, 0, {}],\n",
       "     ['block8_10_conv', 0, 0, {}]]]},\n",
       "  {'name': 'conv_7b',\n",
       "   'class_name': 'Conv2D',\n",
       "   'config': {'name': 'conv_7b',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'filters': 1536,\n",
       "    'kernel_size': (1, 1),\n",
       "    'strides': (1, 1),\n",
       "    'padding': 'same',\n",
       "    'data_format': 'channels_last',\n",
       "    'dilation_rate': (1, 1),\n",
       "    'activation': 'linear',\n",
       "    'use_bias': False,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'inbound_nodes': [[['block8_10', 0, 0, {}]]]},\n",
       "  {'name': 'conv_7b_bn',\n",
       "   'class_name': 'BatchNormalization',\n",
       "   'config': {'name': 'conv_7b_bn',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': 3,\n",
       "    'momentum': 0.99,\n",
       "    'epsilon': 0.001,\n",
       "    'center': True,\n",
       "    'scale': False,\n",
       "    'beta_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'gamma_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'moving_variance_initializer': {'class_name': 'Ones', 'config': {}},\n",
       "    'beta_regularizer': None,\n",
       "    'gamma_regularizer': None,\n",
       "    'beta_constraint': None,\n",
       "    'gamma_constraint': None},\n",
       "   'inbound_nodes': [[['conv_7b', 0, 0, {}]]]},\n",
       "  {'name': 'conv_7b_ac',\n",
       "   'class_name': 'Activation',\n",
       "   'config': {'name': 'conv_7b_ac',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'activation': 'relu'},\n",
       "   'inbound_nodes': [[['conv_7b_bn', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['conv_7b_ac', 0, 0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13022, 5, 5, 1536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5509, 5, 5, 1536)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(13022, 5*5*1536)\n",
    "X_test = X_test.reshape(5509, 5*5*1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the pixel values\n",
    "max = X_train.max()\n",
    "X_train = X_train/max\n",
    "X_test = X_test/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/InceptionResNetV2_X_test.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(X_train, '../Pickle/InceptionResNetV2_X_train.pkl') \n",
    "joblib.dump(X_test, '../Pickle/InceptionResNetV2_X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "X_train = joblib.load('../Pickle/InceptionResNetV2_X_train.pkl') \n",
    "X_test = joblib.load('../Pickle/InceptionResNetV2_X_test.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13022, 38400)\n",
      "(5509, 38400)\n",
      "(13022, 51)\n",
      "(5509, 51)\n"
     ]
    }
   ],
   "source": [
    "# shape of images\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(38400,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(51, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 51)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              39322624  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 51)                6579      \n",
      "=================================================================\n",
      "Total params: 40,018,227\n",
      "Trainable params: 40,018,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_1',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 38400),\n",
       "    'dtype': 'float32',\n",
       "    'units': 1024,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 512,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 256,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 128,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.5,\n",
       "    'noise_shape': None,\n",
       "    'seed': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 51,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('../Models/weightInceptionResNetV2.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13022 samples, validate on 5509 samples\n",
      "Epoch 1/100\n",
      "13022/13022 [==============================] - ETA: 4:32 - loss: 3.9442 - accuracy: 0.00 - ETA: 2:50 - loss: 4.0095 - accuracy: 0.00 - ETA: 2:16 - loss: 4.0621 - accuracy: 0.01 - ETA: 1:58 - loss: 4.1850 - accuracy: 0.01 - ETA: 1:47 - loss: 4.2108 - accuracy: 0.01 - ETA: 1:39 - loss: 4.1798 - accuracy: 0.01 - ETA: 1:33 - loss: 4.1997 - accuracy: 0.01 - ETA: 1:30 - loss: 4.1799 - accuracy: 0.01 - ETA: 1:27 - loss: 4.1549 - accuracy: 0.02 - ETA: 1:23 - loss: 4.1392 - accuracy: 0.01 - ETA: 1:21 - loss: 4.1287 - accuracy: 0.01 - ETA: 1:19 - loss: 4.1197 - accuracy: 0.02 - ETA: 1:16 - loss: 4.1138 - accuracy: 0.01 - ETA: 1:14 - loss: 4.1131 - accuracy: 0.01 - ETA: 1:13 - loss: 4.1060 - accuracy: 0.01 - ETA: 1:11 - loss: 4.1049 - accuracy: 0.02 - ETA: 1:10 - loss: 4.1007 - accuracy: 0.02 - ETA: 1:08 - loss: 4.0895 - accuracy: 0.02 - ETA: 1:07 - loss: 4.0856 - accuracy: 0.02 - ETA: 1:05 - loss: 4.0821 - accuracy: 0.02 - ETA: 1:04 - loss: 4.0755 - accuracy: 0.02 - ETA: 1:03 - loss: 4.0691 - accuracy: 0.02 - ETA: 1:02 - loss: 4.0650 - accuracy: 0.02 - ETA: 1:01 - loss: 4.0600 - accuracy: 0.02 - ETA: 1:00 - loss: 4.0561 - accuracy: 0.02 - ETA: 59s - loss: 4.0505 - accuracy: 0.0243 - ETA: 57s - loss: 4.0463 - accuracy: 0.024 - ETA: 56s - loss: 4.0429 - accuracy: 0.024 - ETA: 55s - loss: 4.0385 - accuracy: 0.025 - ETA: 54s - loss: 4.0346 - accuracy: 0.026 - ETA: 53s - loss: 4.0319 - accuracy: 0.025 - ETA: 53s - loss: 4.0279 - accuracy: 0.026 - ETA: 52s - loss: 4.0253 - accuracy: 0.026 - ETA: 51s - loss: 4.0203 - accuracy: 0.027 - ETA: 50s - loss: 4.0165 - accuracy: 0.027 - ETA: 49s - loss: 4.0135 - accuracy: 0.028 - ETA: 48s - loss: 4.0123 - accuracy: 0.029 - ETA: 47s - loss: 4.0090 - accuracy: 0.029 - ETA: 47s - loss: 4.0079 - accuracy: 0.030 - ETA: 46s - loss: 4.0034 - accuracy: 0.030 - ETA: 45s - loss: 4.0016 - accuracy: 0.030 - ETA: 44s - loss: 3.9975 - accuracy: 0.031 - ETA: 43s - loss: 3.9944 - accuracy: 0.031 - ETA: 42s - loss: 3.9902 - accuracy: 0.032 - ETA: 41s - loss: 3.9881 - accuracy: 0.032 - ETA: 41s - loss: 3.9864 - accuracy: 0.032 - ETA: 40s - loss: 3.9843 - accuracy: 0.032 - ETA: 39s - loss: 3.9831 - accuracy: 0.032 - ETA: 38s - loss: 3.9816 - accuracy: 0.032 - ETA: 37s - loss: 3.9812 - accuracy: 0.033 - ETA: 37s - loss: 3.9800 - accuracy: 0.033 - ETA: 36s - loss: 3.9782 - accuracy: 0.033 - ETA: 35s - loss: 3.9739 - accuracy: 0.034 - ETA: 34s - loss: 3.9725 - accuracy: 0.034 - ETA: 34s - loss: 3.9699 - accuracy: 0.035 - ETA: 33s - loss: 3.9669 - accuracy: 0.035 - ETA: 32s - loss: 3.9662 - accuracy: 0.035 - ETA: 31s - loss: 3.9649 - accuracy: 0.035 - ETA: 31s - loss: 3.9618 - accuracy: 0.035 - ETA: 30s - loss: 3.9597 - accuracy: 0.035 - ETA: 29s - loss: 3.9579 - accuracy: 0.035 - ETA: 28s - loss: 3.9551 - accuracy: 0.036 - ETA: 28s - loss: 3.9534 - accuracy: 0.037 - ETA: 27s - loss: 3.9516 - accuracy: 0.037 - ETA: 26s - loss: 3.9518 - accuracy: 0.037 - ETA: 25s - loss: 3.9505 - accuracy: 0.038 - ETA: 25s - loss: 3.9499 - accuracy: 0.037 - ETA: 24s - loss: 3.9481 - accuracy: 0.037 - ETA: 23s - loss: 3.9465 - accuracy: 0.038 - ETA: 22s - loss: 3.9446 - accuracy: 0.038 - ETA: 22s - loss: 3.9433 - accuracy: 0.038 - ETA: 21s - loss: 3.9431 - accuracy: 0.038 - ETA: 20s - loss: 3.9409 - accuracy: 0.039 - ETA: 19s - loss: 3.9392 - accuracy: 0.039 - ETA: 19s - loss: 3.9374 - accuracy: 0.040 - ETA: 18s - loss: 3.9353 - accuracy: 0.040 - ETA: 17s - loss: 3.9337 - accuracy: 0.040 - ETA: 17s - loss: 3.9316 - accuracy: 0.040 - ETA: 16s - loss: 3.9301 - accuracy: 0.040 - ETA: 15s - loss: 3.9280 - accuracy: 0.041 - ETA: 14s - loss: 3.9259 - accuracy: 0.041 - ETA: 14s - loss: 3.9255 - accuracy: 0.041 - ETA: 13s - loss: 3.9230 - accuracy: 0.042 - ETA: 12s - loss: 3.9205 - accuracy: 0.042 - ETA: 11s - loss: 3.9182 - accuracy: 0.043 - ETA: 11s - loss: 3.9169 - accuracy: 0.043 - ETA: 10s - loss: 3.9157 - accuracy: 0.043 - ETA: 9s - loss: 3.9133 - accuracy: 0.043 - ETA: 9s - loss: 3.9115 - accuracy: 0.04 - ETA: 8s - loss: 3.9106 - accuracy: 0.04 - ETA: 7s - loss: 3.9089 - accuracy: 0.04 - ETA: 6s - loss: 3.9075 - accuracy: 0.04 - ETA: 6s - loss: 3.9059 - accuracy: 0.04 - ETA: 5s - loss: 3.9041 - accuracy: 0.04 - ETA: 4s - loss: 3.9023 - accuracy: 0.04 - ETA: 4s - loss: 3.8998 - accuracy: 0.04 - ETA: 3s - loss: 3.8985 - accuracy: 0.04 - ETA: 2s - loss: 3.8966 - accuracy: 0.04 - ETA: 1s - loss: 3.8929 - accuracy: 0.04 - ETA: 1s - loss: 3.8920 - accuracy: 0.04 - ETA: 0s - loss: 3.8914 - accuracy: 0.04 - 84s 6ms/step - loss: 3.8900 - accuracy: 0.0486 - val_loss: 3.8143 - val_accuracy: 0.0604\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:08 - loss: 3.6958 - accuracy: 0.08 - ETA: 1:06 - loss: 3.6793 - accuracy: 0.09 - ETA: 1:08 - loss: 3.6480 - accuracy: 0.09 - ETA: 1:08 - loss: 3.6574 - accuracy: 0.08 - ETA: 1:07 - loss: 3.6813 - accuracy: 0.08 - ETA: 1:06 - loss: 3.6545 - accuracy: 0.09 - ETA: 1:06 - loss: 3.6587 - accuracy: 0.09 - ETA: 1:05 - loss: 3.6404 - accuracy: 0.09 - ETA: 1:04 - loss: 3.6386 - accuracy: 0.09 - ETA: 1:03 - loss: 3.6238 - accuracy: 0.10 - ETA: 1:03 - loss: 3.6170 - accuracy: 0.10 - ETA: 1:02 - loss: 3.6057 - accuracy: 0.10 - ETA: 1:01 - loss: 3.5969 - accuracy: 0.10 - ETA: 1:00 - loss: 3.6030 - accuracy: 0.10 - ETA: 59s - loss: 3.5988 - accuracy: 0.1052 - ETA: 59s - loss: 3.5916 - accuracy: 0.106 - ETA: 58s - loss: 3.5953 - accuracy: 0.106 - ETA: 57s - loss: 3.5886 - accuracy: 0.107 - ETA: 57s - loss: 3.6003 - accuracy: 0.106 - ETA: 56s - loss: 3.5959 - accuracy: 0.105 - ETA: 55s - loss: 3.5878 - accuracy: 0.108 - ETA: 55s - loss: 3.5885 - accuracy: 0.108 - ETA: 54s - loss: 3.5839 - accuracy: 0.109 - ETA: 53s - loss: 3.5808 - accuracy: 0.109 - ETA: 52s - loss: 3.5783 - accuracy: 0.109 - ETA: 52s - loss: 3.5770 - accuracy: 0.109 - ETA: 51s - loss: 3.5772 - accuracy: 0.108 - ETA: 50s - loss: 3.5710 - accuracy: 0.111 - ETA: 50s - loss: 3.5678 - accuracy: 0.113 - ETA: 49s - loss: 3.5584 - accuracy: 0.114 - ETA: 48s - loss: 3.5568 - accuracy: 0.114 - ETA: 48s - loss: 3.5569 - accuracy: 0.114 - ETA: 47s - loss: 3.5515 - accuracy: 0.115 - ETA: 46s - loss: 3.5483 - accuracy: 0.116 - ETA: 46s - loss: 3.5456 - accuracy: 0.116 - ETA: 45s - loss: 3.5464 - accuracy: 0.115 - ETA: 44s - loss: 3.5442 - accuracy: 0.116 - ETA: 43s - loss: 3.5420 - accuracy: 0.117 - ETA: 43s - loss: 3.5376 - accuracy: 0.118 - ETA: 42s - loss: 3.5356 - accuracy: 0.118 - ETA: 41s - loss: 3.5349 - accuracy: 0.118 - ETA: 41s - loss: 3.5307 - accuracy: 0.118 - ETA: 40s - loss: 3.5283 - accuracy: 0.119 - ETA: 39s - loss: 3.5248 - accuracy: 0.120 - ETA: 38s - loss: 3.5213 - accuracy: 0.121 - ETA: 38s - loss: 3.5224 - accuracy: 0.121 - ETA: 37s - loss: 3.5210 - accuracy: 0.121 - ETA: 36s - loss: 3.5175 - accuracy: 0.123 - ETA: 36s - loss: 3.5114 - accuracy: 0.124 - ETA: 35s - loss: 3.5098 - accuracy: 0.124 - ETA: 34s - loss: 3.5096 - accuracy: 0.124 - ETA: 34s - loss: 3.5037 - accuracy: 0.125 - ETA: 33s - loss: 3.4999 - accuracy: 0.126 - ETA: 32s - loss: 3.4958 - accuracy: 0.127 - ETA: 32s - loss: 3.4926 - accuracy: 0.127 - ETA: 31s - loss: 3.4880 - accuracy: 0.128 - ETA: 30s - loss: 3.4875 - accuracy: 0.128 - ETA: 30s - loss: 3.4821 - accuracy: 0.129 - ETA: 29s - loss: 3.4835 - accuracy: 0.129 - ETA: 28s - loss: 3.4838 - accuracy: 0.128 - ETA: 27s - loss: 3.4807 - accuracy: 0.129 - ETA: 27s - loss: 3.4774 - accuracy: 0.129 - ETA: 26s - loss: 3.4755 - accuracy: 0.129 - ETA: 25s - loss: 3.4737 - accuracy: 0.129 - ETA: 25s - loss: 3.4719 - accuracy: 0.130 - ETA: 24s - loss: 3.4709 - accuracy: 0.130 - ETA: 23s - loss: 3.4694 - accuracy: 0.131 - ETA: 23s - loss: 3.4653 - accuracy: 0.131 - ETA: 22s - loss: 3.4637 - accuracy: 0.132 - ETA: 21s - loss: 3.4582 - accuracy: 0.134 - ETA: 21s - loss: 3.4565 - accuracy: 0.133 - ETA: 20s - loss: 3.4524 - accuracy: 0.134 - ETA: 19s - loss: 3.4511 - accuracy: 0.135 - ETA: 18s - loss: 3.4479 - accuracy: 0.135 - ETA: 18s - loss: 3.4473 - accuracy: 0.135 - ETA: 17s - loss: 3.4438 - accuracy: 0.136 - ETA: 16s - loss: 3.4398 - accuracy: 0.136 - ETA: 16s - loss: 3.4348 - accuracy: 0.137 - ETA: 15s - loss: 3.4341 - accuracy: 0.137 - ETA: 14s - loss: 3.4295 - accuracy: 0.138 - ETA: 14s - loss: 3.4277 - accuracy: 0.138 - ETA: 13s - loss: 3.4275 - accuracy: 0.138 - ETA: 12s - loss: 3.4246 - accuracy: 0.138 - ETA: 12s - loss: 3.4213 - accuracy: 0.139 - ETA: 11s - loss: 3.4187 - accuracy: 0.139 - ETA: 10s - loss: 3.4161 - accuracy: 0.140 - ETA: 10s - loss: 3.4126 - accuracy: 0.141 - ETA: 9s - loss: 3.4104 - accuracy: 0.141 - ETA: 8s - loss: 3.4075 - accuracy: 0.14 - ETA: 8s - loss: 3.4036 - accuracy: 0.14 - ETA: 7s - loss: 3.4006 - accuracy: 0.14 - ETA: 6s - loss: 3.3978 - accuracy: 0.14 - ETA: 6s - loss: 3.3953 - accuracy: 0.14 - ETA: 5s - loss: 3.3922 - accuracy: 0.14 - ETA: 4s - loss: 3.3892 - accuracy: 0.14 - ETA: 3s - loss: 3.3867 - accuracy: 0.14 - ETA: 3s - loss: 3.3845 - accuracy: 0.14 - ETA: 2s - loss: 3.3795 - accuracy: 0.14 - ETA: 1s - loss: 3.3788 - accuracy: 0.14 - ETA: 1s - loss: 3.3752 - accuracy: 0.14 - ETA: 0s - loss: 3.3737 - accuracy: 0.14 - 77s 6ms/step - loss: 3.3710 - accuracy: 0.1493 - val_loss: 3.5690 - val_accuracy: 0.0995\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:05 - loss: 2.9434 - accuracy: 0.24 - ETA: 1:07 - loss: 3.0554 - accuracy: 0.20 - ETA: 1:09 - loss: 3.0508 - accuracy: 0.20 - ETA: 1:08 - loss: 3.0380 - accuracy: 0.20 - ETA: 1:08 - loss: 3.0453 - accuracy: 0.20 - ETA: 1:07 - loss: 3.0403 - accuracy: 0.20 - ETA: 1:06 - loss: 3.0302 - accuracy: 0.21 - ETA: 1:05 - loss: 3.0243 - accuracy: 0.21 - ETA: 1:04 - loss: 3.0288 - accuracy: 0.21 - ETA: 1:04 - loss: 3.0402 - accuracy: 0.21 - ETA: 1:03 - loss: 3.0633 - accuracy: 0.21 - ETA: 1:02 - loss: 3.0644 - accuracy: 0.21 - ETA: 1:01 - loss: 3.0642 - accuracy: 0.21 - ETA: 1:01 - loss: 3.0703 - accuracy: 0.21 - ETA: 1:00 - loss: 3.0504 - accuracy: 0.21 - ETA: 59s - loss: 3.0497 - accuracy: 0.2168 - ETA: 58s - loss: 3.0425 - accuracy: 0.220 - ETA: 58s - loss: 3.0532 - accuracy: 0.219 - ETA: 57s - loss: 3.0528 - accuracy: 0.217 - ETA: 56s - loss: 3.0433 - accuracy: 0.219 - ETA: 56s - loss: 3.0463 - accuracy: 0.219 - ETA: 55s - loss: 3.0501 - accuracy: 0.219 - ETA: 54s - loss: 3.0500 - accuracy: 0.218 - ETA: 54s - loss: 3.0484 - accuracy: 0.218 - ETA: 53s - loss: 3.0460 - accuracy: 0.218 - ETA: 52s - loss: 3.0427 - accuracy: 0.218 - ETA: 51s - loss: 3.0445 - accuracy: 0.216 - ETA: 51s - loss: 3.0466 - accuracy: 0.216 - ETA: 50s - loss: 3.0479 - accuracy: 0.215 - ETA: 49s - loss: 3.0438 - accuracy: 0.214 - ETA: 49s - loss: 3.0455 - accuracy: 0.215 - ETA: 48s - loss: 3.0401 - accuracy: 0.216 - ETA: 47s - loss: 3.0358 - accuracy: 0.216 - ETA: 47s - loss: 3.0356 - accuracy: 0.217 - ETA: 46s - loss: 3.0286 - accuracy: 0.219 - ETA: 45s - loss: 3.0313 - accuracy: 0.218 - ETA: 44s - loss: 3.0293 - accuracy: 0.220 - ETA: 44s - loss: 3.0309 - accuracy: 0.221 - ETA: 43s - loss: 3.0302 - accuracy: 0.220 - ETA: 42s - loss: 3.0274 - accuracy: 0.220 - ETA: 42s - loss: 3.0258 - accuracy: 0.220 - ETA: 41s - loss: 3.0211 - accuracy: 0.220 - ETA: 40s - loss: 3.0199 - accuracy: 0.221 - ETA: 40s - loss: 3.0204 - accuracy: 0.221 - ETA: 39s - loss: 3.0204 - accuracy: 0.221 - ETA: 38s - loss: 3.0175 - accuracy: 0.221 - ETA: 37s - loss: 3.0177 - accuracy: 0.221 - ETA: 37s - loss: 3.0149 - accuracy: 0.222 - ETA: 36s - loss: 3.0179 - accuracy: 0.222 - ETA: 35s - loss: 3.0136 - accuracy: 0.223 - ETA: 35s - loss: 3.0087 - accuracy: 0.224 - ETA: 34s - loss: 3.0012 - accuracy: 0.225 - ETA: 33s - loss: 2.9988 - accuracy: 0.225 - ETA: 33s - loss: 2.9971 - accuracy: 0.226 - ETA: 32s - loss: 2.9922 - accuracy: 0.226 - ETA: 31s - loss: 2.9894 - accuracy: 0.227 - ETA: 31s - loss: 2.9862 - accuracy: 0.227 - ETA: 30s - loss: 2.9808 - accuracy: 0.228 - ETA: 29s - loss: 2.9794 - accuracy: 0.229 - ETA: 29s - loss: 2.9775 - accuracy: 0.229 - ETA: 28s - loss: 2.9770 - accuracy: 0.229 - ETA: 27s - loss: 2.9754 - accuracy: 0.229 - ETA: 27s - loss: 2.9724 - accuracy: 0.229 - ETA: 26s - loss: 2.9684 - accuracy: 0.231 - ETA: 25s - loss: 2.9656 - accuracy: 0.231 - ETA: 24s - loss: 2.9678 - accuracy: 0.230 - ETA: 24s - loss: 2.9644 - accuracy: 0.231 - ETA: 23s - loss: 2.9626 - accuracy: 0.231 - ETA: 22s - loss: 2.9651 - accuracy: 0.230 - ETA: 22s - loss: 2.9622 - accuracy: 0.231 - ETA: 21s - loss: 2.9567 - accuracy: 0.232 - ETA: 20s - loss: 2.9541 - accuracy: 0.233 - ETA: 20s - loss: 2.9500 - accuracy: 0.234 - ETA: 19s - loss: 2.9494 - accuracy: 0.234 - ETA: 18s - loss: 2.9442 - accuracy: 0.236 - ETA: 17s - loss: 2.9416 - accuracy: 0.236 - ETA: 17s - loss: 2.9398 - accuracy: 0.237 - ETA: 16s - loss: 2.9364 - accuracy: 0.237 - ETA: 15s - loss: 2.9338 - accuracy: 0.238 - ETA: 15s - loss: 2.9323 - accuracy: 0.238 - ETA: 14s - loss: 2.9303 - accuracy: 0.238 - ETA: 13s - loss: 2.9289 - accuracy: 0.238 - ETA: 13s - loss: 2.9264 - accuracy: 0.239 - ETA: 12s - loss: 2.9231 - accuracy: 0.240 - ETA: 11s - loss: 2.9190 - accuracy: 0.241 - ETA: 10s - loss: 2.9169 - accuracy: 0.241 - ETA: 10s - loss: 2.9155 - accuracy: 0.241 - ETA: 9s - loss: 2.9153 - accuracy: 0.242 - ETA: 8s - loss: 2.9144 - accuracy: 0.24 - ETA: 8s - loss: 2.9120 - accuracy: 0.24 - ETA: 7s - loss: 2.9123 - accuracy: 0.24 - ETA: 6s - loss: 2.9158 - accuracy: 0.24 - ETA: 6s - loss: 2.9133 - accuracy: 0.24 - ETA: 5s - loss: 2.9120 - accuracy: 0.24 - ETA: 4s - loss: 2.9099 - accuracy: 0.24 - ETA: 3s - loss: 2.9099 - accuracy: 0.24 - ETA: 3s - loss: 2.9081 - accuracy: 0.24 - ETA: 2s - loss: 2.9035 - accuracy: 0.24 - ETA: 1s - loss: 2.9025 - accuracy: 0.24 - ETA: 1s - loss: 2.9011 - accuracy: 0.24 - ETA: 0s - loss: 2.9027 - accuracy: 0.24 - 81s 6ms/step - loss: 2.9010 - accuracy: 0.2433 - val_loss: 3.3553 - val_accuracy: 0.1583\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:06 - loss: 2.8821 - accuracy: 0.21 - ETA: 1:06 - loss: 2.8571 - accuracy: 0.23 - ETA: 1:05 - loss: 2.7920 - accuracy: 0.26 - ETA: 1:05 - loss: 2.7648 - accuracy: 0.27 - ETA: 1:05 - loss: 2.7563 - accuracy: 0.27 - ETA: 1:04 - loss: 2.7392 - accuracy: 0.27 - ETA: 1:04 - loss: 2.7520 - accuracy: 0.27 - ETA: 1:03 - loss: 2.7319 - accuracy: 0.28 - ETA: 1:03 - loss: 2.7265 - accuracy: 0.28 - ETA: 1:02 - loss: 2.7429 - accuracy: 0.27 - ETA: 1:01 - loss: 2.7314 - accuracy: 0.28 - ETA: 1:01 - loss: 2.7366 - accuracy: 0.27 - ETA: 1:00 - loss: 2.7253 - accuracy: 0.27 - ETA: 59s - loss: 2.7220 - accuracy: 0.2835 - ETA: 59s - loss: 2.7086 - accuracy: 0.282 - ETA: 59s - loss: 2.6950 - accuracy: 0.284 - ETA: 58s - loss: 2.6890 - accuracy: 0.286 - ETA: 58s - loss: 2.6771 - accuracy: 0.287 - ETA: 57s - loss: 2.6640 - accuracy: 0.291 - ETA: 57s - loss: 2.6603 - accuracy: 0.289 - ETA: 56s - loss: 2.6570 - accuracy: 0.291 - ETA: 55s - loss: 2.6606 - accuracy: 0.291 - ETA: 55s - loss: 2.6443 - accuracy: 0.295 - ETA: 54s - loss: 2.6422 - accuracy: 0.294 - ETA: 53s - loss: 2.6406 - accuracy: 0.297 - ETA: 52s - loss: 2.6418 - accuracy: 0.297 - ETA: 52s - loss: 2.6421 - accuracy: 0.298 - ETA: 51s - loss: 2.6397 - accuracy: 0.299 - ETA: 50s - loss: 2.6436 - accuracy: 0.296 - ETA: 50s - loss: 2.6413 - accuracy: 0.296 - ETA: 49s - loss: 2.6430 - accuracy: 0.296 - ETA: 48s - loss: 2.6415 - accuracy: 0.296 - ETA: 48s - loss: 2.6422 - accuracy: 0.296 - ETA: 47s - loss: 2.6430 - accuracy: 0.297 - ETA: 46s - loss: 2.6518 - accuracy: 0.295 - ETA: 46s - loss: 2.6449 - accuracy: 0.295 - ETA: 45s - loss: 2.6482 - accuracy: 0.295 - ETA: 44s - loss: 2.6438 - accuracy: 0.296 - ETA: 43s - loss: 2.6411 - accuracy: 0.295 - ETA: 43s - loss: 2.6345 - accuracy: 0.296 - ETA: 42s - loss: 2.6284 - accuracy: 0.297 - ETA: 41s - loss: 2.6266 - accuracy: 0.297 - ETA: 41s - loss: 2.6277 - accuracy: 0.297 - ETA: 40s - loss: 2.6234 - accuracy: 0.298 - ETA: 39s - loss: 2.6229 - accuracy: 0.298 - ETA: 38s - loss: 2.6215 - accuracy: 0.298 - ETA: 38s - loss: 2.6194 - accuracy: 0.299 - ETA: 37s - loss: 2.6201 - accuracy: 0.299 - ETA: 36s - loss: 2.6165 - accuracy: 0.300 - ETA: 36s - loss: 2.6141 - accuracy: 0.301 - ETA: 35s - loss: 2.6136 - accuracy: 0.301 - ETA: 34s - loss: 2.6094 - accuracy: 0.303 - ETA: 33s - loss: 2.6087 - accuracy: 0.303 - ETA: 33s - loss: 2.6004 - accuracy: 0.304 - ETA: 32s - loss: 2.5945 - accuracy: 0.306 - ETA: 31s - loss: 2.6010 - accuracy: 0.305 - ETA: 31s - loss: 2.5928 - accuracy: 0.307 - ETA: 30s - loss: 2.5918 - accuracy: 0.307 - ETA: 29s - loss: 2.5928 - accuracy: 0.307 - ETA: 29s - loss: 2.5922 - accuracy: 0.307 - ETA: 28s - loss: 2.5914 - accuracy: 0.307 - ETA: 27s - loss: 2.5893 - accuracy: 0.307 - ETA: 27s - loss: 2.5888 - accuracy: 0.307 - ETA: 26s - loss: 2.5884 - accuracy: 0.307 - ETA: 25s - loss: 2.5901 - accuracy: 0.307 - ETA: 24s - loss: 2.5899 - accuracy: 0.307 - ETA: 24s - loss: 2.5889 - accuracy: 0.307 - ETA: 23s - loss: 2.5891 - accuracy: 0.307 - ETA: 22s - loss: 2.5884 - accuracy: 0.308 - ETA: 22s - loss: 2.5865 - accuracy: 0.309 - ETA: 21s - loss: 2.5869 - accuracy: 0.309 - ETA: 20s - loss: 2.5865 - accuracy: 0.310 - ETA: 19s - loss: 2.5839 - accuracy: 0.311 - ETA: 19s - loss: 2.5786 - accuracy: 0.313 - ETA: 18s - loss: 2.5753 - accuracy: 0.313 - ETA: 17s - loss: 2.5772 - accuracy: 0.313 - ETA: 17s - loss: 2.5792 - accuracy: 0.312 - ETA: 16s - loss: 2.5759 - accuracy: 0.313 - ETA: 15s - loss: 2.5763 - accuracy: 0.312 - ETA: 15s - loss: 2.5773 - accuracy: 0.312 - ETA: 14s - loss: 2.5781 - accuracy: 0.312 - ETA: 13s - loss: 2.5769 - accuracy: 0.312 - ETA: 12s - loss: 2.5772 - accuracy: 0.313 - ETA: 12s - loss: 2.5768 - accuracy: 0.313 - ETA: 11s - loss: 2.5739 - accuracy: 0.314 - ETA: 10s - loss: 2.5708 - accuracy: 0.314 - ETA: 10s - loss: 2.5675 - accuracy: 0.315 - ETA: 9s - loss: 2.5676 - accuracy: 0.315 - ETA: 8s - loss: 2.5678 - accuracy: 0.31 - ETA: 8s - loss: 2.5655 - accuracy: 0.31 - ETA: 7s - loss: 2.5636 - accuracy: 0.31 - ETA: 6s - loss: 2.5641 - accuracy: 0.31 - ETA: 6s - loss: 2.5613 - accuracy: 0.31 - ETA: 5s - loss: 2.5609 - accuracy: 0.31 - ETA: 4s - loss: 2.5564 - accuracy: 0.31 - ETA: 3s - loss: 2.5567 - accuracy: 0.31 - ETA: 3s - loss: 2.5573 - accuracy: 0.31 - ETA: 2s - loss: 2.5572 - accuracy: 0.31 - ETA: 1s - loss: 2.5548 - accuracy: 0.31 - ETA: 1s - loss: 2.5559 - accuracy: 0.31 - ETA: 0s - loss: 2.5541 - accuracy: 0.32 - 81s 6ms/step - loss: 2.5522 - accuracy: 0.3205 - val_loss: 3.1398 - val_accuracy: 0.2378\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 2.4270 - accuracy: 0.32 - ETA: 1:12 - loss: 2.4841 - accuracy: 0.31 - ETA: 1:11 - loss: 2.4195 - accuracy: 0.34 - ETA: 1:12 - loss: 2.4157 - accuracy: 0.35 - ETA: 1:11 - loss: 2.4347 - accuracy: 0.33 - ETA: 1:10 - loss: 2.4259 - accuracy: 0.35 - ETA: 1:09 - loss: 2.3882 - accuracy: 0.35 - ETA: 1:08 - loss: 2.3690 - accuracy: 0.36 - ETA: 1:07 - loss: 2.3872 - accuracy: 0.35 - ETA: 1:06 - loss: 2.3853 - accuracy: 0.35 - ETA: 1:05 - loss: 2.3665 - accuracy: 0.35 - ETA: 1:03 - loss: 2.3524 - accuracy: 0.36 - ETA: 1:03 - loss: 2.3607 - accuracy: 0.36 - ETA: 1:02 - loss: 2.3531 - accuracy: 0.36 - ETA: 1:01 - loss: 2.3690 - accuracy: 0.36 - ETA: 1:01 - loss: 2.3773 - accuracy: 0.36 - ETA: 1:00 - loss: 2.3614 - accuracy: 0.36 - ETA: 59s - loss: 2.3602 - accuracy: 0.3633 - ETA: 58s - loss: 2.3474 - accuracy: 0.366 - ETA: 57s - loss: 2.3435 - accuracy: 0.365 - ETA: 56s - loss: 2.3452 - accuracy: 0.363 - ETA: 56s - loss: 2.3438 - accuracy: 0.364 - ETA: 55s - loss: 2.3384 - accuracy: 0.364 - ETA: 54s - loss: 2.3370 - accuracy: 0.364 - ETA: 53s - loss: 2.3354 - accuracy: 0.366 - ETA: 53s - loss: 2.3378 - accuracy: 0.365 - ETA: 52s - loss: 2.3405 - accuracy: 0.363 - ETA: 51s - loss: 2.3404 - accuracy: 0.363 - ETA: 50s - loss: 2.3397 - accuracy: 0.364 - ETA: 50s - loss: 2.3334 - accuracy: 0.365 - ETA: 49s - loss: 2.3371 - accuracy: 0.362 - ETA: 48s - loss: 2.3311 - accuracy: 0.364 - ETA: 47s - loss: 2.3286 - accuracy: 0.365 - ETA: 47s - loss: 2.3283 - accuracy: 0.366 - ETA: 46s - loss: 2.3257 - accuracy: 0.367 - ETA: 45s - loss: 2.3231 - accuracy: 0.369 - ETA: 45s - loss: 2.3213 - accuracy: 0.369 - ETA: 44s - loss: 2.3257 - accuracy: 0.367 - ETA: 43s - loss: 2.3307 - accuracy: 0.366 - ETA: 42s - loss: 2.3340 - accuracy: 0.366 - ETA: 42s - loss: 2.3304 - accuracy: 0.368 - ETA: 41s - loss: 2.3329 - accuracy: 0.367 - ETA: 40s - loss: 2.3380 - accuracy: 0.366 - ETA: 40s - loss: 2.3357 - accuracy: 0.367 - ETA: 39s - loss: 2.3284 - accuracy: 0.368 - ETA: 38s - loss: 2.3240 - accuracy: 0.369 - ETA: 38s - loss: 2.3239 - accuracy: 0.369 - ETA: 37s - loss: 2.3204 - accuracy: 0.369 - ETA: 36s - loss: 2.3153 - accuracy: 0.370 - ETA: 36s - loss: 2.3093 - accuracy: 0.371 - ETA: 35s - loss: 2.3064 - accuracy: 0.371 - ETA: 34s - loss: 2.3065 - accuracy: 0.371 - ETA: 33s - loss: 2.3040 - accuracy: 0.371 - ETA: 33s - loss: 2.3010 - accuracy: 0.372 - ETA: 32s - loss: 2.2999 - accuracy: 0.372 - ETA: 31s - loss: 2.2995 - accuracy: 0.371 - ETA: 31s - loss: 2.3009 - accuracy: 0.371 - ETA: 30s - loss: 2.2989 - accuracy: 0.371 - ETA: 29s - loss: 2.2963 - accuracy: 0.371 - ETA: 29s - loss: 2.2943 - accuracy: 0.371 - ETA: 28s - loss: 2.2910 - accuracy: 0.372 - ETA: 27s - loss: 2.2881 - accuracy: 0.372 - ETA: 26s - loss: 2.2890 - accuracy: 0.372 - ETA: 26s - loss: 2.2882 - accuracy: 0.373 - ETA: 25s - loss: 2.2890 - accuracy: 0.373 - ETA: 24s - loss: 2.2904 - accuracy: 0.372 - ETA: 24s - loss: 2.2834 - accuracy: 0.374 - ETA: 23s - loss: 2.2835 - accuracy: 0.374 - ETA: 22s - loss: 2.2822 - accuracy: 0.374 - ETA: 22s - loss: 2.2827 - accuracy: 0.374 - ETA: 21s - loss: 2.2820 - accuracy: 0.375 - ETA: 20s - loss: 2.2801 - accuracy: 0.376 - ETA: 19s - loss: 2.2783 - accuracy: 0.376 - ETA: 19s - loss: 2.2786 - accuracy: 0.376 - ETA: 18s - loss: 2.2762 - accuracy: 0.377 - ETA: 17s - loss: 2.2761 - accuracy: 0.377 - ETA: 17s - loss: 2.2762 - accuracy: 0.377 - ETA: 16s - loss: 2.2727 - accuracy: 0.378 - ETA: 15s - loss: 2.2706 - accuracy: 0.378 - ETA: 15s - loss: 2.2705 - accuracy: 0.378 - ETA: 14s - loss: 2.2733 - accuracy: 0.378 - ETA: 13s - loss: 2.2717 - accuracy: 0.379 - ETA: 13s - loss: 2.2741 - accuracy: 0.379 - ETA: 12s - loss: 2.2740 - accuracy: 0.379 - ETA: 11s - loss: 2.2733 - accuracy: 0.379 - ETA: 10s - loss: 2.2726 - accuracy: 0.379 - ETA: 10s - loss: 2.2721 - accuracy: 0.379 - ETA: 9s - loss: 2.2746 - accuracy: 0.378 - ETA: 8s - loss: 2.2738 - accuracy: 0.37 - ETA: 8s - loss: 2.2716 - accuracy: 0.38 - ETA: 7s - loss: 2.2715 - accuracy: 0.38 - ETA: 6s - loss: 2.2695 - accuracy: 0.38 - ETA: 6s - loss: 2.2691 - accuracy: 0.38 - ETA: 5s - loss: 2.2692 - accuracy: 0.38 - ETA: 4s - loss: 2.2682 - accuracy: 0.38 - ETA: 3s - loss: 2.2659 - accuracy: 0.38 - ETA: 3s - loss: 2.2661 - accuracy: 0.38 - ETA: 2s - loss: 2.2655 - accuracy: 0.38 - ETA: 1s - loss: 2.2631 - accuracy: 0.38 - ETA: 1s - loss: 2.2615 - accuracy: 0.38 - ETA: 0s - loss: 2.2590 - accuracy: 0.38 - 81s 6ms/step - loss: 2.2591 - accuracy: 0.3844 - val_loss: 3.0448 - val_accuracy: 0.2503\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:06 - loss: 2.2391 - accuracy: 0.37 - ETA: 1:09 - loss: 2.2324 - accuracy: 0.40 - ETA: 1:07 - loss: 2.2752 - accuracy: 0.41 - ETA: 1:09 - loss: 2.2259 - accuracy: 0.41 - ETA: 1:09 - loss: 2.2169 - accuracy: 0.40 - ETA: 1:08 - loss: 2.1702 - accuracy: 0.40 - ETA: 1:07 - loss: 2.1651 - accuracy: 0.41 - ETA: 1:06 - loss: 2.1924 - accuracy: 0.40 - ETA: 1:05 - loss: 2.1911 - accuracy: 0.40 - ETA: 1:04 - loss: 2.1885 - accuracy: 0.39 - ETA: 1:04 - loss: 2.2001 - accuracy: 0.39 - ETA: 1:03 - loss: 2.1978 - accuracy: 0.39 - ETA: 1:02 - loss: 2.1859 - accuracy: 0.39 - ETA: 1:01 - loss: 2.1991 - accuracy: 0.39 - ETA: 1:00 - loss: 2.1879 - accuracy: 0.39 - ETA: 59s - loss: 2.1825 - accuracy: 0.4004 - ETA: 59s - loss: 2.1732 - accuracy: 0.404 - ETA: 58s - loss: 2.1714 - accuracy: 0.406 - ETA: 57s - loss: 2.1629 - accuracy: 0.407 - ETA: 56s - loss: 2.1598 - accuracy: 0.408 - ETA: 56s - loss: 2.1578 - accuracy: 0.410 - ETA: 55s - loss: 2.1558 - accuracy: 0.409 - ETA: 54s - loss: 2.1454 - accuracy: 0.411 - ETA: 53s - loss: 2.1486 - accuracy: 0.408 - ETA: 53s - loss: 2.1501 - accuracy: 0.406 - ETA: 52s - loss: 2.1505 - accuracy: 0.408 - ETA: 51s - loss: 2.1475 - accuracy: 0.408 - ETA: 51s - loss: 2.1454 - accuracy: 0.407 - ETA: 50s - loss: 2.1346 - accuracy: 0.409 - ETA: 49s - loss: 2.1298 - accuracy: 0.412 - ETA: 49s - loss: 2.1197 - accuracy: 0.415 - ETA: 48s - loss: 2.1120 - accuracy: 0.416 - ETA: 47s - loss: 2.1093 - accuracy: 0.416 - ETA: 47s - loss: 2.1090 - accuracy: 0.415 - ETA: 46s - loss: 2.1129 - accuracy: 0.415 - ETA: 45s - loss: 2.1117 - accuracy: 0.414 - ETA: 45s - loss: 2.1019 - accuracy: 0.416 - ETA: 44s - loss: 2.0992 - accuracy: 0.416 - ETA: 43s - loss: 2.1023 - accuracy: 0.415 - ETA: 43s - loss: 2.0988 - accuracy: 0.417 - ETA: 42s - loss: 2.0991 - accuracy: 0.416 - ETA: 41s - loss: 2.0993 - accuracy: 0.417 - ETA: 40s - loss: 2.1046 - accuracy: 0.416 - ETA: 40s - loss: 2.1029 - accuracy: 0.416 - ETA: 39s - loss: 2.1020 - accuracy: 0.414 - ETA: 38s - loss: 2.1006 - accuracy: 0.415 - ETA: 38s - loss: 2.0992 - accuracy: 0.415 - ETA: 37s - loss: 2.1002 - accuracy: 0.414 - ETA: 36s - loss: 2.0998 - accuracy: 0.415 - ETA: 35s - loss: 2.1000 - accuracy: 0.414 - ETA: 35s - loss: 2.1035 - accuracy: 0.414 - ETA: 34s - loss: 2.0985 - accuracy: 0.415 - ETA: 33s - loss: 2.0945 - accuracy: 0.416 - ETA: 33s - loss: 2.0938 - accuracy: 0.415 - ETA: 32s - loss: 2.0917 - accuracy: 0.415 - ETA: 31s - loss: 2.0952 - accuracy: 0.414 - ETA: 31s - loss: 2.0930 - accuracy: 0.414 - ETA: 30s - loss: 2.0946 - accuracy: 0.415 - ETA: 29s - loss: 2.0929 - accuracy: 0.416 - ETA: 28s - loss: 2.0954 - accuracy: 0.416 - ETA: 28s - loss: 2.0916 - accuracy: 0.416 - ETA: 27s - loss: 2.0953 - accuracy: 0.416 - ETA: 26s - loss: 2.0936 - accuracy: 0.416 - ETA: 26s - loss: 2.0904 - accuracy: 0.418 - ETA: 25s - loss: 2.0886 - accuracy: 0.418 - ETA: 24s - loss: 2.0921 - accuracy: 0.418 - ETA: 24s - loss: 2.0933 - accuracy: 0.418 - ETA: 23s - loss: 2.0933 - accuracy: 0.418 - ETA: 22s - loss: 2.0938 - accuracy: 0.418 - ETA: 22s - loss: 2.0927 - accuracy: 0.418 - ETA: 21s - loss: 2.0928 - accuracy: 0.418 - ETA: 20s - loss: 2.0920 - accuracy: 0.419 - ETA: 19s - loss: 2.0918 - accuracy: 0.419 - ETA: 19s - loss: 2.0906 - accuracy: 0.420 - ETA: 18s - loss: 2.0915 - accuracy: 0.420 - ETA: 17s - loss: 2.0930 - accuracy: 0.420 - ETA: 17s - loss: 2.0942 - accuracy: 0.419 - ETA: 16s - loss: 2.0937 - accuracy: 0.419 - ETA: 15s - loss: 2.0899 - accuracy: 0.420 - ETA: 15s - loss: 2.0895 - accuracy: 0.420 - ETA: 14s - loss: 2.0876 - accuracy: 0.421 - ETA: 13s - loss: 2.0849 - accuracy: 0.421 - ETA: 13s - loss: 2.0843 - accuracy: 0.421 - ETA: 12s - loss: 2.0867 - accuracy: 0.420 - ETA: 11s - loss: 2.0837 - accuracy: 0.421 - ETA: 10s - loss: 2.0831 - accuracy: 0.421 - ETA: 10s - loss: 2.0810 - accuracy: 0.422 - ETA: 9s - loss: 2.0812 - accuracy: 0.422 - ETA: 8s - loss: 2.0795 - accuracy: 0.42 - ETA: 8s - loss: 2.0812 - accuracy: 0.42 - ETA: 7s - loss: 2.0804 - accuracy: 0.42 - ETA: 6s - loss: 2.0800 - accuracy: 0.42 - ETA: 6s - loss: 2.0800 - accuracy: 0.42 - ETA: 5s - loss: 2.0844 - accuracy: 0.42 - ETA: 4s - loss: 2.0825 - accuracy: 0.42 - ETA: 3s - loss: 2.0812 - accuracy: 0.42 - ETA: 3s - loss: 2.0805 - accuracy: 0.42 - ETA: 2s - loss: 2.0810 - accuracy: 0.42 - ETA: 1s - loss: 2.0810 - accuracy: 0.42 - ETA: 1s - loss: 2.0788 - accuracy: 0.42 - ETA: 0s - loss: 2.0792 - accuracy: 0.42 - 81s 6ms/step - loss: 2.0788 - accuracy: 0.4221 - val_loss: 2.8550 - val_accuracy: 0.3126\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:07 - loss: 1.9935 - accuracy: 0.41 - ETA: 1:08 - loss: 1.8757 - accuracy: 0.45 - ETA: 1:08 - loss: 1.8347 - accuracy: 0.45 - ETA: 1:07 - loss: 1.7893 - accuracy: 0.46 - ETA: 1:06 - loss: 1.7996 - accuracy: 0.46 - ETA: 1:05 - loss: 1.8154 - accuracy: 0.45 - ETA: 1:04 - loss: 1.8292 - accuracy: 0.44 - ETA: 1:03 - loss: 1.8927 - accuracy: 0.43 - ETA: 1:02 - loss: 1.9351 - accuracy: 0.43 - ETA: 1:03 - loss: 1.9371 - accuracy: 0.43 - ETA: 1:02 - loss: 1.9326 - accuracy: 0.43 - ETA: 1:01 - loss: 1.9469 - accuracy: 0.42 - ETA: 1:00 - loss: 1.9554 - accuracy: 0.42 - ETA: 1:00 - loss: 1.9341 - accuracy: 0.43 - ETA: 59s - loss: 1.9422 - accuracy: 0.4318 - ETA: 58s - loss: 1.9391 - accuracy: 0.429 - ETA: 58s - loss: 1.9377 - accuracy: 0.433 - ETA: 57s - loss: 1.9384 - accuracy: 0.437 - ETA: 57s - loss: 1.9315 - accuracy: 0.439 - ETA: 56s - loss: 1.9200 - accuracy: 0.443 - ETA: 55s - loss: 1.9180 - accuracy: 0.444 - ETA: 55s - loss: 1.9188 - accuracy: 0.446 - ETA: 54s - loss: 1.9232 - accuracy: 0.446 - ETA: 54s - loss: 1.9269 - accuracy: 0.445 - ETA: 53s - loss: 1.9257 - accuracy: 0.446 - ETA: 52s - loss: 1.9233 - accuracy: 0.448 - ETA: 51s - loss: 1.9280 - accuracy: 0.446 - ETA: 51s - loss: 1.9247 - accuracy: 0.447 - ETA: 50s - loss: 1.9302 - accuracy: 0.446 - ETA: 49s - loss: 1.9308 - accuracy: 0.447 - ETA: 49s - loss: 1.9283 - accuracy: 0.448 - ETA: 48s - loss: 1.9231 - accuracy: 0.449 - ETA: 47s - loss: 1.9210 - accuracy: 0.450 - ETA: 47s - loss: 1.9244 - accuracy: 0.449 - ETA: 46s - loss: 1.9273 - accuracy: 0.450 - ETA: 45s - loss: 1.9340 - accuracy: 0.449 - ETA: 45s - loss: 1.9358 - accuracy: 0.450 - ETA: 44s - loss: 1.9339 - accuracy: 0.450 - ETA: 43s - loss: 1.9389 - accuracy: 0.449 - ETA: 43s - loss: 1.9408 - accuracy: 0.450 - ETA: 42s - loss: 1.9356 - accuracy: 0.452 - ETA: 41s - loss: 1.9411 - accuracy: 0.451 - ETA: 41s - loss: 1.9443 - accuracy: 0.451 - ETA: 40s - loss: 1.9426 - accuracy: 0.452 - ETA: 39s - loss: 1.9406 - accuracy: 0.454 - ETA: 39s - loss: 1.9383 - accuracy: 0.454 - ETA: 38s - loss: 1.9378 - accuracy: 0.455 - ETA: 37s - loss: 1.9409 - accuracy: 0.453 - ETA: 36s - loss: 1.9399 - accuracy: 0.452 - ETA: 36s - loss: 1.9424 - accuracy: 0.451 - ETA: 35s - loss: 1.9418 - accuracy: 0.451 - ETA: 34s - loss: 1.9387 - accuracy: 0.452 - ETA: 34s - loss: 1.9402 - accuracy: 0.451 - ETA: 33s - loss: 1.9389 - accuracy: 0.453 - ETA: 32s - loss: 1.9359 - accuracy: 0.454 - ETA: 31s - loss: 1.9360 - accuracy: 0.454 - ETA: 31s - loss: 1.9357 - accuracy: 0.454 - ETA: 30s - loss: 1.9353 - accuracy: 0.455 - ETA: 29s - loss: 1.9310 - accuracy: 0.456 - ETA: 29s - loss: 1.9266 - accuracy: 0.458 - ETA: 28s - loss: 1.9258 - accuracy: 0.458 - ETA: 27s - loss: 1.9210 - accuracy: 0.459 - ETA: 26s - loss: 1.9200 - accuracy: 0.460 - ETA: 26s - loss: 1.9243 - accuracy: 0.459 - ETA: 25s - loss: 1.9254 - accuracy: 0.460 - ETA: 24s - loss: 1.9249 - accuracy: 0.460 - ETA: 24s - loss: 1.9256 - accuracy: 0.460 - ETA: 23s - loss: 1.9290 - accuracy: 0.459 - ETA: 22s - loss: 1.9260 - accuracy: 0.460 - ETA: 22s - loss: 1.9224 - accuracy: 0.460 - ETA: 21s - loss: 1.9232 - accuracy: 0.460 - ETA: 20s - loss: 1.9231 - accuracy: 0.460 - ETA: 20s - loss: 1.9225 - accuracy: 0.461 - ETA: 19s - loss: 1.9243 - accuracy: 0.461 - ETA: 18s - loss: 1.9251 - accuracy: 0.462 - ETA: 17s - loss: 1.9251 - accuracy: 0.463 - ETA: 17s - loss: 1.9246 - accuracy: 0.463 - ETA: 16s - loss: 1.9268 - accuracy: 0.462 - ETA: 15s - loss: 1.9268 - accuracy: 0.462 - ETA: 15s - loss: 1.9252 - accuracy: 0.462 - ETA: 14s - loss: 1.9222 - accuracy: 0.464 - ETA: 13s - loss: 1.9233 - accuracy: 0.463 - ETA: 13s - loss: 1.9199 - accuracy: 0.464 - ETA: 12s - loss: 1.9217 - accuracy: 0.464 - ETA: 11s - loss: 1.9208 - accuracy: 0.464 - ETA: 10s - loss: 1.9219 - accuracy: 0.463 - ETA: 10s - loss: 1.9213 - accuracy: 0.463 - ETA: 9s - loss: 1.9228 - accuracy: 0.463 - ETA: 8s - loss: 1.9232 - accuracy: 0.46 - ETA: 8s - loss: 1.9198 - accuracy: 0.46 - ETA: 7s - loss: 1.9183 - accuracy: 0.46 - ETA: 6s - loss: 1.9147 - accuracy: 0.46 - ETA: 6s - loss: 1.9121 - accuracy: 0.46 - ETA: 5s - loss: 1.9102 - accuracy: 0.46 - ETA: 4s - loss: 1.9086 - accuracy: 0.46 - ETA: 3s - loss: 1.9087 - accuracy: 0.46 - ETA: 3s - loss: 1.9070 - accuracy: 0.46 - ETA: 2s - loss: 1.9065 - accuracy: 0.46 - ETA: 1s - loss: 1.9067 - accuracy: 0.46 - ETA: 1s - loss: 1.9060 - accuracy: 0.46 - ETA: 0s - loss: 1.9056 - accuracy: 0.46 - 81s 6ms/step - loss: 1.9036 - accuracy: 0.4669 - val_loss: 2.6827 - val_accuracy: 0.3554\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:08 - loss: 1.6953 - accuracy: 0.51 - ETA: 1:06 - loss: 1.6846 - accuracy: 0.53 - ETA: 1:06 - loss: 1.6973 - accuracy: 0.51 - ETA: 1:06 - loss: 1.6674 - accuracy: 0.52 - ETA: 1:05 - loss: 1.6979 - accuracy: 0.51 - ETA: 1:05 - loss: 1.7545 - accuracy: 0.49 - ETA: 1:05 - loss: 1.7258 - accuracy: 0.50 - ETA: 1:05 - loss: 1.7372 - accuracy: 0.50 - ETA: 1:04 - loss: 1.7406 - accuracy: 0.50 - ETA: 1:04 - loss: 1.7407 - accuracy: 0.50 - ETA: 1:04 - loss: 1.7569 - accuracy: 0.49 - ETA: 1:03 - loss: 1.7635 - accuracy: 0.49 - ETA: 1:02 - loss: 1.7647 - accuracy: 0.49 - ETA: 1:02 - loss: 1.7583 - accuracy: 0.49 - ETA: 1:01 - loss: 1.7612 - accuracy: 0.48 - ETA: 1:00 - loss: 1.7653 - accuracy: 0.48 - ETA: 59s - loss: 1.7645 - accuracy: 0.4903 - ETA: 58s - loss: 1.7645 - accuracy: 0.489 - ETA: 58s - loss: 1.7740 - accuracy: 0.488 - ETA: 57s - loss: 1.7773 - accuracy: 0.487 - ETA: 56s - loss: 1.7767 - accuracy: 0.487 - ETA: 55s - loss: 1.7851 - accuracy: 0.486 - ETA: 54s - loss: 1.7928 - accuracy: 0.484 - ETA: 54s - loss: 1.7972 - accuracy: 0.482 - ETA: 53s - loss: 1.7905 - accuracy: 0.485 - ETA: 52s - loss: 1.7900 - accuracy: 0.485 - ETA: 51s - loss: 1.7944 - accuracy: 0.485 - ETA: 51s - loss: 1.7977 - accuracy: 0.483 - ETA: 50s - loss: 1.7891 - accuracy: 0.485 - ETA: 49s - loss: 1.7773 - accuracy: 0.489 - ETA: 48s - loss: 1.7788 - accuracy: 0.488 - ETA: 48s - loss: 1.7765 - accuracy: 0.489 - ETA: 47s - loss: 1.7792 - accuracy: 0.489 - ETA: 46s - loss: 1.7855 - accuracy: 0.486 - ETA: 46s - loss: 1.7753 - accuracy: 0.490 - ETA: 45s - loss: 1.7633 - accuracy: 0.494 - ETA: 44s - loss: 1.7676 - accuracy: 0.493 - ETA: 44s - loss: 1.7656 - accuracy: 0.495 - ETA: 43s - loss: 1.7670 - accuracy: 0.494 - ETA: 42s - loss: 1.7636 - accuracy: 0.496 - ETA: 42s - loss: 1.7612 - accuracy: 0.496 - ETA: 41s - loss: 1.7633 - accuracy: 0.495 - ETA: 40s - loss: 1.7600 - accuracy: 0.496 - ETA: 39s - loss: 1.7565 - accuracy: 0.497 - ETA: 39s - loss: 1.7582 - accuracy: 0.497 - ETA: 38s - loss: 1.7589 - accuracy: 0.497 - ETA: 37s - loss: 1.7583 - accuracy: 0.497 - ETA: 37s - loss: 1.7544 - accuracy: 0.498 - ETA: 36s - loss: 1.7573 - accuracy: 0.498 - ETA: 35s - loss: 1.7594 - accuracy: 0.498 - ETA: 34s - loss: 1.7563 - accuracy: 0.498 - ETA: 34s - loss: 1.7585 - accuracy: 0.498 - ETA: 33s - loss: 1.7647 - accuracy: 0.496 - ETA: 32s - loss: 1.7652 - accuracy: 0.496 - ETA: 32s - loss: 1.7615 - accuracy: 0.497 - ETA: 31s - loss: 1.7613 - accuracy: 0.496 - ETA: 30s - loss: 1.7633 - accuracy: 0.496 - ETA: 30s - loss: 1.7640 - accuracy: 0.496 - ETA: 29s - loss: 1.7651 - accuracy: 0.495 - ETA: 28s - loss: 1.7655 - accuracy: 0.494 - ETA: 28s - loss: 1.7665 - accuracy: 0.493 - ETA: 27s - loss: 1.7636 - accuracy: 0.495 - ETA: 26s - loss: 1.7671 - accuracy: 0.494 - ETA: 25s - loss: 1.7650 - accuracy: 0.494 - ETA: 25s - loss: 1.7695 - accuracy: 0.493 - ETA: 24s - loss: 1.7703 - accuracy: 0.493 - ETA: 23s - loss: 1.7714 - accuracy: 0.493 - ETA: 23s - loss: 1.7659 - accuracy: 0.494 - ETA: 22s - loss: 1.7612 - accuracy: 0.495 - ETA: 21s - loss: 1.7592 - accuracy: 0.496 - ETA: 21s - loss: 1.7637 - accuracy: 0.495 - ETA: 20s - loss: 1.7653 - accuracy: 0.495 - ETA: 19s - loss: 1.7645 - accuracy: 0.495 - ETA: 19s - loss: 1.7626 - accuracy: 0.496 - ETA: 18s - loss: 1.7623 - accuracy: 0.496 - ETA: 17s - loss: 1.7633 - accuracy: 0.496 - ETA: 17s - loss: 1.7611 - accuracy: 0.496 - ETA: 16s - loss: 1.7620 - accuracy: 0.496 - ETA: 15s - loss: 1.7637 - accuracy: 0.496 - ETA: 14s - loss: 1.7612 - accuracy: 0.497 - ETA: 14s - loss: 1.7590 - accuracy: 0.497 - ETA: 13s - loss: 1.7611 - accuracy: 0.497 - ETA: 12s - loss: 1.7611 - accuracy: 0.497 - ETA: 12s - loss: 1.7617 - accuracy: 0.497 - ETA: 11s - loss: 1.7645 - accuracy: 0.497 - ETA: 10s - loss: 1.7637 - accuracy: 0.497 - ETA: 10s - loss: 1.7628 - accuracy: 0.497 - ETA: 9s - loss: 1.7598 - accuracy: 0.498 - ETA: 8s - loss: 1.7575 - accuracy: 0.49 - ETA: 8s - loss: 1.7593 - accuracy: 0.49 - ETA: 7s - loss: 1.7596 - accuracy: 0.49 - ETA: 6s - loss: 1.7575 - accuracy: 0.49 - ETA: 6s - loss: 1.7560 - accuracy: 0.49 - ETA: 5s - loss: 1.7558 - accuracy: 0.49 - ETA: 4s - loss: 1.7542 - accuracy: 0.49 - ETA: 3s - loss: 1.7530 - accuracy: 0.49 - ETA: 3s - loss: 1.7530 - accuracy: 0.49 - ETA: 2s - loss: 1.7503 - accuracy: 0.50 - ETA: 1s - loss: 1.7497 - accuracy: 0.50 - ETA: 1s - loss: 1.7491 - accuracy: 0.50 - ETA: 0s - loss: 1.7495 - accuracy: 0.50 - 81s 6ms/step - loss: 1.7496 - accuracy: 0.5002 - val_loss: 2.6520 - val_accuracy: 0.3329\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 1.6954 - accuracy: 0.57 - ETA: 1:12 - loss: 1.7009 - accuracy: 0.54 - ETA: 1:11 - loss: 1.6990 - accuracy: 0.54 - ETA: 1:09 - loss: 1.7279 - accuracy: 0.52 - ETA: 1:08 - loss: 1.7692 - accuracy: 0.51 - ETA: 1:07 - loss: 1.7710 - accuracy: 0.51 - ETA: 1:06 - loss: 1.7779 - accuracy: 0.51 - ETA: 1:06 - loss: 1.7556 - accuracy: 0.51 - ETA: 1:05 - loss: 1.7491 - accuracy: 0.51 - ETA: 1:05 - loss: 1.7336 - accuracy: 0.51 - ETA: 1:04 - loss: 1.7258 - accuracy: 0.51 - ETA: 1:03 - loss: 1.7214 - accuracy: 0.51 - ETA: 1:03 - loss: 1.7106 - accuracy: 0.51 - ETA: 1:02 - loss: 1.7056 - accuracy: 0.51 - ETA: 1:01 - loss: 1.6939 - accuracy: 0.51 - ETA: 1:00 - loss: 1.6960 - accuracy: 0.51 - ETA: 59s - loss: 1.7018 - accuracy: 0.5161 - ETA: 58s - loss: 1.7018 - accuracy: 0.517 - ETA: 58s - loss: 1.6992 - accuracy: 0.519 - ETA: 57s - loss: 1.6964 - accuracy: 0.521 - ETA: 56s - loss: 1.7044 - accuracy: 0.519 - ETA: 55s - loss: 1.7018 - accuracy: 0.520 - ETA: 55s - loss: 1.6869 - accuracy: 0.523 - ETA: 54s - loss: 1.6827 - accuracy: 0.523 - ETA: 53s - loss: 1.6843 - accuracy: 0.523 - ETA: 53s - loss: 1.6753 - accuracy: 0.524 - ETA: 52s - loss: 1.6685 - accuracy: 0.526 - ETA: 51s - loss: 1.6685 - accuracy: 0.525 - ETA: 50s - loss: 1.6615 - accuracy: 0.527 - ETA: 50s - loss: 1.6584 - accuracy: 0.527 - ETA: 49s - loss: 1.6601 - accuracy: 0.527 - ETA: 48s - loss: 1.6594 - accuracy: 0.526 - ETA: 48s - loss: 1.6521 - accuracy: 0.527 - ETA: 47s - loss: 1.6548 - accuracy: 0.527 - ETA: 46s - loss: 1.6536 - accuracy: 0.528 - ETA: 45s - loss: 1.6571 - accuracy: 0.527 - ETA: 45s - loss: 1.6540 - accuracy: 0.528 - ETA: 44s - loss: 1.6521 - accuracy: 0.528 - ETA: 43s - loss: 1.6497 - accuracy: 0.529 - ETA: 43s - loss: 1.6522 - accuracy: 0.528 - ETA: 42s - loss: 1.6520 - accuracy: 0.528 - ETA: 41s - loss: 1.6557 - accuracy: 0.527 - ETA: 40s - loss: 1.6592 - accuracy: 0.525 - ETA: 40s - loss: 1.6592 - accuracy: 0.525 - ETA: 39s - loss: 1.6628 - accuracy: 0.523 - ETA: 38s - loss: 1.6612 - accuracy: 0.523 - ETA: 38s - loss: 1.6599 - accuracy: 0.524 - ETA: 37s - loss: 1.6551 - accuracy: 0.524 - ETA: 36s - loss: 1.6594 - accuracy: 0.523 - ETA: 36s - loss: 1.6555 - accuracy: 0.525 - ETA: 35s - loss: 1.6536 - accuracy: 0.524 - ETA: 34s - loss: 1.6516 - accuracy: 0.525 - ETA: 33s - loss: 1.6505 - accuracy: 0.526 - ETA: 33s - loss: 1.6536 - accuracy: 0.525 - ETA: 32s - loss: 1.6554 - accuracy: 0.525 - ETA: 31s - loss: 1.6542 - accuracy: 0.526 - ETA: 31s - loss: 1.6625 - accuracy: 0.525 - ETA: 30s - loss: 1.6688 - accuracy: 0.524 - ETA: 29s - loss: 1.6685 - accuracy: 0.525 - ETA: 29s - loss: 1.6648 - accuracy: 0.526 - ETA: 28s - loss: 1.6621 - accuracy: 0.526 - ETA: 27s - loss: 1.6581 - accuracy: 0.526 - ETA: 26s - loss: 1.6560 - accuracy: 0.527 - ETA: 26s - loss: 1.6570 - accuracy: 0.526 - ETA: 25s - loss: 1.6584 - accuracy: 0.526 - ETA: 24s - loss: 1.6560 - accuracy: 0.527 - ETA: 24s - loss: 1.6559 - accuracy: 0.527 - ETA: 23s - loss: 1.6561 - accuracy: 0.527 - ETA: 22s - loss: 1.6553 - accuracy: 0.527 - ETA: 22s - loss: 1.6563 - accuracy: 0.527 - ETA: 21s - loss: 1.6571 - accuracy: 0.526 - ETA: 20s - loss: 1.6563 - accuracy: 0.526 - ETA: 20s - loss: 1.6550 - accuracy: 0.526 - ETA: 19s - loss: 1.6575 - accuracy: 0.526 - ETA: 18s - loss: 1.6592 - accuracy: 0.525 - ETA: 17s - loss: 1.6579 - accuracy: 0.526 - ETA: 17s - loss: 1.6600 - accuracy: 0.526 - ETA: 16s - loss: 1.6629 - accuracy: 0.525 - ETA: 15s - loss: 1.6642 - accuracy: 0.525 - ETA: 15s - loss: 1.6650 - accuracy: 0.524 - ETA: 14s - loss: 1.6628 - accuracy: 0.524 - ETA: 13s - loss: 1.6620 - accuracy: 0.525 - ETA: 13s - loss: 1.6598 - accuracy: 0.525 - ETA: 12s - loss: 1.6593 - accuracy: 0.525 - ETA: 11s - loss: 1.6602 - accuracy: 0.525 - ETA: 10s - loss: 1.6583 - accuracy: 0.525 - ETA: 10s - loss: 1.6573 - accuracy: 0.525 - ETA: 9s - loss: 1.6561 - accuracy: 0.525 - ETA: 8s - loss: 1.6559 - accuracy: 0.52 - ETA: 8s - loss: 1.6566 - accuracy: 0.52 - ETA: 7s - loss: 1.6578 - accuracy: 0.52 - ETA: 6s - loss: 1.6572 - accuracy: 0.52 - ETA: 6s - loss: 1.6583 - accuracy: 0.52 - ETA: 5s - loss: 1.6597 - accuracy: 0.52 - ETA: 4s - loss: 1.6587 - accuracy: 0.52 - ETA: 4s - loss: 1.6589 - accuracy: 0.52 - ETA: 3s - loss: 1.6579 - accuracy: 0.52 - ETA: 2s - loss: 1.6577 - accuracy: 0.52 - ETA: 1s - loss: 1.6584 - accuracy: 0.52 - ETA: 1s - loss: 1.6587 - accuracy: 0.52 - ETA: 0s - loss: 1.6577 - accuracy: 0.52 - 82s 6ms/step - loss: 1.6572 - accuracy: 0.5244 - val_loss: 2.6979 - val_accuracy: 0.3298\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 1.7322 - accuracy: 0.55 - ETA: 1:12 - loss: 1.7073 - accuracy: 0.51 - ETA: 1:11 - loss: 1.6496 - accuracy: 0.52 - ETA: 1:10 - loss: 1.6113 - accuracy: 0.53 - ETA: 1:09 - loss: 1.6573 - accuracy: 0.52 - ETA: 1:07 - loss: 1.6835 - accuracy: 0.52 - ETA: 1:06 - loss: 1.6560 - accuracy: 0.52 - ETA: 1:05 - loss: 1.6628 - accuracy: 0.52 - ETA: 1:04 - loss: 1.6638 - accuracy: 0.52 - ETA: 1:03 - loss: 1.6488 - accuracy: 0.53 - ETA: 1:02 - loss: 1.6372 - accuracy: 0.53 - ETA: 1:02 - loss: 1.6098 - accuracy: 0.54 - ETA: 1:01 - loss: 1.6106 - accuracy: 0.53 - ETA: 1:00 - loss: 1.5985 - accuracy: 0.53 - ETA: 59s - loss: 1.5825 - accuracy: 0.5396 - ETA: 59s - loss: 1.5875 - accuracy: 0.542 - ETA: 58s - loss: 1.5743 - accuracy: 0.542 - ETA: 58s - loss: 1.5942 - accuracy: 0.536 - ETA: 57s - loss: 1.5975 - accuracy: 0.537 - ETA: 56s - loss: 1.5906 - accuracy: 0.540 - ETA: 56s - loss: 1.5858 - accuracy: 0.538 - ETA: 55s - loss: 1.5760 - accuracy: 0.540 - ETA: 55s - loss: 1.5751 - accuracy: 0.540 - ETA: 54s - loss: 1.5888 - accuracy: 0.538 - ETA: 53s - loss: 1.5779 - accuracy: 0.540 - ETA: 53s - loss: 1.5762 - accuracy: 0.540 - ETA: 52s - loss: 1.5737 - accuracy: 0.540 - ETA: 51s - loss: 1.5651 - accuracy: 0.543 - ETA: 50s - loss: 1.5636 - accuracy: 0.544 - ETA: 50s - loss: 1.5680 - accuracy: 0.542 - ETA: 49s - loss: 1.5631 - accuracy: 0.543 - ETA: 48s - loss: 1.5605 - accuracy: 0.545 - ETA: 47s - loss: 1.5528 - accuracy: 0.548 - ETA: 47s - loss: 1.5563 - accuracy: 0.547 - ETA: 46s - loss: 1.5620 - accuracy: 0.545 - ETA: 45s - loss: 1.5600 - accuracy: 0.545 - ETA: 45s - loss: 1.5511 - accuracy: 0.548 - ETA: 44s - loss: 1.5504 - accuracy: 0.548 - ETA: 43s - loss: 1.5472 - accuracy: 0.549 - ETA: 43s - loss: 1.5499 - accuracy: 0.548 - ETA: 42s - loss: 1.5574 - accuracy: 0.546 - ETA: 41s - loss: 1.5566 - accuracy: 0.547 - ETA: 41s - loss: 1.5561 - accuracy: 0.545 - ETA: 40s - loss: 1.5593 - accuracy: 0.544 - ETA: 39s - loss: 1.5598 - accuracy: 0.544 - ETA: 38s - loss: 1.5590 - accuracy: 0.544 - ETA: 38s - loss: 1.5581 - accuracy: 0.544 - ETA: 37s - loss: 1.5597 - accuracy: 0.544 - ETA: 36s - loss: 1.5599 - accuracy: 0.543 - ETA: 36s - loss: 1.5633 - accuracy: 0.543 - ETA: 35s - loss: 1.5612 - accuracy: 0.543 - ETA: 34s - loss: 1.5574 - accuracy: 0.544 - ETA: 34s - loss: 1.5582 - accuracy: 0.544 - ETA: 33s - loss: 1.5574 - accuracy: 0.545 - ETA: 32s - loss: 1.5570 - accuracy: 0.544 - ETA: 32s - loss: 1.5577 - accuracy: 0.544 - ETA: 31s - loss: 1.5597 - accuracy: 0.544 - ETA: 30s - loss: 1.5587 - accuracy: 0.545 - ETA: 29s - loss: 1.5600 - accuracy: 0.544 - ETA: 29s - loss: 1.5597 - accuracy: 0.545 - ETA: 28s - loss: 1.5561 - accuracy: 0.545 - ETA: 27s - loss: 1.5564 - accuracy: 0.545 - ETA: 27s - loss: 1.5570 - accuracy: 0.545 - ETA: 26s - loss: 1.5561 - accuracy: 0.545 - ETA: 25s - loss: 1.5544 - accuracy: 0.546 - ETA: 25s - loss: 1.5576 - accuracy: 0.545 - ETA: 24s - loss: 1.5596 - accuracy: 0.544 - ETA: 23s - loss: 1.5570 - accuracy: 0.544 - ETA: 22s - loss: 1.5546 - accuracy: 0.545 - ETA: 22s - loss: 1.5584 - accuracy: 0.543 - ETA: 21s - loss: 1.5566 - accuracy: 0.543 - ETA: 20s - loss: 1.5541 - accuracy: 0.544 - ETA: 20s - loss: 1.5537 - accuracy: 0.544 - ETA: 19s - loss: 1.5510 - accuracy: 0.545 - ETA: 18s - loss: 1.5500 - accuracy: 0.545 - ETA: 17s - loss: 1.5468 - accuracy: 0.546 - ETA: 17s - loss: 1.5496 - accuracy: 0.545 - ETA: 16s - loss: 1.5505 - accuracy: 0.546 - ETA: 15s - loss: 1.5523 - accuracy: 0.546 - ETA: 15s - loss: 1.5536 - accuracy: 0.545 - ETA: 14s - loss: 1.5525 - accuracy: 0.545 - ETA: 13s - loss: 1.5508 - accuracy: 0.546 - ETA: 13s - loss: 1.5526 - accuracy: 0.546 - ETA: 12s - loss: 1.5557 - accuracy: 0.545 - ETA: 11s - loss: 1.5556 - accuracy: 0.545 - ETA: 10s - loss: 1.5559 - accuracy: 0.545 - ETA: 10s - loss: 1.5547 - accuracy: 0.545 - ETA: 9s - loss: 1.5583 - accuracy: 0.544 - ETA: 8s - loss: 1.5572 - accuracy: 0.54 - ETA: 8s - loss: 1.5558 - accuracy: 0.54 - ETA: 7s - loss: 1.5553 - accuracy: 0.54 - ETA: 6s - loss: 1.5537 - accuracy: 0.54 - ETA: 6s - loss: 1.5518 - accuracy: 0.54 - ETA: 5s - loss: 1.5536 - accuracy: 0.54 - ETA: 4s - loss: 1.5508 - accuracy: 0.54 - ETA: 3s - loss: 1.5511 - accuracy: 0.54 - ETA: 3s - loss: 1.5522 - accuracy: 0.54 - ETA: 2s - loss: 1.5520 - accuracy: 0.54 - ETA: 1s - loss: 1.5510 - accuracy: 0.54 - ETA: 1s - loss: 1.5500 - accuracy: 0.54 - ETA: 0s - loss: 1.5501 - accuracy: 0.54 - 82s 6ms/step - loss: 1.5477 - accuracy: 0.5494 - val_loss: 2.7094 - val_accuracy: 0.3217\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 1.5284 - accuracy: 0.54 - ETA: 1:08 - loss: 1.5889 - accuracy: 0.51 - ETA: 1:08 - loss: 1.4968 - accuracy: 0.55 - ETA: 1:06 - loss: 1.4808 - accuracy: 0.56 - ETA: 1:05 - loss: 1.4535 - accuracy: 0.56 - ETA: 1:05 - loss: 1.4625 - accuracy: 0.55 - ETA: 1:05 - loss: 1.4123 - accuracy: 0.57 - ETA: 1:04 - loss: 1.4271 - accuracy: 0.57 - ETA: 1:04 - loss: 1.4381 - accuracy: 0.57 - ETA: 1:03 - loss: 1.4426 - accuracy: 0.57 - ETA: 1:03 - loss: 1.4334 - accuracy: 0.57 - ETA: 1:02 - loss: 1.4354 - accuracy: 0.58 - ETA: 1:02 - loss: 1.4494 - accuracy: 0.57 - ETA: 1:01 - loss: 1.4408 - accuracy: 0.57 - ETA: 1:01 - loss: 1.4368 - accuracy: 0.58 - ETA: 1:01 - loss: 1.4509 - accuracy: 0.57 - ETA: 1:00 - loss: 1.4363 - accuracy: 0.57 - ETA: 1:00 - loss: 1.4373 - accuracy: 0.57 - ETA: 59s - loss: 1.4310 - accuracy: 0.5777 - ETA: 58s - loss: 1.4383 - accuracy: 0.574 - ETA: 58s - loss: 1.4405 - accuracy: 0.575 - ETA: 57s - loss: 1.4352 - accuracy: 0.577 - ETA: 56s - loss: 1.4363 - accuracy: 0.576 - ETA: 56s - loss: 1.4299 - accuracy: 0.578 - ETA: 55s - loss: 1.4210 - accuracy: 0.580 - ETA: 55s - loss: 1.4298 - accuracy: 0.578 - ETA: 54s - loss: 1.4345 - accuracy: 0.578 - ETA: 53s - loss: 1.4345 - accuracy: 0.577 - ETA: 52s - loss: 1.4444 - accuracy: 0.574 - ETA: 52s - loss: 1.4494 - accuracy: 0.574 - ETA: 51s - loss: 1.4488 - accuracy: 0.575 - ETA: 50s - loss: 1.4443 - accuracy: 0.575 - ETA: 49s - loss: 1.4448 - accuracy: 0.576 - ETA: 48s - loss: 1.4391 - accuracy: 0.578 - ETA: 48s - loss: 1.4354 - accuracy: 0.579 - ETA: 47s - loss: 1.4353 - accuracy: 0.577 - ETA: 46s - loss: 1.4409 - accuracy: 0.576 - ETA: 45s - loss: 1.4410 - accuracy: 0.576 - ETA: 45s - loss: 1.4393 - accuracy: 0.576 - ETA: 44s - loss: 1.4346 - accuracy: 0.578 - ETA: 43s - loss: 1.4370 - accuracy: 0.577 - ETA: 42s - loss: 1.4425 - accuracy: 0.576 - ETA: 42s - loss: 1.4459 - accuracy: 0.575 - ETA: 41s - loss: 1.4433 - accuracy: 0.576 - ETA: 40s - loss: 1.4463 - accuracy: 0.575 - ETA: 40s - loss: 1.4486 - accuracy: 0.575 - ETA: 39s - loss: 1.4484 - accuracy: 0.575 - ETA: 38s - loss: 1.4480 - accuracy: 0.576 - ETA: 37s - loss: 1.4484 - accuracy: 0.574 - ETA: 37s - loss: 1.4442 - accuracy: 0.575 - ETA: 36s - loss: 1.4474 - accuracy: 0.574 - ETA: 35s - loss: 1.4476 - accuracy: 0.574 - ETA: 34s - loss: 1.4517 - accuracy: 0.573 - ETA: 34s - loss: 1.4542 - accuracy: 0.572 - ETA: 33s - loss: 1.4552 - accuracy: 0.571 - ETA: 32s - loss: 1.4551 - accuracy: 0.572 - ETA: 31s - loss: 1.4597 - accuracy: 0.571 - ETA: 31s - loss: 1.4562 - accuracy: 0.572 - ETA: 30s - loss: 1.4567 - accuracy: 0.572 - ETA: 29s - loss: 1.4562 - accuracy: 0.572 - ETA: 28s - loss: 1.4551 - accuracy: 0.572 - ETA: 28s - loss: 1.4561 - accuracy: 0.573 - ETA: 27s - loss: 1.4591 - accuracy: 0.572 - ETA: 26s - loss: 1.4581 - accuracy: 0.572 - ETA: 26s - loss: 1.4547 - accuracy: 0.572 - ETA: 25s - loss: 1.4552 - accuracy: 0.572 - ETA: 24s - loss: 1.4527 - accuracy: 0.573 - ETA: 23s - loss: 1.4540 - accuracy: 0.573 - ETA: 23s - loss: 1.4535 - accuracy: 0.572 - ETA: 22s - loss: 1.4523 - accuracy: 0.573 - ETA: 21s - loss: 1.4510 - accuracy: 0.573 - ETA: 21s - loss: 1.4523 - accuracy: 0.572 - ETA: 20s - loss: 1.4495 - accuracy: 0.573 - ETA: 19s - loss: 1.4502 - accuracy: 0.572 - ETA: 18s - loss: 1.4506 - accuracy: 0.572 - ETA: 18s - loss: 1.4501 - accuracy: 0.572 - ETA: 17s - loss: 1.4509 - accuracy: 0.571 - ETA: 16s - loss: 1.4525 - accuracy: 0.571 - ETA: 16s - loss: 1.4546 - accuracy: 0.570 - ETA: 15s - loss: 1.4510 - accuracy: 0.572 - ETA: 14s - loss: 1.4503 - accuracy: 0.571 - ETA: 13s - loss: 1.4519 - accuracy: 0.571 - ETA: 13s - loss: 1.4555 - accuracy: 0.570 - ETA: 12s - loss: 1.4560 - accuracy: 0.570 - ETA: 11s - loss: 1.4555 - accuracy: 0.570 - ETA: 11s - loss: 1.4525 - accuracy: 0.570 - ETA: 10s - loss: 1.4519 - accuracy: 0.570 - ETA: 9s - loss: 1.4523 - accuracy: 0.570 - ETA: 9s - loss: 1.4519 - accuracy: 0.57 - ETA: 8s - loss: 1.4543 - accuracy: 0.57 - ETA: 7s - loss: 1.4547 - accuracy: 0.57 - ETA: 6s - loss: 1.4548 - accuracy: 0.57 - ETA: 6s - loss: 1.4544 - accuracy: 0.57 - ETA: 5s - loss: 1.4526 - accuracy: 0.57 - ETA: 4s - loss: 1.4499 - accuracy: 0.57 - ETA: 4s - loss: 1.4516 - accuracy: 0.57 - ETA: 3s - loss: 1.4509 - accuracy: 0.57 - ETA: 2s - loss: 1.4512 - accuracy: 0.57 - ETA: 1s - loss: 1.4524 - accuracy: 0.57 - ETA: 1s - loss: 1.4525 - accuracy: 0.57 - ETA: 0s - loss: 1.4505 - accuracy: 0.57 - 83s 6ms/step - loss: 1.4487 - accuracy: 0.5723 - val_loss: 2.6024 - val_accuracy: 0.3725\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:09 - loss: 1.5695 - accuracy: 0.53 - ETA: 1:08 - loss: 1.4868 - accuracy: 0.55 - ETA: 1:07 - loss: 1.5325 - accuracy: 0.53 - ETA: 1:08 - loss: 1.4881 - accuracy: 0.54 - ETA: 1:08 - loss: 1.4679 - accuracy: 0.55 - ETA: 1:06 - loss: 1.4272 - accuracy: 0.57 - ETA: 1:06 - loss: 1.4087 - accuracy: 0.57 - ETA: 1:05 - loss: 1.3921 - accuracy: 0.58 - ETA: 1:04 - loss: 1.3834 - accuracy: 0.58 - ETA: 1:03 - loss: 1.3728 - accuracy: 0.58 - ETA: 1:02 - loss: 1.3454 - accuracy: 0.59 - ETA: 1:01 - loss: 1.3566 - accuracy: 0.58 - ETA: 1:01 - loss: 1.3752 - accuracy: 0.57 - ETA: 1:00 - loss: 1.3896 - accuracy: 0.57 - ETA: 1:00 - loss: 1.4017 - accuracy: 0.57 - ETA: 59s - loss: 1.3983 - accuracy: 0.5732 - ETA: 58s - loss: 1.3996 - accuracy: 0.574 - ETA: 57s - loss: 1.3886 - accuracy: 0.577 - ETA: 56s - loss: 1.3942 - accuracy: 0.576 - ETA: 56s - loss: 1.3840 - accuracy: 0.580 - ETA: 55s - loss: 1.3861 - accuracy: 0.580 - ETA: 54s - loss: 1.3879 - accuracy: 0.581 - ETA: 54s - loss: 1.3882 - accuracy: 0.579 - ETA: 53s - loss: 1.3822 - accuracy: 0.579 - ETA: 52s - loss: 1.3814 - accuracy: 0.580 - ETA: 52s - loss: 1.3875 - accuracy: 0.578 - ETA: 51s - loss: 1.3949 - accuracy: 0.577 - ETA: 50s - loss: 1.3865 - accuracy: 0.580 - ETA: 50s - loss: 1.3918 - accuracy: 0.578 - ETA: 49s - loss: 1.3933 - accuracy: 0.577 - ETA: 48s - loss: 1.3958 - accuracy: 0.576 - ETA: 48s - loss: 1.3959 - accuracy: 0.577 - ETA: 47s - loss: 1.3964 - accuracy: 0.576 - ETA: 46s - loss: 1.3907 - accuracy: 0.578 - ETA: 45s - loss: 1.3917 - accuracy: 0.577 - ETA: 45s - loss: 1.3888 - accuracy: 0.579 - ETA: 44s - loss: 1.3843 - accuracy: 0.579 - ETA: 43s - loss: 1.3901 - accuracy: 0.579 - ETA: 43s - loss: 1.3886 - accuracy: 0.579 - ETA: 42s - loss: 1.3872 - accuracy: 0.579 - ETA: 41s - loss: 1.3827 - accuracy: 0.581 - ETA: 41s - loss: 1.3823 - accuracy: 0.581 - ETA: 40s - loss: 1.3822 - accuracy: 0.581 - ETA: 39s - loss: 1.3829 - accuracy: 0.582 - ETA: 39s - loss: 1.3798 - accuracy: 0.584 - ETA: 38s - loss: 1.3808 - accuracy: 0.584 - ETA: 37s - loss: 1.3778 - accuracy: 0.584 - ETA: 36s - loss: 1.3812 - accuracy: 0.583 - ETA: 36s - loss: 1.3876 - accuracy: 0.582 - ETA: 35s - loss: 1.3890 - accuracy: 0.580 - ETA: 34s - loss: 1.3861 - accuracy: 0.580 - ETA: 34s - loss: 1.3855 - accuracy: 0.581 - ETA: 33s - loss: 1.3853 - accuracy: 0.580 - ETA: 32s - loss: 1.3814 - accuracy: 0.581 - ETA: 32s - loss: 1.3777 - accuracy: 0.582 - ETA: 31s - loss: 1.3829 - accuracy: 0.581 - ETA: 30s - loss: 1.3818 - accuracy: 0.581 - ETA: 30s - loss: 1.3799 - accuracy: 0.582 - ETA: 29s - loss: 1.3772 - accuracy: 0.583 - ETA: 28s - loss: 1.3805 - accuracy: 0.583 - ETA: 27s - loss: 1.3814 - accuracy: 0.583 - ETA: 27s - loss: 1.3821 - accuracy: 0.583 - ETA: 26s - loss: 1.3830 - accuracy: 0.583 - ETA: 25s - loss: 1.3844 - accuracy: 0.582 - ETA: 25s - loss: 1.3821 - accuracy: 0.582 - ETA: 24s - loss: 1.3839 - accuracy: 0.582 - ETA: 23s - loss: 1.3837 - accuracy: 0.582 - ETA: 23s - loss: 1.3826 - accuracy: 0.583 - ETA: 22s - loss: 1.3857 - accuracy: 0.582 - ETA: 21s - loss: 1.3833 - accuracy: 0.582 - ETA: 21s - loss: 1.3856 - accuracy: 0.582 - ETA: 20s - loss: 1.3833 - accuracy: 0.582 - ETA: 19s - loss: 1.3813 - accuracy: 0.582 - ETA: 19s - loss: 1.3811 - accuracy: 0.582 - ETA: 18s - loss: 1.3812 - accuracy: 0.582 - ETA: 17s - loss: 1.3784 - accuracy: 0.582 - ETA: 17s - loss: 1.3777 - accuracy: 0.582 - ETA: 16s - loss: 1.3788 - accuracy: 0.582 - ETA: 15s - loss: 1.3738 - accuracy: 0.584 - ETA: 14s - loss: 1.3730 - accuracy: 0.584 - ETA: 14s - loss: 1.3722 - accuracy: 0.585 - ETA: 13s - loss: 1.3739 - accuracy: 0.584 - ETA: 12s - loss: 1.3754 - accuracy: 0.584 - ETA: 12s - loss: 1.3741 - accuracy: 0.584 - ETA: 11s - loss: 1.3750 - accuracy: 0.584 - ETA: 10s - loss: 1.3727 - accuracy: 0.585 - ETA: 10s - loss: 1.3728 - accuracy: 0.585 - ETA: 9s - loss: 1.3736 - accuracy: 0.585 - ETA: 8s - loss: 1.3748 - accuracy: 0.58 - ETA: 8s - loss: 1.3726 - accuracy: 0.58 - ETA: 7s - loss: 1.3743 - accuracy: 0.58 - ETA: 6s - loss: 1.3744 - accuracy: 0.58 - ETA: 6s - loss: 1.3752 - accuracy: 0.58 - ETA: 5s - loss: 1.3742 - accuracy: 0.58 - ETA: 4s - loss: 1.3760 - accuracy: 0.58 - ETA: 3s - loss: 1.3771 - accuracy: 0.58 - ETA: 3s - loss: 1.3776 - accuracy: 0.58 - ETA: 2s - loss: 1.3773 - accuracy: 0.58 - ETA: 1s - loss: 1.3769 - accuracy: 0.58 - ETA: 1s - loss: 1.3765 - accuracy: 0.58 - ETA: 0s - loss: 1.3736 - accuracy: 0.58 - 81s 6ms/step - loss: 1.3733 - accuracy: 0.5868 - val_loss: 2.5171 - val_accuracy: 0.3943\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:10 - loss: 1.3402 - accuracy: 0.61 - ETA: 1:09 - loss: 1.3440 - accuracy: 0.59 - ETA: 1:08 - loss: 1.3516 - accuracy: 0.59 - ETA: 1:07 - loss: 1.3119 - accuracy: 0.60 - ETA: 1:06 - loss: 1.3236 - accuracy: 0.60 - ETA: 1:05 - loss: 1.3033 - accuracy: 0.60 - ETA: 1:05 - loss: 1.2797 - accuracy: 0.61 - ETA: 1:04 - loss: 1.2812 - accuracy: 0.61 - ETA: 1:03 - loss: 1.2712 - accuracy: 0.61 - ETA: 1:02 - loss: 1.2948 - accuracy: 0.61 - ETA: 1:02 - loss: 1.3255 - accuracy: 0.60 - ETA: 1:01 - loss: 1.3285 - accuracy: 0.60 - ETA: 1:00 - loss: 1.3257 - accuracy: 0.60 - ETA: 1:00 - loss: 1.3290 - accuracy: 0.60 - ETA: 59s - loss: 1.3464 - accuracy: 0.5995 - ETA: 58s - loss: 1.3522 - accuracy: 0.597 - ETA: 57s - loss: 1.3540 - accuracy: 0.595 - ETA: 57s - loss: 1.3578 - accuracy: 0.593 - ETA: 56s - loss: 1.3434 - accuracy: 0.597 - ETA: 55s - loss: 1.3520 - accuracy: 0.594 - ETA: 55s - loss: 1.3385 - accuracy: 0.597 - ETA: 54s - loss: 1.3476 - accuracy: 0.596 - ETA: 53s - loss: 1.3515 - accuracy: 0.597 - ETA: 53s - loss: 1.3474 - accuracy: 0.599 - ETA: 52s - loss: 1.3468 - accuracy: 0.598 - ETA: 51s - loss: 1.3484 - accuracy: 0.598 - ETA: 51s - loss: 1.3495 - accuracy: 0.597 - ETA: 50s - loss: 1.3460 - accuracy: 0.598 - ETA: 49s - loss: 1.3492 - accuracy: 0.598 - ETA: 49s - loss: 1.3463 - accuracy: 0.598 - ETA: 48s - loss: 1.3473 - accuracy: 0.597 - ETA: 47s - loss: 1.3431 - accuracy: 0.598 - ETA: 47s - loss: 1.3434 - accuracy: 0.598 - ETA: 46s - loss: 1.3476 - accuracy: 0.597 - ETA: 45s - loss: 1.3531 - accuracy: 0.595 - ETA: 45s - loss: 1.3524 - accuracy: 0.595 - ETA: 44s - loss: 1.3528 - accuracy: 0.595 - ETA: 43s - loss: 1.3482 - accuracy: 0.595 - ETA: 43s - loss: 1.3521 - accuracy: 0.595 - ETA: 42s - loss: 1.3538 - accuracy: 0.594 - ETA: 41s - loss: 1.3533 - accuracy: 0.595 - ETA: 41s - loss: 1.3513 - accuracy: 0.596 - ETA: 40s - loss: 1.3518 - accuracy: 0.595 - ETA: 39s - loss: 1.3490 - accuracy: 0.595 - ETA: 39s - loss: 1.3498 - accuracy: 0.595 - ETA: 38s - loss: 1.3498 - accuracy: 0.594 - ETA: 37s - loss: 1.3569 - accuracy: 0.592 - ETA: 36s - loss: 1.3573 - accuracy: 0.592 - ETA: 36s - loss: 1.3575 - accuracy: 0.591 - ETA: 35s - loss: 1.3569 - accuracy: 0.593 - ETA: 35s - loss: 1.3572 - accuracy: 0.593 - ETA: 34s - loss: 1.3537 - accuracy: 0.593 - ETA: 33s - loss: 1.3523 - accuracy: 0.594 - ETA: 33s - loss: 1.3500 - accuracy: 0.595 - ETA: 32s - loss: 1.3511 - accuracy: 0.594 - ETA: 31s - loss: 1.3501 - accuracy: 0.593 - ETA: 31s - loss: 1.3535 - accuracy: 0.593 - ETA: 30s - loss: 1.3558 - accuracy: 0.592 - ETA: 29s - loss: 1.3600 - accuracy: 0.591 - ETA: 28s - loss: 1.3560 - accuracy: 0.591 - ETA: 28s - loss: 1.3570 - accuracy: 0.591 - ETA: 27s - loss: 1.3578 - accuracy: 0.592 - ETA: 26s - loss: 1.3573 - accuracy: 0.593 - ETA: 26s - loss: 1.3594 - accuracy: 0.593 - ETA: 25s - loss: 1.3559 - accuracy: 0.594 - ETA: 24s - loss: 1.3563 - accuracy: 0.593 - ETA: 24s - loss: 1.3559 - accuracy: 0.594 - ETA: 23s - loss: 1.3544 - accuracy: 0.594 - ETA: 22s - loss: 1.3575 - accuracy: 0.594 - ETA: 22s - loss: 1.3562 - accuracy: 0.594 - ETA: 21s - loss: 1.3568 - accuracy: 0.593 - ETA: 20s - loss: 1.3582 - accuracy: 0.593 - ETA: 19s - loss: 1.3593 - accuracy: 0.593 - ETA: 19s - loss: 1.3579 - accuracy: 0.593 - ETA: 18s - loss: 1.3582 - accuracy: 0.594 - ETA: 17s - loss: 1.3580 - accuracy: 0.594 - ETA: 17s - loss: 1.3558 - accuracy: 0.594 - ETA: 16s - loss: 1.3561 - accuracy: 0.595 - ETA: 15s - loss: 1.3554 - accuracy: 0.595 - ETA: 15s - loss: 1.3554 - accuracy: 0.595 - ETA: 14s - loss: 1.3539 - accuracy: 0.595 - ETA: 13s - loss: 1.3558 - accuracy: 0.594 - ETA: 13s - loss: 1.3589 - accuracy: 0.594 - ETA: 12s - loss: 1.3602 - accuracy: 0.593 - ETA: 11s - loss: 1.3603 - accuracy: 0.593 - ETA: 10s - loss: 1.3587 - accuracy: 0.593 - ETA: 10s - loss: 1.3571 - accuracy: 0.593 - ETA: 9s - loss: 1.3582 - accuracy: 0.593 - ETA: 8s - loss: 1.3560 - accuracy: 0.59 - ETA: 8s - loss: 1.3544 - accuracy: 0.59 - ETA: 7s - loss: 1.3512 - accuracy: 0.59 - ETA: 6s - loss: 1.3539 - accuracy: 0.59 - ETA: 6s - loss: 1.3535 - accuracy: 0.59 - ETA: 5s - loss: 1.3515 - accuracy: 0.59 - ETA: 4s - loss: 1.3532 - accuracy: 0.59 - ETA: 3s - loss: 1.3533 - accuracy: 0.59 - ETA: 3s - loss: 1.3526 - accuracy: 0.59 - ETA: 2s - loss: 1.3547 - accuracy: 0.59 - ETA: 1s - loss: 1.3549 - accuracy: 0.59 - ETA: 1s - loss: 1.3558 - accuracy: 0.59 - ETA: 0s - loss: 1.3571 - accuracy: 0.59 - 81s 6ms/step - loss: 1.3579 - accuracy: 0.5958 - val_loss: 2.4872 - val_accuracy: 0.3859\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:09 - loss: 1.2473 - accuracy: 0.60 - ETA: 1:09 - loss: 1.2100 - accuracy: 0.60 - ETA: 1:09 - loss: 1.2286 - accuracy: 0.59 - ETA: 1:07 - loss: 1.2630 - accuracy: 0.60 - ETA: 1:06 - loss: 1.2232 - accuracy: 0.61 - ETA: 1:05 - loss: 1.2386 - accuracy: 0.61 - ETA: 1:05 - loss: 1.2572 - accuracy: 0.61 - ETA: 1:04 - loss: 1.2368 - accuracy: 0.62 - ETA: 1:04 - loss: 1.2157 - accuracy: 0.62 - ETA: 1:03 - loss: 1.2438 - accuracy: 0.62 - ETA: 1:02 - loss: 1.2367 - accuracy: 0.62 - ETA: 1:02 - loss: 1.2333 - accuracy: 0.62 - ETA: 1:01 - loss: 1.2387 - accuracy: 0.61 - ETA: 1:00 - loss: 1.2535 - accuracy: 0.61 - ETA: 1:00 - loss: 1.2494 - accuracy: 0.61 - ETA: 59s - loss: 1.2576 - accuracy: 0.6152 - ETA: 59s - loss: 1.2550 - accuracy: 0.615 - ETA: 58s - loss: 1.2550 - accuracy: 0.615 - ETA: 58s - loss: 1.2526 - accuracy: 0.616 - ETA: 57s - loss: 1.2508 - accuracy: 0.619 - ETA: 56s - loss: 1.2632 - accuracy: 0.617 - ETA: 56s - loss: 1.2679 - accuracy: 0.615 - ETA: 55s - loss: 1.2642 - accuracy: 0.615 - ETA: 55s - loss: 1.2693 - accuracy: 0.616 - ETA: 54s - loss: 1.2695 - accuracy: 0.616 - ETA: 53s - loss: 1.2687 - accuracy: 0.615 - ETA: 52s - loss: 1.2795 - accuracy: 0.614 - ETA: 52s - loss: 1.2879 - accuracy: 0.613 - ETA: 51s - loss: 1.2932 - accuracy: 0.612 - ETA: 50s - loss: 1.2953 - accuracy: 0.613 - ETA: 50s - loss: 1.2942 - accuracy: 0.613 - ETA: 49s - loss: 1.2984 - accuracy: 0.614 - ETA: 48s - loss: 1.2965 - accuracy: 0.613 - ETA: 47s - loss: 1.3045 - accuracy: 0.613 - ETA: 47s - loss: 1.3020 - accuracy: 0.613 - ETA: 46s - loss: 1.3053 - accuracy: 0.611 - ETA: 45s - loss: 1.3041 - accuracy: 0.611 - ETA: 44s - loss: 1.3002 - accuracy: 0.613 - ETA: 44s - loss: 1.3018 - accuracy: 0.612 - ETA: 43s - loss: 1.2978 - accuracy: 0.612 - ETA: 42s - loss: 1.2943 - accuracy: 0.612 - ETA: 41s - loss: 1.2897 - accuracy: 0.613 - ETA: 41s - loss: 1.2878 - accuracy: 0.614 - ETA: 40s - loss: 1.2848 - accuracy: 0.615 - ETA: 39s - loss: 1.2919 - accuracy: 0.613 - ETA: 39s - loss: 1.2922 - accuracy: 0.612 - ETA: 38s - loss: 1.2921 - accuracy: 0.612 - ETA: 37s - loss: 1.2928 - accuracy: 0.611 - ETA: 37s - loss: 1.2962 - accuracy: 0.611 - ETA: 36s - loss: 1.2951 - accuracy: 0.611 - ETA: 35s - loss: 1.2936 - accuracy: 0.611 - ETA: 34s - loss: 1.2922 - accuracy: 0.611 - ETA: 34s - loss: 1.2934 - accuracy: 0.611 - ETA: 33s - loss: 1.2922 - accuracy: 0.611 - ETA: 32s - loss: 1.2904 - accuracy: 0.612 - ETA: 32s - loss: 1.2880 - accuracy: 0.614 - ETA: 31s - loss: 1.2897 - accuracy: 0.614 - ETA: 30s - loss: 1.2889 - accuracy: 0.615 - ETA: 30s - loss: 1.2854 - accuracy: 0.616 - ETA: 29s - loss: 1.2825 - accuracy: 0.616 - ETA: 28s - loss: 1.2801 - accuracy: 0.616 - ETA: 27s - loss: 1.2813 - accuracy: 0.617 - ETA: 27s - loss: 1.2792 - accuracy: 0.617 - ETA: 26s - loss: 1.2829 - accuracy: 0.616 - ETA: 25s - loss: 1.2823 - accuracy: 0.616 - ETA: 25s - loss: 1.2818 - accuracy: 0.616 - ETA: 24s - loss: 1.2839 - accuracy: 0.616 - ETA: 23s - loss: 1.2808 - accuracy: 0.616 - ETA: 22s - loss: 1.2818 - accuracy: 0.616 - ETA: 22s - loss: 1.2820 - accuracy: 0.616 - ETA: 21s - loss: 1.2821 - accuracy: 0.616 - ETA: 20s - loss: 1.2858 - accuracy: 0.615 - ETA: 20s - loss: 1.2850 - accuracy: 0.616 - ETA: 19s - loss: 1.2856 - accuracy: 0.616 - ETA: 18s - loss: 1.2852 - accuracy: 0.616 - ETA: 18s - loss: 1.2834 - accuracy: 0.617 - ETA: 17s - loss: 1.2831 - accuracy: 0.617 - ETA: 16s - loss: 1.2818 - accuracy: 0.618 - ETA: 15s - loss: 1.2818 - accuracy: 0.618 - ETA: 15s - loss: 1.2806 - accuracy: 0.618 - ETA: 14s - loss: 1.2804 - accuracy: 0.618 - ETA: 13s - loss: 1.2818 - accuracy: 0.618 - ETA: 13s - loss: 1.2818 - accuracy: 0.618 - ETA: 12s - loss: 1.2816 - accuracy: 0.618 - ETA: 11s - loss: 1.2838 - accuracy: 0.617 - ETA: 11s - loss: 1.2833 - accuracy: 0.618 - ETA: 10s - loss: 1.2853 - accuracy: 0.617 - ETA: 9s - loss: 1.2871 - accuracy: 0.616 - ETA: 8s - loss: 1.2858 - accuracy: 0.61 - ETA: 8s - loss: 1.2867 - accuracy: 0.61 - ETA: 7s - loss: 1.2840 - accuracy: 0.61 - ETA: 6s - loss: 1.2836 - accuracy: 0.61 - ETA: 6s - loss: 1.2848 - accuracy: 0.61 - ETA: 5s - loss: 1.2832 - accuracy: 0.61 - ETA: 4s - loss: 1.2828 - accuracy: 0.61 - ETA: 4s - loss: 1.2805 - accuracy: 0.61 - ETA: 3s - loss: 1.2797 - accuracy: 0.61 - ETA: 2s - loss: 1.2783 - accuracy: 0.62 - ETA: 1s - loss: 1.2760 - accuracy: 0.62 - ETA: 1s - loss: 1.2765 - accuracy: 0.62 - ETA: 0s - loss: 1.2781 - accuracy: 0.61 - 82s 6ms/step - loss: 1.2783 - accuracy: 0.6195 - val_loss: 2.6266 - val_accuracy: 0.3442\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:16 - loss: 0.9969 - accuracy: 0.67 - ETA: 1:12 - loss: 1.1177 - accuracy: 0.65 - ETA: 1:11 - loss: 1.1861 - accuracy: 0.63 - ETA: 1:10 - loss: 1.2106 - accuracy: 0.62 - ETA: 1:08 - loss: 1.2325 - accuracy: 0.61 - ETA: 1:07 - loss: 1.2493 - accuracy: 0.61 - ETA: 1:06 - loss: 1.2227 - accuracy: 0.63 - ETA: 1:05 - loss: 1.1946 - accuracy: 0.63 - ETA: 1:04 - loss: 1.1917 - accuracy: 0.63 - ETA: 1:03 - loss: 1.1907 - accuracy: 0.63 - ETA: 1:02 - loss: 1.2233 - accuracy: 0.63 - ETA: 1:01 - loss: 1.2254 - accuracy: 0.63 - ETA: 1:01 - loss: 1.2254 - accuracy: 0.63 - ETA: 1:00 - loss: 1.2231 - accuracy: 0.63 - ETA: 59s - loss: 1.2272 - accuracy: 0.6292 - ETA: 59s - loss: 1.2200 - accuracy: 0.629 - ETA: 58s - loss: 1.2259 - accuracy: 0.626 - ETA: 57s - loss: 1.2236 - accuracy: 0.628 - ETA: 57s - loss: 1.2251 - accuracy: 0.630 - ETA: 56s - loss: 1.2183 - accuracy: 0.630 - ETA: 55s - loss: 1.2168 - accuracy: 0.630 - ETA: 55s - loss: 1.2133 - accuracy: 0.632 - ETA: 54s - loss: 1.2083 - accuracy: 0.634 - ETA: 53s - loss: 1.2175 - accuracy: 0.633 - ETA: 53s - loss: 1.2170 - accuracy: 0.631 - ETA: 52s - loss: 1.2138 - accuracy: 0.634 - ETA: 51s - loss: 1.2209 - accuracy: 0.632 - ETA: 50s - loss: 1.2148 - accuracy: 0.633 - ETA: 50s - loss: 1.2143 - accuracy: 0.634 - ETA: 49s - loss: 1.2193 - accuracy: 0.629 - ETA: 48s - loss: 1.2172 - accuracy: 0.629 - ETA: 48s - loss: 1.2156 - accuracy: 0.628 - ETA: 47s - loss: 1.2142 - accuracy: 0.630 - ETA: 46s - loss: 1.2206 - accuracy: 0.628 - ETA: 46s - loss: 1.2195 - accuracy: 0.628 - ETA: 45s - loss: 1.2297 - accuracy: 0.627 - ETA: 44s - loss: 1.2338 - accuracy: 0.625 - ETA: 44s - loss: 1.2321 - accuracy: 0.626 - ETA: 43s - loss: 1.2347 - accuracy: 0.625 - ETA: 42s - loss: 1.2264 - accuracy: 0.628 - ETA: 42s - loss: 1.2280 - accuracy: 0.627 - ETA: 41s - loss: 1.2318 - accuracy: 0.626 - ETA: 40s - loss: 1.2292 - accuracy: 0.627 - ETA: 40s - loss: 1.2273 - accuracy: 0.628 - ETA: 39s - loss: 1.2228 - accuracy: 0.629 - ETA: 38s - loss: 1.2217 - accuracy: 0.630 - ETA: 38s - loss: 1.2242 - accuracy: 0.630 - ETA: 37s - loss: 1.2272 - accuracy: 0.628 - ETA: 36s - loss: 1.2285 - accuracy: 0.627 - ETA: 36s - loss: 1.2254 - accuracy: 0.628 - ETA: 35s - loss: 1.2268 - accuracy: 0.627 - ETA: 34s - loss: 1.2267 - accuracy: 0.628 - ETA: 34s - loss: 1.2251 - accuracy: 0.628 - ETA: 33s - loss: 1.2223 - accuracy: 0.629 - ETA: 32s - loss: 1.2225 - accuracy: 0.629 - ETA: 32s - loss: 1.2195 - accuracy: 0.630 - ETA: 31s - loss: 1.2211 - accuracy: 0.630 - ETA: 30s - loss: 1.2213 - accuracy: 0.630 - ETA: 29s - loss: 1.2270 - accuracy: 0.629 - ETA: 29s - loss: 1.2287 - accuracy: 0.628 - ETA: 28s - loss: 1.2283 - accuracy: 0.629 - ETA: 27s - loss: 1.2294 - accuracy: 0.628 - ETA: 27s - loss: 1.2338 - accuracy: 0.627 - ETA: 26s - loss: 1.2318 - accuracy: 0.627 - ETA: 25s - loss: 1.2317 - accuracy: 0.627 - ETA: 25s - loss: 1.2371 - accuracy: 0.626 - ETA: 24s - loss: 1.2384 - accuracy: 0.626 - ETA: 23s - loss: 1.2389 - accuracy: 0.625 - ETA: 22s - loss: 1.2400 - accuracy: 0.625 - ETA: 22s - loss: 1.2438 - accuracy: 0.624 - ETA: 21s - loss: 1.2399 - accuracy: 0.625 - ETA: 20s - loss: 1.2373 - accuracy: 0.625 - ETA: 20s - loss: 1.2346 - accuracy: 0.625 - ETA: 19s - loss: 1.2372 - accuracy: 0.624 - ETA: 18s - loss: 1.2393 - accuracy: 0.624 - ETA: 18s - loss: 1.2391 - accuracy: 0.624 - ETA: 17s - loss: 1.2355 - accuracy: 0.626 - ETA: 16s - loss: 1.2400 - accuracy: 0.625 - ETA: 15s - loss: 1.2403 - accuracy: 0.624 - ETA: 15s - loss: 1.2390 - accuracy: 0.625 - ETA: 14s - loss: 1.2395 - accuracy: 0.625 - ETA: 13s - loss: 1.2428 - accuracy: 0.624 - ETA: 13s - loss: 1.2410 - accuracy: 0.625 - ETA: 12s - loss: 1.2374 - accuracy: 0.625 - ETA: 11s - loss: 1.2368 - accuracy: 0.626 - ETA: 11s - loss: 1.2370 - accuracy: 0.625 - ETA: 10s - loss: 1.2354 - accuracy: 0.626 - ETA: 9s - loss: 1.2357 - accuracy: 0.625 - ETA: 8s - loss: 1.2362 - accuracy: 0.62 - ETA: 8s - loss: 1.2363 - accuracy: 0.62 - ETA: 7s - loss: 1.2327 - accuracy: 0.62 - ETA: 6s - loss: 1.2321 - accuracy: 0.62 - ETA: 6s - loss: 1.2308 - accuracy: 0.62 - ETA: 5s - loss: 1.2332 - accuracy: 0.62 - ETA: 4s - loss: 1.2349 - accuracy: 0.62 - ETA: 4s - loss: 1.2353 - accuracy: 0.62 - ETA: 3s - loss: 1.2355 - accuracy: 0.62 - ETA: 2s - loss: 1.2377 - accuracy: 0.62 - ETA: 1s - loss: 1.2359 - accuracy: 0.62 - ETA: 1s - loss: 1.2370 - accuracy: 0.62 - ETA: 0s - loss: 1.2360 - accuracy: 0.62 - 82s 6ms/step - loss: 1.2345 - accuracy: 0.6258 - val_loss: 2.5906 - val_accuracy: 0.3387\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 1.1804 - accuracy: 0.67 - ETA: 1:10 - loss: 1.2273 - accuracy: 0.65 - ETA: 1:08 - loss: 1.2329 - accuracy: 0.64 - ETA: 1:07 - loss: 1.2157 - accuracy: 0.64 - ETA: 1:06 - loss: 1.1723 - accuracy: 0.65 - ETA: 1:05 - loss: 1.2052 - accuracy: 0.64 - ETA: 1:05 - loss: 1.2062 - accuracy: 0.64 - ETA: 1:04 - loss: 1.2233 - accuracy: 0.63 - ETA: 1:04 - loss: 1.2122 - accuracy: 0.64 - ETA: 1:03 - loss: 1.2039 - accuracy: 0.64 - ETA: 1:03 - loss: 1.2153 - accuracy: 0.63 - ETA: 1:02 - loss: 1.2022 - accuracy: 0.64 - ETA: 1:02 - loss: 1.2098 - accuracy: 0.64 - ETA: 1:01 - loss: 1.2063 - accuracy: 0.64 - ETA: 1:00 - loss: 1.1899 - accuracy: 0.64 - ETA: 59s - loss: 1.1959 - accuracy: 0.6421 - ETA: 59s - loss: 1.2140 - accuracy: 0.636 - ETA: 58s - loss: 1.2134 - accuracy: 0.636 - ETA: 58s - loss: 1.2213 - accuracy: 0.632 - ETA: 57s - loss: 1.2177 - accuracy: 0.628 - ETA: 56s - loss: 1.2150 - accuracy: 0.633 - ETA: 55s - loss: 1.2178 - accuracy: 0.632 - ETA: 55s - loss: 1.2223 - accuracy: 0.633 - ETA: 54s - loss: 1.2139 - accuracy: 0.635 - ETA: 53s - loss: 1.2151 - accuracy: 0.636 - ETA: 52s - loss: 1.2132 - accuracy: 0.637 - ETA: 52s - loss: 1.2199 - accuracy: 0.635 - ETA: 51s - loss: 1.2278 - accuracy: 0.633 - ETA: 50s - loss: 1.2268 - accuracy: 0.635 - ETA: 49s - loss: 1.2242 - accuracy: 0.636 - ETA: 49s - loss: 1.2266 - accuracy: 0.636 - ETA: 48s - loss: 1.2207 - accuracy: 0.636 - ETA: 47s - loss: 1.2236 - accuracy: 0.634 - ETA: 47s - loss: 1.2304 - accuracy: 0.631 - ETA: 46s - loss: 1.2329 - accuracy: 0.631 - ETA: 45s - loss: 1.2450 - accuracy: 0.629 - ETA: 45s - loss: 1.2423 - accuracy: 0.631 - ETA: 44s - loss: 1.2392 - accuracy: 0.631 - ETA: 43s - loss: 1.2379 - accuracy: 0.632 - ETA: 43s - loss: 1.2304 - accuracy: 0.633 - ETA: 42s - loss: 1.2290 - accuracy: 0.633 - ETA: 41s - loss: 1.2299 - accuracy: 0.633 - ETA: 41s - loss: 1.2303 - accuracy: 0.632 - ETA: 40s - loss: 1.2301 - accuracy: 0.632 - ETA: 39s - loss: 1.2308 - accuracy: 0.632 - ETA: 38s - loss: 1.2297 - accuracy: 0.632 - ETA: 38s - loss: 1.2308 - accuracy: 0.632 - ETA: 37s - loss: 1.2303 - accuracy: 0.631 - ETA: 36s - loss: 1.2379 - accuracy: 0.629 - ETA: 36s - loss: 1.2383 - accuracy: 0.629 - ETA: 35s - loss: 1.2385 - accuracy: 0.629 - ETA: 34s - loss: 1.2392 - accuracy: 0.630 - ETA: 33s - loss: 1.2426 - accuracy: 0.629 - ETA: 33s - loss: 1.2427 - accuracy: 0.628 - ETA: 32s - loss: 1.2459 - accuracy: 0.628 - ETA: 31s - loss: 1.2464 - accuracy: 0.628 - ETA: 31s - loss: 1.2441 - accuracy: 0.628 - ETA: 30s - loss: 1.2445 - accuracy: 0.628 - ETA: 29s - loss: 1.2473 - accuracy: 0.627 - ETA: 29s - loss: 1.2455 - accuracy: 0.628 - ETA: 28s - loss: 1.2464 - accuracy: 0.628 - ETA: 27s - loss: 1.2485 - accuracy: 0.627 - ETA: 27s - loss: 1.2477 - accuracy: 0.627 - ETA: 26s - loss: 1.2476 - accuracy: 0.627 - ETA: 25s - loss: 1.2443 - accuracy: 0.628 - ETA: 25s - loss: 1.2421 - accuracy: 0.628 - ETA: 24s - loss: 1.2426 - accuracy: 0.628 - ETA: 23s - loss: 1.2421 - accuracy: 0.628 - ETA: 22s - loss: 1.2410 - accuracy: 0.628 - ETA: 22s - loss: 1.2398 - accuracy: 0.628 - ETA: 21s - loss: 1.2400 - accuracy: 0.629 - ETA: 20s - loss: 1.2396 - accuracy: 0.629 - ETA: 20s - loss: 1.2384 - accuracy: 0.629 - ETA: 19s - loss: 1.2379 - accuracy: 0.629 - ETA: 18s - loss: 1.2383 - accuracy: 0.629 - ETA: 17s - loss: 1.2382 - accuracy: 0.629 - ETA: 17s - loss: 1.2376 - accuracy: 0.629 - ETA: 16s - loss: 1.2358 - accuracy: 0.629 - ETA: 15s - loss: 1.2364 - accuracy: 0.630 - ETA: 15s - loss: 1.2386 - accuracy: 0.629 - ETA: 14s - loss: 1.2369 - accuracy: 0.630 - ETA: 13s - loss: 1.2355 - accuracy: 0.630 - ETA: 13s - loss: 1.2333 - accuracy: 0.631 - ETA: 12s - loss: 1.2322 - accuracy: 0.631 - ETA: 11s - loss: 1.2302 - accuracy: 0.631 - ETA: 11s - loss: 1.2299 - accuracy: 0.631 - ETA: 10s - loss: 1.2320 - accuracy: 0.631 - ETA: 9s - loss: 1.2323 - accuracy: 0.630 - ETA: 8s - loss: 1.2304 - accuracy: 0.63 - ETA: 8s - loss: 1.2313 - accuracy: 0.63 - ETA: 7s - loss: 1.2329 - accuracy: 0.63 - ETA: 6s - loss: 1.2310 - accuracy: 0.63 - ETA: 6s - loss: 1.2305 - accuracy: 0.63 - ETA: 5s - loss: 1.2293 - accuracy: 0.63 - ETA: 4s - loss: 1.2285 - accuracy: 0.63 - ETA: 4s - loss: 1.2288 - accuracy: 0.63 - ETA: 3s - loss: 1.2265 - accuracy: 0.63 - ETA: 2s - loss: 1.2265 - accuracy: 0.63 - ETA: 1s - loss: 1.2265 - accuracy: 0.63 - ETA: 1s - loss: 1.2255 - accuracy: 0.63 - ETA: 0s - loss: 1.2238 - accuracy: 0.63 - 82s 6ms/step - loss: 1.2220 - accuracy: 0.6322 - val_loss: 2.6118 - val_accuracy: 0.3571\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.9982 - accuracy: 0.68 - ETA: 1:10 - loss: 1.2029 - accuracy: 0.63 - ETA: 1:08 - loss: 1.2476 - accuracy: 0.62 - ETA: 1:07 - loss: 1.2559 - accuracy: 0.63 - ETA: 1:06 - loss: 1.2613 - accuracy: 0.62 - ETA: 1:05 - loss: 1.2375 - accuracy: 0.63 - ETA: 1:04 - loss: 1.2101 - accuracy: 0.64 - ETA: 1:04 - loss: 1.1903 - accuracy: 0.64 - ETA: 1:03 - loss: 1.1735 - accuracy: 0.65 - ETA: 1:02 - loss: 1.1609 - accuracy: 0.65 - ETA: 1:02 - loss: 1.1410 - accuracy: 0.65 - ETA: 1:01 - loss: 1.1525 - accuracy: 0.65 - ETA: 1:00 - loss: 1.1426 - accuracy: 0.66 - ETA: 1:00 - loss: 1.1536 - accuracy: 0.65 - ETA: 59s - loss: 1.1673 - accuracy: 0.6526 - ETA: 59s - loss: 1.1548 - accuracy: 0.658 - ETA: 58s - loss: 1.1507 - accuracy: 0.658 - ETA: 58s - loss: 1.1506 - accuracy: 0.657 - ETA: 57s - loss: 1.1529 - accuracy: 0.655 - ETA: 56s - loss: 1.1482 - accuracy: 0.654 - ETA: 56s - loss: 1.1435 - accuracy: 0.655 - ETA: 55s - loss: 1.1486 - accuracy: 0.655 - ETA: 54s - loss: 1.1543 - accuracy: 0.654 - ETA: 54s - loss: 1.1550 - accuracy: 0.655 - ETA: 53s - loss: 1.1486 - accuracy: 0.655 - ETA: 52s - loss: 1.1560 - accuracy: 0.654 - ETA: 51s - loss: 1.1556 - accuracy: 0.653 - ETA: 51s - loss: 1.1548 - accuracy: 0.653 - ETA: 50s - loss: 1.1554 - accuracy: 0.653 - ETA: 49s - loss: 1.1563 - accuracy: 0.652 - ETA: 49s - loss: 1.1534 - accuracy: 0.652 - ETA: 48s - loss: 1.1557 - accuracy: 0.651 - ETA: 47s - loss: 1.1567 - accuracy: 0.651 - ETA: 47s - loss: 1.1531 - accuracy: 0.650 - ETA: 46s - loss: 1.1540 - accuracy: 0.648 - ETA: 45s - loss: 1.1556 - accuracy: 0.647 - ETA: 45s - loss: 1.1572 - accuracy: 0.647 - ETA: 44s - loss: 1.1571 - accuracy: 0.647 - ETA: 43s - loss: 1.1590 - accuracy: 0.646 - ETA: 43s - loss: 1.1610 - accuracy: 0.645 - ETA: 42s - loss: 1.1610 - accuracy: 0.645 - ETA: 41s - loss: 1.1591 - accuracy: 0.645 - ETA: 41s - loss: 1.1588 - accuracy: 0.646 - ETA: 40s - loss: 1.1613 - accuracy: 0.645 - ETA: 39s - loss: 1.1601 - accuracy: 0.645 - ETA: 39s - loss: 1.1564 - accuracy: 0.646 - ETA: 38s - loss: 1.1565 - accuracy: 0.647 - ETA: 37s - loss: 1.1603 - accuracy: 0.646 - ETA: 36s - loss: 1.1560 - accuracy: 0.647 - ETA: 36s - loss: 1.1590 - accuracy: 0.646 - ETA: 35s - loss: 1.1627 - accuracy: 0.645 - ETA: 34s - loss: 1.1657 - accuracy: 0.644 - ETA: 34s - loss: 1.1648 - accuracy: 0.645 - ETA: 33s - loss: 1.1639 - accuracy: 0.645 - ETA: 32s - loss: 1.1631 - accuracy: 0.645 - ETA: 31s - loss: 1.1639 - accuracy: 0.645 - ETA: 31s - loss: 1.1647 - accuracy: 0.645 - ETA: 30s - loss: 1.1639 - accuracy: 0.645 - ETA: 29s - loss: 1.1640 - accuracy: 0.645 - ETA: 29s - loss: 1.1620 - accuracy: 0.645 - ETA: 28s - loss: 1.1638 - accuracy: 0.644 - ETA: 27s - loss: 1.1655 - accuracy: 0.644 - ETA: 27s - loss: 1.1641 - accuracy: 0.645 - ETA: 26s - loss: 1.1658 - accuracy: 0.644 - ETA: 25s - loss: 1.1666 - accuracy: 0.643 - ETA: 24s - loss: 1.1669 - accuracy: 0.643 - ETA: 24s - loss: 1.1636 - accuracy: 0.644 - ETA: 23s - loss: 1.1602 - accuracy: 0.645 - ETA: 22s - loss: 1.1614 - accuracy: 0.644 - ETA: 22s - loss: 1.1617 - accuracy: 0.644 - ETA: 21s - loss: 1.1626 - accuracy: 0.645 - ETA: 20s - loss: 1.1656 - accuracy: 0.644 - ETA: 20s - loss: 1.1698 - accuracy: 0.643 - ETA: 19s - loss: 1.1689 - accuracy: 0.644 - ETA: 18s - loss: 1.1663 - accuracy: 0.644 - ETA: 17s - loss: 1.1675 - accuracy: 0.644 - ETA: 17s - loss: 1.1666 - accuracy: 0.644 - ETA: 16s - loss: 1.1703 - accuracy: 0.643 - ETA: 15s - loss: 1.1725 - accuracy: 0.643 - ETA: 15s - loss: 1.1762 - accuracy: 0.642 - ETA: 14s - loss: 1.1744 - accuracy: 0.642 - ETA: 13s - loss: 1.1738 - accuracy: 0.643 - ETA: 13s - loss: 1.1727 - accuracy: 0.643 - ETA: 12s - loss: 1.1752 - accuracy: 0.642 - ETA: 11s - loss: 1.1756 - accuracy: 0.642 - ETA: 10s - loss: 1.1739 - accuracy: 0.642 - ETA: 10s - loss: 1.1716 - accuracy: 0.642 - ETA: 9s - loss: 1.1719 - accuracy: 0.642 - ETA: 8s - loss: 1.1722 - accuracy: 0.64 - ETA: 8s - loss: 1.1719 - accuracy: 0.64 - ETA: 7s - loss: 1.1712 - accuracy: 0.64 - ETA: 6s - loss: 1.1728 - accuracy: 0.64 - ETA: 6s - loss: 1.1732 - accuracy: 0.64 - ETA: 5s - loss: 1.1746 - accuracy: 0.64 - ETA: 4s - loss: 1.1765 - accuracy: 0.64 - ETA: 4s - loss: 1.1776 - accuracy: 0.64 - ETA: 3s - loss: 1.1793 - accuracy: 0.64 - ETA: 2s - loss: 1.1774 - accuracy: 0.64 - ETA: 1s - loss: 1.1765 - accuracy: 0.64 - ETA: 1s - loss: 1.1774 - accuracy: 0.64 - ETA: 0s - loss: 1.1752 - accuracy: 0.64 - 82s 6ms/step - loss: 1.1727 - accuracy: 0.6432 - val_loss: 2.6372 - val_accuracy: 0.3707\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 1.2935 - accuracy: 0.63 - ETA: 1:10 - loss: 1.2833 - accuracy: 0.62 - ETA: 1:08 - loss: 1.2245 - accuracy: 0.64 - ETA: 1:09 - loss: 1.2013 - accuracy: 0.63 - ETA: 1:09 - loss: 1.1850 - accuracy: 0.64 - ETA: 1:08 - loss: 1.1537 - accuracy: 0.65 - ETA: 1:06 - loss: 1.1597 - accuracy: 0.64 - ETA: 1:05 - loss: 1.1949 - accuracy: 0.63 - ETA: 1:05 - loss: 1.1699 - accuracy: 0.64 - ETA: 1:04 - loss: 1.1674 - accuracy: 0.64 - ETA: 1:04 - loss: 1.1665 - accuracy: 0.64 - ETA: 1:03 - loss: 1.1555 - accuracy: 0.64 - ETA: 1:02 - loss: 1.1536 - accuracy: 0.64 - ETA: 1:02 - loss: 1.1571 - accuracy: 0.64 - ETA: 1:01 - loss: 1.1621 - accuracy: 0.64 - ETA: 1:00 - loss: 1.1741 - accuracy: 0.64 - ETA: 59s - loss: 1.1623 - accuracy: 0.6494 - ETA: 59s - loss: 1.1530 - accuracy: 0.652 - ETA: 58s - loss: 1.1516 - accuracy: 0.653 - ETA: 58s - loss: 1.1643 - accuracy: 0.650 - ETA: 57s - loss: 1.1812 - accuracy: 0.646 - ETA: 57s - loss: 1.1831 - accuracy: 0.646 - ETA: 56s - loss: 1.1699 - accuracy: 0.650 - ETA: 55s - loss: 1.1734 - accuracy: 0.649 - ETA: 54s - loss: 1.1711 - accuracy: 0.651 - ETA: 54s - loss: 1.1719 - accuracy: 0.651 - ETA: 53s - loss: 1.1702 - accuracy: 0.650 - ETA: 52s - loss: 1.1763 - accuracy: 0.649 - ETA: 51s - loss: 1.1794 - accuracy: 0.649 - ETA: 51s - loss: 1.1713 - accuracy: 0.651 - ETA: 50s - loss: 1.1656 - accuracy: 0.652 - ETA: 49s - loss: 1.1663 - accuracy: 0.650 - ETA: 48s - loss: 1.1622 - accuracy: 0.652 - ETA: 48s - loss: 1.1639 - accuracy: 0.652 - ETA: 47s - loss: 1.1642 - accuracy: 0.651 - ETA: 46s - loss: 1.1577 - accuracy: 0.653 - ETA: 45s - loss: 1.1553 - accuracy: 0.652 - ETA: 45s - loss: 1.1551 - accuracy: 0.653 - ETA: 44s - loss: 1.1557 - accuracy: 0.652 - ETA: 43s - loss: 1.1619 - accuracy: 0.651 - ETA: 43s - loss: 1.1602 - accuracy: 0.650 - ETA: 42s - loss: 1.1551 - accuracy: 0.651 - ETA: 41s - loss: 1.1528 - accuracy: 0.651 - ETA: 40s - loss: 1.1477 - accuracy: 0.652 - ETA: 40s - loss: 1.1509 - accuracy: 0.651 - ETA: 39s - loss: 1.1551 - accuracy: 0.650 - ETA: 38s - loss: 1.1542 - accuracy: 0.649 - ETA: 37s - loss: 1.1519 - accuracy: 0.650 - ETA: 37s - loss: 1.1526 - accuracy: 0.649 - ETA: 36s - loss: 1.1479 - accuracy: 0.650 - ETA: 35s - loss: 1.1442 - accuracy: 0.651 - ETA: 35s - loss: 1.1404 - accuracy: 0.652 - ETA: 34s - loss: 1.1349 - accuracy: 0.654 - ETA: 33s - loss: 1.1370 - accuracy: 0.653 - ETA: 33s - loss: 1.1404 - accuracy: 0.651 - ETA: 32s - loss: 1.1410 - accuracy: 0.651 - ETA: 31s - loss: 1.1465 - accuracy: 0.649 - ETA: 30s - loss: 1.1459 - accuracy: 0.649 - ETA: 30s - loss: 1.1486 - accuracy: 0.648 - ETA: 29s - loss: 1.1454 - accuracy: 0.648 - ETA: 28s - loss: 1.1455 - accuracy: 0.649 - ETA: 28s - loss: 1.1430 - accuracy: 0.649 - ETA: 27s - loss: 1.1430 - accuracy: 0.649 - ETA: 26s - loss: 1.1411 - accuracy: 0.650 - ETA: 25s - loss: 1.1390 - accuracy: 0.651 - ETA: 25s - loss: 1.1390 - accuracy: 0.651 - ETA: 24s - loss: 1.1423 - accuracy: 0.650 - ETA: 23s - loss: 1.1444 - accuracy: 0.650 - ETA: 23s - loss: 1.1452 - accuracy: 0.649 - ETA: 22s - loss: 1.1444 - accuracy: 0.649 - ETA: 21s - loss: 1.1477 - accuracy: 0.648 - ETA: 20s - loss: 1.1464 - accuracy: 0.649 - ETA: 20s - loss: 1.1451 - accuracy: 0.649 - ETA: 19s - loss: 1.1437 - accuracy: 0.650 - ETA: 18s - loss: 1.1433 - accuracy: 0.650 - ETA: 18s - loss: 1.1443 - accuracy: 0.650 - ETA: 17s - loss: 1.1434 - accuracy: 0.650 - ETA: 16s - loss: 1.1444 - accuracy: 0.649 - ETA: 15s - loss: 1.1455 - accuracy: 0.649 - ETA: 15s - loss: 1.1460 - accuracy: 0.649 - ETA: 14s - loss: 1.1441 - accuracy: 0.650 - ETA: 13s - loss: 1.1437 - accuracy: 0.650 - ETA: 13s - loss: 1.1454 - accuracy: 0.649 - ETA: 12s - loss: 1.1476 - accuracy: 0.648 - ETA: 11s - loss: 1.1484 - accuracy: 0.648 - ETA: 11s - loss: 1.1468 - accuracy: 0.648 - ETA: 10s - loss: 1.1458 - accuracy: 0.649 - ETA: 9s - loss: 1.1459 - accuracy: 0.649 - ETA: 8s - loss: 1.1472 - accuracy: 0.64 - ETA: 8s - loss: 1.1499 - accuracy: 0.64 - ETA: 7s - loss: 1.1482 - accuracy: 0.64 - ETA: 6s - loss: 1.1474 - accuracy: 0.64 - ETA: 6s - loss: 1.1454 - accuracy: 0.64 - ETA: 5s - loss: 1.1444 - accuracy: 0.64 - ETA: 4s - loss: 1.1427 - accuracy: 0.64 - ETA: 4s - loss: 1.1438 - accuracy: 0.64 - ETA: 3s - loss: 1.1455 - accuracy: 0.64 - ETA: 2s - loss: 1.1461 - accuracy: 0.64 - ETA: 1s - loss: 1.1488 - accuracy: 0.64 - ETA: 1s - loss: 1.1464 - accuracy: 0.64 - ETA: 0s - loss: 1.1455 - accuracy: 0.64 - 82s 6ms/step - loss: 1.1443 - accuracy: 0.6491 - val_loss: 2.6889 - val_accuracy: 0.3367\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 1.1669 - accuracy: 0.64 - ETA: 1:13 - loss: 1.2249 - accuracy: 0.62 - ETA: 1:12 - loss: 1.2041 - accuracy: 0.63 - ETA: 1:11 - loss: 1.1655 - accuracy: 0.65 - ETA: 1:10 - loss: 1.1356 - accuracy: 0.66 - ETA: 1:08 - loss: 1.2052 - accuracy: 0.64 - ETA: 1:08 - loss: 1.2078 - accuracy: 0.64 - ETA: 1:07 - loss: 1.1844 - accuracy: 0.65 - ETA: 1:07 - loss: 1.1771 - accuracy: 0.65 - ETA: 1:06 - loss: 1.1608 - accuracy: 0.66 - ETA: 1:05 - loss: 1.1650 - accuracy: 0.66 - ETA: 1:04 - loss: 1.1542 - accuracy: 0.66 - ETA: 1:03 - loss: 1.1405 - accuracy: 0.66 - ETA: 1:02 - loss: 1.1381 - accuracy: 0.66 - ETA: 1:01 - loss: 1.1484 - accuracy: 0.65 - ETA: 1:00 - loss: 1.1467 - accuracy: 0.65 - ETA: 59s - loss: 1.1474 - accuracy: 0.6572 - ETA: 58s - loss: 1.1375 - accuracy: 0.659 - ETA: 58s - loss: 1.1294 - accuracy: 0.662 - ETA: 57s - loss: 1.1259 - accuracy: 0.663 - ETA: 56s - loss: 1.1150 - accuracy: 0.664 - ETA: 55s - loss: 1.1118 - accuracy: 0.664 - ETA: 54s - loss: 1.1094 - accuracy: 0.665 - ETA: 54s - loss: 1.1165 - accuracy: 0.663 - ETA: 53s - loss: 1.1165 - accuracy: 0.664 - ETA: 52s - loss: 1.1116 - accuracy: 0.664 - ETA: 52s - loss: 1.1197 - accuracy: 0.661 - ETA: 51s - loss: 1.1289 - accuracy: 0.659 - ETA: 50s - loss: 1.1301 - accuracy: 0.661 - ETA: 49s - loss: 1.1264 - accuracy: 0.662 - ETA: 49s - loss: 1.1163 - accuracy: 0.662 - ETA: 48s - loss: 1.1168 - accuracy: 0.663 - ETA: 47s - loss: 1.1110 - accuracy: 0.665 - ETA: 47s - loss: 1.1144 - accuracy: 0.664 - ETA: 46s - loss: 1.1196 - accuracy: 0.663 - ETA: 45s - loss: 1.1234 - accuracy: 0.662 - ETA: 45s - loss: 1.1276 - accuracy: 0.661 - ETA: 44s - loss: 1.1250 - accuracy: 0.661 - ETA: 43s - loss: 1.1248 - accuracy: 0.661 - ETA: 42s - loss: 1.1273 - accuracy: 0.660 - ETA: 42s - loss: 1.1212 - accuracy: 0.661 - ETA: 41s - loss: 1.1198 - accuracy: 0.663 - ETA: 40s - loss: 1.1217 - accuracy: 0.663 - ETA: 40s - loss: 1.1212 - accuracy: 0.663 - ETA: 39s - loss: 1.1249 - accuracy: 0.661 - ETA: 38s - loss: 1.1288 - accuracy: 0.660 - ETA: 38s - loss: 1.1302 - accuracy: 0.660 - ETA: 37s - loss: 1.1331 - accuracy: 0.659 - ETA: 36s - loss: 1.1295 - accuracy: 0.660 - ETA: 35s - loss: 1.1306 - accuracy: 0.659 - ETA: 35s - loss: 1.1230 - accuracy: 0.661 - ETA: 34s - loss: 1.1249 - accuracy: 0.660 - ETA: 33s - loss: 1.1206 - accuracy: 0.660 - ETA: 33s - loss: 1.1206 - accuracy: 0.659 - ETA: 32s - loss: 1.1205 - accuracy: 0.659 - ETA: 31s - loss: 1.1215 - accuracy: 0.659 - ETA: 31s - loss: 1.1214 - accuracy: 0.660 - ETA: 30s - loss: 1.1234 - accuracy: 0.659 - ETA: 29s - loss: 1.1221 - accuracy: 0.659 - ETA: 29s - loss: 1.1283 - accuracy: 0.659 - ETA: 28s - loss: 1.1322 - accuracy: 0.658 - ETA: 27s - loss: 1.1314 - accuracy: 0.658 - ETA: 26s - loss: 1.1281 - accuracy: 0.660 - ETA: 26s - loss: 1.1286 - accuracy: 0.660 - ETA: 25s - loss: 1.1260 - accuracy: 0.660 - ETA: 24s - loss: 1.1235 - accuracy: 0.660 - ETA: 24s - loss: 1.1244 - accuracy: 0.659 - ETA: 23s - loss: 1.1228 - accuracy: 0.659 - ETA: 22s - loss: 1.1236 - accuracy: 0.659 - ETA: 22s - loss: 1.1231 - accuracy: 0.659 - ETA: 21s - loss: 1.1229 - accuracy: 0.659 - ETA: 20s - loss: 1.1234 - accuracy: 0.658 - ETA: 19s - loss: 1.1260 - accuracy: 0.658 - ETA: 19s - loss: 1.1253 - accuracy: 0.659 - ETA: 18s - loss: 1.1241 - accuracy: 0.659 - ETA: 17s - loss: 1.1234 - accuracy: 0.659 - ETA: 17s - loss: 1.1226 - accuracy: 0.660 - ETA: 16s - loss: 1.1180 - accuracy: 0.661 - ETA: 15s - loss: 1.1162 - accuracy: 0.661 - ETA: 15s - loss: 1.1136 - accuracy: 0.662 - ETA: 14s - loss: 1.1147 - accuracy: 0.661 - ETA: 13s - loss: 1.1145 - accuracy: 0.662 - ETA: 13s - loss: 1.1154 - accuracy: 0.662 - ETA: 12s - loss: 1.1153 - accuracy: 0.662 - ETA: 11s - loss: 1.1163 - accuracy: 0.661 - ETA: 10s - loss: 1.1148 - accuracy: 0.662 - ETA: 10s - loss: 1.1130 - accuracy: 0.662 - ETA: 9s - loss: 1.1134 - accuracy: 0.663 - ETA: 8s - loss: 1.1123 - accuracy: 0.66 - ETA: 8s - loss: 1.1113 - accuracy: 0.66 - ETA: 7s - loss: 1.1118 - accuracy: 0.66 - ETA: 6s - loss: 1.1116 - accuracy: 0.66 - ETA: 6s - loss: 1.1100 - accuracy: 0.66 - ETA: 5s - loss: 1.1116 - accuracy: 0.66 - ETA: 4s - loss: 1.1110 - accuracy: 0.66 - ETA: 3s - loss: 1.1101 - accuracy: 0.66 - ETA: 3s - loss: 1.1102 - accuracy: 0.66 - ETA: 2s - loss: 1.1096 - accuracy: 0.66 - ETA: 1s - loss: 1.1097 - accuracy: 0.66 - ETA: 1s - loss: 1.1096 - accuracy: 0.66 - ETA: 0s - loss: 1.1108 - accuracy: 0.66 - 82s 6ms/step - loss: 1.1085 - accuracy: 0.6646 - val_loss: 2.6495 - val_accuracy: 0.3625\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:15 - loss: 1.0130 - accuracy: 0.68 - ETA: 1:11 - loss: 1.0367 - accuracy: 0.66 - ETA: 1:09 - loss: 1.0566 - accuracy: 0.67 - ETA: 1:08 - loss: 1.0647 - accuracy: 0.67 - ETA: 1:07 - loss: 1.0329 - accuracy: 0.68 - ETA: 1:07 - loss: 1.0251 - accuracy: 0.68 - ETA: 1:06 - loss: 1.0398 - accuracy: 0.68 - ETA: 1:05 - loss: 1.0189 - accuracy: 0.68 - ETA: 1:04 - loss: 1.0374 - accuracy: 0.68 - ETA: 1:03 - loss: 1.0540 - accuracy: 0.67 - ETA: 1:03 - loss: 1.0633 - accuracy: 0.67 - ETA: 1:02 - loss: 1.0842 - accuracy: 0.66 - ETA: 1:01 - loss: 1.1109 - accuracy: 0.66 - ETA: 1:00 - loss: 1.1063 - accuracy: 0.66 - ETA: 59s - loss: 1.1022 - accuracy: 0.6661 - ETA: 59s - loss: 1.1063 - accuracy: 0.665 - ETA: 58s - loss: 1.1205 - accuracy: 0.662 - ETA: 57s - loss: 1.1134 - accuracy: 0.663 - ETA: 57s - loss: 1.1156 - accuracy: 0.664 - ETA: 56s - loss: 1.1295 - accuracy: 0.662 - ETA: 55s - loss: 1.1188 - accuracy: 0.664 - ETA: 55s - loss: 1.1167 - accuracy: 0.664 - ETA: 54s - loss: 1.1160 - accuracy: 0.665 - ETA: 53s - loss: 1.1250 - accuracy: 0.663 - ETA: 53s - loss: 1.1203 - accuracy: 0.666 - ETA: 52s - loss: 1.1194 - accuracy: 0.665 - ETA: 52s - loss: 1.1133 - accuracy: 0.667 - ETA: 51s - loss: 1.1126 - accuracy: 0.667 - ETA: 50s - loss: 1.1102 - accuracy: 0.668 - ETA: 50s - loss: 1.1127 - accuracy: 0.667 - ETA: 49s - loss: 1.1124 - accuracy: 0.666 - ETA: 48s - loss: 1.1150 - accuracy: 0.666 - ETA: 48s - loss: 1.1103 - accuracy: 0.668 - ETA: 47s - loss: 1.1131 - accuracy: 0.668 - ETA: 46s - loss: 1.1138 - accuracy: 0.669 - ETA: 45s - loss: 1.1102 - accuracy: 0.669 - ETA: 45s - loss: 1.1090 - accuracy: 0.670 - ETA: 44s - loss: 1.1057 - accuracy: 0.670 - ETA: 43s - loss: 1.1095 - accuracy: 0.670 - ETA: 43s - loss: 1.1082 - accuracy: 0.669 - ETA: 42s - loss: 1.1081 - accuracy: 0.669 - ETA: 41s - loss: 1.1040 - accuracy: 0.670 - ETA: 41s - loss: 1.1019 - accuracy: 0.671 - ETA: 40s - loss: 1.1103 - accuracy: 0.668 - ETA: 39s - loss: 1.1124 - accuracy: 0.667 - ETA: 38s - loss: 1.1137 - accuracy: 0.667 - ETA: 38s - loss: 1.1115 - accuracy: 0.667 - ETA: 37s - loss: 1.1097 - accuracy: 0.666 - ETA: 36s - loss: 1.1132 - accuracy: 0.665 - ETA: 36s - loss: 1.1135 - accuracy: 0.664 - ETA: 35s - loss: 1.1106 - accuracy: 0.665 - ETA: 34s - loss: 1.1121 - accuracy: 0.664 - ETA: 34s - loss: 1.1098 - accuracy: 0.665 - ETA: 33s - loss: 1.1068 - accuracy: 0.666 - ETA: 32s - loss: 1.1060 - accuracy: 0.666 - ETA: 32s - loss: 1.1037 - accuracy: 0.666 - ETA: 31s - loss: 1.0998 - accuracy: 0.667 - ETA: 30s - loss: 1.1002 - accuracy: 0.667 - ETA: 29s - loss: 1.1042 - accuracy: 0.665 - ETA: 29s - loss: 1.1031 - accuracy: 0.665 - ETA: 28s - loss: 1.1061 - accuracy: 0.664 - ETA: 27s - loss: 1.1045 - accuracy: 0.664 - ETA: 27s - loss: 1.1013 - accuracy: 0.665 - ETA: 26s - loss: 1.1005 - accuracy: 0.665 - ETA: 25s - loss: 1.1009 - accuracy: 0.665 - ETA: 25s - loss: 1.1008 - accuracy: 0.666 - ETA: 24s - loss: 1.0989 - accuracy: 0.666 - ETA: 23s - loss: 1.0985 - accuracy: 0.666 - ETA: 22s - loss: 1.0979 - accuracy: 0.666 - ETA: 22s - loss: 1.0970 - accuracy: 0.667 - ETA: 21s - loss: 1.0990 - accuracy: 0.666 - ETA: 20s - loss: 1.0979 - accuracy: 0.667 - ETA: 20s - loss: 1.0995 - accuracy: 0.668 - ETA: 19s - loss: 1.0988 - accuracy: 0.668 - ETA: 18s - loss: 1.0991 - accuracy: 0.669 - ETA: 18s - loss: 1.0974 - accuracy: 0.669 - ETA: 17s - loss: 1.0960 - accuracy: 0.670 - ETA: 16s - loss: 1.0937 - accuracy: 0.670 - ETA: 15s - loss: 1.0944 - accuracy: 0.670 - ETA: 15s - loss: 1.0951 - accuracy: 0.669 - ETA: 14s - loss: 1.0916 - accuracy: 0.670 - ETA: 13s - loss: 1.0912 - accuracy: 0.670 - ETA: 13s - loss: 1.0911 - accuracy: 0.670 - ETA: 12s - loss: 1.0918 - accuracy: 0.669 - ETA: 11s - loss: 1.0908 - accuracy: 0.670 - ETA: 11s - loss: 1.0875 - accuracy: 0.671 - ETA: 10s - loss: 1.0861 - accuracy: 0.671 - ETA: 9s - loss: 1.0869 - accuracy: 0.670 - ETA: 8s - loss: 1.0877 - accuracy: 0.67 - ETA: 8s - loss: 1.0853 - accuracy: 0.67 - ETA: 7s - loss: 1.0853 - accuracy: 0.67 - ETA: 6s - loss: 1.0875 - accuracy: 0.67 - ETA: 6s - loss: 1.0856 - accuracy: 0.67 - ETA: 5s - loss: 1.0831 - accuracy: 0.67 - ETA: 4s - loss: 1.0811 - accuracy: 0.67 - ETA: 4s - loss: 1.0808 - accuracy: 0.67 - ETA: 3s - loss: 1.0826 - accuracy: 0.67 - ETA: 2s - loss: 1.0834 - accuracy: 0.67 - ETA: 1s - loss: 1.0842 - accuracy: 0.67 - ETA: 1s - loss: 1.0837 - accuracy: 0.67 - ETA: 0s - loss: 1.0854 - accuracy: 0.67 - 82s 6ms/step - loss: 1.0855 - accuracy: 0.6721 - val_loss: 2.6635 - val_accuracy: 0.3736\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 1.1481 - accuracy: 0.61 - ETA: 1:10 - loss: 1.0080 - accuracy: 0.67 - ETA: 1:09 - loss: 1.0285 - accuracy: 0.68 - ETA: 1:09 - loss: 1.0429 - accuracy: 0.67 - ETA: 1:08 - loss: 1.0411 - accuracy: 0.67 - ETA: 1:07 - loss: 1.0426 - accuracy: 0.67 - ETA: 1:06 - loss: 1.0514 - accuracy: 0.67 - ETA: 1:06 - loss: 1.0308 - accuracy: 0.68 - ETA: 1:05 - loss: 1.0277 - accuracy: 0.68 - ETA: 1:04 - loss: 1.0226 - accuracy: 0.68 - ETA: 1:03 - loss: 1.0095 - accuracy: 0.68 - ETA: 1:02 - loss: 1.0324 - accuracy: 0.68 - ETA: 1:01 - loss: 1.0362 - accuracy: 0.68 - ETA: 1:01 - loss: 1.0357 - accuracy: 0.68 - ETA: 1:00 - loss: 1.0398 - accuracy: 0.67 - ETA: 59s - loss: 1.0396 - accuracy: 0.6758 - ETA: 59s - loss: 1.0346 - accuracy: 0.678 - ETA: 58s - loss: 1.0254 - accuracy: 0.681 - ETA: 57s - loss: 1.0183 - accuracy: 0.682 - ETA: 57s - loss: 1.0088 - accuracy: 0.685 - ETA: 56s - loss: 1.0115 - accuracy: 0.686 - ETA: 55s - loss: 1.0102 - accuracy: 0.685 - ETA: 55s - loss: 1.0118 - accuracy: 0.683 - ETA: 54s - loss: 1.0105 - accuracy: 0.684 - ETA: 53s - loss: 1.0193 - accuracy: 0.680 - ETA: 52s - loss: 1.0361 - accuracy: 0.674 - ETA: 52s - loss: 1.0342 - accuracy: 0.675 - ETA: 51s - loss: 1.0329 - accuracy: 0.675 - ETA: 50s - loss: 1.0256 - accuracy: 0.678 - ETA: 50s - loss: 1.0196 - accuracy: 0.679 - ETA: 49s - loss: 1.0191 - accuracy: 0.678 - ETA: 48s - loss: 1.0260 - accuracy: 0.677 - ETA: 48s - loss: 1.0265 - accuracy: 0.676 - ETA: 47s - loss: 1.0208 - accuracy: 0.678 - ETA: 46s - loss: 1.0178 - accuracy: 0.679 - ETA: 46s - loss: 1.0198 - accuracy: 0.679 - ETA: 45s - loss: 1.0186 - accuracy: 0.680 - ETA: 44s - loss: 1.0164 - accuracy: 0.680 - ETA: 43s - loss: 1.0105 - accuracy: 0.681 - ETA: 43s - loss: 1.0134 - accuracy: 0.681 - ETA: 42s - loss: 1.0199 - accuracy: 0.680 - ETA: 41s - loss: 1.0218 - accuracy: 0.679 - ETA: 41s - loss: 1.0209 - accuracy: 0.679 - ETA: 40s - loss: 1.0218 - accuracy: 0.679 - ETA: 39s - loss: 1.0217 - accuracy: 0.678 - ETA: 39s - loss: 1.0231 - accuracy: 0.678 - ETA: 38s - loss: 1.0234 - accuracy: 0.679 - ETA: 37s - loss: 1.0216 - accuracy: 0.680 - ETA: 37s - loss: 1.0264 - accuracy: 0.678 - ETA: 36s - loss: 1.0237 - accuracy: 0.679 - ETA: 35s - loss: 1.0216 - accuracy: 0.679 - ETA: 34s - loss: 1.0205 - accuracy: 0.680 - ETA: 34s - loss: 1.0260 - accuracy: 0.679 - ETA: 33s - loss: 1.0309 - accuracy: 0.677 - ETA: 32s - loss: 1.0321 - accuracy: 0.677 - ETA: 32s - loss: 1.0373 - accuracy: 0.677 - ETA: 31s - loss: 1.0410 - accuracy: 0.676 - ETA: 30s - loss: 1.0392 - accuracy: 0.676 - ETA: 29s - loss: 1.0389 - accuracy: 0.676 - ETA: 29s - loss: 1.0409 - accuracy: 0.677 - ETA: 28s - loss: 1.0386 - accuracy: 0.677 - ETA: 27s - loss: 1.0377 - accuracy: 0.677 - ETA: 27s - loss: 1.0376 - accuracy: 0.678 - ETA: 26s - loss: 1.0388 - accuracy: 0.678 - ETA: 25s - loss: 1.0390 - accuracy: 0.678 - ETA: 24s - loss: 1.0418 - accuracy: 0.678 - ETA: 24s - loss: 1.0396 - accuracy: 0.678 - ETA: 23s - loss: 1.0392 - accuracy: 0.679 - ETA: 22s - loss: 1.0406 - accuracy: 0.678 - ETA: 22s - loss: 1.0438 - accuracy: 0.677 - ETA: 21s - loss: 1.0435 - accuracy: 0.678 - ETA: 20s - loss: 1.0461 - accuracy: 0.677 - ETA: 20s - loss: 1.0458 - accuracy: 0.677 - ETA: 19s - loss: 1.0425 - accuracy: 0.678 - ETA: 18s - loss: 1.0401 - accuracy: 0.678 - ETA: 17s - loss: 1.0428 - accuracy: 0.678 - ETA: 17s - loss: 1.0426 - accuracy: 0.678 - ETA: 16s - loss: 1.0414 - accuracy: 0.678 - ETA: 15s - loss: 1.0406 - accuracy: 0.678 - ETA: 15s - loss: 1.0409 - accuracy: 0.678 - ETA: 14s - loss: 1.0388 - accuracy: 0.679 - ETA: 13s - loss: 1.0395 - accuracy: 0.679 - ETA: 13s - loss: 1.0402 - accuracy: 0.679 - ETA: 12s - loss: 1.0408 - accuracy: 0.679 - ETA: 11s - loss: 1.0427 - accuracy: 0.678 - ETA: 10s - loss: 1.0426 - accuracy: 0.678 - ETA: 10s - loss: 1.0426 - accuracy: 0.678 - ETA: 9s - loss: 1.0424 - accuracy: 0.678 - ETA: 8s - loss: 1.0410 - accuracy: 0.67 - ETA: 8s - loss: 1.0401 - accuracy: 0.67 - ETA: 7s - loss: 1.0373 - accuracy: 0.67 - ETA: 6s - loss: 1.0350 - accuracy: 0.68 - ETA: 6s - loss: 1.0362 - accuracy: 0.68 - ETA: 5s - loss: 1.0360 - accuracy: 0.67 - ETA: 4s - loss: 1.0334 - accuracy: 0.68 - ETA: 4s - loss: 1.0335 - accuracy: 0.67 - ETA: 3s - loss: 1.0327 - accuracy: 0.68 - ETA: 2s - loss: 1.0327 - accuracy: 0.68 - ETA: 1s - loss: 1.0325 - accuracy: 0.68 - ETA: 1s - loss: 1.0322 - accuracy: 0.68 - ETA: 0s - loss: 1.0328 - accuracy: 0.67 - 83s 6ms/step - loss: 1.0346 - accuracy: 0.6793 - val_loss: 2.6771 - val_accuracy: 0.3320\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.8160 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8360 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9301 - accuracy: 0.72 - ETA: 1:08 - loss: 0.9173 - accuracy: 0.71 - ETA: 1:07 - loss: 0.9674 - accuracy: 0.69 - ETA: 1:07 - loss: 0.9694 - accuracy: 0.68 - ETA: 1:06 - loss: 0.9655 - accuracy: 0.68 - ETA: 1:05 - loss: 0.9828 - accuracy: 0.68 - ETA: 1:04 - loss: 0.9984 - accuracy: 0.68 - ETA: 1:04 - loss: 1.0127 - accuracy: 0.68 - ETA: 1:03 - loss: 1.0184 - accuracy: 0.68 - ETA: 1:02 - loss: 1.0224 - accuracy: 0.68 - ETA: 1:01 - loss: 1.0200 - accuracy: 0.68 - ETA: 1:01 - loss: 1.0218 - accuracy: 0.68 - ETA: 1:00 - loss: 1.0106 - accuracy: 0.68 - ETA: 59s - loss: 1.0110 - accuracy: 0.6851 - ETA: 58s - loss: 1.0186 - accuracy: 0.682 - ETA: 58s - loss: 1.0170 - accuracy: 0.683 - ETA: 57s - loss: 1.0209 - accuracy: 0.684 - ETA: 57s - loss: 1.0145 - accuracy: 0.684 - ETA: 56s - loss: 1.0091 - accuracy: 0.687 - ETA: 55s - loss: 1.0069 - accuracy: 0.687 - ETA: 55s - loss: 1.0102 - accuracy: 0.685 - ETA: 54s - loss: 1.0012 - accuracy: 0.686 - ETA: 54s - loss: 1.0008 - accuracy: 0.686 - ETA: 53s - loss: 1.0023 - accuracy: 0.688 - ETA: 52s - loss: 1.0067 - accuracy: 0.686 - ETA: 51s - loss: 1.0008 - accuracy: 0.687 - ETA: 51s - loss: 0.9989 - accuracy: 0.687 - ETA: 50s - loss: 0.9998 - accuracy: 0.687 - ETA: 49s - loss: 0.9958 - accuracy: 0.688 - ETA: 48s - loss: 0.9941 - accuracy: 0.689 - ETA: 48s - loss: 0.9958 - accuracy: 0.688 - ETA: 47s - loss: 0.9984 - accuracy: 0.688 - ETA: 46s - loss: 0.9974 - accuracy: 0.688 - ETA: 45s - loss: 0.9884 - accuracy: 0.690 - ETA: 45s - loss: 0.9896 - accuracy: 0.690 - ETA: 44s - loss: 0.9936 - accuracy: 0.690 - ETA: 43s - loss: 0.9924 - accuracy: 0.690 - ETA: 43s - loss: 0.9933 - accuracy: 0.691 - ETA: 42s - loss: 0.9950 - accuracy: 0.690 - ETA: 41s - loss: 0.9902 - accuracy: 0.690 - ETA: 41s - loss: 0.9952 - accuracy: 0.689 - ETA: 40s - loss: 0.9994 - accuracy: 0.687 - ETA: 39s - loss: 1.0016 - accuracy: 0.687 - ETA: 39s - loss: 0.9982 - accuracy: 0.687 - ETA: 38s - loss: 0.9945 - accuracy: 0.689 - ETA: 37s - loss: 0.9933 - accuracy: 0.689 - ETA: 36s - loss: 0.9940 - accuracy: 0.688 - ETA: 36s - loss: 0.9957 - accuracy: 0.688 - ETA: 35s - loss: 1.0000 - accuracy: 0.687 - ETA: 34s - loss: 0.9986 - accuracy: 0.687 - ETA: 34s - loss: 1.0004 - accuracy: 0.686 - ETA: 33s - loss: 1.0005 - accuracy: 0.686 - ETA: 32s - loss: 0.9975 - accuracy: 0.686 - ETA: 31s - loss: 0.9970 - accuracy: 0.686 - ETA: 31s - loss: 1.0028 - accuracy: 0.687 - ETA: 30s - loss: 0.9998 - accuracy: 0.687 - ETA: 29s - loss: 0.9959 - accuracy: 0.689 - ETA: 29s - loss: 0.9950 - accuracy: 0.690 - ETA: 28s - loss: 0.9971 - accuracy: 0.689 - ETA: 27s - loss: 0.9988 - accuracy: 0.689 - ETA: 27s - loss: 1.0000 - accuracy: 0.689 - ETA: 26s - loss: 1.0017 - accuracy: 0.689 - ETA: 25s - loss: 1.0050 - accuracy: 0.688 - ETA: 24s - loss: 1.0062 - accuracy: 0.688 - ETA: 24s - loss: 1.0074 - accuracy: 0.687 - ETA: 23s - loss: 1.0061 - accuracy: 0.687 - ETA: 22s - loss: 1.0065 - accuracy: 0.686 - ETA: 22s - loss: 1.0082 - accuracy: 0.686 - ETA: 21s - loss: 1.0106 - accuracy: 0.686 - ETA: 20s - loss: 1.0099 - accuracy: 0.686 - ETA: 20s - loss: 1.0100 - accuracy: 0.686 - ETA: 19s - loss: 1.0119 - accuracy: 0.686 - ETA: 18s - loss: 1.0119 - accuracy: 0.687 - ETA: 17s - loss: 1.0116 - accuracy: 0.687 - ETA: 17s - loss: 1.0117 - accuracy: 0.687 - ETA: 16s - loss: 1.0144 - accuracy: 0.686 - ETA: 15s - loss: 1.0145 - accuracy: 0.686 - ETA: 15s - loss: 1.0127 - accuracy: 0.686 - ETA: 14s - loss: 1.0126 - accuracy: 0.686 - ETA: 13s - loss: 1.0112 - accuracy: 0.686 - ETA: 13s - loss: 1.0112 - accuracy: 0.686 - ETA: 12s - loss: 1.0087 - accuracy: 0.687 - ETA: 11s - loss: 1.0089 - accuracy: 0.688 - ETA: 10s - loss: 1.0130 - accuracy: 0.687 - ETA: 10s - loss: 1.0147 - accuracy: 0.687 - ETA: 9s - loss: 1.0151 - accuracy: 0.687 - ETA: 8s - loss: 1.0140 - accuracy: 0.68 - ETA: 8s - loss: 1.0137 - accuracy: 0.68 - ETA: 7s - loss: 1.0133 - accuracy: 0.68 - ETA: 6s - loss: 1.0124 - accuracy: 0.68 - ETA: 6s - loss: 1.0140 - accuracy: 0.68 - ETA: 5s - loss: 1.0164 - accuracy: 0.68 - ETA: 4s - loss: 1.0153 - accuracy: 0.68 - ETA: 3s - loss: 1.0134 - accuracy: 0.68 - ETA: 3s - loss: 1.0153 - accuracy: 0.68 - ETA: 2s - loss: 1.0175 - accuracy: 0.68 - ETA: 1s - loss: 1.0172 - accuracy: 0.68 - ETA: 1s - loss: 1.0194 - accuracy: 0.68 - ETA: 0s - loss: 1.0194 - accuracy: 0.68 - 81s 6ms/step - loss: 1.0189 - accuracy: 0.6878 - val_loss: 2.6954 - val_accuracy: 0.3485\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:16 - loss: 1.0491 - accuracy: 0.65 - ETA: 1:12 - loss: 0.9928 - accuracy: 0.66 - ETA: 1:09 - loss: 0.9863 - accuracy: 0.67 - ETA: 1:09 - loss: 1.0064 - accuracy: 0.67 - ETA: 1:08 - loss: 1.0286 - accuracy: 0.67 - ETA: 1:07 - loss: 1.0171 - accuracy: 0.67 - ETA: 1:05 - loss: 1.0191 - accuracy: 0.67 - ETA: 1:05 - loss: 1.0177 - accuracy: 0.67 - ETA: 1:04 - loss: 1.0174 - accuracy: 0.68 - ETA: 1:03 - loss: 0.9919 - accuracy: 0.69 - ETA: 1:02 - loss: 0.9891 - accuracy: 0.70 - ETA: 1:02 - loss: 1.0021 - accuracy: 0.69 - ETA: 1:01 - loss: 1.0030 - accuracy: 0.69 - ETA: 1:01 - loss: 1.0046 - accuracy: 0.69 - ETA: 1:00 - loss: 1.0036 - accuracy: 0.69 - ETA: 59s - loss: 1.0070 - accuracy: 0.6929 - ETA: 58s - loss: 1.0071 - accuracy: 0.693 - ETA: 58s - loss: 1.0060 - accuracy: 0.692 - ETA: 57s - loss: 0.9947 - accuracy: 0.694 - ETA: 56s - loss: 0.9997 - accuracy: 0.694 - ETA: 56s - loss: 0.9996 - accuracy: 0.694 - ETA: 55s - loss: 0.9975 - accuracy: 0.694 - ETA: 54s - loss: 1.0010 - accuracy: 0.692 - ETA: 54s - loss: 0.9964 - accuracy: 0.694 - ETA: 53s - loss: 1.0036 - accuracy: 0.694 - ETA: 52s - loss: 1.0101 - accuracy: 0.695 - ETA: 52s - loss: 1.0050 - accuracy: 0.696 - ETA: 51s - loss: 1.0119 - accuracy: 0.695 - ETA: 50s - loss: 1.0056 - accuracy: 0.696 - ETA: 50s - loss: 1.0022 - accuracy: 0.696 - ETA: 49s - loss: 0.9970 - accuracy: 0.697 - ETA: 48s - loss: 0.9974 - accuracy: 0.697 - ETA: 48s - loss: 1.0016 - accuracy: 0.697 - ETA: 47s - loss: 1.0076 - accuracy: 0.696 - ETA: 46s - loss: 1.0014 - accuracy: 0.698 - ETA: 45s - loss: 0.9987 - accuracy: 0.699 - ETA: 45s - loss: 0.9992 - accuracy: 0.698 - ETA: 44s - loss: 0.9993 - accuracy: 0.698 - ETA: 43s - loss: 1.0001 - accuracy: 0.697 - ETA: 43s - loss: 1.0062 - accuracy: 0.697 - ETA: 42s - loss: 1.0088 - accuracy: 0.696 - ETA: 41s - loss: 1.0145 - accuracy: 0.693 - ETA: 40s - loss: 1.0142 - accuracy: 0.694 - ETA: 40s - loss: 1.0096 - accuracy: 0.695 - ETA: 39s - loss: 1.0118 - accuracy: 0.694 - ETA: 38s - loss: 1.0172 - accuracy: 0.694 - ETA: 38s - loss: 1.0188 - accuracy: 0.693 - ETA: 37s - loss: 1.0142 - accuracy: 0.694 - ETA: 36s - loss: 1.0132 - accuracy: 0.695 - ETA: 36s - loss: 1.0119 - accuracy: 0.695 - ETA: 35s - loss: 1.0110 - accuracy: 0.696 - ETA: 34s - loss: 1.0071 - accuracy: 0.697 - ETA: 34s - loss: 1.0042 - accuracy: 0.698 - ETA: 33s - loss: 1.0042 - accuracy: 0.697 - ETA: 32s - loss: 1.0059 - accuracy: 0.697 - ETA: 31s - loss: 1.0049 - accuracy: 0.697 - ETA: 31s - loss: 1.0044 - accuracy: 0.696 - ETA: 30s - loss: 1.0048 - accuracy: 0.695 - ETA: 29s - loss: 1.0051 - accuracy: 0.695 - ETA: 29s - loss: 1.0026 - accuracy: 0.695 - ETA: 28s - loss: 1.0033 - accuracy: 0.695 - ETA: 27s - loss: 1.0048 - accuracy: 0.694 - ETA: 26s - loss: 1.0065 - accuracy: 0.693 - ETA: 26s - loss: 1.0078 - accuracy: 0.692 - ETA: 25s - loss: 1.0053 - accuracy: 0.692 - ETA: 24s - loss: 1.0080 - accuracy: 0.692 - ETA: 24s - loss: 1.0055 - accuracy: 0.693 - ETA: 23s - loss: 1.0045 - accuracy: 0.693 - ETA: 22s - loss: 1.0035 - accuracy: 0.693 - ETA: 22s - loss: 1.0051 - accuracy: 0.693 - ETA: 21s - loss: 1.0063 - accuracy: 0.693 - ETA: 20s - loss: 1.0068 - accuracy: 0.693 - ETA: 20s - loss: 1.0087 - accuracy: 0.692 - ETA: 19s - loss: 1.0051 - accuracy: 0.693 - ETA: 18s - loss: 1.0062 - accuracy: 0.692 - ETA: 17s - loss: 1.0090 - accuracy: 0.691 - ETA: 17s - loss: 1.0104 - accuracy: 0.690 - ETA: 16s - loss: 1.0113 - accuracy: 0.690 - ETA: 15s - loss: 1.0117 - accuracy: 0.690 - ETA: 15s - loss: 1.0103 - accuracy: 0.690 - ETA: 14s - loss: 1.0084 - accuracy: 0.691 - ETA: 13s - loss: 1.0090 - accuracy: 0.690 - ETA: 13s - loss: 1.0085 - accuracy: 0.690 - ETA: 12s - loss: 1.0079 - accuracy: 0.690 - ETA: 11s - loss: 1.0055 - accuracy: 0.691 - ETA: 10s - loss: 1.0038 - accuracy: 0.691 - ETA: 10s - loss: 1.0028 - accuracy: 0.692 - ETA: 9s - loss: 1.0048 - accuracy: 0.691 - ETA: 8s - loss: 1.0063 - accuracy: 0.69 - ETA: 8s - loss: 1.0047 - accuracy: 0.69 - ETA: 7s - loss: 1.0071 - accuracy: 0.69 - ETA: 6s - loss: 1.0078 - accuracy: 0.69 - ETA: 6s - loss: 1.0066 - accuracy: 0.69 - ETA: 5s - loss: 1.0094 - accuracy: 0.69 - ETA: 4s - loss: 1.0105 - accuracy: 0.69 - ETA: 3s - loss: 1.0113 - accuracy: 0.68 - ETA: 3s - loss: 1.0104 - accuracy: 0.69 - ETA: 2s - loss: 1.0100 - accuracy: 0.69 - ETA: 1s - loss: 1.0091 - accuracy: 0.69 - ETA: 1s - loss: 1.0089 - accuracy: 0.69 - ETA: 0s - loss: 1.0105 - accuracy: 0.69 - 82s 6ms/step - loss: 1.0108 - accuracy: 0.6904 - val_loss: 2.6672 - val_accuracy: 0.3641\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.8784 - accuracy: 0.73 - ETA: 1:10 - loss: 0.8826 - accuracy: 0.73 - ETA: 1:08 - loss: 0.9073 - accuracy: 0.70 - ETA: 1:08 - loss: 0.9065 - accuracy: 0.70 - ETA: 1:06 - loss: 0.9286 - accuracy: 0.70 - ETA: 1:05 - loss: 0.9234 - accuracy: 0.69 - ETA: 1:04 - loss: 0.9297 - accuracy: 0.69 - ETA: 1:04 - loss: 0.9465 - accuracy: 0.69 - ETA: 1:03 - loss: 0.9647 - accuracy: 0.68 - ETA: 1:03 - loss: 0.9569 - accuracy: 0.68 - ETA: 1:03 - loss: 0.9578 - accuracy: 0.68 - ETA: 1:02 - loss: 0.9520 - accuracy: 0.69 - ETA: 1:01 - loss: 0.9577 - accuracy: 0.68 - ETA: 1:00 - loss: 0.9676 - accuracy: 0.68 - ETA: 59s - loss: 0.9758 - accuracy: 0.6854 - ETA: 59s - loss: 0.9752 - accuracy: 0.686 - ETA: 58s - loss: 0.9760 - accuracy: 0.686 - ETA: 57s - loss: 0.9758 - accuracy: 0.686 - ETA: 57s - loss: 0.9862 - accuracy: 0.687 - ETA: 56s - loss: 0.9818 - accuracy: 0.689 - ETA: 56s - loss: 0.9745 - accuracy: 0.689 - ETA: 55s - loss: 0.9836 - accuracy: 0.687 - ETA: 54s - loss: 0.9877 - accuracy: 0.689 - ETA: 54s - loss: 0.9873 - accuracy: 0.689 - ETA: 53s - loss: 0.9833 - accuracy: 0.692 - ETA: 52s - loss: 0.9789 - accuracy: 0.693 - ETA: 52s - loss: 0.9768 - accuracy: 0.693 - ETA: 51s - loss: 0.9700 - accuracy: 0.695 - ETA: 50s - loss: 0.9713 - accuracy: 0.694 - ETA: 49s - loss: 0.9679 - accuracy: 0.695 - ETA: 49s - loss: 0.9668 - accuracy: 0.696 - ETA: 48s - loss: 0.9699 - accuracy: 0.695 - ETA: 47s - loss: 0.9679 - accuracy: 0.694 - ETA: 47s - loss: 0.9676 - accuracy: 0.694 - ETA: 46s - loss: 0.9641 - accuracy: 0.695 - ETA: 45s - loss: 0.9678 - accuracy: 0.694 - ETA: 45s - loss: 0.9687 - accuracy: 0.693 - ETA: 44s - loss: 0.9623 - accuracy: 0.694 - ETA: 43s - loss: 0.9624 - accuracy: 0.695 - ETA: 42s - loss: 0.9654 - accuracy: 0.694 - ETA: 42s - loss: 0.9660 - accuracy: 0.694 - ETA: 41s - loss: 0.9650 - accuracy: 0.695 - ETA: 40s - loss: 0.9678 - accuracy: 0.694 - ETA: 40s - loss: 0.9692 - accuracy: 0.694 - ETA: 39s - loss: 0.9650 - accuracy: 0.696 - ETA: 38s - loss: 0.9653 - accuracy: 0.696 - ETA: 38s - loss: 0.9663 - accuracy: 0.696 - ETA: 37s - loss: 0.9650 - accuracy: 0.696 - ETA: 36s - loss: 0.9646 - accuracy: 0.696 - ETA: 36s - loss: 0.9632 - accuracy: 0.697 - ETA: 35s - loss: 0.9661 - accuracy: 0.696 - ETA: 34s - loss: 0.9654 - accuracy: 0.696 - ETA: 33s - loss: 0.9651 - accuracy: 0.697 - ETA: 33s - loss: 0.9642 - accuracy: 0.697 - ETA: 32s - loss: 0.9646 - accuracy: 0.698 - ETA: 31s - loss: 0.9638 - accuracy: 0.698 - ETA: 31s - loss: 0.9588 - accuracy: 0.699 - ETA: 30s - loss: 0.9614 - accuracy: 0.697 - ETA: 29s - loss: 0.9600 - accuracy: 0.697 - ETA: 29s - loss: 0.9593 - accuracy: 0.697 - ETA: 28s - loss: 0.9603 - accuracy: 0.698 - ETA: 27s - loss: 0.9609 - accuracy: 0.697 - ETA: 27s - loss: 0.9626 - accuracy: 0.697 - ETA: 26s - loss: 0.9609 - accuracy: 0.697 - ETA: 25s - loss: 0.9593 - accuracy: 0.698 - ETA: 24s - loss: 0.9604 - accuracy: 0.698 - ETA: 24s - loss: 0.9597 - accuracy: 0.698 - ETA: 23s - loss: 0.9571 - accuracy: 0.699 - ETA: 22s - loss: 0.9574 - accuracy: 0.699 - ETA: 22s - loss: 0.9572 - accuracy: 0.699 - ETA: 21s - loss: 0.9623 - accuracy: 0.698 - ETA: 20s - loss: 0.9618 - accuracy: 0.698 - ETA: 20s - loss: 0.9611 - accuracy: 0.699 - ETA: 19s - loss: 0.9628 - accuracy: 0.698 - ETA: 18s - loss: 0.9637 - accuracy: 0.698 - ETA: 18s - loss: 0.9630 - accuracy: 0.698 - ETA: 17s - loss: 0.9641 - accuracy: 0.698 - ETA: 16s - loss: 0.9639 - accuracy: 0.698 - ETA: 15s - loss: 0.9653 - accuracy: 0.698 - ETA: 15s - loss: 0.9650 - accuracy: 0.699 - ETA: 14s - loss: 0.9690 - accuracy: 0.697 - ETA: 13s - loss: 0.9712 - accuracy: 0.697 - ETA: 13s - loss: 0.9669 - accuracy: 0.699 - ETA: 12s - loss: 0.9689 - accuracy: 0.698 - ETA: 11s - loss: 0.9686 - accuracy: 0.698 - ETA: 10s - loss: 0.9662 - accuracy: 0.699 - ETA: 10s - loss: 0.9647 - accuracy: 0.699 - ETA: 9s - loss: 0.9632 - accuracy: 0.700 - ETA: 8s - loss: 0.9641 - accuracy: 0.69 - ETA: 8s - loss: 0.9640 - accuracy: 0.69 - ETA: 7s - loss: 0.9603 - accuracy: 0.70 - ETA: 6s - loss: 0.9613 - accuracy: 0.70 - ETA: 6s - loss: 0.9634 - accuracy: 0.69 - ETA: 5s - loss: 0.9653 - accuracy: 0.69 - ETA: 4s - loss: 0.9666 - accuracy: 0.69 - ETA: 4s - loss: 0.9662 - accuracy: 0.69 - ETA: 3s - loss: 0.9666 - accuracy: 0.69 - ETA: 2s - loss: 0.9657 - accuracy: 0.69 - ETA: 1s - loss: 0.9654 - accuracy: 0.69 - ETA: 1s - loss: 0.9645 - accuracy: 0.69 - ETA: 0s - loss: 0.9647 - accuracy: 0.69 - 82s 6ms/step - loss: 0.9658 - accuracy: 0.6985 - val_loss: 2.7943 - val_accuracy: 0.3384\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.8437 - accuracy: 0.72 - ETA: 1:10 - loss: 0.8009 - accuracy: 0.74 - ETA: 1:08 - loss: 0.8495 - accuracy: 0.72 - ETA: 1:08 - loss: 0.8144 - accuracy: 0.74 - ETA: 1:07 - loss: 0.8847 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8982 - accuracy: 0.72 - ETA: 1:06 - loss: 0.8727 - accuracy: 0.72 - ETA: 1:05 - loss: 0.8862 - accuracy: 0.72 - ETA: 1:04 - loss: 0.8997 - accuracy: 0.71 - ETA: 1:03 - loss: 0.8923 - accuracy: 0.71 - ETA: 1:03 - loss: 0.8985 - accuracy: 0.71 - ETA: 1:02 - loss: 0.9097 - accuracy: 0.71 - ETA: 1:01 - loss: 0.9133 - accuracy: 0.71 - ETA: 1:01 - loss: 0.9303 - accuracy: 0.71 - ETA: 1:00 - loss: 0.9263 - accuracy: 0.71 - ETA: 59s - loss: 0.9195 - accuracy: 0.7104 - ETA: 59s - loss: 0.9167 - accuracy: 0.710 - ETA: 58s - loss: 0.9146 - accuracy: 0.713 - ETA: 58s - loss: 0.9129 - accuracy: 0.714 - ETA: 57s - loss: 0.9250 - accuracy: 0.711 - ETA: 56s - loss: 0.9317 - accuracy: 0.709 - ETA: 55s - loss: 0.9275 - accuracy: 0.711 - ETA: 54s - loss: 0.9223 - accuracy: 0.712 - ETA: 54s - loss: 0.9220 - accuracy: 0.712 - ETA: 53s - loss: 0.9267 - accuracy: 0.711 - ETA: 52s - loss: 0.9231 - accuracy: 0.711 - ETA: 52s - loss: 0.9186 - accuracy: 0.713 - ETA: 51s - loss: 0.9252 - accuracy: 0.709 - ETA: 50s - loss: 0.9164 - accuracy: 0.712 - ETA: 50s - loss: 0.9171 - accuracy: 0.713 - ETA: 49s - loss: 0.9105 - accuracy: 0.714 - ETA: 48s - loss: 0.9070 - accuracy: 0.715 - ETA: 47s - loss: 0.9069 - accuracy: 0.715 - ETA: 47s - loss: 0.9123 - accuracy: 0.714 - ETA: 46s - loss: 0.9177 - accuracy: 0.712 - ETA: 45s - loss: 0.9233 - accuracy: 0.710 - ETA: 44s - loss: 0.9185 - accuracy: 0.711 - ETA: 44s - loss: 0.9190 - accuracy: 0.712 - ETA: 43s - loss: 0.9135 - accuracy: 0.713 - ETA: 42s - loss: 0.9118 - accuracy: 0.714 - ETA: 42s - loss: 0.9114 - accuracy: 0.713 - ETA: 41s - loss: 0.9119 - accuracy: 0.715 - ETA: 40s - loss: 0.9098 - accuracy: 0.715 - ETA: 40s - loss: 0.9123 - accuracy: 0.714 - ETA: 39s - loss: 0.9165 - accuracy: 0.713 - ETA: 38s - loss: 0.9198 - accuracy: 0.711 - ETA: 38s - loss: 0.9236 - accuracy: 0.710 - ETA: 37s - loss: 0.9214 - accuracy: 0.710 - ETA: 36s - loss: 0.9223 - accuracy: 0.710 - ETA: 36s - loss: 0.9209 - accuracy: 0.711 - ETA: 35s - loss: 0.9208 - accuracy: 0.711 - ETA: 34s - loss: 0.9179 - accuracy: 0.711 - ETA: 34s - loss: 0.9191 - accuracy: 0.710 - ETA: 33s - loss: 0.9249 - accuracy: 0.708 - ETA: 32s - loss: 0.9271 - accuracy: 0.708 - ETA: 31s - loss: 0.9295 - accuracy: 0.708 - ETA: 31s - loss: 0.9301 - accuracy: 0.707 - ETA: 30s - loss: 0.9305 - accuracy: 0.707 - ETA: 29s - loss: 0.9308 - accuracy: 0.707 - ETA: 29s - loss: 0.9303 - accuracy: 0.708 - ETA: 28s - loss: 0.9290 - accuracy: 0.708 - ETA: 27s - loss: 0.9303 - accuracy: 0.707 - ETA: 27s - loss: 0.9338 - accuracy: 0.706 - ETA: 26s - loss: 0.9322 - accuracy: 0.706 - ETA: 25s - loss: 0.9330 - accuracy: 0.706 - ETA: 25s - loss: 0.9328 - accuracy: 0.706 - ETA: 24s - loss: 0.9311 - accuracy: 0.706 - ETA: 23s - loss: 0.9296 - accuracy: 0.707 - ETA: 22s - loss: 0.9283 - accuracy: 0.707 - ETA: 22s - loss: 0.9313 - accuracy: 0.708 - ETA: 21s - loss: 0.9332 - accuracy: 0.707 - ETA: 20s - loss: 0.9297 - accuracy: 0.708 - ETA: 20s - loss: 0.9280 - accuracy: 0.708 - ETA: 19s - loss: 0.9285 - accuracy: 0.708 - ETA: 18s - loss: 0.9296 - accuracy: 0.707 - ETA: 17s - loss: 0.9313 - accuracy: 0.707 - ETA: 17s - loss: 0.9318 - accuracy: 0.707 - ETA: 16s - loss: 0.9357 - accuracy: 0.705 - ETA: 15s - loss: 0.9353 - accuracy: 0.705 - ETA: 15s - loss: 0.9320 - accuracy: 0.706 - ETA: 14s - loss: 0.9337 - accuracy: 0.707 - ETA: 13s - loss: 0.9314 - accuracy: 0.707 - ETA: 13s - loss: 0.9326 - accuracy: 0.707 - ETA: 12s - loss: 0.9323 - accuracy: 0.707 - ETA: 11s - loss: 0.9320 - accuracy: 0.706 - ETA: 10s - loss: 0.9309 - accuracy: 0.707 - ETA: 10s - loss: 0.9306 - accuracy: 0.706 - ETA: 9s - loss: 0.9350 - accuracy: 0.705 - ETA: 8s - loss: 0.9367 - accuracy: 0.70 - ETA: 8s - loss: 0.9346 - accuracy: 0.70 - ETA: 7s - loss: 0.9345 - accuracy: 0.70 - ETA: 6s - loss: 0.9369 - accuracy: 0.70 - ETA: 6s - loss: 0.9370 - accuracy: 0.70 - ETA: 5s - loss: 0.9370 - accuracy: 0.70 - ETA: 4s - loss: 0.9364 - accuracy: 0.70 - ETA: 3s - loss: 0.9362 - accuracy: 0.70 - ETA: 3s - loss: 0.9370 - accuracy: 0.70 - ETA: 2s - loss: 0.9387 - accuracy: 0.70 - ETA: 1s - loss: 0.9396 - accuracy: 0.70 - ETA: 1s - loss: 0.9399 - accuracy: 0.70 - ETA: 0s - loss: 0.9410 - accuracy: 0.70 - 82s 6ms/step - loss: 0.9429 - accuracy: 0.7032 - val_loss: 2.7234 - val_accuracy: 0.3229\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 1.0413 - accuracy: 0.68 - ETA: 1:09 - loss: 0.9178 - accuracy: 0.72 - ETA: 1:10 - loss: 0.9743 - accuracy: 0.70 - ETA: 1:10 - loss: 0.9631 - accuracy: 0.69 - ETA: 1:08 - loss: 0.9487 - accuracy: 0.70 - ETA: 1:08 - loss: 0.9718 - accuracy: 0.68 - ETA: 1:07 - loss: 0.9642 - accuracy: 0.68 - ETA: 1:06 - loss: 0.9397 - accuracy: 0.69 - ETA: 1:05 - loss: 0.9322 - accuracy: 0.70 - ETA: 1:04 - loss: 0.9294 - accuracy: 0.70 - ETA: 1:03 - loss: 0.9085 - accuracy: 0.71 - ETA: 1:02 - loss: 0.9013 - accuracy: 0.71 - ETA: 1:01 - loss: 0.9017 - accuracy: 0.71 - ETA: 1:01 - loss: 0.9044 - accuracy: 0.71 - ETA: 1:00 - loss: 0.9111 - accuracy: 0.71 - ETA: 1:00 - loss: 0.9178 - accuracy: 0.71 - ETA: 59s - loss: 0.9293 - accuracy: 0.7082 - ETA: 58s - loss: 0.9508 - accuracy: 0.704 - ETA: 58s - loss: 0.9486 - accuracy: 0.704 - ETA: 57s - loss: 0.9522 - accuracy: 0.703 - ETA: 56s - loss: 0.9499 - accuracy: 0.705 - ETA: 55s - loss: 0.9453 - accuracy: 0.707 - ETA: 55s - loss: 0.9490 - accuracy: 0.707 - ETA: 54s - loss: 0.9542 - accuracy: 0.706 - ETA: 54s - loss: 0.9530 - accuracy: 0.707 - ETA: 53s - loss: 0.9542 - accuracy: 0.707 - ETA: 52s - loss: 0.9515 - accuracy: 0.707 - ETA: 51s - loss: 0.9492 - accuracy: 0.707 - ETA: 51s - loss: 0.9519 - accuracy: 0.705 - ETA: 50s - loss: 0.9511 - accuracy: 0.705 - ETA: 49s - loss: 0.9461 - accuracy: 0.705 - ETA: 48s - loss: 0.9455 - accuracy: 0.707 - ETA: 48s - loss: 0.9402 - accuracy: 0.707 - ETA: 47s - loss: 0.9361 - accuracy: 0.709 - ETA: 46s - loss: 0.9337 - accuracy: 0.710 - ETA: 46s - loss: 0.9350 - accuracy: 0.711 - ETA: 45s - loss: 0.9354 - accuracy: 0.711 - ETA: 44s - loss: 0.9365 - accuracy: 0.711 - ETA: 44s - loss: 0.9327 - accuracy: 0.712 - ETA: 43s - loss: 0.9425 - accuracy: 0.710 - ETA: 42s - loss: 0.9432 - accuracy: 0.710 - ETA: 41s - loss: 0.9424 - accuracy: 0.710 - ETA: 41s - loss: 0.9426 - accuracy: 0.709 - ETA: 40s - loss: 0.9430 - accuracy: 0.709 - ETA: 39s - loss: 0.9415 - accuracy: 0.709 - ETA: 39s - loss: 0.9368 - accuracy: 0.710 - ETA: 38s - loss: 0.9364 - accuracy: 0.710 - ETA: 37s - loss: 0.9333 - accuracy: 0.711 - ETA: 36s - loss: 0.9330 - accuracy: 0.710 - ETA: 36s - loss: 0.9332 - accuracy: 0.711 - ETA: 35s - loss: 0.9287 - accuracy: 0.712 - ETA: 34s - loss: 0.9282 - accuracy: 0.713 - ETA: 34s - loss: 0.9296 - accuracy: 0.713 - ETA: 33s - loss: 0.9307 - accuracy: 0.714 - ETA: 32s - loss: 0.9305 - accuracy: 0.714 - ETA: 31s - loss: 0.9299 - accuracy: 0.714 - ETA: 31s - loss: 0.9321 - accuracy: 0.714 - ETA: 30s - loss: 0.9349 - accuracy: 0.714 - ETA: 29s - loss: 0.9349 - accuracy: 0.714 - ETA: 29s - loss: 0.9365 - accuracy: 0.713 - ETA: 28s - loss: 0.9367 - accuracy: 0.713 - ETA: 27s - loss: 0.9358 - accuracy: 0.714 - ETA: 26s - loss: 0.9362 - accuracy: 0.714 - ETA: 26s - loss: 0.9354 - accuracy: 0.714 - ETA: 25s - loss: 0.9347 - accuracy: 0.715 - ETA: 24s - loss: 0.9333 - accuracy: 0.714 - ETA: 24s - loss: 0.9345 - accuracy: 0.714 - ETA: 23s - loss: 0.9358 - accuracy: 0.713 - ETA: 22s - loss: 0.9353 - accuracy: 0.713 - ETA: 22s - loss: 0.9362 - accuracy: 0.713 - ETA: 21s - loss: 0.9345 - accuracy: 0.713 - ETA: 20s - loss: 0.9357 - accuracy: 0.713 - ETA: 20s - loss: 0.9384 - accuracy: 0.712 - ETA: 19s - loss: 0.9411 - accuracy: 0.711 - ETA: 18s - loss: 0.9436 - accuracy: 0.711 - ETA: 17s - loss: 0.9410 - accuracy: 0.712 - ETA: 17s - loss: 0.9403 - accuracy: 0.712 - ETA: 16s - loss: 0.9379 - accuracy: 0.713 - ETA: 15s - loss: 0.9367 - accuracy: 0.713 - ETA: 15s - loss: 0.9366 - accuracy: 0.713 - ETA: 14s - loss: 0.9366 - accuracy: 0.713 - ETA: 13s - loss: 0.9356 - accuracy: 0.713 - ETA: 12s - loss: 0.9339 - accuracy: 0.713 - ETA: 12s - loss: 0.9328 - accuracy: 0.713 - ETA: 11s - loss: 0.9307 - accuracy: 0.714 - ETA: 10s - loss: 0.9322 - accuracy: 0.713 - ETA: 10s - loss: 0.9309 - accuracy: 0.714 - ETA: 9s - loss: 0.9312 - accuracy: 0.714 - ETA: 8s - loss: 0.9327 - accuracy: 0.71 - ETA: 8s - loss: 0.9331 - accuracy: 0.71 - ETA: 7s - loss: 0.9343 - accuracy: 0.71 - ETA: 6s - loss: 0.9360 - accuracy: 0.71 - ETA: 6s - loss: 0.9369 - accuracy: 0.71 - ETA: 5s - loss: 0.9360 - accuracy: 0.71 - ETA: 4s - loss: 0.9370 - accuracy: 0.71 - ETA: 3s - loss: 0.9361 - accuracy: 0.71 - ETA: 3s - loss: 0.9362 - accuracy: 0.71 - ETA: 2s - loss: 0.9348 - accuracy: 0.71 - ETA: 1s - loss: 0.9333 - accuracy: 0.71 - ETA: 1s - loss: 0.9328 - accuracy: 0.71 - ETA: 0s - loss: 0.9347 - accuracy: 0.71 - 82s 6ms/step - loss: 0.9344 - accuracy: 0.7123 - val_loss: 2.6588 - val_accuracy: 0.3534\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.9933 - accuracy: 0.71 - ETA: 1:12 - loss: 0.8748 - accuracy: 0.72 - ETA: 1:10 - loss: 0.9144 - accuracy: 0.72 - ETA: 1:10 - loss: 0.9274 - accuracy: 0.72 - ETA: 1:10 - loss: 0.9164 - accuracy: 0.72 - ETA: 1:08 - loss: 0.9085 - accuracy: 0.72 - ETA: 1:07 - loss: 0.9244 - accuracy: 0.71 - ETA: 1:06 - loss: 0.9274 - accuracy: 0.71 - ETA: 1:05 - loss: 0.9255 - accuracy: 0.71 - ETA: 1:04 - loss: 0.9321 - accuracy: 0.70 - ETA: 1:04 - loss: 0.9349 - accuracy: 0.70 - ETA: 1:03 - loss: 0.9344 - accuracy: 0.70 - ETA: 1:02 - loss: 0.9303 - accuracy: 0.71 - ETA: 1:02 - loss: 0.9383 - accuracy: 0.70 - ETA: 1:01 - loss: 0.9285 - accuracy: 0.71 - ETA: 1:00 - loss: 0.9350 - accuracy: 0.70 - ETA: 59s - loss: 0.9392 - accuracy: 0.7086 - ETA: 59s - loss: 0.9397 - accuracy: 0.705 - ETA: 58s - loss: 0.9428 - accuracy: 0.705 - ETA: 57s - loss: 0.9351 - accuracy: 0.709 - ETA: 56s - loss: 0.9336 - accuracy: 0.712 - ETA: 55s - loss: 0.9249 - accuracy: 0.713 - ETA: 55s - loss: 0.9285 - accuracy: 0.713 - ETA: 54s - loss: 0.9234 - accuracy: 0.714 - ETA: 53s - loss: 0.9236 - accuracy: 0.714 - ETA: 52s - loss: 0.9272 - accuracy: 0.713 - ETA: 52s - loss: 0.9296 - accuracy: 0.712 - ETA: 51s - loss: 0.9249 - accuracy: 0.714 - ETA: 50s - loss: 0.9331 - accuracy: 0.711 - ETA: 49s - loss: 0.9357 - accuracy: 0.710 - ETA: 49s - loss: 0.9368 - accuracy: 0.710 - ETA: 48s - loss: 0.9375 - accuracy: 0.709 - ETA: 47s - loss: 0.9375 - accuracy: 0.709 - ETA: 47s - loss: 0.9431 - accuracy: 0.709 - ETA: 46s - loss: 0.9489 - accuracy: 0.708 - ETA: 45s - loss: 0.9512 - accuracy: 0.708 - ETA: 45s - loss: 0.9474 - accuracy: 0.709 - ETA: 44s - loss: 0.9464 - accuracy: 0.709 - ETA: 43s - loss: 0.9456 - accuracy: 0.709 - ETA: 42s - loss: 0.9444 - accuracy: 0.708 - ETA: 42s - loss: 0.9421 - accuracy: 0.709 - ETA: 41s - loss: 0.9476 - accuracy: 0.708 - ETA: 40s - loss: 0.9507 - accuracy: 0.706 - ETA: 40s - loss: 0.9502 - accuracy: 0.707 - ETA: 39s - loss: 0.9506 - accuracy: 0.708 - ETA: 38s - loss: 0.9462 - accuracy: 0.710 - ETA: 38s - loss: 0.9455 - accuracy: 0.710 - ETA: 37s - loss: 0.9466 - accuracy: 0.710 - ETA: 36s - loss: 0.9472 - accuracy: 0.708 - ETA: 35s - loss: 0.9463 - accuracy: 0.709 - ETA: 35s - loss: 0.9445 - accuracy: 0.710 - ETA: 34s - loss: 0.9433 - accuracy: 0.710 - ETA: 33s - loss: 0.9437 - accuracy: 0.709 - ETA: 33s - loss: 0.9429 - accuracy: 0.710 - ETA: 32s - loss: 0.9423 - accuracy: 0.709 - ETA: 31s - loss: 0.9441 - accuracy: 0.709 - ETA: 31s - loss: 0.9394 - accuracy: 0.710 - ETA: 30s - loss: 0.9377 - accuracy: 0.711 - ETA: 29s - loss: 0.9379 - accuracy: 0.711 - ETA: 29s - loss: 0.9408 - accuracy: 0.711 - ETA: 28s - loss: 0.9401 - accuracy: 0.711 - ETA: 27s - loss: 0.9412 - accuracy: 0.711 - ETA: 27s - loss: 0.9436 - accuracy: 0.710 - ETA: 26s - loss: 0.9442 - accuracy: 0.710 - ETA: 25s - loss: 0.9425 - accuracy: 0.711 - ETA: 24s - loss: 0.9427 - accuracy: 0.711 - ETA: 24s - loss: 0.9429 - accuracy: 0.710 - ETA: 23s - loss: 0.9429 - accuracy: 0.710 - ETA: 22s - loss: 0.9422 - accuracy: 0.711 - ETA: 22s - loss: 0.9430 - accuracy: 0.710 - ETA: 21s - loss: 0.9440 - accuracy: 0.710 - ETA: 20s - loss: 0.9404 - accuracy: 0.711 - ETA: 20s - loss: 0.9408 - accuracy: 0.710 - ETA: 19s - loss: 0.9411 - accuracy: 0.710 - ETA: 18s - loss: 0.9405 - accuracy: 0.710 - ETA: 17s - loss: 0.9390 - accuracy: 0.711 - ETA: 17s - loss: 0.9400 - accuracy: 0.711 - ETA: 16s - loss: 0.9374 - accuracy: 0.712 - ETA: 15s - loss: 0.9363 - accuracy: 0.712 - ETA: 15s - loss: 0.9357 - accuracy: 0.712 - ETA: 14s - loss: 0.9367 - accuracy: 0.712 - ETA: 13s - loss: 0.9384 - accuracy: 0.712 - ETA: 13s - loss: 0.9383 - accuracy: 0.712 - ETA: 12s - loss: 0.9391 - accuracy: 0.712 - ETA: 11s - loss: 0.9382 - accuracy: 0.712 - ETA: 10s - loss: 0.9378 - accuracy: 0.712 - ETA: 10s - loss: 0.9384 - accuracy: 0.712 - ETA: 9s - loss: 0.9398 - accuracy: 0.712 - ETA: 8s - loss: 0.9407 - accuracy: 0.71 - ETA: 8s - loss: 0.9405 - accuracy: 0.71 - ETA: 7s - loss: 0.9385 - accuracy: 0.71 - ETA: 6s - loss: 0.9410 - accuracy: 0.71 - ETA: 6s - loss: 0.9417 - accuracy: 0.71 - ETA: 5s - loss: 0.9410 - accuracy: 0.71 - ETA: 4s - loss: 0.9398 - accuracy: 0.71 - ETA: 4s - loss: 0.9367 - accuracy: 0.71 - ETA: 3s - loss: 0.9354 - accuracy: 0.71 - ETA: 2s - loss: 0.9354 - accuracy: 0.71 - ETA: 1s - loss: 0.9354 - accuracy: 0.71 - ETA: 1s - loss: 0.9353 - accuracy: 0.71 - ETA: 0s - loss: 0.9371 - accuracy: 0.71 - 82s 6ms/step - loss: 0.9392 - accuracy: 0.7129 - val_loss: 2.7087 - val_accuracy: 0.3242\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:16 - loss: 0.7031 - accuracy: 0.75 - ETA: 1:13 - loss: 0.8116 - accuracy: 0.74 - ETA: 1:10 - loss: 0.7531 - accuracy: 0.77 - ETA: 1:09 - loss: 0.8101 - accuracy: 0.75 - ETA: 1:08 - loss: 0.7997 - accuracy: 0.75 - ETA: 1:07 - loss: 0.8203 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8135 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8219 - accuracy: 0.74 - ETA: 1:05 - loss: 0.8232 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8167 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8312 - accuracy: 0.74 - ETA: 1:03 - loss: 0.8235 - accuracy: 0.74 - ETA: 1:02 - loss: 0.8308 - accuracy: 0.73 - ETA: 1:01 - loss: 0.8460 - accuracy: 0.73 - ETA: 1:00 - loss: 0.8498 - accuracy: 0.73 - ETA: 1:00 - loss: 0.8695 - accuracy: 0.73 - ETA: 59s - loss: 0.8724 - accuracy: 0.7293 - ETA: 58s - loss: 0.8676 - accuracy: 0.729 - ETA: 58s - loss: 0.8696 - accuracy: 0.728 - ETA: 57s - loss: 0.8837 - accuracy: 0.724 - ETA: 56s - loss: 0.8833 - accuracy: 0.724 - ETA: 56s - loss: 0.8848 - accuracy: 0.726 - ETA: 55s - loss: 0.8802 - accuracy: 0.728 - ETA: 54s - loss: 0.8888 - accuracy: 0.725 - ETA: 53s - loss: 0.9012 - accuracy: 0.720 - ETA: 53s - loss: 0.9063 - accuracy: 0.719 - ETA: 52s - loss: 0.9052 - accuracy: 0.719 - ETA: 51s - loss: 0.9025 - accuracy: 0.719 - ETA: 50s - loss: 0.9079 - accuracy: 0.718 - ETA: 50s - loss: 0.9058 - accuracy: 0.718 - ETA: 49s - loss: 0.9160 - accuracy: 0.715 - ETA: 48s - loss: 0.9134 - accuracy: 0.717 - ETA: 48s - loss: 0.9121 - accuracy: 0.717 - ETA: 47s - loss: 0.9157 - accuracy: 0.718 - ETA: 46s - loss: 0.9119 - accuracy: 0.719 - ETA: 45s - loss: 0.9199 - accuracy: 0.715 - ETA: 45s - loss: 0.9207 - accuracy: 0.715 - ETA: 44s - loss: 0.9255 - accuracy: 0.714 - ETA: 43s - loss: 0.9292 - accuracy: 0.714 - ETA: 43s - loss: 0.9279 - accuracy: 0.714 - ETA: 42s - loss: 0.9285 - accuracy: 0.715 - ETA: 41s - loss: 0.9298 - accuracy: 0.714 - ETA: 40s - loss: 0.9284 - accuracy: 0.714 - ETA: 40s - loss: 0.9287 - accuracy: 0.714 - ETA: 39s - loss: 0.9252 - accuracy: 0.714 - ETA: 38s - loss: 0.9238 - accuracy: 0.715 - ETA: 38s - loss: 0.9230 - accuracy: 0.716 - ETA: 37s - loss: 0.9281 - accuracy: 0.714 - ETA: 36s - loss: 0.9276 - accuracy: 0.714 - ETA: 36s - loss: 0.9257 - accuracy: 0.715 - ETA: 35s - loss: 0.9255 - accuracy: 0.715 - ETA: 34s - loss: 0.9276 - accuracy: 0.715 - ETA: 33s - loss: 0.9250 - accuracy: 0.716 - ETA: 33s - loss: 0.9260 - accuracy: 0.715 - ETA: 32s - loss: 0.9229 - accuracy: 0.716 - ETA: 31s - loss: 0.9191 - accuracy: 0.717 - ETA: 31s - loss: 0.9158 - accuracy: 0.718 - ETA: 30s - loss: 0.9122 - accuracy: 0.719 - ETA: 29s - loss: 0.9110 - accuracy: 0.719 - ETA: 29s - loss: 0.9136 - accuracy: 0.719 - ETA: 28s - loss: 0.9107 - accuracy: 0.720 - ETA: 27s - loss: 0.9095 - accuracy: 0.720 - ETA: 27s - loss: 0.9113 - accuracy: 0.721 - ETA: 26s - loss: 0.9113 - accuracy: 0.720 - ETA: 25s - loss: 0.9123 - accuracy: 0.720 - ETA: 24s - loss: 0.9135 - accuracy: 0.720 - ETA: 24s - loss: 0.9151 - accuracy: 0.719 - ETA: 23s - loss: 0.9147 - accuracy: 0.719 - ETA: 22s - loss: 0.9169 - accuracy: 0.718 - ETA: 22s - loss: 0.9162 - accuracy: 0.719 - ETA: 21s - loss: 0.9158 - accuracy: 0.718 - ETA: 20s - loss: 0.9187 - accuracy: 0.717 - ETA: 20s - loss: 0.9171 - accuracy: 0.718 - ETA: 19s - loss: 0.9166 - accuracy: 0.718 - ETA: 18s - loss: 0.9173 - accuracy: 0.718 - ETA: 18s - loss: 0.9175 - accuracy: 0.718 - ETA: 17s - loss: 0.9172 - accuracy: 0.718 - ETA: 16s - loss: 0.9185 - accuracy: 0.718 - ETA: 15s - loss: 0.9191 - accuracy: 0.718 - ETA: 15s - loss: 0.9192 - accuracy: 0.718 - ETA: 14s - loss: 0.9170 - accuracy: 0.718 - ETA: 13s - loss: 0.9165 - accuracy: 0.718 - ETA: 13s - loss: 0.9152 - accuracy: 0.718 - ETA: 12s - loss: 0.9152 - accuracy: 0.718 - ETA: 11s - loss: 0.9143 - accuracy: 0.718 - ETA: 11s - loss: 0.9163 - accuracy: 0.717 - ETA: 10s - loss: 0.9195 - accuracy: 0.716 - ETA: 9s - loss: 0.9181 - accuracy: 0.717 - ETA: 8s - loss: 0.9192 - accuracy: 0.71 - ETA: 8s - loss: 0.9185 - accuracy: 0.71 - ETA: 7s - loss: 0.9176 - accuracy: 0.71 - ETA: 6s - loss: 0.9172 - accuracy: 0.71 - ETA: 6s - loss: 0.9174 - accuracy: 0.71 - ETA: 5s - loss: 0.9171 - accuracy: 0.71 - ETA: 4s - loss: 0.9163 - accuracy: 0.71 - ETA: 4s - loss: 0.9150 - accuracy: 0.71 - ETA: 3s - loss: 0.9154 - accuracy: 0.71 - ETA: 2s - loss: 0.9145 - accuracy: 0.71 - ETA: 1s - loss: 0.9150 - accuracy: 0.71 - ETA: 1s - loss: 0.9148 - accuracy: 0.71 - ETA: 0s - loss: 0.9167 - accuracy: 0.71 - 82s 6ms/step - loss: 0.9182 - accuracy: 0.7168 - val_loss: 2.8332 - val_accuracy: 0.3100\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.8926 - accuracy: 0.75 - ETA: 1:10 - loss: 0.9214 - accuracy: 0.72 - ETA: 1:08 - loss: 0.9119 - accuracy: 0.72 - ETA: 1:06 - loss: 0.9577 - accuracy: 0.71 - ETA: 1:07 - loss: 0.9830 - accuracy: 0.70 - ETA: 1:06 - loss: 0.9989 - accuracy: 0.69 - ETA: 1:06 - loss: 1.0037 - accuracy: 0.69 - ETA: 1:05 - loss: 0.9888 - accuracy: 0.70 - ETA: 1:05 - loss: 0.9821 - accuracy: 0.70 - ETA: 1:04 - loss: 0.9696 - accuracy: 0.70 - ETA: 1:03 - loss: 0.9634 - accuracy: 0.71 - ETA: 1:02 - loss: 0.9459 - accuracy: 0.72 - ETA: 1:01 - loss: 0.9395 - accuracy: 0.71 - ETA: 1:00 - loss: 0.9478 - accuracy: 0.71 - ETA: 1:00 - loss: 0.9466 - accuracy: 0.71 - ETA: 59s - loss: 0.9404 - accuracy: 0.7202 - ETA: 58s - loss: 0.9402 - accuracy: 0.718 - ETA: 57s - loss: 0.9283 - accuracy: 0.722 - ETA: 57s - loss: 0.9238 - accuracy: 0.726 - ETA: 56s - loss: 0.9211 - accuracy: 0.725 - ETA: 55s - loss: 0.9232 - accuracy: 0.723 - ETA: 54s - loss: 0.9158 - accuracy: 0.725 - ETA: 54s - loss: 0.9095 - accuracy: 0.726 - ETA: 53s - loss: 0.9101 - accuracy: 0.725 - ETA: 52s - loss: 0.9085 - accuracy: 0.725 - ETA: 52s - loss: 0.9086 - accuracy: 0.723 - ETA: 51s - loss: 0.9053 - accuracy: 0.725 - ETA: 50s - loss: 0.9050 - accuracy: 0.725 - ETA: 50s - loss: 0.9024 - accuracy: 0.726 - ETA: 49s - loss: 0.9000 - accuracy: 0.727 - ETA: 48s - loss: 0.9018 - accuracy: 0.726 - ETA: 48s - loss: 0.9097 - accuracy: 0.725 - ETA: 47s - loss: 0.9108 - accuracy: 0.726 - ETA: 46s - loss: 0.9118 - accuracy: 0.725 - ETA: 46s - loss: 0.9186 - accuracy: 0.724 - ETA: 45s - loss: 0.9188 - accuracy: 0.724 - ETA: 44s - loss: 0.9181 - accuracy: 0.724 - ETA: 44s - loss: 0.9181 - accuracy: 0.725 - ETA: 43s - loss: 0.9163 - accuracy: 0.725 - ETA: 42s - loss: 0.9130 - accuracy: 0.727 - ETA: 42s - loss: 0.9116 - accuracy: 0.727 - ETA: 41s - loss: 0.9143 - accuracy: 0.726 - ETA: 40s - loss: 0.9129 - accuracy: 0.727 - ETA: 40s - loss: 0.9109 - accuracy: 0.728 - ETA: 39s - loss: 0.9089 - accuracy: 0.728 - ETA: 38s - loss: 0.9100 - accuracy: 0.727 - ETA: 38s - loss: 0.9162 - accuracy: 0.725 - ETA: 37s - loss: 0.9174 - accuracy: 0.724 - ETA: 36s - loss: 0.9222 - accuracy: 0.724 - ETA: 36s - loss: 0.9255 - accuracy: 0.723 - ETA: 35s - loss: 0.9243 - accuracy: 0.723 - ETA: 34s - loss: 0.9215 - accuracy: 0.724 - ETA: 34s - loss: 0.9236 - accuracy: 0.724 - ETA: 33s - loss: 0.9253 - accuracy: 0.723 - ETA: 32s - loss: 0.9248 - accuracy: 0.723 - ETA: 31s - loss: 0.9245 - accuracy: 0.723 - ETA: 31s - loss: 0.9245 - accuracy: 0.723 - ETA: 30s - loss: 0.9225 - accuracy: 0.723 - ETA: 29s - loss: 0.9239 - accuracy: 0.723 - ETA: 29s - loss: 0.9257 - accuracy: 0.722 - ETA: 28s - loss: 0.9255 - accuracy: 0.722 - ETA: 27s - loss: 0.9225 - accuracy: 0.723 - ETA: 27s - loss: 0.9203 - accuracy: 0.724 - ETA: 26s - loss: 0.9210 - accuracy: 0.724 - ETA: 25s - loss: 0.9219 - accuracy: 0.723 - ETA: 24s - loss: 0.9228 - accuracy: 0.723 - ETA: 24s - loss: 0.9218 - accuracy: 0.723 - ETA: 23s - loss: 0.9189 - accuracy: 0.724 - ETA: 22s - loss: 0.9183 - accuracy: 0.724 - ETA: 22s - loss: 0.9176 - accuracy: 0.724 - ETA: 21s - loss: 0.9176 - accuracy: 0.724 - ETA: 20s - loss: 0.9171 - accuracy: 0.724 - ETA: 20s - loss: 0.9161 - accuracy: 0.724 - ETA: 19s - loss: 0.9120 - accuracy: 0.725 - ETA: 18s - loss: 0.9135 - accuracy: 0.724 - ETA: 17s - loss: 0.9155 - accuracy: 0.724 - ETA: 17s - loss: 0.9165 - accuracy: 0.724 - ETA: 16s - loss: 0.9171 - accuracy: 0.724 - ETA: 15s - loss: 0.9173 - accuracy: 0.723 - ETA: 15s - loss: 0.9161 - accuracy: 0.724 - ETA: 14s - loss: 0.9142 - accuracy: 0.724 - ETA: 13s - loss: 0.9134 - accuracy: 0.725 - ETA: 13s - loss: 0.9156 - accuracy: 0.724 - ETA: 12s - loss: 0.9144 - accuracy: 0.724 - ETA: 11s - loss: 0.9146 - accuracy: 0.724 - ETA: 10s - loss: 0.9141 - accuracy: 0.724 - ETA: 10s - loss: 0.9120 - accuracy: 0.724 - ETA: 9s - loss: 0.9105 - accuracy: 0.724 - ETA: 8s - loss: 0.9092 - accuracy: 0.72 - ETA: 8s - loss: 0.9088 - accuracy: 0.72 - ETA: 7s - loss: 0.9086 - accuracy: 0.72 - ETA: 6s - loss: 0.9078 - accuracy: 0.72 - ETA: 6s - loss: 0.9082 - accuracy: 0.72 - ETA: 5s - loss: 0.9075 - accuracy: 0.72 - ETA: 4s - loss: 0.9077 - accuracy: 0.72 - ETA: 3s - loss: 0.9081 - accuracy: 0.72 - ETA: 3s - loss: 0.9064 - accuracy: 0.72 - ETA: 2s - loss: 0.9067 - accuracy: 0.72 - ETA: 1s - loss: 0.9048 - accuracy: 0.72 - ETA: 1s - loss: 0.9033 - accuracy: 0.72 - ETA: 0s - loss: 0.9044 - accuracy: 0.72 - 82s 6ms/step - loss: 0.9056 - accuracy: 0.7248 - val_loss: 2.7605 - val_accuracy: 0.3242\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:17 - loss: 0.7662 - accuracy: 0.81 - ETA: 1:12 - loss: 0.7464 - accuracy: 0.79 - ETA: 1:11 - loss: 0.7832 - accuracy: 0.78 - ETA: 1:10 - loss: 0.8706 - accuracy: 0.73 - ETA: 1:09 - loss: 0.8755 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8624 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8577 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8662 - accuracy: 0.73 - ETA: 1:05 - loss: 0.8548 - accuracy: 0.73 - ETA: 1:04 - loss: 0.8625 - accuracy: 0.73 - ETA: 1:03 - loss: 0.8599 - accuracy: 0.73 - ETA: 1:02 - loss: 0.8722 - accuracy: 0.73 - ETA: 1:01 - loss: 0.8911 - accuracy: 0.72 - ETA: 1:00 - loss: 0.8984 - accuracy: 0.72 - ETA: 59s - loss: 0.8980 - accuracy: 0.7234 - ETA: 59s - loss: 0.9062 - accuracy: 0.723 - ETA: 59s - loss: 0.9011 - accuracy: 0.725 - ETA: 58s - loss: 0.8923 - accuracy: 0.727 - ETA: 57s - loss: 0.8886 - accuracy: 0.730 - ETA: 56s - loss: 0.8947 - accuracy: 0.729 - ETA: 56s - loss: 0.8923 - accuracy: 0.727 - ETA: 55s - loss: 0.8844 - accuracy: 0.729 - ETA: 54s - loss: 0.8870 - accuracy: 0.728 - ETA: 54s - loss: 0.8770 - accuracy: 0.731 - ETA: 53s - loss: 0.8690 - accuracy: 0.734 - ETA: 53s - loss: 0.8579 - accuracy: 0.736 - ETA: 52s - loss: 0.8523 - accuracy: 0.738 - ETA: 51s - loss: 0.8501 - accuracy: 0.739 - ETA: 51s - loss: 0.8456 - accuracy: 0.740 - ETA: 50s - loss: 0.8452 - accuracy: 0.740 - ETA: 49s - loss: 0.8467 - accuracy: 0.740 - ETA: 49s - loss: 0.8450 - accuracy: 0.738 - ETA: 48s - loss: 0.8518 - accuracy: 0.735 - ETA: 47s - loss: 0.8541 - accuracy: 0.735 - ETA: 46s - loss: 0.8508 - accuracy: 0.736 - ETA: 46s - loss: 0.8563 - accuracy: 0.733 - ETA: 45s - loss: 0.8607 - accuracy: 0.732 - ETA: 44s - loss: 0.8611 - accuracy: 0.733 - ETA: 43s - loss: 0.8594 - accuracy: 0.732 - ETA: 43s - loss: 0.8580 - accuracy: 0.731 - ETA: 42s - loss: 0.8597 - accuracy: 0.731 - ETA: 41s - loss: 0.8619 - accuracy: 0.730 - ETA: 41s - loss: 0.8666 - accuracy: 0.730 - ETA: 40s - loss: 0.8697 - accuracy: 0.729 - ETA: 39s - loss: 0.8740 - accuracy: 0.728 - ETA: 38s - loss: 0.8761 - accuracy: 0.728 - ETA: 38s - loss: 0.8764 - accuracy: 0.728 - ETA: 37s - loss: 0.8762 - accuracy: 0.728 - ETA: 36s - loss: 0.8744 - accuracy: 0.727 - ETA: 36s - loss: 0.8785 - accuracy: 0.726 - ETA: 35s - loss: 0.8771 - accuracy: 0.726 - ETA: 34s - loss: 0.8771 - accuracy: 0.726 - ETA: 34s - loss: 0.8762 - accuracy: 0.726 - ETA: 33s - loss: 0.8781 - accuracy: 0.725 - ETA: 32s - loss: 0.8790 - accuracy: 0.724 - ETA: 31s - loss: 0.8763 - accuracy: 0.726 - ETA: 31s - loss: 0.8765 - accuracy: 0.726 - ETA: 30s - loss: 0.8752 - accuracy: 0.727 - ETA: 29s - loss: 0.8706 - accuracy: 0.728 - ETA: 29s - loss: 0.8700 - accuracy: 0.728 - ETA: 28s - loss: 0.8713 - accuracy: 0.728 - ETA: 27s - loss: 0.8729 - accuracy: 0.728 - ETA: 26s - loss: 0.8783 - accuracy: 0.726 - ETA: 26s - loss: 0.8749 - accuracy: 0.727 - ETA: 25s - loss: 0.8751 - accuracy: 0.727 - ETA: 24s - loss: 0.8756 - accuracy: 0.726 - ETA: 24s - loss: 0.8778 - accuracy: 0.726 - ETA: 23s - loss: 0.8759 - accuracy: 0.726 - ETA: 22s - loss: 0.8784 - accuracy: 0.725 - ETA: 22s - loss: 0.8752 - accuracy: 0.726 - ETA: 21s - loss: 0.8735 - accuracy: 0.726 - ETA: 20s - loss: 0.8735 - accuracy: 0.726 - ETA: 19s - loss: 0.8762 - accuracy: 0.726 - ETA: 19s - loss: 0.8748 - accuracy: 0.725 - ETA: 18s - loss: 0.8753 - accuracy: 0.725 - ETA: 17s - loss: 0.8737 - accuracy: 0.725 - ETA: 17s - loss: 0.8737 - accuracy: 0.725 - ETA: 16s - loss: 0.8737 - accuracy: 0.725 - ETA: 15s - loss: 0.8731 - accuracy: 0.725 - ETA: 15s - loss: 0.8738 - accuracy: 0.725 - ETA: 14s - loss: 0.8728 - accuracy: 0.726 - ETA: 13s - loss: 0.8724 - accuracy: 0.726 - ETA: 13s - loss: 0.8708 - accuracy: 0.727 - ETA: 12s - loss: 0.8741 - accuracy: 0.726 - ETA: 11s - loss: 0.8727 - accuracy: 0.727 - ETA: 10s - loss: 0.8731 - accuracy: 0.727 - ETA: 10s - loss: 0.8743 - accuracy: 0.727 - ETA: 9s - loss: 0.8740 - accuracy: 0.728 - ETA: 8s - loss: 0.8754 - accuracy: 0.72 - ETA: 8s - loss: 0.8747 - accuracy: 0.72 - ETA: 7s - loss: 0.8764 - accuracy: 0.72 - ETA: 6s - loss: 0.8761 - accuracy: 0.72 - ETA: 6s - loss: 0.8757 - accuracy: 0.72 - ETA: 5s - loss: 0.8769 - accuracy: 0.72 - ETA: 4s - loss: 0.8773 - accuracy: 0.72 - ETA: 3s - loss: 0.8784 - accuracy: 0.72 - ETA: 3s - loss: 0.8768 - accuracy: 0.72 - ETA: 2s - loss: 0.8788 - accuracy: 0.72 - ETA: 1s - loss: 0.8809 - accuracy: 0.72 - ETA: 1s - loss: 0.8802 - accuracy: 0.72 - ETA: 0s - loss: 0.8792 - accuracy: 0.72 - 81s 6ms/step - loss: 0.8797 - accuracy: 0.7265 - val_loss: 2.7667 - val_accuracy: 0.3306\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:19 - loss: 0.8647 - accuracy: 0.71 - ETA: 1:17 - loss: 0.7990 - accuracy: 0.75 - ETA: 1:14 - loss: 0.8523 - accuracy: 0.74 - ETA: 1:13 - loss: 0.8675 - accuracy: 0.73 - ETA: 1:12 - loss: 0.8850 - accuracy: 0.72 - ETA: 1:11 - loss: 0.8724 - accuracy: 0.73 - ETA: 1:10 - loss: 0.8883 - accuracy: 0.72 - ETA: 1:09 - loss: 0.8835 - accuracy: 0.72 - ETA: 1:07 - loss: 0.8725 - accuracy: 0.72 - ETA: 1:06 - loss: 0.8766 - accuracy: 0.72 - ETA: 1:05 - loss: 0.8815 - accuracy: 0.72 - ETA: 1:04 - loss: 0.8604 - accuracy: 0.72 - ETA: 1:03 - loss: 0.8716 - accuracy: 0.72 - ETA: 1:02 - loss: 0.8829 - accuracy: 0.72 - ETA: 1:01 - loss: 0.8808 - accuracy: 0.72 - ETA: 1:00 - loss: 0.8942 - accuracy: 0.72 - ETA: 1:00 - loss: 0.8934 - accuracy: 0.72 - ETA: 59s - loss: 0.8952 - accuracy: 0.7235 - ETA: 58s - loss: 0.8893 - accuracy: 0.725 - ETA: 58s - loss: 0.8974 - accuracy: 0.722 - ETA: 57s - loss: 0.9000 - accuracy: 0.723 - ETA: 56s - loss: 0.8907 - accuracy: 0.725 - ETA: 55s - loss: 0.8908 - accuracy: 0.724 - ETA: 54s - loss: 0.8932 - accuracy: 0.722 - ETA: 54s - loss: 0.8878 - accuracy: 0.725 - ETA: 53s - loss: 0.8841 - accuracy: 0.726 - ETA: 52s - loss: 0.8768 - accuracy: 0.730 - ETA: 52s - loss: 0.8817 - accuracy: 0.728 - ETA: 51s - loss: 0.8784 - accuracy: 0.729 - ETA: 50s - loss: 0.8705 - accuracy: 0.731 - ETA: 50s - loss: 0.8696 - accuracy: 0.731 - ETA: 49s - loss: 0.8723 - accuracy: 0.730 - ETA: 48s - loss: 0.8694 - accuracy: 0.731 - ETA: 47s - loss: 0.8702 - accuracy: 0.732 - ETA: 47s - loss: 0.8675 - accuracy: 0.732 - ETA: 46s - loss: 0.8690 - accuracy: 0.731 - ETA: 45s - loss: 0.8670 - accuracy: 0.732 - ETA: 45s - loss: 0.8679 - accuracy: 0.731 - ETA: 44s - loss: 0.8685 - accuracy: 0.732 - ETA: 43s - loss: 0.8649 - accuracy: 0.733 - ETA: 42s - loss: 0.8646 - accuracy: 0.732 - ETA: 42s - loss: 0.8624 - accuracy: 0.733 - ETA: 41s - loss: 0.8645 - accuracy: 0.732 - ETA: 40s - loss: 0.8658 - accuracy: 0.732 - ETA: 39s - loss: 0.8649 - accuracy: 0.732 - ETA: 39s - loss: 0.8687 - accuracy: 0.732 - ETA: 38s - loss: 0.8710 - accuracy: 0.731 - ETA: 37s - loss: 0.8718 - accuracy: 0.731 - ETA: 37s - loss: 0.8742 - accuracy: 0.730 - ETA: 36s - loss: 0.8764 - accuracy: 0.730 - ETA: 35s - loss: 0.8779 - accuracy: 0.731 - ETA: 34s - loss: 0.8743 - accuracy: 0.732 - ETA: 34s - loss: 0.8729 - accuracy: 0.733 - ETA: 33s - loss: 0.8731 - accuracy: 0.732 - ETA: 32s - loss: 0.8734 - accuracy: 0.732 - ETA: 32s - loss: 0.8734 - accuracy: 0.732 - ETA: 31s - loss: 0.8703 - accuracy: 0.732 - ETA: 30s - loss: 0.8737 - accuracy: 0.731 - ETA: 30s - loss: 0.8696 - accuracy: 0.733 - ETA: 29s - loss: 0.8680 - accuracy: 0.733 - ETA: 28s - loss: 0.8671 - accuracy: 0.734 - ETA: 27s - loss: 0.8648 - accuracy: 0.734 - ETA: 27s - loss: 0.8626 - accuracy: 0.735 - ETA: 26s - loss: 0.8592 - accuracy: 0.736 - ETA: 25s - loss: 0.8572 - accuracy: 0.736 - ETA: 25s - loss: 0.8569 - accuracy: 0.736 - ETA: 24s - loss: 0.8586 - accuracy: 0.736 - ETA: 23s - loss: 0.8592 - accuracy: 0.736 - ETA: 22s - loss: 0.8583 - accuracy: 0.736 - ETA: 22s - loss: 0.8600 - accuracy: 0.736 - ETA: 21s - loss: 0.8622 - accuracy: 0.735 - ETA: 20s - loss: 0.8634 - accuracy: 0.734 - ETA: 20s - loss: 0.8636 - accuracy: 0.734 - ETA: 19s - loss: 0.8633 - accuracy: 0.734 - ETA: 18s - loss: 0.8613 - accuracy: 0.734 - ETA: 18s - loss: 0.8622 - accuracy: 0.733 - ETA: 17s - loss: 0.8628 - accuracy: 0.734 - ETA: 16s - loss: 0.8630 - accuracy: 0.734 - ETA: 15s - loss: 0.8630 - accuracy: 0.734 - ETA: 15s - loss: 0.8624 - accuracy: 0.734 - ETA: 14s - loss: 0.8615 - accuracy: 0.735 - ETA: 13s - loss: 0.8618 - accuracy: 0.735 - ETA: 13s - loss: 0.8625 - accuracy: 0.735 - ETA: 12s - loss: 0.8645 - accuracy: 0.734 - ETA: 11s - loss: 0.8637 - accuracy: 0.734 - ETA: 11s - loss: 0.8650 - accuracy: 0.734 - ETA: 10s - loss: 0.8630 - accuracy: 0.735 - ETA: 9s - loss: 0.8631 - accuracy: 0.735 - ETA: 8s - loss: 0.8645 - accuracy: 0.73 - ETA: 8s - loss: 0.8638 - accuracy: 0.73 - ETA: 7s - loss: 0.8625 - accuracy: 0.73 - ETA: 6s - loss: 0.8626 - accuracy: 0.73 - ETA: 6s - loss: 0.8624 - accuracy: 0.73 - ETA: 5s - loss: 0.8607 - accuracy: 0.73 - ETA: 4s - loss: 0.8607 - accuracy: 0.73 - ETA: 4s - loss: 0.8606 - accuracy: 0.73 - ETA: 3s - loss: 0.8597 - accuracy: 0.73 - ETA: 2s - loss: 0.8579 - accuracy: 0.73 - ETA: 1s - loss: 0.8583 - accuracy: 0.73 - ETA: 1s - loss: 0.8581 - accuracy: 0.73 - ETA: 0s - loss: 0.8572 - accuracy: 0.73 - 82s 6ms/step - loss: 0.8567 - accuracy: 0.7372 - val_loss: 2.8135 - val_accuracy: 0.3416\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 1.0254 - accuracy: 0.68 - ETA: 1:09 - loss: 0.8963 - accuracy: 0.72 - ETA: 1:08 - loss: 0.8883 - accuracy: 0.72 - ETA: 1:07 - loss: 0.8448 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8682 - accuracy: 0.72 - ETA: 1:06 - loss: 0.8597 - accuracy: 0.72 - ETA: 1:05 - loss: 0.8417 - accuracy: 0.72 - ETA: 1:04 - loss: 0.8571 - accuracy: 0.72 - ETA: 1:04 - loss: 0.8431 - accuracy: 0.72 - ETA: 1:03 - loss: 0.8478 - accuracy: 0.72 - ETA: 1:02 - loss: 0.8481 - accuracy: 0.72 - ETA: 1:02 - loss: 0.8569 - accuracy: 0.72 - ETA: 1:01 - loss: 0.8732 - accuracy: 0.72 - ETA: 1:00 - loss: 0.8597 - accuracy: 0.72 - ETA: 1:00 - loss: 0.8602 - accuracy: 0.72 - ETA: 59s - loss: 0.8661 - accuracy: 0.7280 - ETA: 58s - loss: 0.8605 - accuracy: 0.730 - ETA: 58s - loss: 0.8678 - accuracy: 0.730 - ETA: 57s - loss: 0.8658 - accuracy: 0.732 - ETA: 56s - loss: 0.8562 - accuracy: 0.733 - ETA: 56s - loss: 0.8610 - accuracy: 0.732 - ETA: 55s - loss: 0.8678 - accuracy: 0.730 - ETA: 55s - loss: 0.8644 - accuracy: 0.732 - ETA: 54s - loss: 0.8525 - accuracy: 0.735 - ETA: 53s - loss: 0.8468 - accuracy: 0.735 - ETA: 52s - loss: 0.8500 - accuracy: 0.735 - ETA: 52s - loss: 0.8473 - accuracy: 0.736 - ETA: 51s - loss: 0.8584 - accuracy: 0.734 - ETA: 50s - loss: 0.8581 - accuracy: 0.733 - ETA: 50s - loss: 0.8655 - accuracy: 0.731 - ETA: 49s - loss: 0.8634 - accuracy: 0.732 - ETA: 48s - loss: 0.8656 - accuracy: 0.731 - ETA: 48s - loss: 0.8618 - accuracy: 0.732 - ETA: 47s - loss: 0.8628 - accuracy: 0.731 - ETA: 46s - loss: 0.8560 - accuracy: 0.732 - ETA: 45s - loss: 0.8599 - accuracy: 0.732 - ETA: 45s - loss: 0.8615 - accuracy: 0.731 - ETA: 44s - loss: 0.8588 - accuracy: 0.733 - ETA: 43s - loss: 0.8600 - accuracy: 0.732 - ETA: 42s - loss: 0.8610 - accuracy: 0.731 - ETA: 42s - loss: 0.8547 - accuracy: 0.733 - ETA: 41s - loss: 0.8527 - accuracy: 0.733 - ETA: 40s - loss: 0.8554 - accuracy: 0.732 - ETA: 40s - loss: 0.8560 - accuracy: 0.732 - ETA: 39s - loss: 0.8546 - accuracy: 0.733 - ETA: 38s - loss: 0.8528 - accuracy: 0.733 - ETA: 37s - loss: 0.8498 - accuracy: 0.734 - ETA: 37s - loss: 0.8492 - accuracy: 0.734 - ETA: 36s - loss: 0.8488 - accuracy: 0.736 - ETA: 35s - loss: 0.8458 - accuracy: 0.737 - ETA: 35s - loss: 0.8444 - accuracy: 0.738 - ETA: 34s - loss: 0.8466 - accuracy: 0.737 - ETA: 33s - loss: 0.8506 - accuracy: 0.735 - ETA: 33s - loss: 0.8500 - accuracy: 0.735 - ETA: 32s - loss: 0.8470 - accuracy: 0.736 - ETA: 31s - loss: 0.8502 - accuracy: 0.735 - ETA: 30s - loss: 0.8520 - accuracy: 0.734 - ETA: 30s - loss: 0.8500 - accuracy: 0.734 - ETA: 29s - loss: 0.8488 - accuracy: 0.734 - ETA: 28s - loss: 0.8513 - accuracy: 0.733 - ETA: 28s - loss: 0.8518 - accuracy: 0.733 - ETA: 27s - loss: 0.8598 - accuracy: 0.732 - ETA: 26s - loss: 0.8602 - accuracy: 0.732 - ETA: 26s - loss: 0.8588 - accuracy: 0.733 - ETA: 25s - loss: 0.8568 - accuracy: 0.733 - ETA: 24s - loss: 0.8589 - accuracy: 0.733 - ETA: 24s - loss: 0.8617 - accuracy: 0.732 - ETA: 23s - loss: 0.8582 - accuracy: 0.733 - ETA: 22s - loss: 0.8587 - accuracy: 0.733 - ETA: 21s - loss: 0.8585 - accuracy: 0.734 - ETA: 21s - loss: 0.8590 - accuracy: 0.734 - ETA: 20s - loss: 0.8611 - accuracy: 0.733 - ETA: 19s - loss: 0.8626 - accuracy: 0.733 - ETA: 19s - loss: 0.8628 - accuracy: 0.733 - ETA: 18s - loss: 0.8654 - accuracy: 0.732 - ETA: 17s - loss: 0.8669 - accuracy: 0.732 - ETA: 17s - loss: 0.8657 - accuracy: 0.732 - ETA: 16s - loss: 0.8638 - accuracy: 0.732 - ETA: 15s - loss: 0.8645 - accuracy: 0.732 - ETA: 15s - loss: 0.8665 - accuracy: 0.731 - ETA: 14s - loss: 0.8656 - accuracy: 0.732 - ETA: 13s - loss: 0.8645 - accuracy: 0.732 - ETA: 13s - loss: 0.8646 - accuracy: 0.732 - ETA: 12s - loss: 0.8620 - accuracy: 0.733 - ETA: 11s - loss: 0.8616 - accuracy: 0.732 - ETA: 10s - loss: 0.8643 - accuracy: 0.731 - ETA: 10s - loss: 0.8648 - accuracy: 0.732 - ETA: 9s - loss: 0.8658 - accuracy: 0.732 - ETA: 8s - loss: 0.8637 - accuracy: 0.73 - ETA: 8s - loss: 0.8638 - accuracy: 0.73 - ETA: 7s - loss: 0.8642 - accuracy: 0.73 - ETA: 6s - loss: 0.8650 - accuracy: 0.73 - ETA: 6s - loss: 0.8646 - accuracy: 0.73 - ETA: 5s - loss: 0.8641 - accuracy: 0.73 - ETA: 4s - loss: 0.8644 - accuracy: 0.73 - ETA: 3s - loss: 0.8631 - accuracy: 0.73 - ETA: 3s - loss: 0.8624 - accuracy: 0.73 - ETA: 2s - loss: 0.8592 - accuracy: 0.73 - ETA: 1s - loss: 0.8580 - accuracy: 0.73 - ETA: 1s - loss: 0.8579 - accuracy: 0.73 - ETA: 0s - loss: 0.8561 - accuracy: 0.73 - 82s 6ms/step - loss: 0.8562 - accuracy: 0.7352 - val_loss: 2.8587 - val_accuracy: 0.3280\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 1.0167 - accuracy: 0.70 - ETA: 1:14 - loss: 0.9515 - accuracy: 0.71 - ETA: 1:14 - loss: 0.9153 - accuracy: 0.72 - ETA: 1:13 - loss: 0.9075 - accuracy: 0.72 - ETA: 1:12 - loss: 0.9083 - accuracy: 0.72 - ETA: 1:11 - loss: 0.9248 - accuracy: 0.72 - ETA: 1:10 - loss: 0.9114 - accuracy: 0.71 - ETA: 1:09 - loss: 0.9182 - accuracy: 0.71 - ETA: 1:09 - loss: 0.9136 - accuracy: 0.71 - ETA: 1:08 - loss: 0.8959 - accuracy: 0.72 - ETA: 1:07 - loss: 0.8969 - accuracy: 0.72 - ETA: 1:06 - loss: 0.8982 - accuracy: 0.72 - ETA: 1:05 - loss: 0.8930 - accuracy: 0.72 - ETA: 1:04 - loss: 0.8990 - accuracy: 0.72 - ETA: 1:03 - loss: 0.8859 - accuracy: 0.72 - ETA: 1:02 - loss: 0.8802 - accuracy: 0.73 - ETA: 1:01 - loss: 0.8802 - accuracy: 0.72 - ETA: 1:00 - loss: 0.8720 - accuracy: 0.73 - ETA: 1:00 - loss: 0.8708 - accuracy: 0.72 - ETA: 59s - loss: 0.8585 - accuracy: 0.7320 - ETA: 58s - loss: 0.8703 - accuracy: 0.728 - ETA: 57s - loss: 0.8768 - accuracy: 0.727 - ETA: 56s - loss: 0.8732 - accuracy: 0.728 - ETA: 55s - loss: 0.8708 - accuracy: 0.728 - ETA: 55s - loss: 0.8754 - accuracy: 0.730 - ETA: 54s - loss: 0.8756 - accuracy: 0.729 - ETA: 53s - loss: 0.8708 - accuracy: 0.730 - ETA: 52s - loss: 0.8646 - accuracy: 0.733 - ETA: 51s - loss: 0.8582 - accuracy: 0.734 - ETA: 50s - loss: 0.8602 - accuracy: 0.733 - ETA: 50s - loss: 0.8641 - accuracy: 0.733 - ETA: 49s - loss: 0.8597 - accuracy: 0.734 - ETA: 48s - loss: 0.8529 - accuracy: 0.736 - ETA: 47s - loss: 0.8465 - accuracy: 0.737 - ETA: 47s - loss: 0.8536 - accuracy: 0.734 - ETA: 46s - loss: 0.8529 - accuracy: 0.735 - ETA: 45s - loss: 0.8440 - accuracy: 0.737 - ETA: 44s - loss: 0.8395 - accuracy: 0.739 - ETA: 44s - loss: 0.8388 - accuracy: 0.739 - ETA: 43s - loss: 0.8363 - accuracy: 0.740 - ETA: 42s - loss: 0.8358 - accuracy: 0.739 - ETA: 41s - loss: 0.8396 - accuracy: 0.738 - ETA: 41s - loss: 0.8426 - accuracy: 0.737 - ETA: 40s - loss: 0.8446 - accuracy: 0.736 - ETA: 39s - loss: 0.8452 - accuracy: 0.735 - ETA: 39s - loss: 0.8423 - accuracy: 0.736 - ETA: 38s - loss: 0.8446 - accuracy: 0.735 - ETA: 37s - loss: 0.8456 - accuracy: 0.736 - ETA: 37s - loss: 0.8492 - accuracy: 0.736 - ETA: 36s - loss: 0.8498 - accuracy: 0.736 - ETA: 35s - loss: 0.8485 - accuracy: 0.736 - ETA: 34s - loss: 0.8466 - accuracy: 0.737 - ETA: 34s - loss: 0.8457 - accuracy: 0.737 - ETA: 33s - loss: 0.8467 - accuracy: 0.738 - ETA: 32s - loss: 0.8500 - accuracy: 0.736 - ETA: 32s - loss: 0.8547 - accuracy: 0.735 - ETA: 31s - loss: 0.8513 - accuracy: 0.737 - ETA: 30s - loss: 0.8556 - accuracy: 0.736 - ETA: 30s - loss: 0.8535 - accuracy: 0.736 - ETA: 29s - loss: 0.8560 - accuracy: 0.735 - ETA: 28s - loss: 0.8553 - accuracy: 0.735 - ETA: 27s - loss: 0.8529 - accuracy: 0.736 - ETA: 27s - loss: 0.8512 - accuracy: 0.736 - ETA: 26s - loss: 0.8504 - accuracy: 0.736 - ETA: 25s - loss: 0.8471 - accuracy: 0.738 - ETA: 25s - loss: 0.8478 - accuracy: 0.737 - ETA: 24s - loss: 0.8468 - accuracy: 0.737 - ETA: 23s - loss: 0.8453 - accuracy: 0.738 - ETA: 23s - loss: 0.8452 - accuracy: 0.738 - ETA: 22s - loss: 0.8413 - accuracy: 0.739 - ETA: 21s - loss: 0.8430 - accuracy: 0.738 - ETA: 20s - loss: 0.8407 - accuracy: 0.739 - ETA: 20s - loss: 0.8385 - accuracy: 0.739 - ETA: 19s - loss: 0.8359 - accuracy: 0.740 - ETA: 18s - loss: 0.8356 - accuracy: 0.740 - ETA: 18s - loss: 0.8345 - accuracy: 0.740 - ETA: 17s - loss: 0.8332 - accuracy: 0.740 - ETA: 16s - loss: 0.8318 - accuracy: 0.741 - ETA: 15s - loss: 0.8339 - accuracy: 0.740 - ETA: 15s - loss: 0.8332 - accuracy: 0.740 - ETA: 14s - loss: 0.8340 - accuracy: 0.739 - ETA: 13s - loss: 0.8338 - accuracy: 0.739 - ETA: 13s - loss: 0.8355 - accuracy: 0.739 - ETA: 12s - loss: 0.8352 - accuracy: 0.739 - ETA: 11s - loss: 0.8364 - accuracy: 0.739 - ETA: 11s - loss: 0.8350 - accuracy: 0.739 - ETA: 10s - loss: 0.8346 - accuracy: 0.739 - ETA: 9s - loss: 0.8337 - accuracy: 0.740 - ETA: 8s - loss: 0.8340 - accuracy: 0.74 - ETA: 8s - loss: 0.8336 - accuracy: 0.74 - ETA: 7s - loss: 0.8364 - accuracy: 0.74 - ETA: 6s - loss: 0.8350 - accuracy: 0.74 - ETA: 6s - loss: 0.8367 - accuracy: 0.74 - ETA: 5s - loss: 0.8372 - accuracy: 0.74 - ETA: 4s - loss: 0.8381 - accuracy: 0.74 - ETA: 4s - loss: 0.8390 - accuracy: 0.74 - ETA: 3s - loss: 0.8384 - accuracy: 0.74 - ETA: 2s - loss: 0.8399 - accuracy: 0.73 - ETA: 1s - loss: 0.8409 - accuracy: 0.73 - ETA: 1s - loss: 0.8418 - accuracy: 0.73 - ETA: 0s - loss: 0.8419 - accuracy: 0.73 - 82s 6ms/step - loss: 0.8417 - accuracy: 0.7396 - val_loss: 2.7990 - val_accuracy: 0.3402\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.8190 - accuracy: 0.79 - ETA: 1:11 - loss: 0.8202 - accuracy: 0.75 - ETA: 1:09 - loss: 0.8326 - accuracy: 0.74 - ETA: 1:08 - loss: 0.7908 - accuracy: 0.76 - ETA: 1:07 - loss: 0.7757 - accuracy: 0.76 - ETA: 1:06 - loss: 0.7388 - accuracy: 0.77 - ETA: 1:05 - loss: 0.7498 - accuracy: 0.76 - ETA: 1:04 - loss: 0.7582 - accuracy: 0.76 - ETA: 1:03 - loss: 0.7732 - accuracy: 0.75 - ETA: 1:03 - loss: 0.7632 - accuracy: 0.76 - ETA: 1:02 - loss: 0.7753 - accuracy: 0.75 - ETA: 1:01 - loss: 0.7815 - accuracy: 0.75 - ETA: 1:01 - loss: 0.8080 - accuracy: 0.75 - ETA: 1:00 - loss: 0.8099 - accuracy: 0.75 - ETA: 59s - loss: 0.8007 - accuracy: 0.7536 - ETA: 59s - loss: 0.7953 - accuracy: 0.754 - ETA: 58s - loss: 0.7917 - accuracy: 0.754 - ETA: 57s - loss: 0.7915 - accuracy: 0.753 - ETA: 57s - loss: 0.7972 - accuracy: 0.751 - ETA: 56s - loss: 0.8114 - accuracy: 0.748 - ETA: 55s - loss: 0.8093 - accuracy: 0.749 - ETA: 55s - loss: 0.8081 - accuracy: 0.749 - ETA: 54s - loss: 0.8086 - accuracy: 0.750 - ETA: 53s - loss: 0.8196 - accuracy: 0.748 - ETA: 53s - loss: 0.8183 - accuracy: 0.747 - ETA: 52s - loss: 0.8233 - accuracy: 0.746 - ETA: 51s - loss: 0.8217 - accuracy: 0.747 - ETA: 51s - loss: 0.8227 - accuracy: 0.747 - ETA: 50s - loss: 0.8234 - accuracy: 0.746 - ETA: 49s - loss: 0.8234 - accuracy: 0.746 - ETA: 49s - loss: 0.8244 - accuracy: 0.746 - ETA: 48s - loss: 0.8285 - accuracy: 0.744 - ETA: 47s - loss: 0.8307 - accuracy: 0.745 - ETA: 47s - loss: 0.8291 - accuracy: 0.745 - ETA: 46s - loss: 0.8300 - accuracy: 0.744 - ETA: 45s - loss: 0.8275 - accuracy: 0.745 - ETA: 45s - loss: 0.8288 - accuracy: 0.744 - ETA: 44s - loss: 0.8341 - accuracy: 0.743 - ETA: 43s - loss: 0.8354 - accuracy: 0.743 - ETA: 43s - loss: 0.8360 - accuracy: 0.743 - ETA: 42s - loss: 0.8342 - accuracy: 0.744 - ETA: 41s - loss: 0.8341 - accuracy: 0.743 - ETA: 40s - loss: 0.8381 - accuracy: 0.743 - ETA: 40s - loss: 0.8367 - accuracy: 0.743 - ETA: 39s - loss: 0.8326 - accuracy: 0.744 - ETA: 38s - loss: 0.8277 - accuracy: 0.746 - ETA: 38s - loss: 0.8287 - accuracy: 0.745 - ETA: 37s - loss: 0.8305 - accuracy: 0.745 - ETA: 36s - loss: 0.8309 - accuracy: 0.744 - ETA: 36s - loss: 0.8304 - accuracy: 0.743 - ETA: 35s - loss: 0.8342 - accuracy: 0.743 - ETA: 34s - loss: 0.8390 - accuracy: 0.742 - ETA: 33s - loss: 0.8357 - accuracy: 0.743 - ETA: 33s - loss: 0.8367 - accuracy: 0.743 - ETA: 32s - loss: 0.8380 - accuracy: 0.742 - ETA: 31s - loss: 0.8422 - accuracy: 0.741 - ETA: 31s - loss: 0.8408 - accuracy: 0.742 - ETA: 30s - loss: 0.8377 - accuracy: 0.743 - ETA: 29s - loss: 0.8396 - accuracy: 0.743 - ETA: 29s - loss: 0.8427 - accuracy: 0.742 - ETA: 28s - loss: 0.8417 - accuracy: 0.742 - ETA: 27s - loss: 0.8405 - accuracy: 0.742 - ETA: 26s - loss: 0.8398 - accuracy: 0.742 - ETA: 26s - loss: 0.8385 - accuracy: 0.742 - ETA: 25s - loss: 0.8366 - accuracy: 0.743 - ETA: 24s - loss: 0.8367 - accuracy: 0.742 - ETA: 24s - loss: 0.8364 - accuracy: 0.742 - ETA: 23s - loss: 0.8359 - accuracy: 0.743 - ETA: 22s - loss: 0.8366 - accuracy: 0.742 - ETA: 22s - loss: 0.8395 - accuracy: 0.742 - ETA: 21s - loss: 0.8414 - accuracy: 0.741 - ETA: 20s - loss: 0.8401 - accuracy: 0.741 - ETA: 19s - loss: 0.8379 - accuracy: 0.742 - ETA: 19s - loss: 0.8399 - accuracy: 0.741 - ETA: 18s - loss: 0.8382 - accuracy: 0.741 - ETA: 17s - loss: 0.8394 - accuracy: 0.742 - ETA: 17s - loss: 0.8413 - accuracy: 0.742 - ETA: 16s - loss: 0.8405 - accuracy: 0.742 - ETA: 15s - loss: 0.8408 - accuracy: 0.742 - ETA: 15s - loss: 0.8395 - accuracy: 0.743 - ETA: 14s - loss: 0.8402 - accuracy: 0.742 - ETA: 13s - loss: 0.8413 - accuracy: 0.742 - ETA: 12s - loss: 0.8432 - accuracy: 0.742 - ETA: 12s - loss: 0.8414 - accuracy: 0.742 - ETA: 11s - loss: 0.8412 - accuracy: 0.742 - ETA: 10s - loss: 0.8420 - accuracy: 0.742 - ETA: 10s - loss: 0.8415 - accuracy: 0.742 - ETA: 9s - loss: 0.8422 - accuracy: 0.742 - ETA: 8s - loss: 0.8410 - accuracy: 0.74 - ETA: 8s - loss: 0.8438 - accuracy: 0.74 - ETA: 7s - loss: 0.8441 - accuracy: 0.74 - ETA: 6s - loss: 0.8452 - accuracy: 0.74 - ETA: 6s - loss: 0.8450 - accuracy: 0.74 - ETA: 5s - loss: 0.8433 - accuracy: 0.74 - ETA: 4s - loss: 0.8425 - accuracy: 0.74 - ETA: 3s - loss: 0.8406 - accuracy: 0.74 - ETA: 3s - loss: 0.8405 - accuracy: 0.74 - ETA: 2s - loss: 0.8395 - accuracy: 0.74 - ETA: 1s - loss: 0.8395 - accuracy: 0.74 - ETA: 1s - loss: 0.8382 - accuracy: 0.74 - ETA: 0s - loss: 0.8380 - accuracy: 0.74 - 81s 6ms/step - loss: 0.8376 - accuracy: 0.7436 - val_loss: 2.9676 - val_accuracy: 0.3146\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:09 - loss: 0.9656 - accuracy: 0.75 - ETA: 1:09 - loss: 0.8936 - accuracy: 0.75 - ETA: 1:09 - loss: 0.8540 - accuracy: 0.75 - ETA: 1:10 - loss: 0.8158 - accuracy: 0.75 - ETA: 1:09 - loss: 0.7514 - accuracy: 0.77 - ETA: 1:08 - loss: 0.7675 - accuracy: 0.76 - ETA: 1:08 - loss: 0.7490 - accuracy: 0.77 - ETA: 1:07 - loss: 0.7713 - accuracy: 0.76 - ETA: 1:07 - loss: 0.7951 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8124 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8161 - accuracy: 0.75 - ETA: 1:04 - loss: 0.8186 - accuracy: 0.74 - ETA: 1:03 - loss: 0.8271 - accuracy: 0.74 - ETA: 1:02 - loss: 0.8464 - accuracy: 0.74 - ETA: 1:02 - loss: 0.8410 - accuracy: 0.74 - ETA: 1:01 - loss: 0.8410 - accuracy: 0.74 - ETA: 1:00 - loss: 0.8435 - accuracy: 0.74 - ETA: 59s - loss: 0.8453 - accuracy: 0.7431 - ETA: 58s - loss: 0.8380 - accuracy: 0.744 - ETA: 58s - loss: 0.8374 - accuracy: 0.744 - ETA: 57s - loss: 0.8319 - accuracy: 0.746 - ETA: 56s - loss: 0.8282 - accuracy: 0.746 - ETA: 55s - loss: 0.8275 - accuracy: 0.747 - ETA: 55s - loss: 0.8198 - accuracy: 0.749 - ETA: 54s - loss: 0.8163 - accuracy: 0.749 - ETA: 54s - loss: 0.8259 - accuracy: 0.747 - ETA: 53s - loss: 0.8257 - accuracy: 0.748 - ETA: 52s - loss: 0.8257 - accuracy: 0.746 - ETA: 51s - loss: 0.8275 - accuracy: 0.745 - ETA: 50s - loss: 0.8382 - accuracy: 0.745 - ETA: 50s - loss: 0.8486 - accuracy: 0.741 - ETA: 49s - loss: 0.8426 - accuracy: 0.743 - ETA: 48s - loss: 0.8473 - accuracy: 0.742 - ETA: 47s - loss: 0.8514 - accuracy: 0.742 - ETA: 47s - loss: 0.8480 - accuracy: 0.742 - ETA: 46s - loss: 0.8475 - accuracy: 0.741 - ETA: 45s - loss: 0.8458 - accuracy: 0.740 - ETA: 45s - loss: 0.8474 - accuracy: 0.741 - ETA: 44s - loss: 0.8476 - accuracy: 0.741 - ETA: 43s - loss: 0.8468 - accuracy: 0.741 - ETA: 42s - loss: 0.8426 - accuracy: 0.743 - ETA: 42s - loss: 0.8420 - accuracy: 0.742 - ETA: 41s - loss: 0.8378 - accuracy: 0.743 - ETA: 40s - loss: 0.8374 - accuracy: 0.742 - ETA: 40s - loss: 0.8330 - accuracy: 0.744 - ETA: 39s - loss: 0.8387 - accuracy: 0.743 - ETA: 38s - loss: 0.8410 - accuracy: 0.743 - ETA: 37s - loss: 0.8362 - accuracy: 0.744 - ETA: 37s - loss: 0.8357 - accuracy: 0.744 - ETA: 36s - loss: 0.8365 - accuracy: 0.744 - ETA: 35s - loss: 0.8387 - accuracy: 0.744 - ETA: 35s - loss: 0.8349 - accuracy: 0.746 - ETA: 34s - loss: 0.8330 - accuracy: 0.746 - ETA: 33s - loss: 0.8351 - accuracy: 0.744 - ETA: 32s - loss: 0.8365 - accuracy: 0.743 - ETA: 32s - loss: 0.8387 - accuracy: 0.743 - ETA: 31s - loss: 0.8403 - accuracy: 0.742 - ETA: 30s - loss: 0.8396 - accuracy: 0.742 - ETA: 30s - loss: 0.8435 - accuracy: 0.740 - ETA: 29s - loss: 0.8439 - accuracy: 0.740 - ETA: 28s - loss: 0.8438 - accuracy: 0.740 - ETA: 28s - loss: 0.8444 - accuracy: 0.739 - ETA: 27s - loss: 0.8444 - accuracy: 0.738 - ETA: 26s - loss: 0.8461 - accuracy: 0.738 - ETA: 25s - loss: 0.8449 - accuracy: 0.738 - ETA: 25s - loss: 0.8446 - accuracy: 0.739 - ETA: 24s - loss: 0.8451 - accuracy: 0.738 - ETA: 23s - loss: 0.8478 - accuracy: 0.737 - ETA: 23s - loss: 0.8483 - accuracy: 0.737 - ETA: 22s - loss: 0.8474 - accuracy: 0.738 - ETA: 21s - loss: 0.8463 - accuracy: 0.738 - ETA: 20s - loss: 0.8425 - accuracy: 0.739 - ETA: 20s - loss: 0.8432 - accuracy: 0.738 - ETA: 19s - loss: 0.8440 - accuracy: 0.738 - ETA: 18s - loss: 0.8453 - accuracy: 0.737 - ETA: 18s - loss: 0.8465 - accuracy: 0.737 - ETA: 17s - loss: 0.8441 - accuracy: 0.738 - ETA: 16s - loss: 0.8451 - accuracy: 0.738 - ETA: 15s - loss: 0.8444 - accuracy: 0.739 - ETA: 15s - loss: 0.8424 - accuracy: 0.740 - ETA: 14s - loss: 0.8428 - accuracy: 0.739 - ETA: 13s - loss: 0.8431 - accuracy: 0.739 - ETA: 13s - loss: 0.8432 - accuracy: 0.739 - ETA: 12s - loss: 0.8429 - accuracy: 0.739 - ETA: 11s - loss: 0.8427 - accuracy: 0.739 - ETA: 11s - loss: 0.8438 - accuracy: 0.739 - ETA: 10s - loss: 0.8440 - accuracy: 0.739 - ETA: 9s - loss: 0.8451 - accuracy: 0.738 - ETA: 8s - loss: 0.8443 - accuracy: 0.73 - ETA: 8s - loss: 0.8458 - accuracy: 0.73 - ETA: 7s - loss: 0.8453 - accuracy: 0.73 - ETA: 6s - loss: 0.8424 - accuracy: 0.73 - ETA: 6s - loss: 0.8401 - accuracy: 0.74 - ETA: 5s - loss: 0.8395 - accuracy: 0.74 - ETA: 4s - loss: 0.8376 - accuracy: 0.74 - ETA: 4s - loss: 0.8396 - accuracy: 0.74 - ETA: 3s - loss: 0.8378 - accuracy: 0.74 - ETA: 2s - loss: 0.8368 - accuracy: 0.74 - ETA: 1s - loss: 0.8391 - accuracy: 0.74 - ETA: 1s - loss: 0.8394 - accuracy: 0.74 - ETA: 0s - loss: 0.8367 - accuracy: 0.74 - 82s 6ms/step - loss: 0.8376 - accuracy: 0.7427 - val_loss: 2.7216 - val_accuracy: 0.3456\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:15 - loss: 0.6535 - accuracy: 0.80 - ETA: 1:11 - loss: 0.6517 - accuracy: 0.78 - ETA: 1:10 - loss: 0.7264 - accuracy: 0.78 - ETA: 1:08 - loss: 0.7424 - accuracy: 0.79 - ETA: 1:07 - loss: 0.7313 - accuracy: 0.78 - ETA: 1:06 - loss: 0.7664 - accuracy: 0.77 - ETA: 1:06 - loss: 0.7734 - accuracy: 0.77 - ETA: 1:05 - loss: 0.7749 - accuracy: 0.77 - ETA: 1:05 - loss: 0.7670 - accuracy: 0.77 - ETA: 1:04 - loss: 0.7626 - accuracy: 0.77 - ETA: 1:03 - loss: 0.7719 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7763 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7739 - accuracy: 0.77 - ETA: 1:01 - loss: 0.7598 - accuracy: 0.77 - ETA: 1:00 - loss: 0.7530 - accuracy: 0.78 - ETA: 59s - loss: 0.7538 - accuracy: 0.7773 - ETA: 59s - loss: 0.7581 - accuracy: 0.775 - ETA: 58s - loss: 0.7542 - accuracy: 0.776 - ETA: 57s - loss: 0.7676 - accuracy: 0.773 - ETA: 56s - loss: 0.7682 - accuracy: 0.772 - ETA: 56s - loss: 0.7700 - accuracy: 0.771 - ETA: 55s - loss: 0.7690 - accuracy: 0.771 - ETA: 54s - loss: 0.7647 - accuracy: 0.771 - ETA: 54s - loss: 0.7704 - accuracy: 0.768 - ETA: 53s - loss: 0.7732 - accuracy: 0.768 - ETA: 52s - loss: 0.7837 - accuracy: 0.766 - ETA: 52s - loss: 0.7955 - accuracy: 0.760 - ETA: 51s - loss: 0.7986 - accuracy: 0.759 - ETA: 50s - loss: 0.8031 - accuracy: 0.757 - ETA: 49s - loss: 0.8069 - accuracy: 0.756 - ETA: 49s - loss: 0.8084 - accuracy: 0.756 - ETA: 48s - loss: 0.8021 - accuracy: 0.758 - ETA: 47s - loss: 0.8010 - accuracy: 0.758 - ETA: 46s - loss: 0.8001 - accuracy: 0.758 - ETA: 46s - loss: 0.8028 - accuracy: 0.758 - ETA: 45s - loss: 0.8002 - accuracy: 0.757 - ETA: 45s - loss: 0.7996 - accuracy: 0.758 - ETA: 44s - loss: 0.8008 - accuracy: 0.758 - ETA: 43s - loss: 0.7973 - accuracy: 0.760 - ETA: 42s - loss: 0.7970 - accuracy: 0.760 - ETA: 42s - loss: 0.7944 - accuracy: 0.761 - ETA: 41s - loss: 0.7901 - accuracy: 0.761 - ETA: 40s - loss: 0.7888 - accuracy: 0.762 - ETA: 40s - loss: 0.7896 - accuracy: 0.761 - ETA: 39s - loss: 0.7898 - accuracy: 0.761 - ETA: 38s - loss: 0.7880 - accuracy: 0.761 - ETA: 38s - loss: 0.7893 - accuracy: 0.760 - ETA: 37s - loss: 0.7915 - accuracy: 0.760 - ETA: 36s - loss: 0.7896 - accuracy: 0.760 - ETA: 35s - loss: 0.7895 - accuracy: 0.760 - ETA: 35s - loss: 0.7913 - accuracy: 0.760 - ETA: 34s - loss: 0.7906 - accuracy: 0.760 - ETA: 33s - loss: 0.7907 - accuracy: 0.760 - ETA: 33s - loss: 0.7881 - accuracy: 0.760 - ETA: 32s - loss: 0.7884 - accuracy: 0.760 - ETA: 31s - loss: 0.7898 - accuracy: 0.760 - ETA: 30s - loss: 0.7921 - accuracy: 0.759 - ETA: 30s - loss: 0.7927 - accuracy: 0.759 - ETA: 29s - loss: 0.7942 - accuracy: 0.759 - ETA: 28s - loss: 0.7942 - accuracy: 0.759 - ETA: 28s - loss: 0.7939 - accuracy: 0.759 - ETA: 27s - loss: 0.7924 - accuracy: 0.759 - ETA: 26s - loss: 0.7970 - accuracy: 0.757 - ETA: 26s - loss: 0.7962 - accuracy: 0.757 - ETA: 25s - loss: 0.8001 - accuracy: 0.757 - ETA: 24s - loss: 0.8005 - accuracy: 0.757 - ETA: 24s - loss: 0.7990 - accuracy: 0.757 - ETA: 23s - loss: 0.7966 - accuracy: 0.757 - ETA: 22s - loss: 0.7961 - accuracy: 0.758 - ETA: 21s - loss: 0.7947 - accuracy: 0.758 - ETA: 21s - loss: 0.7942 - accuracy: 0.758 - ETA: 20s - loss: 0.7967 - accuracy: 0.757 - ETA: 19s - loss: 0.7982 - accuracy: 0.757 - ETA: 19s - loss: 0.8001 - accuracy: 0.756 - ETA: 18s - loss: 0.7998 - accuracy: 0.756 - ETA: 17s - loss: 0.7975 - accuracy: 0.757 - ETA: 17s - loss: 0.8002 - accuracy: 0.756 - ETA: 16s - loss: 0.8003 - accuracy: 0.756 - ETA: 15s - loss: 0.7975 - accuracy: 0.757 - ETA: 15s - loss: 0.7971 - accuracy: 0.756 - ETA: 14s - loss: 0.7958 - accuracy: 0.756 - ETA: 13s - loss: 0.7961 - accuracy: 0.757 - ETA: 12s - loss: 0.7978 - accuracy: 0.757 - ETA: 12s - loss: 0.7987 - accuracy: 0.756 - ETA: 11s - loss: 0.7969 - accuracy: 0.756 - ETA: 10s - loss: 0.7956 - accuracy: 0.757 - ETA: 10s - loss: 0.7936 - accuracy: 0.757 - ETA: 9s - loss: 0.7951 - accuracy: 0.756 - ETA: 8s - loss: 0.7978 - accuracy: 0.75 - ETA: 8s - loss: 0.7993 - accuracy: 0.75 - ETA: 7s - loss: 0.7990 - accuracy: 0.75 - ETA: 6s - loss: 0.7970 - accuracy: 0.75 - ETA: 6s - loss: 0.7953 - accuracy: 0.75 - ETA: 5s - loss: 0.7956 - accuracy: 0.75 - ETA: 4s - loss: 0.7966 - accuracy: 0.75 - ETA: 3s - loss: 0.7958 - accuracy: 0.75 - ETA: 3s - loss: 0.7937 - accuracy: 0.75 - ETA: 2s - loss: 0.7944 - accuracy: 0.75 - ETA: 1s - loss: 0.7948 - accuracy: 0.75 - ETA: 1s - loss: 0.7968 - accuracy: 0.75 - ETA: 0s - loss: 0.7955 - accuracy: 0.75 - 81s 6ms/step - loss: 0.7954 - accuracy: 0.7566 - val_loss: 2.8625 - val_accuracy: 0.3333\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.8548 - accuracy: 0.72 - ETA: 1:09 - loss: 0.8311 - accuracy: 0.74 - ETA: 1:08 - loss: 0.8364 - accuracy: 0.73 - ETA: 1:07 - loss: 0.8270 - accuracy: 0.73 - ETA: 1:06 - loss: 0.8568 - accuracy: 0.73 - ETA: 1:05 - loss: 0.8282 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8156 - accuracy: 0.74 - ETA: 1:04 - loss: 0.8050 - accuracy: 0.75 - ETA: 1:03 - loss: 0.8066 - accuracy: 0.75 - ETA: 1:03 - loss: 0.8023 - accuracy: 0.75 - ETA: 1:02 - loss: 0.7833 - accuracy: 0.75 - ETA: 1:02 - loss: 0.7878 - accuracy: 0.75 - ETA: 1:01 - loss: 0.7927 - accuracy: 0.75 - ETA: 1:00 - loss: 0.8022 - accuracy: 0.75 - ETA: 1:00 - loss: 0.8056 - accuracy: 0.75 - ETA: 59s - loss: 0.8004 - accuracy: 0.7529 - ETA: 58s - loss: 0.7888 - accuracy: 0.755 - ETA: 57s - loss: 0.7864 - accuracy: 0.756 - ETA: 57s - loss: 0.7810 - accuracy: 0.757 - ETA: 56s - loss: 0.7920 - accuracy: 0.754 - ETA: 55s - loss: 0.7949 - accuracy: 0.753 - ETA: 55s - loss: 0.7950 - accuracy: 0.750 - ETA: 54s - loss: 0.7906 - accuracy: 0.751 - ETA: 53s - loss: 0.7925 - accuracy: 0.750 - ETA: 52s - loss: 0.7887 - accuracy: 0.750 - ETA: 52s - loss: 0.7965 - accuracy: 0.749 - ETA: 51s - loss: 0.7992 - accuracy: 0.749 - ETA: 50s - loss: 0.7946 - accuracy: 0.751 - ETA: 50s - loss: 0.7980 - accuracy: 0.750 - ETA: 49s - loss: 0.7956 - accuracy: 0.752 - ETA: 48s - loss: 0.7937 - accuracy: 0.751 - ETA: 48s - loss: 0.8028 - accuracy: 0.749 - ETA: 47s - loss: 0.8051 - accuracy: 0.748 - ETA: 46s - loss: 0.8115 - accuracy: 0.747 - ETA: 46s - loss: 0.8077 - accuracy: 0.749 - ETA: 45s - loss: 0.8033 - accuracy: 0.751 - ETA: 44s - loss: 0.8036 - accuracy: 0.751 - ETA: 44s - loss: 0.7995 - accuracy: 0.752 - ETA: 43s - loss: 0.8047 - accuracy: 0.750 - ETA: 42s - loss: 0.8030 - accuracy: 0.751 - ETA: 42s - loss: 0.8074 - accuracy: 0.750 - ETA: 41s - loss: 0.8038 - accuracy: 0.751 - ETA: 40s - loss: 0.8091 - accuracy: 0.750 - ETA: 39s - loss: 0.8069 - accuracy: 0.750 - ETA: 39s - loss: 0.8058 - accuracy: 0.750 - ETA: 38s - loss: 0.8099 - accuracy: 0.749 - ETA: 37s - loss: 0.8130 - accuracy: 0.749 - ETA: 37s - loss: 0.8137 - accuracy: 0.749 - ETA: 36s - loss: 0.8161 - accuracy: 0.749 - ETA: 35s - loss: 0.8209 - accuracy: 0.747 - ETA: 35s - loss: 0.8202 - accuracy: 0.748 - ETA: 34s - loss: 0.8181 - accuracy: 0.749 - ETA: 33s - loss: 0.8201 - accuracy: 0.749 - ETA: 33s - loss: 0.8220 - accuracy: 0.750 - ETA: 32s - loss: 0.8190 - accuracy: 0.751 - ETA: 31s - loss: 0.8204 - accuracy: 0.750 - ETA: 31s - loss: 0.8178 - accuracy: 0.750 - ETA: 30s - loss: 0.8217 - accuracy: 0.749 - ETA: 29s - loss: 0.8185 - accuracy: 0.750 - ETA: 29s - loss: 0.8192 - accuracy: 0.750 - ETA: 28s - loss: 0.8217 - accuracy: 0.750 - ETA: 27s - loss: 0.8203 - accuracy: 0.750 - ETA: 26s - loss: 0.8180 - accuracy: 0.750 - ETA: 26s - loss: 0.8176 - accuracy: 0.750 - ETA: 25s - loss: 0.8191 - accuracy: 0.750 - ETA: 24s - loss: 0.8169 - accuracy: 0.750 - ETA: 24s - loss: 0.8158 - accuracy: 0.750 - ETA: 23s - loss: 0.8144 - accuracy: 0.750 - ETA: 22s - loss: 0.8174 - accuracy: 0.750 - ETA: 22s - loss: 0.8186 - accuracy: 0.749 - ETA: 21s - loss: 0.8178 - accuracy: 0.749 - ETA: 20s - loss: 0.8141 - accuracy: 0.750 - ETA: 19s - loss: 0.8162 - accuracy: 0.749 - ETA: 19s - loss: 0.8159 - accuracy: 0.749 - ETA: 18s - loss: 0.8160 - accuracy: 0.749 - ETA: 17s - loss: 0.8151 - accuracy: 0.749 - ETA: 17s - loss: 0.8160 - accuracy: 0.749 - ETA: 16s - loss: 0.8118 - accuracy: 0.750 - ETA: 15s - loss: 0.8109 - accuracy: 0.750 - ETA: 15s - loss: 0.8134 - accuracy: 0.749 - ETA: 14s - loss: 0.8124 - accuracy: 0.750 - ETA: 13s - loss: 0.8128 - accuracy: 0.750 - ETA: 12s - loss: 0.8142 - accuracy: 0.750 - ETA: 12s - loss: 0.8144 - accuracy: 0.749 - ETA: 11s - loss: 0.8151 - accuracy: 0.749 - ETA: 10s - loss: 0.8162 - accuracy: 0.748 - ETA: 10s - loss: 0.8170 - accuracy: 0.748 - ETA: 9s - loss: 0.8162 - accuracy: 0.748 - ETA: 8s - loss: 0.8151 - accuracy: 0.74 - ETA: 8s - loss: 0.8149 - accuracy: 0.74 - ETA: 7s - loss: 0.8136 - accuracy: 0.74 - ETA: 6s - loss: 0.8158 - accuracy: 0.74 - ETA: 6s - loss: 0.8155 - accuracy: 0.74 - ETA: 5s - loss: 0.8144 - accuracy: 0.74 - ETA: 4s - loss: 0.8132 - accuracy: 0.74 - ETA: 3s - loss: 0.8144 - accuracy: 0.74 - ETA: 3s - loss: 0.8143 - accuracy: 0.74 - ETA: 2s - loss: 0.8144 - accuracy: 0.74 - ETA: 1s - loss: 0.8146 - accuracy: 0.74 - ETA: 1s - loss: 0.8122 - accuracy: 0.74 - ETA: 0s - loss: 0.8126 - accuracy: 0.74 - 81s 6ms/step - loss: 0.8113 - accuracy: 0.7491 - val_loss: 2.8257 - val_accuracy: 0.3467\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.7172 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8942 - accuracy: 0.74 - ETA: 1:09 - loss: 0.8854 - accuracy: 0.75 - ETA: 1:09 - loss: 0.8353 - accuracy: 0.76 - ETA: 1:08 - loss: 0.8351 - accuracy: 0.75 - ETA: 1:07 - loss: 0.8437 - accuracy: 0.76 - ETA: 1:07 - loss: 0.8637 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8411 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8439 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8209 - accuracy: 0.76 - ETA: 1:04 - loss: 0.8266 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8176 - accuracy: 0.76 - ETA: 1:03 - loss: 0.8147 - accuracy: 0.76 - ETA: 1:02 - loss: 0.8165 - accuracy: 0.75 - ETA: 1:01 - loss: 0.8008 - accuracy: 0.76 - ETA: 1:01 - loss: 0.7953 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7922 - accuracy: 0.75 - ETA: 59s - loss: 0.7963 - accuracy: 0.7556 - ETA: 58s - loss: 0.7930 - accuracy: 0.757 - ETA: 57s - loss: 0.7934 - accuracy: 0.759 - ETA: 57s - loss: 0.7978 - accuracy: 0.756 - ETA: 56s - loss: 0.8057 - accuracy: 0.754 - ETA: 55s - loss: 0.8098 - accuracy: 0.752 - ETA: 54s - loss: 0.8040 - accuracy: 0.753 - ETA: 53s - loss: 0.8067 - accuracy: 0.753 - ETA: 53s - loss: 0.7995 - accuracy: 0.755 - ETA: 52s - loss: 0.7996 - accuracy: 0.753 - ETA: 51s - loss: 0.7998 - accuracy: 0.753 - ETA: 50s - loss: 0.7985 - accuracy: 0.754 - ETA: 50s - loss: 0.8024 - accuracy: 0.754 - ETA: 49s - loss: 0.8011 - accuracy: 0.754 - ETA: 49s - loss: 0.7994 - accuracy: 0.755 - ETA: 48s - loss: 0.7984 - accuracy: 0.754 - ETA: 47s - loss: 0.8000 - accuracy: 0.753 - ETA: 47s - loss: 0.8088 - accuracy: 0.750 - ETA: 46s - loss: 0.8069 - accuracy: 0.751 - ETA: 45s - loss: 0.8045 - accuracy: 0.752 - ETA: 44s - loss: 0.8087 - accuracy: 0.751 - ETA: 44s - loss: 0.8107 - accuracy: 0.751 - ETA: 43s - loss: 0.8091 - accuracy: 0.751 - ETA: 42s - loss: 0.8116 - accuracy: 0.749 - ETA: 42s - loss: 0.8110 - accuracy: 0.749 - ETA: 41s - loss: 0.8111 - accuracy: 0.748 - ETA: 40s - loss: 0.8101 - accuracy: 0.750 - ETA: 39s - loss: 0.8068 - accuracy: 0.751 - ETA: 39s - loss: 0.8027 - accuracy: 0.752 - ETA: 38s - loss: 0.7996 - accuracy: 0.753 - ETA: 37s - loss: 0.7954 - accuracy: 0.754 - ETA: 37s - loss: 0.7945 - accuracy: 0.754 - ETA: 36s - loss: 0.7950 - accuracy: 0.754 - ETA: 35s - loss: 0.7979 - accuracy: 0.754 - ETA: 34s - loss: 0.8001 - accuracy: 0.755 - ETA: 34s - loss: 0.8017 - accuracy: 0.754 - ETA: 33s - loss: 0.8074 - accuracy: 0.753 - ETA: 32s - loss: 0.8070 - accuracy: 0.753 - ETA: 32s - loss: 0.8067 - accuracy: 0.753 - ETA: 31s - loss: 0.8080 - accuracy: 0.752 - ETA: 30s - loss: 0.8064 - accuracy: 0.752 - ETA: 30s - loss: 0.8081 - accuracy: 0.752 - ETA: 29s - loss: 0.8047 - accuracy: 0.752 - ETA: 28s - loss: 0.8090 - accuracy: 0.752 - ETA: 27s - loss: 0.8117 - accuracy: 0.751 - ETA: 27s - loss: 0.8089 - accuracy: 0.752 - ETA: 26s - loss: 0.8083 - accuracy: 0.752 - ETA: 25s - loss: 0.8074 - accuracy: 0.753 - ETA: 25s - loss: 0.8066 - accuracy: 0.753 - ETA: 24s - loss: 0.8049 - accuracy: 0.754 - ETA: 23s - loss: 0.8069 - accuracy: 0.753 - ETA: 22s - loss: 0.8067 - accuracy: 0.753 - ETA: 22s - loss: 0.8060 - accuracy: 0.754 - ETA: 21s - loss: 0.8065 - accuracy: 0.754 - ETA: 20s - loss: 0.8056 - accuracy: 0.754 - ETA: 20s - loss: 0.8076 - accuracy: 0.754 - ETA: 19s - loss: 0.8107 - accuracy: 0.753 - ETA: 18s - loss: 0.8105 - accuracy: 0.753 - ETA: 18s - loss: 0.8103 - accuracy: 0.754 - ETA: 17s - loss: 0.8119 - accuracy: 0.753 - ETA: 16s - loss: 0.8119 - accuracy: 0.753 - ETA: 15s - loss: 0.8123 - accuracy: 0.752 - ETA: 15s - loss: 0.8151 - accuracy: 0.752 - ETA: 14s - loss: 0.8137 - accuracy: 0.753 - ETA: 13s - loss: 0.8123 - accuracy: 0.753 - ETA: 13s - loss: 0.8118 - accuracy: 0.753 - ETA: 12s - loss: 0.8107 - accuracy: 0.754 - ETA: 11s - loss: 0.8141 - accuracy: 0.754 - ETA: 11s - loss: 0.8147 - accuracy: 0.754 - ETA: 10s - loss: 0.8155 - accuracy: 0.753 - ETA: 9s - loss: 0.8166 - accuracy: 0.753 - ETA: 8s - loss: 0.8182 - accuracy: 0.75 - ETA: 8s - loss: 0.8168 - accuracy: 0.75 - ETA: 7s - loss: 0.8174 - accuracy: 0.75 - ETA: 6s - loss: 0.8181 - accuracy: 0.75 - ETA: 6s - loss: 0.8192 - accuracy: 0.75 - ETA: 5s - loss: 0.8206 - accuracy: 0.75 - ETA: 4s - loss: 0.8211 - accuracy: 0.75 - ETA: 4s - loss: 0.8200 - accuracy: 0.75 - ETA: 3s - loss: 0.8203 - accuracy: 0.75 - ETA: 2s - loss: 0.8196 - accuracy: 0.75 - ETA: 1s - loss: 0.8215 - accuracy: 0.75 - ETA: 1s - loss: 0.8215 - accuracy: 0.75 - ETA: 0s - loss: 0.8215 - accuracy: 0.75 - 82s 6ms/step - loss: 0.8203 - accuracy: 0.7517 - val_loss: 2.8440 - val_accuracy: 0.3251\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.6352 - accuracy: 0.78 - ETA: 1:11 - loss: 0.6669 - accuracy: 0.78 - ETA: 1:10 - loss: 0.7271 - accuracy: 0.77 - ETA: 1:08 - loss: 0.7711 - accuracy: 0.77 - ETA: 1:08 - loss: 0.7716 - accuracy: 0.77 - ETA: 1:08 - loss: 0.7760 - accuracy: 0.77 - ETA: 1:07 - loss: 0.7813 - accuracy: 0.77 - ETA: 1:07 - loss: 0.8085 - accuracy: 0.75 - ETA: 1:07 - loss: 0.8194 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8174 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8064 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8030 - accuracy: 0.75 - ETA: 1:04 - loss: 0.7893 - accuracy: 0.75 - ETA: 1:03 - loss: 0.7815 - accuracy: 0.75 - ETA: 1:02 - loss: 0.7927 - accuracy: 0.75 - ETA: 1:01 - loss: 0.7886 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7898 - accuracy: 0.75 - ETA: 59s - loss: 0.7982 - accuracy: 0.7504 - ETA: 58s - loss: 0.7973 - accuracy: 0.750 - ETA: 58s - loss: 0.8040 - accuracy: 0.750 - ETA: 57s - loss: 0.8026 - accuracy: 0.749 - ETA: 56s - loss: 0.7992 - accuracy: 0.750 - ETA: 55s - loss: 0.7916 - accuracy: 0.752 - ETA: 55s - loss: 0.7940 - accuracy: 0.751 - ETA: 54s - loss: 0.7897 - accuracy: 0.751 - ETA: 53s - loss: 0.7894 - accuracy: 0.752 - ETA: 52s - loss: 0.7922 - accuracy: 0.750 - ETA: 52s - loss: 0.7901 - accuracy: 0.751 - ETA: 51s - loss: 0.7914 - accuracy: 0.751 - ETA: 50s - loss: 0.7903 - accuracy: 0.750 - ETA: 50s - loss: 0.7927 - accuracy: 0.749 - ETA: 49s - loss: 0.7920 - accuracy: 0.748 - ETA: 48s - loss: 0.7921 - accuracy: 0.747 - ETA: 47s - loss: 0.7925 - accuracy: 0.746 - ETA: 46s - loss: 0.7891 - accuracy: 0.748 - ETA: 46s - loss: 0.7894 - accuracy: 0.746 - ETA: 45s - loss: 0.7909 - accuracy: 0.747 - ETA: 44s - loss: 0.7899 - accuracy: 0.746 - ETA: 44s - loss: 0.7914 - accuracy: 0.745 - ETA: 43s - loss: 0.7903 - accuracy: 0.747 - ETA: 42s - loss: 0.7926 - accuracy: 0.746 - ETA: 41s - loss: 0.7900 - accuracy: 0.747 - ETA: 41s - loss: 0.7889 - accuracy: 0.747 - ETA: 40s - loss: 0.7854 - accuracy: 0.748 - ETA: 39s - loss: 0.7878 - accuracy: 0.748 - ETA: 39s - loss: 0.7867 - accuracy: 0.750 - ETA: 38s - loss: 0.7820 - accuracy: 0.751 - ETA: 37s - loss: 0.7812 - accuracy: 0.752 - ETA: 36s - loss: 0.7893 - accuracy: 0.751 - ETA: 36s - loss: 0.7893 - accuracy: 0.751 - ETA: 35s - loss: 0.7903 - accuracy: 0.750 - ETA: 34s - loss: 0.7893 - accuracy: 0.751 - ETA: 34s - loss: 0.7868 - accuracy: 0.752 - ETA: 33s - loss: 0.7877 - accuracy: 0.752 - ETA: 32s - loss: 0.7829 - accuracy: 0.753 - ETA: 32s - loss: 0.7814 - accuracy: 0.755 - ETA: 31s - loss: 0.7813 - accuracy: 0.754 - ETA: 30s - loss: 0.7813 - accuracy: 0.755 - ETA: 29s - loss: 0.7824 - accuracy: 0.754 - ETA: 29s - loss: 0.7811 - accuracy: 0.754 - ETA: 28s - loss: 0.7801 - accuracy: 0.755 - ETA: 27s - loss: 0.7804 - accuracy: 0.755 - ETA: 27s - loss: 0.7825 - accuracy: 0.754 - ETA: 26s - loss: 0.7825 - accuracy: 0.754 - ETA: 25s - loss: 0.7808 - accuracy: 0.755 - ETA: 24s - loss: 0.7802 - accuracy: 0.755 - ETA: 24s - loss: 0.7822 - accuracy: 0.754 - ETA: 23s - loss: 0.7807 - accuracy: 0.754 - ETA: 22s - loss: 0.7793 - accuracy: 0.755 - ETA: 22s - loss: 0.7805 - accuracy: 0.754 - ETA: 21s - loss: 0.7813 - accuracy: 0.755 - ETA: 20s - loss: 0.7810 - accuracy: 0.755 - ETA: 20s - loss: 0.7847 - accuracy: 0.754 - ETA: 19s - loss: 0.7827 - accuracy: 0.754 - ETA: 18s - loss: 0.7819 - accuracy: 0.755 - ETA: 17s - loss: 0.7810 - accuracy: 0.755 - ETA: 17s - loss: 0.7811 - accuracy: 0.755 - ETA: 16s - loss: 0.7811 - accuracy: 0.755 - ETA: 15s - loss: 0.7794 - accuracy: 0.755 - ETA: 15s - loss: 0.7784 - accuracy: 0.755 - ETA: 14s - loss: 0.7788 - accuracy: 0.755 - ETA: 13s - loss: 0.7822 - accuracy: 0.754 - ETA: 13s - loss: 0.7791 - accuracy: 0.755 - ETA: 12s - loss: 0.7797 - accuracy: 0.755 - ETA: 11s - loss: 0.7795 - accuracy: 0.755 - ETA: 10s - loss: 0.7779 - accuracy: 0.755 - ETA: 10s - loss: 0.7778 - accuracy: 0.756 - ETA: 9s - loss: 0.7771 - accuracy: 0.756 - ETA: 8s - loss: 0.7745 - accuracy: 0.75 - ETA: 8s - loss: 0.7752 - accuracy: 0.75 - ETA: 7s - loss: 0.7728 - accuracy: 0.75 - ETA: 6s - loss: 0.7730 - accuracy: 0.75 - ETA: 6s - loss: 0.7725 - accuracy: 0.75 - ETA: 5s - loss: 0.7734 - accuracy: 0.75 - ETA: 4s - loss: 0.7717 - accuracy: 0.75 - ETA: 4s - loss: 0.7739 - accuracy: 0.75 - ETA: 3s - loss: 0.7746 - accuracy: 0.75 - ETA: 2s - loss: 0.7724 - accuracy: 0.75 - ETA: 1s - loss: 0.7712 - accuracy: 0.75 - ETA: 1s - loss: 0.7716 - accuracy: 0.75 - ETA: 0s - loss: 0.7708 - accuracy: 0.75 - 82s 6ms/step - loss: 0.7710 - accuracy: 0.7585 - val_loss: 2.9623 - val_accuracy: 0.3229\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:08 - loss: 0.7717 - accuracy: 0.77 - ETA: 1:09 - loss: 0.7462 - accuracy: 0.77 - ETA: 1:10 - loss: 0.7412 - accuracy: 0.78 - ETA: 1:09 - loss: 0.7320 - accuracy: 0.77 - ETA: 1:08 - loss: 0.7207 - accuracy: 0.78 - ETA: 1:06 - loss: 0.7076 - accuracy: 0.78 - ETA: 1:06 - loss: 0.6784 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6824 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6741 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6951 - accuracy: 0.78 - ETA: 1:02 - loss: 0.6855 - accuracy: 0.78 - ETA: 1:02 - loss: 0.6908 - accuracy: 0.79 - ETA: 1:01 - loss: 0.7061 - accuracy: 0.78 - ETA: 1:00 - loss: 0.7165 - accuracy: 0.78 - ETA: 1:00 - loss: 0.7292 - accuracy: 0.77 - ETA: 59s - loss: 0.7304 - accuracy: 0.7769 - ETA: 58s - loss: 0.7403 - accuracy: 0.775 - ETA: 57s - loss: 0.7340 - accuracy: 0.775 - ETA: 57s - loss: 0.7357 - accuracy: 0.775 - ETA: 56s - loss: 0.7375 - accuracy: 0.776 - ETA: 55s - loss: 0.7316 - accuracy: 0.776 - ETA: 55s - loss: 0.7280 - accuracy: 0.777 - ETA: 54s - loss: 0.7315 - accuracy: 0.776 - ETA: 53s - loss: 0.7296 - accuracy: 0.776 - ETA: 53s - loss: 0.7307 - accuracy: 0.774 - ETA: 52s - loss: 0.7286 - accuracy: 0.776 - ETA: 51s - loss: 0.7345 - accuracy: 0.774 - ETA: 51s - loss: 0.7414 - accuracy: 0.772 - ETA: 50s - loss: 0.7458 - accuracy: 0.771 - ETA: 49s - loss: 0.7488 - accuracy: 0.770 - ETA: 49s - loss: 0.7534 - accuracy: 0.770 - ETA: 48s - loss: 0.7501 - accuracy: 0.771 - ETA: 47s - loss: 0.7551 - accuracy: 0.771 - ETA: 47s - loss: 0.7528 - accuracy: 0.771 - ETA: 46s - loss: 0.7589 - accuracy: 0.769 - ETA: 45s - loss: 0.7607 - accuracy: 0.768 - ETA: 45s - loss: 0.7599 - accuracy: 0.767 - ETA: 44s - loss: 0.7581 - accuracy: 0.766 - ETA: 43s - loss: 0.7630 - accuracy: 0.766 - ETA: 42s - loss: 0.7656 - accuracy: 0.765 - ETA: 42s - loss: 0.7644 - accuracy: 0.765 - ETA: 41s - loss: 0.7658 - accuracy: 0.765 - ETA: 40s - loss: 0.7668 - accuracy: 0.766 - ETA: 40s - loss: 0.7659 - accuracy: 0.765 - ETA: 39s - loss: 0.7644 - accuracy: 0.765 - ETA: 38s - loss: 0.7672 - accuracy: 0.764 - ETA: 37s - loss: 0.7642 - accuracy: 0.765 - ETA: 37s - loss: 0.7718 - accuracy: 0.764 - ETA: 36s - loss: 0.7698 - accuracy: 0.765 - ETA: 35s - loss: 0.7676 - accuracy: 0.765 - ETA: 35s - loss: 0.7660 - accuracy: 0.766 - ETA: 34s - loss: 0.7637 - accuracy: 0.767 - ETA: 33s - loss: 0.7621 - accuracy: 0.766 - ETA: 33s - loss: 0.7645 - accuracy: 0.766 - ETA: 32s - loss: 0.7633 - accuracy: 0.767 - ETA: 31s - loss: 0.7638 - accuracy: 0.767 - ETA: 31s - loss: 0.7645 - accuracy: 0.767 - ETA: 30s - loss: 0.7663 - accuracy: 0.767 - ETA: 29s - loss: 0.7699 - accuracy: 0.766 - ETA: 28s - loss: 0.7690 - accuracy: 0.766 - ETA: 28s - loss: 0.7670 - accuracy: 0.767 - ETA: 27s - loss: 0.7661 - accuracy: 0.766 - ETA: 26s - loss: 0.7663 - accuracy: 0.766 - ETA: 26s - loss: 0.7653 - accuracy: 0.766 - ETA: 25s - loss: 0.7664 - accuracy: 0.766 - ETA: 24s - loss: 0.7673 - accuracy: 0.765 - ETA: 24s - loss: 0.7677 - accuracy: 0.766 - ETA: 23s - loss: 0.7683 - accuracy: 0.765 - ETA: 22s - loss: 0.7680 - accuracy: 0.765 - ETA: 21s - loss: 0.7677 - accuracy: 0.766 - ETA: 21s - loss: 0.7722 - accuracy: 0.765 - ETA: 20s - loss: 0.7726 - accuracy: 0.765 - ETA: 19s - loss: 0.7720 - accuracy: 0.765 - ETA: 19s - loss: 0.7733 - accuracy: 0.765 - ETA: 18s - loss: 0.7721 - accuracy: 0.765 - ETA: 17s - loss: 0.7684 - accuracy: 0.765 - ETA: 17s - loss: 0.7664 - accuracy: 0.766 - ETA: 16s - loss: 0.7660 - accuracy: 0.766 - ETA: 15s - loss: 0.7700 - accuracy: 0.765 - ETA: 15s - loss: 0.7698 - accuracy: 0.766 - ETA: 14s - loss: 0.7728 - accuracy: 0.765 - ETA: 13s - loss: 0.7735 - accuracy: 0.764 - ETA: 13s - loss: 0.7755 - accuracy: 0.763 - ETA: 12s - loss: 0.7775 - accuracy: 0.762 - ETA: 11s - loss: 0.7776 - accuracy: 0.762 - ETA: 10s - loss: 0.7785 - accuracy: 0.762 - ETA: 10s - loss: 0.7752 - accuracy: 0.762 - ETA: 9s - loss: 0.7742 - accuracy: 0.763 - ETA: 8s - loss: 0.7732 - accuracy: 0.76 - ETA: 8s - loss: 0.7741 - accuracy: 0.76 - ETA: 7s - loss: 0.7747 - accuracy: 0.76 - ETA: 6s - loss: 0.7749 - accuracy: 0.76 - ETA: 6s - loss: 0.7743 - accuracy: 0.76 - ETA: 5s - loss: 0.7740 - accuracy: 0.76 - ETA: 4s - loss: 0.7725 - accuracy: 0.76 - ETA: 3s - loss: 0.7718 - accuracy: 0.76 - ETA: 3s - loss: 0.7729 - accuracy: 0.76 - ETA: 2s - loss: 0.7728 - accuracy: 0.76 - ETA: 1s - loss: 0.7721 - accuracy: 0.76 - ETA: 1s - loss: 0.7720 - accuracy: 0.76 - ETA: 0s - loss: 0.7720 - accuracy: 0.76 - 81s 6ms/step - loss: 0.7703 - accuracy: 0.7648 - val_loss: 2.8005 - val_accuracy: 0.3402\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.6747 - accuracy: 0.76 - ETA: 1:12 - loss: 0.7561 - accuracy: 0.77 - ETA: 1:10 - loss: 0.7353 - accuracy: 0.78 - ETA: 1:08 - loss: 0.7407 - accuracy: 0.77 - ETA: 1:07 - loss: 0.7433 - accuracy: 0.77 - ETA: 1:06 - loss: 0.7224 - accuracy: 0.77 - ETA: 1:06 - loss: 0.7065 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7180 - accuracy: 0.77 - ETA: 1:04 - loss: 0.7227 - accuracy: 0.77 - ETA: 1:04 - loss: 0.7523 - accuracy: 0.76 - ETA: 1:03 - loss: 0.7417 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7480 - accuracy: 0.77 - ETA: 1:01 - loss: 0.7620 - accuracy: 0.76 - ETA: 1:00 - loss: 0.7553 - accuracy: 0.76 - ETA: 59s - loss: 0.7511 - accuracy: 0.7677 - ETA: 59s - loss: 0.7451 - accuracy: 0.769 - ETA: 58s - loss: 0.7384 - accuracy: 0.770 - ETA: 58s - loss: 0.7283 - accuracy: 0.772 - ETA: 57s - loss: 0.7246 - accuracy: 0.773 - ETA: 56s - loss: 0.7212 - accuracy: 0.771 - ETA: 55s - loss: 0.7160 - accuracy: 0.773 - ETA: 55s - loss: 0.7179 - accuracy: 0.773 - ETA: 54s - loss: 0.7130 - accuracy: 0.775 - ETA: 54s - loss: 0.7109 - accuracy: 0.776 - ETA: 53s - loss: 0.7097 - accuracy: 0.777 - ETA: 52s - loss: 0.7079 - accuracy: 0.776 - ETA: 52s - loss: 0.7029 - accuracy: 0.778 - ETA: 51s - loss: 0.7075 - accuracy: 0.777 - ETA: 50s - loss: 0.7103 - accuracy: 0.776 - ETA: 50s - loss: 0.7126 - accuracy: 0.775 - ETA: 49s - loss: 0.7082 - accuracy: 0.777 - ETA: 48s - loss: 0.7138 - accuracy: 0.775 - ETA: 47s - loss: 0.7186 - accuracy: 0.775 - ETA: 47s - loss: 0.7233 - accuracy: 0.775 - ETA: 46s - loss: 0.7281 - accuracy: 0.774 - ETA: 45s - loss: 0.7283 - accuracy: 0.773 - ETA: 45s - loss: 0.7257 - accuracy: 0.773 - ETA: 44s - loss: 0.7295 - accuracy: 0.772 - ETA: 43s - loss: 0.7385 - accuracy: 0.770 - ETA: 43s - loss: 0.7371 - accuracy: 0.770 - ETA: 42s - loss: 0.7330 - accuracy: 0.772 - ETA: 41s - loss: 0.7351 - accuracy: 0.770 - ETA: 41s - loss: 0.7315 - accuracy: 0.772 - ETA: 40s - loss: 0.7311 - accuracy: 0.773 - ETA: 39s - loss: 0.7287 - accuracy: 0.774 - ETA: 38s - loss: 0.7253 - accuracy: 0.775 - ETA: 38s - loss: 0.7298 - accuracy: 0.774 - ETA: 37s - loss: 0.7305 - accuracy: 0.774 - ETA: 36s - loss: 0.7313 - accuracy: 0.773 - ETA: 36s - loss: 0.7322 - accuracy: 0.773 - ETA: 35s - loss: 0.7314 - accuracy: 0.774 - ETA: 34s - loss: 0.7318 - accuracy: 0.774 - ETA: 33s - loss: 0.7298 - accuracy: 0.774 - ETA: 33s - loss: 0.7287 - accuracy: 0.775 - ETA: 32s - loss: 0.7324 - accuracy: 0.773 - ETA: 31s - loss: 0.7310 - accuracy: 0.773 - ETA: 31s - loss: 0.7324 - accuracy: 0.774 - ETA: 30s - loss: 0.7331 - accuracy: 0.773 - ETA: 29s - loss: 0.7309 - accuracy: 0.774 - ETA: 29s - loss: 0.7331 - accuracy: 0.773 - ETA: 28s - loss: 0.7324 - accuracy: 0.773 - ETA: 27s - loss: 0.7317 - accuracy: 0.773 - ETA: 27s - loss: 0.7361 - accuracy: 0.773 - ETA: 26s - loss: 0.7389 - accuracy: 0.772 - ETA: 25s - loss: 0.7365 - accuracy: 0.773 - ETA: 25s - loss: 0.7348 - accuracy: 0.773 - ETA: 24s - loss: 0.7365 - accuracy: 0.773 - ETA: 23s - loss: 0.7400 - accuracy: 0.772 - ETA: 22s - loss: 0.7449 - accuracy: 0.771 - ETA: 22s - loss: 0.7470 - accuracy: 0.771 - ETA: 21s - loss: 0.7471 - accuracy: 0.771 - ETA: 20s - loss: 0.7491 - accuracy: 0.770 - ETA: 20s - loss: 0.7463 - accuracy: 0.771 - ETA: 19s - loss: 0.7476 - accuracy: 0.771 - ETA: 18s - loss: 0.7515 - accuracy: 0.770 - ETA: 18s - loss: 0.7509 - accuracy: 0.770 - ETA: 17s - loss: 0.7538 - accuracy: 0.769 - ETA: 16s - loss: 0.7539 - accuracy: 0.769 - ETA: 15s - loss: 0.7544 - accuracy: 0.770 - ETA: 15s - loss: 0.7525 - accuracy: 0.770 - ETA: 14s - loss: 0.7527 - accuracy: 0.770 - ETA: 13s - loss: 0.7517 - accuracy: 0.770 - ETA: 13s - loss: 0.7510 - accuracy: 0.770 - ETA: 12s - loss: 0.7532 - accuracy: 0.770 - ETA: 11s - loss: 0.7531 - accuracy: 0.770 - ETA: 10s - loss: 0.7545 - accuracy: 0.769 - ETA: 10s - loss: 0.7545 - accuracy: 0.769 - ETA: 9s - loss: 0.7545 - accuracy: 0.769 - ETA: 8s - loss: 0.7544 - accuracy: 0.76 - ETA: 8s - loss: 0.7537 - accuracy: 0.77 - ETA: 7s - loss: 0.7522 - accuracy: 0.77 - ETA: 6s - loss: 0.7559 - accuracy: 0.77 - ETA: 6s - loss: 0.7548 - accuracy: 0.77 - ETA: 5s - loss: 0.7534 - accuracy: 0.77 - ETA: 4s - loss: 0.7547 - accuracy: 0.77 - ETA: 4s - loss: 0.7558 - accuracy: 0.76 - ETA: 3s - loss: 0.7586 - accuracy: 0.76 - ETA: 2s - loss: 0.7599 - accuracy: 0.76 - ETA: 1s - loss: 0.7587 - accuracy: 0.76 - ETA: 1s - loss: 0.7572 - accuracy: 0.76 - ETA: 0s - loss: 0.7550 - accuracy: 0.76 - 82s 6ms/step - loss: 0.7556 - accuracy: 0.7686 - val_loss: 2.9598 - val_accuracy: 0.3267\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:19 - loss: 0.5806 - accuracy: 0.84 - ETA: 1:14 - loss: 0.7621 - accuracy: 0.75 - ETA: 1:12 - loss: 0.7414 - accuracy: 0.76 - ETA: 1:10 - loss: 0.8343 - accuracy: 0.74 - ETA: 1:09 - loss: 0.8238 - accuracy: 0.74 - ETA: 1:08 - loss: 0.8011 - accuracy: 0.75 - ETA: 1:07 - loss: 0.7880 - accuracy: 0.76 - ETA: 1:07 - loss: 0.7969 - accuracy: 0.75 - ETA: 1:06 - loss: 0.7997 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8286 - accuracy: 0.75 - ETA: 1:04 - loss: 0.8178 - accuracy: 0.75 - ETA: 1:03 - loss: 0.8219 - accuracy: 0.75 - ETA: 1:02 - loss: 0.8102 - accuracy: 0.75 - ETA: 1:01 - loss: 0.8266 - accuracy: 0.75 - ETA: 1:01 - loss: 0.8097 - accuracy: 0.75 - ETA: 1:00 - loss: 0.7975 - accuracy: 0.76 - ETA: 59s - loss: 0.7934 - accuracy: 0.7661 - ETA: 59s - loss: 0.7827 - accuracy: 0.767 - ETA: 58s - loss: 0.7754 - accuracy: 0.770 - ETA: 57s - loss: 0.7784 - accuracy: 0.768 - ETA: 57s - loss: 0.7791 - accuracy: 0.769 - ETA: 56s - loss: 0.7809 - accuracy: 0.767 - ETA: 55s - loss: 0.7759 - accuracy: 0.769 - ETA: 54s - loss: 0.7694 - accuracy: 0.770 - ETA: 54s - loss: 0.7643 - accuracy: 0.772 - ETA: 53s - loss: 0.7646 - accuracy: 0.771 - ETA: 52s - loss: 0.7650 - accuracy: 0.770 - ETA: 51s - loss: 0.7626 - accuracy: 0.771 - ETA: 51s - loss: 0.7558 - accuracy: 0.773 - ETA: 50s - loss: 0.7541 - accuracy: 0.774 - ETA: 49s - loss: 0.7558 - accuracy: 0.773 - ETA: 49s - loss: 0.7543 - accuracy: 0.774 - ETA: 48s - loss: 0.7558 - accuracy: 0.773 - ETA: 47s - loss: 0.7606 - accuracy: 0.772 - ETA: 47s - loss: 0.7605 - accuracy: 0.772 - ETA: 46s - loss: 0.7594 - accuracy: 0.771 - ETA: 45s - loss: 0.7595 - accuracy: 0.771 - ETA: 45s - loss: 0.7632 - accuracy: 0.769 - ETA: 44s - loss: 0.7600 - accuracy: 0.771 - ETA: 43s - loss: 0.7590 - accuracy: 0.770 - ETA: 42s - loss: 0.7612 - accuracy: 0.771 - ETA: 42s - loss: 0.7654 - accuracy: 0.769 - ETA: 41s - loss: 0.7655 - accuracy: 0.769 - ETA: 40s - loss: 0.7645 - accuracy: 0.769 - ETA: 40s - loss: 0.7609 - accuracy: 0.771 - ETA: 39s - loss: 0.7636 - accuracy: 0.771 - ETA: 38s - loss: 0.7597 - accuracy: 0.771 - ETA: 38s - loss: 0.7595 - accuracy: 0.772 - ETA: 37s - loss: 0.7551 - accuracy: 0.773 - ETA: 36s - loss: 0.7546 - accuracy: 0.773 - ETA: 35s - loss: 0.7538 - accuracy: 0.773 - ETA: 35s - loss: 0.7550 - accuracy: 0.773 - ETA: 34s - loss: 0.7586 - accuracy: 0.772 - ETA: 33s - loss: 0.7538 - accuracy: 0.773 - ETA: 33s - loss: 0.7536 - accuracy: 0.773 - ETA: 32s - loss: 0.7532 - accuracy: 0.774 - ETA: 31s - loss: 0.7497 - accuracy: 0.775 - ETA: 30s - loss: 0.7525 - accuracy: 0.774 - ETA: 30s - loss: 0.7541 - accuracy: 0.773 - ETA: 29s - loss: 0.7519 - accuracy: 0.773 - ETA: 28s - loss: 0.7513 - accuracy: 0.773 - ETA: 27s - loss: 0.7528 - accuracy: 0.772 - ETA: 27s - loss: 0.7536 - accuracy: 0.771 - ETA: 26s - loss: 0.7525 - accuracy: 0.771 - ETA: 25s - loss: 0.7505 - accuracy: 0.772 - ETA: 25s - loss: 0.7553 - accuracy: 0.771 - ETA: 24s - loss: 0.7555 - accuracy: 0.771 - ETA: 23s - loss: 0.7522 - accuracy: 0.773 - ETA: 23s - loss: 0.7495 - accuracy: 0.774 - ETA: 22s - loss: 0.7490 - accuracy: 0.774 - ETA: 21s - loss: 0.7499 - accuracy: 0.774 - ETA: 20s - loss: 0.7491 - accuracy: 0.774 - ETA: 20s - loss: 0.7491 - accuracy: 0.775 - ETA: 19s - loss: 0.7498 - accuracy: 0.774 - ETA: 18s - loss: 0.7484 - accuracy: 0.774 - ETA: 18s - loss: 0.7483 - accuracy: 0.775 - ETA: 17s - loss: 0.7503 - accuracy: 0.774 - ETA: 16s - loss: 0.7484 - accuracy: 0.774 - ETA: 15s - loss: 0.7482 - accuracy: 0.774 - ETA: 15s - loss: 0.7467 - accuracy: 0.774 - ETA: 14s - loss: 0.7471 - accuracy: 0.774 - ETA: 13s - loss: 0.7441 - accuracy: 0.775 - ETA: 13s - loss: 0.7438 - accuracy: 0.775 - ETA: 12s - loss: 0.7433 - accuracy: 0.775 - ETA: 11s - loss: 0.7432 - accuracy: 0.775 - ETA: 11s - loss: 0.7428 - accuracy: 0.775 - ETA: 10s - loss: 0.7429 - accuracy: 0.775 - ETA: 9s - loss: 0.7420 - accuracy: 0.775 - ETA: 8s - loss: 0.7414 - accuracy: 0.77 - ETA: 8s - loss: 0.7421 - accuracy: 0.77 - ETA: 7s - loss: 0.7425 - accuracy: 0.77 - ETA: 6s - loss: 0.7412 - accuracy: 0.77 - ETA: 6s - loss: 0.7400 - accuracy: 0.77 - ETA: 5s - loss: 0.7390 - accuracy: 0.77 - ETA: 4s - loss: 0.7403 - accuracy: 0.77 - ETA: 4s - loss: 0.7419 - accuracy: 0.77 - ETA: 3s - loss: 0.7392 - accuracy: 0.77 - ETA: 2s - loss: 0.7386 - accuracy: 0.77 - ETA: 1s - loss: 0.7389 - accuracy: 0.77 - ETA: 1s - loss: 0.7394 - accuracy: 0.77 - ETA: 0s - loss: 0.7394 - accuracy: 0.77 - 83s 6ms/step - loss: 0.7409 - accuracy: 0.7758 - val_loss: 2.9630 - val_accuracy: 0.3315\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.6128 - accuracy: 0.79 - ETA: 1:09 - loss: 0.6315 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6644 - accuracy: 0.78 - ETA: 1:06 - loss: 0.6829 - accuracy: 0.78 - ETA: 1:07 - loss: 0.7437 - accuracy: 0.76 - ETA: 1:06 - loss: 0.7282 - accuracy: 0.77 - ETA: 1:06 - loss: 0.7408 - accuracy: 0.77 - ETA: 1:05 - loss: 0.7478 - accuracy: 0.77 - ETA: 1:05 - loss: 0.7679 - accuracy: 0.76 - ETA: 1:04 - loss: 0.7363 - accuracy: 0.77 - ETA: 1:03 - loss: 0.7205 - accuracy: 0.77 - ETA: 1:03 - loss: 0.7232 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7257 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7239 - accuracy: 0.77 - ETA: 1:01 - loss: 0.7210 - accuracy: 0.77 - ETA: 1:00 - loss: 0.7219 - accuracy: 0.77 - ETA: 1:00 - loss: 0.7251 - accuracy: 0.77 - ETA: 59s - loss: 0.7271 - accuracy: 0.7739 - ETA: 59s - loss: 0.7156 - accuracy: 0.776 - ETA: 58s - loss: 0.7148 - accuracy: 0.776 - ETA: 57s - loss: 0.7199 - accuracy: 0.774 - ETA: 56s - loss: 0.7293 - accuracy: 0.773 - ETA: 55s - loss: 0.7243 - accuracy: 0.774 - ETA: 54s - loss: 0.7239 - accuracy: 0.775 - ETA: 54s - loss: 0.7296 - accuracy: 0.775 - ETA: 53s - loss: 0.7330 - accuracy: 0.774 - ETA: 52s - loss: 0.7447 - accuracy: 0.774 - ETA: 52s - loss: 0.7408 - accuracy: 0.775 - ETA: 51s - loss: 0.7455 - accuracy: 0.773 - ETA: 50s - loss: 0.7412 - accuracy: 0.774 - ETA: 49s - loss: 0.7391 - accuracy: 0.773 - ETA: 48s - loss: 0.7343 - accuracy: 0.775 - ETA: 48s - loss: 0.7377 - accuracy: 0.774 - ETA: 47s - loss: 0.7393 - accuracy: 0.773 - ETA: 46s - loss: 0.7383 - accuracy: 0.773 - ETA: 45s - loss: 0.7414 - accuracy: 0.773 - ETA: 45s - loss: 0.7407 - accuracy: 0.774 - ETA: 44s - loss: 0.7428 - accuracy: 0.772 - ETA: 43s - loss: 0.7441 - accuracy: 0.772 - ETA: 43s - loss: 0.7435 - accuracy: 0.771 - ETA: 42s - loss: 0.7405 - accuracy: 0.771 - ETA: 41s - loss: 0.7387 - accuracy: 0.771 - ETA: 41s - loss: 0.7365 - accuracy: 0.773 - ETA: 40s - loss: 0.7395 - accuracy: 0.771 - ETA: 39s - loss: 0.7398 - accuracy: 0.771 - ETA: 39s - loss: 0.7473 - accuracy: 0.769 - ETA: 38s - loss: 0.7492 - accuracy: 0.768 - ETA: 37s - loss: 0.7496 - accuracy: 0.769 - ETA: 36s - loss: 0.7458 - accuracy: 0.770 - ETA: 36s - loss: 0.7450 - accuracy: 0.769 - ETA: 35s - loss: 0.7455 - accuracy: 0.770 - ETA: 34s - loss: 0.7436 - accuracy: 0.770 - ETA: 34s - loss: 0.7449 - accuracy: 0.769 - ETA: 33s - loss: 0.7420 - accuracy: 0.770 - ETA: 32s - loss: 0.7414 - accuracy: 0.769 - ETA: 32s - loss: 0.7430 - accuracy: 0.768 - ETA: 31s - loss: 0.7442 - accuracy: 0.768 - ETA: 30s - loss: 0.7444 - accuracy: 0.768 - ETA: 29s - loss: 0.7446 - accuracy: 0.768 - ETA: 29s - loss: 0.7452 - accuracy: 0.768 - ETA: 28s - loss: 0.7441 - accuracy: 0.768 - ETA: 27s - loss: 0.7437 - accuracy: 0.768 - ETA: 27s - loss: 0.7435 - accuracy: 0.769 - ETA: 26s - loss: 0.7457 - accuracy: 0.768 - ETA: 25s - loss: 0.7465 - accuracy: 0.768 - ETA: 25s - loss: 0.7466 - accuracy: 0.768 - ETA: 24s - loss: 0.7479 - accuracy: 0.768 - ETA: 23s - loss: 0.7464 - accuracy: 0.768 - ETA: 23s - loss: 0.7458 - accuracy: 0.768 - ETA: 22s - loss: 0.7439 - accuracy: 0.769 - ETA: 21s - loss: 0.7418 - accuracy: 0.770 - ETA: 20s - loss: 0.7434 - accuracy: 0.770 - ETA: 20s - loss: 0.7444 - accuracy: 0.769 - ETA: 19s - loss: 0.7415 - accuracy: 0.770 - ETA: 18s - loss: 0.7436 - accuracy: 0.769 - ETA: 18s - loss: 0.7414 - accuracy: 0.770 - ETA: 17s - loss: 0.7411 - accuracy: 0.770 - ETA: 16s - loss: 0.7419 - accuracy: 0.770 - ETA: 15s - loss: 0.7405 - accuracy: 0.771 - ETA: 15s - loss: 0.7389 - accuracy: 0.770 - ETA: 14s - loss: 0.7363 - accuracy: 0.771 - ETA: 13s - loss: 0.7375 - accuracy: 0.769 - ETA: 13s - loss: 0.7374 - accuracy: 0.770 - ETA: 12s - loss: 0.7363 - accuracy: 0.770 - ETA: 11s - loss: 0.7360 - accuracy: 0.771 - ETA: 11s - loss: 0.7374 - accuracy: 0.771 - ETA: 10s - loss: 0.7396 - accuracy: 0.770 - ETA: 9s - loss: 0.7406 - accuracy: 0.770 - ETA: 8s - loss: 0.7420 - accuracy: 0.77 - ETA: 8s - loss: 0.7411 - accuracy: 0.77 - ETA: 7s - loss: 0.7423 - accuracy: 0.77 - ETA: 6s - loss: 0.7423 - accuracy: 0.77 - ETA: 6s - loss: 0.7434 - accuracy: 0.77 - ETA: 5s - loss: 0.7421 - accuracy: 0.77 - ETA: 4s - loss: 0.7433 - accuracy: 0.76 - ETA: 4s - loss: 0.7434 - accuracy: 0.77 - ETA: 3s - loss: 0.7432 - accuracy: 0.77 - ETA: 2s - loss: 0.7436 - accuracy: 0.77 - ETA: 1s - loss: 0.7447 - accuracy: 0.76 - ETA: 1s - loss: 0.7456 - accuracy: 0.76 - ETA: 0s - loss: 0.7459 - accuracy: 0.76 - 82s 6ms/step - loss: 0.7443 - accuracy: 0.7696 - val_loss: 2.8768 - val_accuracy: 0.3480\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.7855 - accuracy: 0.75 - ETA: 1:09 - loss: 0.9356 - accuracy: 0.71 - ETA: 1:08 - loss: 0.8424 - accuracy: 0.73 - ETA: 1:08 - loss: 0.8020 - accuracy: 0.75 - ETA: 1:08 - loss: 0.7908 - accuracy: 0.75 - ETA: 1:07 - loss: 0.7900 - accuracy: 0.75 - ETA: 1:06 - loss: 0.7575 - accuracy: 0.76 - ETA: 1:05 - loss: 0.7628 - accuracy: 0.76 - ETA: 1:04 - loss: 0.7548 - accuracy: 0.76 - ETA: 1:03 - loss: 0.7408 - accuracy: 0.76 - ETA: 1:02 - loss: 0.7331 - accuracy: 0.77 - ETA: 1:01 - loss: 0.7395 - accuracy: 0.77 - ETA: 1:01 - loss: 0.7357 - accuracy: 0.77 - ETA: 1:00 - loss: 0.7325 - accuracy: 0.77 - ETA: 1:00 - loss: 0.7400 - accuracy: 0.76 - ETA: 59s - loss: 0.7443 - accuracy: 0.7676 - ETA: 59s - loss: 0.7530 - accuracy: 0.765 - ETA: 58s - loss: 0.7430 - accuracy: 0.768 - ETA: 58s - loss: 0.7507 - accuracy: 0.768 - ETA: 58s - loss: 0.7462 - accuracy: 0.770 - ETA: 57s - loss: 0.7415 - accuracy: 0.771 - ETA: 56s - loss: 0.7369 - accuracy: 0.772 - ETA: 56s - loss: 0.7463 - accuracy: 0.769 - ETA: 55s - loss: 0.7431 - accuracy: 0.771 - ETA: 54s - loss: 0.7497 - accuracy: 0.769 - ETA: 54s - loss: 0.7476 - accuracy: 0.769 - ETA: 53s - loss: 0.7429 - accuracy: 0.770 - ETA: 52s - loss: 0.7408 - accuracy: 0.770 - ETA: 51s - loss: 0.7399 - accuracy: 0.770 - ETA: 51s - loss: 0.7392 - accuracy: 0.770 - ETA: 50s - loss: 0.7472 - accuracy: 0.769 - ETA: 49s - loss: 0.7415 - accuracy: 0.772 - ETA: 48s - loss: 0.7403 - accuracy: 0.772 - ETA: 47s - loss: 0.7409 - accuracy: 0.771 - ETA: 47s - loss: 0.7414 - accuracy: 0.771 - ETA: 46s - loss: 0.7418 - accuracy: 0.772 - ETA: 45s - loss: 0.7479 - accuracy: 0.771 - ETA: 45s - loss: 0.7476 - accuracy: 0.771 - ETA: 44s - loss: 0.7405 - accuracy: 0.772 - ETA: 43s - loss: 0.7432 - accuracy: 0.772 - ETA: 42s - loss: 0.7409 - accuracy: 0.773 - ETA: 42s - loss: 0.7435 - accuracy: 0.771 - ETA: 41s - loss: 0.7429 - accuracy: 0.771 - ETA: 40s - loss: 0.7410 - accuracy: 0.772 - ETA: 40s - loss: 0.7379 - accuracy: 0.774 - ETA: 39s - loss: 0.7437 - accuracy: 0.772 - ETA: 38s - loss: 0.7417 - accuracy: 0.772 - ETA: 38s - loss: 0.7370 - accuracy: 0.773 - ETA: 37s - loss: 0.7363 - accuracy: 0.772 - ETA: 36s - loss: 0.7355 - accuracy: 0.772 - ETA: 35s - loss: 0.7344 - accuracy: 0.772 - ETA: 35s - loss: 0.7323 - accuracy: 0.773 - ETA: 34s - loss: 0.7335 - accuracy: 0.772 - ETA: 33s - loss: 0.7325 - accuracy: 0.773 - ETA: 32s - loss: 0.7315 - accuracy: 0.773 - ETA: 32s - loss: 0.7314 - accuracy: 0.773 - ETA: 31s - loss: 0.7306 - accuracy: 0.774 - ETA: 30s - loss: 0.7303 - accuracy: 0.774 - ETA: 30s - loss: 0.7285 - accuracy: 0.774 - ETA: 29s - loss: 0.7283 - accuracy: 0.774 - ETA: 28s - loss: 0.7251 - accuracy: 0.774 - ETA: 28s - loss: 0.7218 - accuracy: 0.776 - ETA: 27s - loss: 0.7242 - accuracy: 0.775 - ETA: 26s - loss: 0.7278 - accuracy: 0.775 - ETA: 25s - loss: 0.7280 - accuracy: 0.774 - ETA: 25s - loss: 0.7274 - accuracy: 0.775 - ETA: 24s - loss: 0.7286 - accuracy: 0.774 - ETA: 23s - loss: 0.7310 - accuracy: 0.774 - ETA: 23s - loss: 0.7310 - accuracy: 0.773 - ETA: 22s - loss: 0.7319 - accuracy: 0.774 - ETA: 21s - loss: 0.7303 - accuracy: 0.774 - ETA: 20s - loss: 0.7310 - accuracy: 0.774 - ETA: 20s - loss: 0.7303 - accuracy: 0.774 - ETA: 19s - loss: 0.7269 - accuracy: 0.775 - ETA: 18s - loss: 0.7269 - accuracy: 0.775 - ETA: 18s - loss: 0.7271 - accuracy: 0.775 - ETA: 17s - loss: 0.7286 - accuracy: 0.775 - ETA: 16s - loss: 0.7305 - accuracy: 0.775 - ETA: 15s - loss: 0.7312 - accuracy: 0.774 - ETA: 15s - loss: 0.7303 - accuracy: 0.774 - ETA: 14s - loss: 0.7307 - accuracy: 0.774 - ETA: 13s - loss: 0.7322 - accuracy: 0.774 - ETA: 13s - loss: 0.7328 - accuracy: 0.774 - ETA: 12s - loss: 0.7355 - accuracy: 0.774 - ETA: 11s - loss: 0.7347 - accuracy: 0.774 - ETA: 11s - loss: 0.7343 - accuracy: 0.775 - ETA: 10s - loss: 0.7336 - accuracy: 0.775 - ETA: 9s - loss: 0.7339 - accuracy: 0.775 - ETA: 8s - loss: 0.7326 - accuracy: 0.77 - ETA: 8s - loss: 0.7337 - accuracy: 0.77 - ETA: 7s - loss: 0.7310 - accuracy: 0.77 - ETA: 6s - loss: 0.7300 - accuracy: 0.77 - ETA: 6s - loss: 0.7294 - accuracy: 0.77 - ETA: 5s - loss: 0.7321 - accuracy: 0.77 - ETA: 4s - loss: 0.7349 - accuracy: 0.77 - ETA: 4s - loss: 0.7342 - accuracy: 0.77 - ETA: 3s - loss: 0.7328 - accuracy: 0.77 - ETA: 2s - loss: 0.7325 - accuracy: 0.77 - ETA: 1s - loss: 0.7320 - accuracy: 0.77 - ETA: 1s - loss: 0.7327 - accuracy: 0.77 - ETA: 0s - loss: 0.7325 - accuracy: 0.77 - 82s 6ms/step - loss: 0.7321 - accuracy: 0.7764 - val_loss: 3.1032 - val_accuracy: 0.3373\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:17 - loss: 0.7385 - accuracy: 0.75 - ETA: 1:11 - loss: 0.7238 - accuracy: 0.76 - ETA: 1:09 - loss: 0.7368 - accuracy: 0.77 - ETA: 1:08 - loss: 0.7544 - accuracy: 0.77 - ETA: 1:07 - loss: 0.7290 - accuracy: 0.78 - ETA: 1:06 - loss: 0.7317 - accuracy: 0.77 - ETA: 1:06 - loss: 0.7083 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7097 - accuracy: 0.77 - ETA: 1:04 - loss: 0.7282 - accuracy: 0.77 - ETA: 1:04 - loss: 0.7378 - accuracy: 0.77 - ETA: 1:03 - loss: 0.7374 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7428 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7371 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7341 - accuracy: 0.78 - ETA: 1:00 - loss: 0.7365 - accuracy: 0.78 - ETA: 1:00 - loss: 0.7380 - accuracy: 0.78 - ETA: 59s - loss: 0.7437 - accuracy: 0.7803 - ETA: 58s - loss: 0.7462 - accuracy: 0.779 - ETA: 58s - loss: 0.7554 - accuracy: 0.778 - ETA: 57s - loss: 0.7581 - accuracy: 0.777 - ETA: 56s - loss: 0.7495 - accuracy: 0.779 - ETA: 55s - loss: 0.7506 - accuracy: 0.778 - ETA: 55s - loss: 0.7482 - accuracy: 0.779 - ETA: 54s - loss: 0.7476 - accuracy: 0.779 - ETA: 53s - loss: 0.7476 - accuracy: 0.777 - ETA: 53s - loss: 0.7516 - accuracy: 0.774 - ETA: 52s - loss: 0.7478 - accuracy: 0.775 - ETA: 51s - loss: 0.7413 - accuracy: 0.777 - ETA: 50s - loss: 0.7379 - accuracy: 0.778 - ETA: 50s - loss: 0.7346 - accuracy: 0.778 - ETA: 49s - loss: 0.7316 - accuracy: 0.778 - ETA: 48s - loss: 0.7301 - accuracy: 0.778 - ETA: 47s - loss: 0.7309 - accuracy: 0.779 - ETA: 47s - loss: 0.7338 - accuracy: 0.778 - ETA: 46s - loss: 0.7354 - accuracy: 0.777 - ETA: 45s - loss: 0.7288 - accuracy: 0.779 - ETA: 45s - loss: 0.7325 - accuracy: 0.779 - ETA: 44s - loss: 0.7318 - accuracy: 0.779 - ETA: 43s - loss: 0.7296 - accuracy: 0.779 - ETA: 43s - loss: 0.7352 - accuracy: 0.778 - ETA: 42s - loss: 0.7343 - accuracy: 0.779 - ETA: 41s - loss: 0.7335 - accuracy: 0.779 - ETA: 40s - loss: 0.7286 - accuracy: 0.781 - ETA: 40s - loss: 0.7286 - accuracy: 0.780 - ETA: 39s - loss: 0.7315 - accuracy: 0.780 - ETA: 38s - loss: 0.7297 - accuracy: 0.780 - ETA: 38s - loss: 0.7298 - accuracy: 0.780 - ETA: 37s - loss: 0.7305 - accuracy: 0.780 - ETA: 36s - loss: 0.7310 - accuracy: 0.780 - ETA: 36s - loss: 0.7327 - accuracy: 0.779 - ETA: 35s - loss: 0.7325 - accuracy: 0.779 - ETA: 34s - loss: 0.7365 - accuracy: 0.778 - ETA: 33s - loss: 0.7341 - accuracy: 0.779 - ETA: 33s - loss: 0.7283 - accuracy: 0.781 - ETA: 32s - loss: 0.7275 - accuracy: 0.780 - ETA: 31s - loss: 0.7276 - accuracy: 0.780 - ETA: 31s - loss: 0.7297 - accuracy: 0.780 - ETA: 30s - loss: 0.7278 - accuracy: 0.780 - ETA: 29s - loss: 0.7314 - accuracy: 0.780 - ETA: 29s - loss: 0.7306 - accuracy: 0.780 - ETA: 28s - loss: 0.7304 - accuracy: 0.780 - ETA: 27s - loss: 0.7305 - accuracy: 0.780 - ETA: 27s - loss: 0.7286 - accuracy: 0.781 - ETA: 26s - loss: 0.7300 - accuracy: 0.780 - ETA: 25s - loss: 0.7291 - accuracy: 0.781 - ETA: 25s - loss: 0.7267 - accuracy: 0.782 - ETA: 24s - loss: 0.7272 - accuracy: 0.781 - ETA: 23s - loss: 0.7272 - accuracy: 0.781 - ETA: 22s - loss: 0.7257 - accuracy: 0.781 - ETA: 22s - loss: 0.7252 - accuracy: 0.781 - ETA: 21s - loss: 0.7268 - accuracy: 0.781 - ETA: 20s - loss: 0.7258 - accuracy: 0.781 - ETA: 20s - loss: 0.7251 - accuracy: 0.781 - ETA: 19s - loss: 0.7247 - accuracy: 0.781 - ETA: 18s - loss: 0.7251 - accuracy: 0.780 - ETA: 18s - loss: 0.7267 - accuracy: 0.780 - ETA: 17s - loss: 0.7267 - accuracy: 0.780 - ETA: 16s - loss: 0.7272 - accuracy: 0.780 - ETA: 15s - loss: 0.7278 - accuracy: 0.780 - ETA: 15s - loss: 0.7272 - accuracy: 0.781 - ETA: 14s - loss: 0.7290 - accuracy: 0.780 - ETA: 13s - loss: 0.7284 - accuracy: 0.780 - ETA: 13s - loss: 0.7290 - accuracy: 0.779 - ETA: 12s - loss: 0.7306 - accuracy: 0.779 - ETA: 11s - loss: 0.7301 - accuracy: 0.780 - ETA: 11s - loss: 0.7330 - accuracy: 0.779 - ETA: 10s - loss: 0.7321 - accuracy: 0.779 - ETA: 9s - loss: 0.7332 - accuracy: 0.778 - ETA: 8s - loss: 0.7355 - accuracy: 0.77 - ETA: 8s - loss: 0.7368 - accuracy: 0.77 - ETA: 7s - loss: 0.7359 - accuracy: 0.77 - ETA: 6s - loss: 0.7384 - accuracy: 0.77 - ETA: 6s - loss: 0.7382 - accuracy: 0.77 - ETA: 5s - loss: 0.7373 - accuracy: 0.77 - ETA: 4s - loss: 0.7384 - accuracy: 0.77 - ETA: 4s - loss: 0.7390 - accuracy: 0.77 - ETA: 3s - loss: 0.7386 - accuracy: 0.77 - ETA: 2s - loss: 0.7375 - accuracy: 0.77 - ETA: 1s - loss: 0.7378 - accuracy: 0.77 - ETA: 1s - loss: 0.7395 - accuracy: 0.77 - ETA: 0s - loss: 0.7382 - accuracy: 0.77 - 82s 6ms/step - loss: 0.7387 - accuracy: 0.7764 - val_loss: 2.9345 - val_accuracy: 0.3191\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.8695 - accuracy: 0.78 - ETA: 1:09 - loss: 0.8299 - accuracy: 0.74 - ETA: 1:08 - loss: 0.8027 - accuracy: 0.75 - ETA: 1:06 - loss: 0.8093 - accuracy: 0.75 - ETA: 1:06 - loss: 0.7585 - accuracy: 0.75 - ETA: 1:06 - loss: 0.7525 - accuracy: 0.76 - ETA: 1:05 - loss: 0.7578 - accuracy: 0.76 - ETA: 1:05 - loss: 0.7489 - accuracy: 0.76 - ETA: 1:04 - loss: 0.7221 - accuracy: 0.77 - ETA: 1:04 - loss: 0.7113 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7227 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7190 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7167 - accuracy: 0.77 - ETA: 1:01 - loss: 0.7116 - accuracy: 0.77 - ETA: 1:00 - loss: 0.7212 - accuracy: 0.77 - ETA: 59s - loss: 0.7195 - accuracy: 0.7773 - ETA: 59s - loss: 0.7148 - accuracy: 0.779 - ETA: 58s - loss: 0.7189 - accuracy: 0.777 - ETA: 57s - loss: 0.7109 - accuracy: 0.779 - ETA: 57s - loss: 0.7083 - accuracy: 0.780 - ETA: 56s - loss: 0.7150 - accuracy: 0.779 - ETA: 55s - loss: 0.7091 - accuracy: 0.779 - ETA: 55s - loss: 0.7067 - accuracy: 0.781 - ETA: 54s - loss: 0.7027 - accuracy: 0.782 - ETA: 53s - loss: 0.7073 - accuracy: 0.780 - ETA: 52s - loss: 0.7066 - accuracy: 0.779 - ETA: 52s - loss: 0.7138 - accuracy: 0.776 - ETA: 51s - loss: 0.7155 - accuracy: 0.776 - ETA: 50s - loss: 0.7189 - accuracy: 0.776 - ETA: 49s - loss: 0.7133 - accuracy: 0.777 - ETA: 49s - loss: 0.7089 - accuracy: 0.778 - ETA: 48s - loss: 0.7091 - accuracy: 0.778 - ETA: 47s - loss: 0.7062 - accuracy: 0.779 - ETA: 47s - loss: 0.7076 - accuracy: 0.779 - ETA: 46s - loss: 0.7103 - accuracy: 0.779 - ETA: 46s - loss: 0.7100 - accuracy: 0.778 - ETA: 45s - loss: 0.7097 - accuracy: 0.777 - ETA: 44s - loss: 0.7064 - accuracy: 0.779 - ETA: 43s - loss: 0.7052 - accuracy: 0.780 - ETA: 42s - loss: 0.7072 - accuracy: 0.779 - ETA: 41s - loss: 0.7051 - accuracy: 0.780 - ETA: 40s - loss: 0.7027 - accuracy: 0.781 - ETA: 39s - loss: 0.7082 - accuracy: 0.779 - ETA: 38s - loss: 0.7055 - accuracy: 0.779 - ETA: 37s - loss: 0.7060 - accuracy: 0.778 - ETA: 36s - loss: 0.7047 - accuracy: 0.779 - ETA: 36s - loss: 0.7029 - accuracy: 0.780 - ETA: 35s - loss: 0.7057 - accuracy: 0.779 - ETA: 34s - loss: 0.7113 - accuracy: 0.778 - ETA: 33s - loss: 0.7086 - accuracy: 0.778 - ETA: 33s - loss: 0.7060 - accuracy: 0.779 - ETA: 32s - loss: 0.7076 - accuracy: 0.777 - ETA: 31s - loss: 0.7063 - accuracy: 0.777 - ETA: 31s - loss: 0.7007 - accuracy: 0.778 - ETA: 30s - loss: 0.6993 - accuracy: 0.779 - ETA: 30s - loss: 0.6973 - accuracy: 0.780 - ETA: 29s - loss: 0.6964 - accuracy: 0.781 - ETA: 28s - loss: 0.6977 - accuracy: 0.781 - ETA: 28s - loss: 0.6967 - accuracy: 0.782 - ETA: 27s - loss: 0.6937 - accuracy: 0.783 - ETA: 26s - loss: 0.6929 - accuracy: 0.783 - ETA: 26s - loss: 0.6951 - accuracy: 0.782 - ETA: 25s - loss: 0.6918 - accuracy: 0.784 - ETA: 24s - loss: 0.6905 - accuracy: 0.784 - ETA: 24s - loss: 0.6915 - accuracy: 0.783 - ETA: 23s - loss: 0.6894 - accuracy: 0.785 - ETA: 23s - loss: 0.6870 - accuracy: 0.786 - ETA: 22s - loss: 0.6894 - accuracy: 0.785 - ETA: 21s - loss: 0.6904 - accuracy: 0.784 - ETA: 21s - loss: 0.6886 - accuracy: 0.785 - ETA: 20s - loss: 0.6906 - accuracy: 0.785 - ETA: 19s - loss: 0.6882 - accuracy: 0.785 - ETA: 19s - loss: 0.6897 - accuracy: 0.785 - ETA: 18s - loss: 0.6899 - accuracy: 0.785 - ETA: 17s - loss: 0.6882 - accuracy: 0.785 - ETA: 17s - loss: 0.6855 - accuracy: 0.786 - ETA: 16s - loss: 0.6861 - accuracy: 0.786 - ETA: 15s - loss: 0.6848 - accuracy: 0.786 - ETA: 15s - loss: 0.6868 - accuracy: 0.786 - ETA: 14s - loss: 0.6876 - accuracy: 0.786 - ETA: 13s - loss: 0.6875 - accuracy: 0.786 - ETA: 13s - loss: 0.6880 - accuracy: 0.787 - ETA: 12s - loss: 0.6890 - accuracy: 0.787 - ETA: 11s - loss: 0.6888 - accuracy: 0.787 - ETA: 11s - loss: 0.6881 - accuracy: 0.788 - ETA: 10s - loss: 0.6866 - accuracy: 0.788 - ETA: 9s - loss: 0.6885 - accuracy: 0.787 - ETA: 9s - loss: 0.6904 - accuracy: 0.78 - ETA: 8s - loss: 0.6925 - accuracy: 0.78 - ETA: 7s - loss: 0.6923 - accuracy: 0.78 - ETA: 7s - loss: 0.6914 - accuracy: 0.78 - ETA: 6s - loss: 0.6935 - accuracy: 0.78 - ETA: 5s - loss: 0.6948 - accuracy: 0.78 - ETA: 5s - loss: 0.6933 - accuracy: 0.78 - ETA: 4s - loss: 0.6942 - accuracy: 0.78 - ETA: 3s - loss: 0.6911 - accuracy: 0.78 - ETA: 3s - loss: 0.6895 - accuracy: 0.78 - ETA: 2s - loss: 0.6881 - accuracy: 0.78 - ETA: 1s - loss: 0.6893 - accuracy: 0.78 - ETA: 1s - loss: 0.6883 - accuracy: 0.78 - ETA: 0s - loss: 0.6884 - accuracy: 0.78 - 79s 6ms/step - loss: 0.6877 - accuracy: 0.7883 - val_loss: 2.8696 - val_accuracy: 0.3300\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:21 - loss: 0.8356 - accuracy: 0.71 - ETA: 1:14 - loss: 0.7565 - accuracy: 0.75 - ETA: 1:12 - loss: 0.6834 - accuracy: 0.78 - ETA: 1:10 - loss: 0.6701 - accuracy: 0.77 - ETA: 1:09 - loss: 0.6542 - accuracy: 0.78 - ETA: 1:07 - loss: 0.6482 - accuracy: 0.78 - ETA: 1:06 - loss: 0.6428 - accuracy: 0.78 - ETA: 1:05 - loss: 0.6573 - accuracy: 0.78 - ETA: 1:05 - loss: 0.6632 - accuracy: 0.78 - ETA: 1:04 - loss: 0.6741 - accuracy: 0.77 - ETA: 1:03 - loss: 0.6765 - accuracy: 0.78 - ETA: 1:03 - loss: 0.6717 - accuracy: 0.78 - ETA: 1:02 - loss: 0.6676 - accuracy: 0.78 - ETA: 1:02 - loss: 0.6690 - accuracy: 0.78 - ETA: 1:01 - loss: 0.6664 - accuracy: 0.78 - ETA: 1:00 - loss: 0.6628 - accuracy: 0.78 - ETA: 59s - loss: 0.6749 - accuracy: 0.7840 - ETA: 59s - loss: 0.6690 - accuracy: 0.786 - ETA: 58s - loss: 0.6732 - accuracy: 0.785 - ETA: 57s - loss: 0.6822 - accuracy: 0.783 - ETA: 57s - loss: 0.6837 - accuracy: 0.781 - ETA: 56s - loss: 0.6859 - accuracy: 0.781 - ETA: 55s - loss: 0.6912 - accuracy: 0.781 - ETA: 55s - loss: 0.6889 - accuracy: 0.782 - ETA: 54s - loss: 0.6853 - accuracy: 0.783 - ETA: 53s - loss: 0.6887 - accuracy: 0.783 - ETA: 52s - loss: 0.6907 - accuracy: 0.785 - ETA: 51s - loss: 0.6943 - accuracy: 0.784 - ETA: 51s - loss: 0.6946 - accuracy: 0.785 - ETA: 50s - loss: 0.6895 - accuracy: 0.786 - ETA: 49s - loss: 0.6996 - accuracy: 0.784 - ETA: 48s - loss: 0.6971 - accuracy: 0.785 - ETA: 48s - loss: 0.6994 - accuracy: 0.784 - ETA: 47s - loss: 0.6990 - accuracy: 0.784 - ETA: 46s - loss: 0.6969 - accuracy: 0.785 - ETA: 46s - loss: 0.6936 - accuracy: 0.786 - ETA: 45s - loss: 0.6955 - accuracy: 0.787 - ETA: 44s - loss: 0.6972 - accuracy: 0.786 - ETA: 44s - loss: 0.6973 - accuracy: 0.786 - ETA: 43s - loss: 0.7002 - accuracy: 0.785 - ETA: 42s - loss: 0.7019 - accuracy: 0.786 - ETA: 41s - loss: 0.7009 - accuracy: 0.786 - ETA: 41s - loss: 0.7006 - accuracy: 0.786 - ETA: 40s - loss: 0.6990 - accuracy: 0.786 - ETA: 39s - loss: 0.6953 - accuracy: 0.787 - ETA: 38s - loss: 0.6951 - accuracy: 0.788 - ETA: 38s - loss: 0.6935 - accuracy: 0.788 - ETA: 37s - loss: 0.6944 - accuracy: 0.788 - ETA: 36s - loss: 0.7008 - accuracy: 0.787 - ETA: 36s - loss: 0.6985 - accuracy: 0.786 - ETA: 35s - loss: 0.6956 - accuracy: 0.787 - ETA: 34s - loss: 0.6961 - accuracy: 0.787 - ETA: 34s - loss: 0.6993 - accuracy: 0.785 - ETA: 33s - loss: 0.6981 - accuracy: 0.785 - ETA: 32s - loss: 0.6969 - accuracy: 0.785 - ETA: 31s - loss: 0.6971 - accuracy: 0.784 - ETA: 31s - loss: 0.6971 - accuracy: 0.785 - ETA: 30s - loss: 0.6941 - accuracy: 0.786 - ETA: 29s - loss: 0.6965 - accuracy: 0.786 - ETA: 29s - loss: 0.6928 - accuracy: 0.787 - ETA: 28s - loss: 0.6927 - accuracy: 0.787 - ETA: 27s - loss: 0.6932 - accuracy: 0.787 - ETA: 27s - loss: 0.6954 - accuracy: 0.786 - ETA: 26s - loss: 0.6962 - accuracy: 0.786 - ETA: 25s - loss: 0.6946 - accuracy: 0.786 - ETA: 24s - loss: 0.6992 - accuracy: 0.785 - ETA: 24s - loss: 0.6979 - accuracy: 0.785 - ETA: 23s - loss: 0.6990 - accuracy: 0.785 - ETA: 22s - loss: 0.6975 - accuracy: 0.785 - ETA: 22s - loss: 0.6965 - accuracy: 0.785 - ETA: 21s - loss: 0.6991 - accuracy: 0.785 - ETA: 20s - loss: 0.7009 - accuracy: 0.785 - ETA: 20s - loss: 0.6981 - accuracy: 0.786 - ETA: 19s - loss: 0.6974 - accuracy: 0.786 - ETA: 18s - loss: 0.6964 - accuracy: 0.786 - ETA: 17s - loss: 0.6963 - accuracy: 0.787 - ETA: 17s - loss: 0.7009 - accuracy: 0.785 - ETA: 16s - loss: 0.7012 - accuracy: 0.785 - ETA: 15s - loss: 0.7001 - accuracy: 0.785 - ETA: 15s - loss: 0.7005 - accuracy: 0.785 - ETA: 14s - loss: 0.7029 - accuracy: 0.785 - ETA: 13s - loss: 0.7032 - accuracy: 0.784 - ETA: 13s - loss: 0.7019 - accuracy: 0.784 - ETA: 12s - loss: 0.7029 - accuracy: 0.784 - ETA: 11s - loss: 0.7030 - accuracy: 0.784 - ETA: 10s - loss: 0.7067 - accuracy: 0.783 - ETA: 10s - loss: 0.7064 - accuracy: 0.783 - ETA: 9s - loss: 0.7075 - accuracy: 0.783 - ETA: 8s - loss: 0.7077 - accuracy: 0.78 - ETA: 8s - loss: 0.7078 - accuracy: 0.78 - ETA: 7s - loss: 0.7092 - accuracy: 0.78 - ETA: 6s - loss: 0.7083 - accuracy: 0.78 - ETA: 6s - loss: 0.7074 - accuracy: 0.78 - ETA: 5s - loss: 0.7073 - accuracy: 0.78 - ETA: 4s - loss: 0.7061 - accuracy: 0.78 - ETA: 3s - loss: 0.7063 - accuracy: 0.78 - ETA: 3s - loss: 0.7074 - accuracy: 0.78 - ETA: 2s - loss: 0.7105 - accuracy: 0.78 - ETA: 1s - loss: 0.7094 - accuracy: 0.78 - ETA: 1s - loss: 0.7080 - accuracy: 0.78 - ETA: 0s - loss: 0.7077 - accuracy: 0.78 - 82s 6ms/step - loss: 0.7084 - accuracy: 0.7828 - val_loss: 3.0451 - val_accuracy: 0.3494\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.8217 - accuracy: 0.75 - ETA: 1:10 - loss: 0.8026 - accuracy: 0.74 - ETA: 1:09 - loss: 0.7020 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6805 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6636 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6932 - accuracy: 0.79 - ETA: 1:06 - loss: 0.7138 - accuracy: 0.79 - ETA: 1:05 - loss: 0.7011 - accuracy: 0.79 - ETA: 1:04 - loss: 0.7012 - accuracy: 0.78 - ETA: 1:04 - loss: 0.6901 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6952 - accuracy: 0.79 - ETA: 1:03 - loss: 0.7001 - accuracy: 0.79 - ETA: 1:02 - loss: 0.7044 - accuracy: 0.79 - ETA: 1:01 - loss: 0.7025 - accuracy: 0.79 - ETA: 1:00 - loss: 0.7134 - accuracy: 0.79 - ETA: 59s - loss: 0.7239 - accuracy: 0.7881 - ETA: 59s - loss: 0.7214 - accuracy: 0.788 - ETA: 58s - loss: 0.7293 - accuracy: 0.787 - ETA: 57s - loss: 0.7251 - accuracy: 0.787 - ETA: 57s - loss: 0.7333 - accuracy: 0.784 - ETA: 56s - loss: 0.7285 - accuracy: 0.785 - ETA: 55s - loss: 0.7358 - accuracy: 0.786 - ETA: 54s - loss: 0.7336 - accuracy: 0.786 - ETA: 54s - loss: 0.7299 - accuracy: 0.786 - ETA: 53s - loss: 0.7313 - accuracy: 0.785 - ETA: 52s - loss: 0.7353 - accuracy: 0.784 - ETA: 52s - loss: 0.7423 - accuracy: 0.783 - ETA: 51s - loss: 0.7431 - accuracy: 0.781 - ETA: 50s - loss: 0.7508 - accuracy: 0.778 - ETA: 49s - loss: 0.7523 - accuracy: 0.777 - ETA: 49s - loss: 0.7546 - accuracy: 0.776 - ETA: 48s - loss: 0.7529 - accuracy: 0.775 - ETA: 47s - loss: 0.7580 - accuracy: 0.774 - ETA: 47s - loss: 0.7620 - accuracy: 0.772 - ETA: 46s - loss: 0.7635 - accuracy: 0.771 - ETA: 45s - loss: 0.7680 - accuracy: 0.770 - ETA: 44s - loss: 0.7631 - accuracy: 0.771 - ETA: 44s - loss: 0.7616 - accuracy: 0.772 - ETA: 43s - loss: 0.7628 - accuracy: 0.773 - ETA: 42s - loss: 0.7609 - accuracy: 0.773 - ETA: 42s - loss: 0.7613 - accuracy: 0.772 - ETA: 41s - loss: 0.7620 - accuracy: 0.772 - ETA: 40s - loss: 0.7572 - accuracy: 0.773 - ETA: 40s - loss: 0.7559 - accuracy: 0.773 - ETA: 39s - loss: 0.7564 - accuracy: 0.771 - ETA: 38s - loss: 0.7531 - accuracy: 0.772 - ETA: 37s - loss: 0.7512 - accuracy: 0.772 - ETA: 37s - loss: 0.7517 - accuracy: 0.772 - ETA: 36s - loss: 0.7521 - accuracy: 0.771 - ETA: 35s - loss: 0.7519 - accuracy: 0.770 - ETA: 35s - loss: 0.7529 - accuracy: 0.770 - ETA: 34s - loss: 0.7503 - accuracy: 0.771 - ETA: 33s - loss: 0.7524 - accuracy: 0.770 - ETA: 33s - loss: 0.7498 - accuracy: 0.771 - ETA: 32s - loss: 0.7511 - accuracy: 0.771 - ETA: 31s - loss: 0.7496 - accuracy: 0.772 - ETA: 31s - loss: 0.7521 - accuracy: 0.771 - ETA: 30s - loss: 0.7522 - accuracy: 0.772 - ETA: 29s - loss: 0.7552 - accuracy: 0.771 - ETA: 28s - loss: 0.7587 - accuracy: 0.771 - ETA: 28s - loss: 0.7598 - accuracy: 0.770 - ETA: 27s - loss: 0.7600 - accuracy: 0.769 - ETA: 26s - loss: 0.7560 - accuracy: 0.770 - ETA: 26s - loss: 0.7574 - accuracy: 0.769 - ETA: 25s - loss: 0.7569 - accuracy: 0.770 - ETA: 24s - loss: 0.7560 - accuracy: 0.770 - ETA: 24s - loss: 0.7570 - accuracy: 0.770 - ETA: 23s - loss: 0.7553 - accuracy: 0.770 - ETA: 22s - loss: 0.7536 - accuracy: 0.771 - ETA: 21s - loss: 0.7521 - accuracy: 0.772 - ETA: 21s - loss: 0.7500 - accuracy: 0.772 - ETA: 20s - loss: 0.7465 - accuracy: 0.773 - ETA: 19s - loss: 0.7486 - accuracy: 0.773 - ETA: 19s - loss: 0.7474 - accuracy: 0.773 - ETA: 18s - loss: 0.7491 - accuracy: 0.773 - ETA: 17s - loss: 0.7478 - accuracy: 0.773 - ETA: 17s - loss: 0.7490 - accuracy: 0.773 - ETA: 16s - loss: 0.7482 - accuracy: 0.773 - ETA: 15s - loss: 0.7481 - accuracy: 0.773 - ETA: 15s - loss: 0.7462 - accuracy: 0.773 - ETA: 14s - loss: 0.7452 - accuracy: 0.773 - ETA: 13s - loss: 0.7462 - accuracy: 0.773 - ETA: 12s - loss: 0.7444 - accuracy: 0.774 - ETA: 12s - loss: 0.7451 - accuracy: 0.774 - ETA: 11s - loss: 0.7436 - accuracy: 0.775 - ETA: 10s - loss: 0.7431 - accuracy: 0.775 - ETA: 10s - loss: 0.7453 - accuracy: 0.774 - ETA: 9s - loss: 0.7478 - accuracy: 0.774 - ETA: 8s - loss: 0.7468 - accuracy: 0.77 - ETA: 8s - loss: 0.7465 - accuracy: 0.77 - ETA: 7s - loss: 0.7479 - accuracy: 0.77 - ETA: 6s - loss: 0.7479 - accuracy: 0.77 - ETA: 6s - loss: 0.7460 - accuracy: 0.77 - ETA: 5s - loss: 0.7444 - accuracy: 0.77 - ETA: 4s - loss: 0.7453 - accuracy: 0.77 - ETA: 3s - loss: 0.7484 - accuracy: 0.77 - ETA: 3s - loss: 0.7482 - accuracy: 0.77 - ETA: 2s - loss: 0.7471 - accuracy: 0.77 - ETA: 1s - loss: 0.7459 - accuracy: 0.77 - ETA: 1s - loss: 0.7432 - accuracy: 0.77 - ETA: 0s - loss: 0.7426 - accuracy: 0.77 - 81s 6ms/step - loss: 0.7419 - accuracy: 0.7761 - val_loss: 2.9181 - val_accuracy: 0.3258\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:18 - loss: 0.9352 - accuracy: 0.75 - ETA: 1:14 - loss: 0.6994 - accuracy: 0.79 - ETA: 1:11 - loss: 0.6726 - accuracy: 0.80 - ETA: 1:10 - loss: 0.6464 - accuracy: 0.81 - ETA: 1:09 - loss: 0.6255 - accuracy: 0.82 - ETA: 1:08 - loss: 0.6482 - accuracy: 0.81 - ETA: 1:07 - loss: 0.6479 - accuracy: 0.81 - ETA: 1:07 - loss: 0.6761 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6861 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6982 - accuracy: 0.80 - ETA: 1:04 - loss: 0.7014 - accuracy: 0.79 - ETA: 1:03 - loss: 0.7214 - accuracy: 0.79 - ETA: 1:03 - loss: 0.7148 - accuracy: 0.79 - ETA: 1:02 - loss: 0.7082 - accuracy: 0.79 - ETA: 1:01 - loss: 0.7047 - accuracy: 0.79 - ETA: 1:00 - loss: 0.6951 - accuracy: 0.79 - ETA: 1:00 - loss: 0.7038 - accuracy: 0.79 - ETA: 59s - loss: 0.6937 - accuracy: 0.7986 - ETA: 58s - loss: 0.6947 - accuracy: 0.797 - ETA: 57s - loss: 0.7029 - accuracy: 0.793 - ETA: 56s - loss: 0.7037 - accuracy: 0.792 - ETA: 56s - loss: 0.7037 - accuracy: 0.791 - ETA: 55s - loss: 0.7029 - accuracy: 0.791 - ETA: 54s - loss: 0.7168 - accuracy: 0.790 - ETA: 53s - loss: 0.7081 - accuracy: 0.792 - ETA: 53s - loss: 0.7180 - accuracy: 0.790 - ETA: 52s - loss: 0.7202 - accuracy: 0.789 - ETA: 51s - loss: 0.7297 - accuracy: 0.788 - ETA: 51s - loss: 0.7243 - accuracy: 0.790 - ETA: 50s - loss: 0.7234 - accuracy: 0.789 - ETA: 49s - loss: 0.7207 - accuracy: 0.790 - ETA: 48s - loss: 0.7163 - accuracy: 0.791 - ETA: 48s - loss: 0.7190 - accuracy: 0.791 - ETA: 47s - loss: 0.7168 - accuracy: 0.792 - ETA: 46s - loss: 0.7258 - accuracy: 0.787 - ETA: 46s - loss: 0.7248 - accuracy: 0.787 - ETA: 45s - loss: 0.7182 - accuracy: 0.788 - ETA: 44s - loss: 0.7170 - accuracy: 0.788 - ETA: 43s - loss: 0.7122 - accuracy: 0.789 - ETA: 43s - loss: 0.7061 - accuracy: 0.791 - ETA: 42s - loss: 0.7062 - accuracy: 0.791 - ETA: 41s - loss: 0.7052 - accuracy: 0.792 - ETA: 41s - loss: 0.7014 - accuracy: 0.792 - ETA: 40s - loss: 0.7008 - accuracy: 0.793 - ETA: 39s - loss: 0.6988 - accuracy: 0.793 - ETA: 39s - loss: 0.7036 - accuracy: 0.792 - ETA: 38s - loss: 0.7014 - accuracy: 0.792 - ETA: 37s - loss: 0.7055 - accuracy: 0.792 - ETA: 36s - loss: 0.7056 - accuracy: 0.791 - ETA: 36s - loss: 0.7024 - accuracy: 0.792 - ETA: 35s - loss: 0.7013 - accuracy: 0.792 - ETA: 34s - loss: 0.7016 - accuracy: 0.792 - ETA: 34s - loss: 0.7005 - accuracy: 0.792 - ETA: 33s - loss: 0.7009 - accuracy: 0.792 - ETA: 32s - loss: 0.7002 - accuracy: 0.791 - ETA: 31s - loss: 0.6993 - accuracy: 0.792 - ETA: 31s - loss: 0.6999 - accuracy: 0.792 - ETA: 30s - loss: 0.6997 - accuracy: 0.792 - ETA: 29s - loss: 0.7013 - accuracy: 0.792 - ETA: 29s - loss: 0.7026 - accuracy: 0.791 - ETA: 28s - loss: 0.7045 - accuracy: 0.790 - ETA: 27s - loss: 0.7045 - accuracy: 0.790 - ETA: 27s - loss: 0.7045 - accuracy: 0.790 - ETA: 26s - loss: 0.7075 - accuracy: 0.790 - ETA: 25s - loss: 0.7066 - accuracy: 0.790 - ETA: 25s - loss: 0.7067 - accuracy: 0.789 - ETA: 24s - loss: 0.7076 - accuracy: 0.789 - ETA: 23s - loss: 0.7084 - accuracy: 0.788 - ETA: 22s - loss: 0.7086 - accuracy: 0.788 - ETA: 22s - loss: 0.7088 - accuracy: 0.787 - ETA: 21s - loss: 0.7069 - accuracy: 0.788 - ETA: 20s - loss: 0.7077 - accuracy: 0.787 - ETA: 20s - loss: 0.7059 - accuracy: 0.788 - ETA: 19s - loss: 0.7071 - accuracy: 0.788 - ETA: 18s - loss: 0.7047 - accuracy: 0.789 - ETA: 18s - loss: 0.7045 - accuracy: 0.789 - ETA: 17s - loss: 0.7042 - accuracy: 0.789 - ETA: 16s - loss: 0.7048 - accuracy: 0.788 - ETA: 15s - loss: 0.7060 - accuracy: 0.788 - ETA: 15s - loss: 0.7039 - accuracy: 0.788 - ETA: 14s - loss: 0.7034 - accuracy: 0.788 - ETA: 13s - loss: 0.7044 - accuracy: 0.788 - ETA: 13s - loss: 0.7061 - accuracy: 0.787 - ETA: 12s - loss: 0.7049 - accuracy: 0.787 - ETA: 11s - loss: 0.7045 - accuracy: 0.787 - ETA: 11s - loss: 0.7045 - accuracy: 0.787 - ETA: 10s - loss: 0.7058 - accuracy: 0.787 - ETA: 9s - loss: 0.7105 - accuracy: 0.786 - ETA: 8s - loss: 0.7085 - accuracy: 0.78 - ETA: 8s - loss: 0.7096 - accuracy: 0.78 - ETA: 7s - loss: 0.7082 - accuracy: 0.78 - ETA: 6s - loss: 0.7096 - accuracy: 0.78 - ETA: 6s - loss: 0.7115 - accuracy: 0.78 - ETA: 5s - loss: 0.7122 - accuracy: 0.78 - ETA: 4s - loss: 0.7111 - accuracy: 0.78 - ETA: 4s - loss: 0.7108 - accuracy: 0.78 - ETA: 3s - loss: 0.7117 - accuracy: 0.78 - ETA: 2s - loss: 0.7126 - accuracy: 0.78 - ETA: 1s - loss: 0.7132 - accuracy: 0.78 - ETA: 1s - loss: 0.7134 - accuracy: 0.78 - ETA: 0s - loss: 0.7123 - accuracy: 0.78 - 82s 6ms/step - loss: 0.7121 - accuracy: 0.7857 - val_loss: 2.9125 - val_accuracy: 0.3313\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.6696 - accuracy: 0.79 - ETA: 1:12 - loss: 0.6767 - accuracy: 0.80 - ETA: 1:10 - loss: 0.6375 - accuracy: 0.80 - ETA: 1:10 - loss: 0.6409 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6461 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6447 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6471 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6497 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6476 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6487 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6591 - accuracy: 0.79 - ETA: 1:02 - loss: 0.6490 - accuracy: 0.79 - ETA: 1:02 - loss: 0.6515 - accuracy: 0.79 - ETA: 1:01 - loss: 0.6571 - accuracy: 0.79 - ETA: 1:00 - loss: 0.6692 - accuracy: 0.78 - ETA: 1:00 - loss: 0.6730 - accuracy: 0.78 - ETA: 59s - loss: 0.6739 - accuracy: 0.7909 - ETA: 58s - loss: 0.6724 - accuracy: 0.790 - ETA: 57s - loss: 0.6679 - accuracy: 0.791 - ETA: 57s - loss: 0.6756 - accuracy: 0.787 - ETA: 56s - loss: 0.6673 - accuracy: 0.790 - ETA: 55s - loss: 0.6633 - accuracy: 0.790 - ETA: 54s - loss: 0.6579 - accuracy: 0.793 - ETA: 53s - loss: 0.6548 - accuracy: 0.793 - ETA: 53s - loss: 0.6579 - accuracy: 0.793 - ETA: 52s - loss: 0.6637 - accuracy: 0.794 - ETA: 51s - loss: 0.6632 - accuracy: 0.794 - ETA: 51s - loss: 0.6652 - accuracy: 0.794 - ETA: 50s - loss: 0.6603 - accuracy: 0.796 - ETA: 49s - loss: 0.6592 - accuracy: 0.795 - ETA: 49s - loss: 0.6598 - accuracy: 0.795 - ETA: 48s - loss: 0.6672 - accuracy: 0.793 - ETA: 47s - loss: 0.6736 - accuracy: 0.791 - ETA: 47s - loss: 0.6738 - accuracy: 0.791 - ETA: 46s - loss: 0.6698 - accuracy: 0.793 - ETA: 45s - loss: 0.6693 - accuracy: 0.793 - ETA: 44s - loss: 0.6692 - accuracy: 0.792 - ETA: 44s - loss: 0.6690 - accuracy: 0.792 - ETA: 43s - loss: 0.6666 - accuracy: 0.793 - ETA: 42s - loss: 0.6624 - accuracy: 0.794 - ETA: 42s - loss: 0.6647 - accuracy: 0.794 - ETA: 41s - loss: 0.6651 - accuracy: 0.794 - ETA: 40s - loss: 0.6659 - accuracy: 0.793 - ETA: 40s - loss: 0.6685 - accuracy: 0.792 - ETA: 39s - loss: 0.6683 - accuracy: 0.792 - ETA: 38s - loss: 0.6672 - accuracy: 0.793 - ETA: 38s - loss: 0.6609 - accuracy: 0.794 - ETA: 37s - loss: 0.6605 - accuracy: 0.794 - ETA: 36s - loss: 0.6609 - accuracy: 0.794 - ETA: 36s - loss: 0.6622 - accuracy: 0.794 - ETA: 35s - loss: 0.6625 - accuracy: 0.794 - ETA: 34s - loss: 0.6593 - accuracy: 0.795 - ETA: 34s - loss: 0.6593 - accuracy: 0.795 - ETA: 33s - loss: 0.6609 - accuracy: 0.795 - ETA: 32s - loss: 0.6639 - accuracy: 0.794 - ETA: 31s - loss: 0.6689 - accuracy: 0.793 - ETA: 31s - loss: 0.6691 - accuracy: 0.793 - ETA: 30s - loss: 0.6704 - accuracy: 0.793 - ETA: 29s - loss: 0.6707 - accuracy: 0.792 - ETA: 29s - loss: 0.6694 - accuracy: 0.792 - ETA: 28s - loss: 0.6720 - accuracy: 0.792 - ETA: 27s - loss: 0.6700 - accuracy: 0.792 - ETA: 27s - loss: 0.6712 - accuracy: 0.792 - ETA: 26s - loss: 0.6706 - accuracy: 0.792 - ETA: 25s - loss: 0.6687 - accuracy: 0.793 - ETA: 24s - loss: 0.6659 - accuracy: 0.794 - ETA: 24s - loss: 0.6669 - accuracy: 0.793 - ETA: 23s - loss: 0.6713 - accuracy: 0.792 - ETA: 22s - loss: 0.6732 - accuracy: 0.791 - ETA: 22s - loss: 0.6746 - accuracy: 0.790 - ETA: 21s - loss: 0.6763 - accuracy: 0.790 - ETA: 20s - loss: 0.6765 - accuracy: 0.790 - ETA: 20s - loss: 0.6779 - accuracy: 0.789 - ETA: 19s - loss: 0.6772 - accuracy: 0.789 - ETA: 18s - loss: 0.6744 - accuracy: 0.790 - ETA: 17s - loss: 0.6741 - accuracy: 0.790 - ETA: 17s - loss: 0.6740 - accuracy: 0.790 - ETA: 16s - loss: 0.6750 - accuracy: 0.789 - ETA: 15s - loss: 0.6756 - accuracy: 0.788 - ETA: 15s - loss: 0.6772 - accuracy: 0.788 - ETA: 14s - loss: 0.6778 - accuracy: 0.788 - ETA: 13s - loss: 0.6774 - accuracy: 0.788 - ETA: 13s - loss: 0.6776 - accuracy: 0.788 - ETA: 12s - loss: 0.6790 - accuracy: 0.787 - ETA: 11s - loss: 0.6786 - accuracy: 0.787 - ETA: 10s - loss: 0.6781 - accuracy: 0.787 - ETA: 10s - loss: 0.6792 - accuracy: 0.787 - ETA: 9s - loss: 0.6802 - accuracy: 0.787 - ETA: 8s - loss: 0.6799 - accuracy: 0.78 - ETA: 8s - loss: 0.6828 - accuracy: 0.78 - ETA: 7s - loss: 0.6820 - accuracy: 0.78 - ETA: 6s - loss: 0.6834 - accuracy: 0.78 - ETA: 6s - loss: 0.6843 - accuracy: 0.78 - ETA: 5s - loss: 0.6855 - accuracy: 0.78 - ETA: 4s - loss: 0.6845 - accuracy: 0.78 - ETA: 4s - loss: 0.6831 - accuracy: 0.78 - ETA: 3s - loss: 0.6852 - accuracy: 0.78 - ETA: 2s - loss: 0.6845 - accuracy: 0.78 - ETA: 1s - loss: 0.6846 - accuracy: 0.78 - ETA: 1s - loss: 0.6847 - accuracy: 0.78 - ETA: 0s - loss: 0.6840 - accuracy: 0.78 - 82s 6ms/step - loss: 0.6834 - accuracy: 0.7867 - val_loss: 2.9265 - val_accuracy: 0.3402\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.4557 - accuracy: 0.85 - ETA: 1:14 - loss: 0.5854 - accuracy: 0.82 - ETA: 1:11 - loss: 0.5881 - accuracy: 0.82 - ETA: 1:10 - loss: 0.6455 - accuracy: 0.80 - ETA: 1:08 - loss: 0.6421 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6673 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6529 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6699 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6495 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6567 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6629 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6633 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6764 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6723 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6692 - accuracy: 0.79 - ETA: 1:00 - loss: 0.6689 - accuracy: 0.79 - ETA: 59s - loss: 0.6864 - accuracy: 0.7918 - ETA: 59s - loss: 0.6981 - accuracy: 0.789 - ETA: 58s - loss: 0.6949 - accuracy: 0.788 - ETA: 57s - loss: 0.6858 - accuracy: 0.791 - ETA: 56s - loss: 0.6798 - accuracy: 0.793 - ETA: 56s - loss: 0.6850 - accuracy: 0.792 - ETA: 55s - loss: 0.6850 - accuracy: 0.793 - ETA: 55s - loss: 0.6909 - accuracy: 0.791 - ETA: 54s - loss: 0.6835 - accuracy: 0.793 - ETA: 53s - loss: 0.6813 - accuracy: 0.794 - ETA: 52s - loss: 0.6804 - accuracy: 0.793 - ETA: 52s - loss: 0.6792 - accuracy: 0.792 - ETA: 51s - loss: 0.6873 - accuracy: 0.790 - ETA: 50s - loss: 0.6848 - accuracy: 0.791 - ETA: 49s - loss: 0.6840 - accuracy: 0.791 - ETA: 49s - loss: 0.6868 - accuracy: 0.792 - ETA: 48s - loss: 0.6858 - accuracy: 0.794 - ETA: 47s - loss: 0.6827 - accuracy: 0.795 - ETA: 46s - loss: 0.6833 - accuracy: 0.795 - ETA: 46s - loss: 0.6841 - accuracy: 0.794 - ETA: 45s - loss: 0.6810 - accuracy: 0.795 - ETA: 44s - loss: 0.6753 - accuracy: 0.796 - ETA: 43s - loss: 0.6820 - accuracy: 0.796 - ETA: 43s - loss: 0.6802 - accuracy: 0.797 - ETA: 42s - loss: 0.6816 - accuracy: 0.797 - ETA: 41s - loss: 0.6783 - accuracy: 0.798 - ETA: 41s - loss: 0.6829 - accuracy: 0.797 - ETA: 40s - loss: 0.6803 - accuracy: 0.797 - ETA: 39s - loss: 0.6779 - accuracy: 0.797 - ETA: 39s - loss: 0.6756 - accuracy: 0.798 - ETA: 38s - loss: 0.6773 - accuracy: 0.798 - ETA: 37s - loss: 0.6780 - accuracy: 0.798 - ETA: 37s - loss: 0.6775 - accuracy: 0.798 - ETA: 36s - loss: 0.6745 - accuracy: 0.798 - ETA: 35s - loss: 0.6742 - accuracy: 0.798 - ETA: 34s - loss: 0.6753 - accuracy: 0.797 - ETA: 34s - loss: 0.6711 - accuracy: 0.798 - ETA: 33s - loss: 0.6737 - accuracy: 0.797 - ETA: 32s - loss: 0.6767 - accuracy: 0.796 - ETA: 32s - loss: 0.6773 - accuracy: 0.796 - ETA: 31s - loss: 0.6750 - accuracy: 0.796 - ETA: 30s - loss: 0.6771 - accuracy: 0.796 - ETA: 29s - loss: 0.6742 - accuracy: 0.796 - ETA: 29s - loss: 0.6724 - accuracy: 0.797 - ETA: 28s - loss: 0.6731 - accuracy: 0.797 - ETA: 27s - loss: 0.6721 - accuracy: 0.796 - ETA: 27s - loss: 0.6722 - accuracy: 0.796 - ETA: 26s - loss: 0.6714 - accuracy: 0.796 - ETA: 25s - loss: 0.6706 - accuracy: 0.796 - ETA: 25s - loss: 0.6711 - accuracy: 0.796 - ETA: 24s - loss: 0.6714 - accuracy: 0.796 - ETA: 23s - loss: 0.6743 - accuracy: 0.795 - ETA: 22s - loss: 0.6753 - accuracy: 0.795 - ETA: 22s - loss: 0.6782 - accuracy: 0.795 - ETA: 21s - loss: 0.6769 - accuracy: 0.795 - ETA: 20s - loss: 0.6785 - accuracy: 0.795 - ETA: 20s - loss: 0.6787 - accuracy: 0.794 - ETA: 19s - loss: 0.6779 - accuracy: 0.795 - ETA: 18s - loss: 0.6784 - accuracy: 0.794 - ETA: 17s - loss: 0.6776 - accuracy: 0.795 - ETA: 17s - loss: 0.6768 - accuracy: 0.795 - ETA: 16s - loss: 0.6784 - accuracy: 0.794 - ETA: 15s - loss: 0.6813 - accuracy: 0.793 - ETA: 15s - loss: 0.6807 - accuracy: 0.793 - ETA: 14s - loss: 0.6814 - accuracy: 0.793 - ETA: 13s - loss: 0.6834 - accuracy: 0.793 - ETA: 13s - loss: 0.6808 - accuracy: 0.793 - ETA: 12s - loss: 0.6823 - accuracy: 0.793 - ETA: 11s - loss: 0.6856 - accuracy: 0.793 - ETA: 10s - loss: 0.6849 - accuracy: 0.793 - ETA: 10s - loss: 0.6845 - accuracy: 0.793 - ETA: 9s - loss: 0.6826 - accuracy: 0.794 - ETA: 8s - loss: 0.6848 - accuracy: 0.79 - ETA: 8s - loss: 0.6853 - accuracy: 0.79 - ETA: 7s - loss: 0.6839 - accuracy: 0.79 - ETA: 6s - loss: 0.6841 - accuracy: 0.79 - ETA: 6s - loss: 0.6859 - accuracy: 0.79 - ETA: 5s - loss: 0.6864 - accuracy: 0.79 - ETA: 4s - loss: 0.6860 - accuracy: 0.79 - ETA: 4s - loss: 0.6858 - accuracy: 0.79 - ETA: 3s - loss: 0.6875 - accuracy: 0.79 - ETA: 2s - loss: 0.6861 - accuracy: 0.79 - ETA: 1s - loss: 0.6875 - accuracy: 0.79 - ETA: 1s - loss: 0.6870 - accuracy: 0.79 - ETA: 0s - loss: 0.6875 - accuracy: 0.79 - 82s 6ms/step - loss: 0.6872 - accuracy: 0.7945 - val_loss: 2.9217 - val_accuracy: 0.3516\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.5586 - accuracy: 0.84 - ETA: 1:10 - loss: 0.5505 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5654 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5944 - accuracy: 0.82 - ETA: 1:07 - loss: 0.6233 - accuracy: 0.81 - ETA: 1:06 - loss: 0.6484 - accuracy: 0.81 - ETA: 1:06 - loss: 0.6374 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6448 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6535 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6354 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6353 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6302 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6384 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6263 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6277 - accuracy: 0.80 - ETA: 59s - loss: 0.6294 - accuracy: 0.8101 - ETA: 58s - loss: 0.6331 - accuracy: 0.808 - ETA: 58s - loss: 0.6437 - accuracy: 0.807 - ETA: 57s - loss: 0.6588 - accuracy: 0.802 - ETA: 56s - loss: 0.6579 - accuracy: 0.801 - ETA: 56s - loss: 0.6558 - accuracy: 0.801 - ETA: 55s - loss: 0.6491 - accuracy: 0.804 - ETA: 54s - loss: 0.6615 - accuracy: 0.801 - ETA: 54s - loss: 0.6684 - accuracy: 0.797 - ETA: 53s - loss: 0.6647 - accuracy: 0.797 - ETA: 52s - loss: 0.6623 - accuracy: 0.799 - ETA: 51s - loss: 0.6615 - accuracy: 0.800 - ETA: 51s - loss: 0.6593 - accuracy: 0.801 - ETA: 50s - loss: 0.6641 - accuracy: 0.798 - ETA: 49s - loss: 0.6640 - accuracy: 0.798 - ETA: 49s - loss: 0.6656 - accuracy: 0.797 - ETA: 48s - loss: 0.6638 - accuracy: 0.796 - ETA: 47s - loss: 0.6627 - accuracy: 0.796 - ETA: 46s - loss: 0.6662 - accuracy: 0.796 - ETA: 46s - loss: 0.6686 - accuracy: 0.795 - ETA: 45s - loss: 0.6708 - accuracy: 0.795 - ETA: 44s - loss: 0.6674 - accuracy: 0.795 - ETA: 44s - loss: 0.6697 - accuracy: 0.794 - ETA: 43s - loss: 0.6735 - accuracy: 0.793 - ETA: 42s - loss: 0.6726 - accuracy: 0.795 - ETA: 42s - loss: 0.6691 - accuracy: 0.795 - ETA: 41s - loss: 0.6712 - accuracy: 0.794 - ETA: 40s - loss: 0.6718 - accuracy: 0.794 - ETA: 39s - loss: 0.6706 - accuracy: 0.795 - ETA: 39s - loss: 0.6678 - accuracy: 0.796 - ETA: 38s - loss: 0.6729 - accuracy: 0.796 - ETA: 37s - loss: 0.6730 - accuracy: 0.796 - ETA: 37s - loss: 0.6747 - accuracy: 0.796 - ETA: 36s - loss: 0.6758 - accuracy: 0.796 - ETA: 35s - loss: 0.6726 - accuracy: 0.797 - ETA: 35s - loss: 0.6786 - accuracy: 0.796 - ETA: 34s - loss: 0.6774 - accuracy: 0.795 - ETA: 33s - loss: 0.6758 - accuracy: 0.795 - ETA: 32s - loss: 0.6748 - accuracy: 0.796 - ETA: 32s - loss: 0.6775 - accuracy: 0.794 - ETA: 31s - loss: 0.6779 - accuracy: 0.794 - ETA: 30s - loss: 0.6828 - accuracy: 0.792 - ETA: 30s - loss: 0.6837 - accuracy: 0.791 - ETA: 29s - loss: 0.6846 - accuracy: 0.791 - ETA: 28s - loss: 0.6867 - accuracy: 0.790 - ETA: 28s - loss: 0.6862 - accuracy: 0.790 - ETA: 27s - loss: 0.6894 - accuracy: 0.789 - ETA: 26s - loss: 0.6910 - accuracy: 0.788 - ETA: 26s - loss: 0.6913 - accuracy: 0.788 - ETA: 25s - loss: 0.6895 - accuracy: 0.789 - ETA: 24s - loss: 0.6861 - accuracy: 0.790 - ETA: 24s - loss: 0.6831 - accuracy: 0.790 - ETA: 23s - loss: 0.6874 - accuracy: 0.790 - ETA: 22s - loss: 0.6885 - accuracy: 0.790 - ETA: 21s - loss: 0.6876 - accuracy: 0.790 - ETA: 21s - loss: 0.6870 - accuracy: 0.790 - ETA: 20s - loss: 0.6897 - accuracy: 0.790 - ETA: 19s - loss: 0.6895 - accuracy: 0.789 - ETA: 19s - loss: 0.6905 - accuracy: 0.789 - ETA: 18s - loss: 0.6903 - accuracy: 0.788 - ETA: 17s - loss: 0.6904 - accuracy: 0.789 - ETA: 17s - loss: 0.6883 - accuracy: 0.789 - ETA: 16s - loss: 0.6887 - accuracy: 0.789 - ETA: 15s - loss: 0.6878 - accuracy: 0.789 - ETA: 15s - loss: 0.6854 - accuracy: 0.791 - ETA: 14s - loss: 0.6853 - accuracy: 0.791 - ETA: 13s - loss: 0.6841 - accuracy: 0.791 - ETA: 12s - loss: 0.6829 - accuracy: 0.791 - ETA: 12s - loss: 0.6851 - accuracy: 0.791 - ETA: 11s - loss: 0.6826 - accuracy: 0.792 - ETA: 10s - loss: 0.6819 - accuracy: 0.792 - ETA: 10s - loss: 0.6813 - accuracy: 0.792 - ETA: 9s - loss: 0.6808 - accuracy: 0.792 - ETA: 8s - loss: 0.6819 - accuracy: 0.79 - ETA: 8s - loss: 0.6804 - accuracy: 0.79 - ETA: 7s - loss: 0.6824 - accuracy: 0.79 - ETA: 6s - loss: 0.6840 - accuracy: 0.79 - ETA: 6s - loss: 0.6838 - accuracy: 0.79 - ETA: 5s - loss: 0.6838 - accuracy: 0.79 - ETA: 4s - loss: 0.6824 - accuracy: 0.79 - ETA: 3s - loss: 0.6824 - accuracy: 0.79 - ETA: 3s - loss: 0.6829 - accuracy: 0.79 - ETA: 2s - loss: 0.6812 - accuracy: 0.79 - ETA: 1s - loss: 0.6827 - accuracy: 0.79 - ETA: 1s - loss: 0.6828 - accuracy: 0.79 - ETA: 0s - loss: 0.6844 - accuracy: 0.79 - 81s 6ms/step - loss: 0.6839 - accuracy: 0.7917 - val_loss: 3.0137 - val_accuracy: 0.3551\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.7965 - accuracy: 0.78 - ETA: 1:10 - loss: 0.6680 - accuracy: 0.81 - ETA: 1:08 - loss: 0.6351 - accuracy: 0.81 - ETA: 1:06 - loss: 0.6728 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6834 - accuracy: 0.80 - ETA: 1:06 - loss: 0.6700 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6408 - accuracy: 0.81 - ETA: 1:04 - loss: 0.6299 - accuracy: 0.81 - ETA: 1:04 - loss: 0.6298 - accuracy: 0.81 - ETA: 1:03 - loss: 0.6217 - accuracy: 0.82 - ETA: 1:03 - loss: 0.6334 - accuracy: 0.81 - ETA: 1:02 - loss: 0.6279 - accuracy: 0.81 - ETA: 1:01 - loss: 0.6393 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6505 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6597 - accuracy: 0.80 - ETA: 59s - loss: 0.6625 - accuracy: 0.8062 - ETA: 58s - loss: 0.6607 - accuracy: 0.805 - ETA: 58s - loss: 0.6555 - accuracy: 0.806 - ETA: 57s - loss: 0.6414 - accuracy: 0.809 - ETA: 56s - loss: 0.6462 - accuracy: 0.808 - ETA: 55s - loss: 0.6562 - accuracy: 0.805 - ETA: 55s - loss: 0.6570 - accuracy: 0.802 - ETA: 54s - loss: 0.6531 - accuracy: 0.803 - ETA: 54s - loss: 0.6562 - accuracy: 0.801 - ETA: 53s - loss: 0.6594 - accuracy: 0.801 - ETA: 52s - loss: 0.6658 - accuracy: 0.800 - ETA: 51s - loss: 0.6674 - accuracy: 0.800 - ETA: 51s - loss: 0.6748 - accuracy: 0.798 - ETA: 50s - loss: 0.6758 - accuracy: 0.798 - ETA: 49s - loss: 0.6759 - accuracy: 0.798 - ETA: 49s - loss: 0.6810 - accuracy: 0.797 - ETA: 48s - loss: 0.6764 - accuracy: 0.798 - ETA: 47s - loss: 0.6735 - accuracy: 0.799 - ETA: 46s - loss: 0.6726 - accuracy: 0.799 - ETA: 46s - loss: 0.6740 - accuracy: 0.798 - ETA: 45s - loss: 0.6729 - accuracy: 0.798 - ETA: 44s - loss: 0.6712 - accuracy: 0.799 - ETA: 44s - loss: 0.6734 - accuracy: 0.799 - ETA: 43s - loss: 0.6698 - accuracy: 0.799 - ETA: 42s - loss: 0.6692 - accuracy: 0.799 - ETA: 42s - loss: 0.6704 - accuracy: 0.799 - ETA: 41s - loss: 0.6758 - accuracy: 0.798 - ETA: 40s - loss: 0.6758 - accuracy: 0.798 - ETA: 40s - loss: 0.6756 - accuracy: 0.798 - ETA: 39s - loss: 0.6786 - accuracy: 0.797 - ETA: 38s - loss: 0.6806 - accuracy: 0.797 - ETA: 37s - loss: 0.6750 - accuracy: 0.798 - ETA: 37s - loss: 0.6738 - accuracy: 0.798 - ETA: 36s - loss: 0.6764 - accuracy: 0.797 - ETA: 35s - loss: 0.6771 - accuracy: 0.796 - ETA: 35s - loss: 0.6755 - accuracy: 0.796 - ETA: 34s - loss: 0.6731 - accuracy: 0.797 - ETA: 33s - loss: 0.6751 - accuracy: 0.795 - ETA: 33s - loss: 0.6722 - accuracy: 0.796 - ETA: 32s - loss: 0.6774 - accuracy: 0.795 - ETA: 31s - loss: 0.6791 - accuracy: 0.796 - ETA: 31s - loss: 0.6776 - accuracy: 0.796 - ETA: 30s - loss: 0.6796 - accuracy: 0.795 - ETA: 29s - loss: 0.6798 - accuracy: 0.795 - ETA: 28s - loss: 0.6841 - accuracy: 0.794 - ETA: 28s - loss: 0.6882 - accuracy: 0.793 - ETA: 27s - loss: 0.6893 - accuracy: 0.793 - ETA: 26s - loss: 0.6859 - accuracy: 0.793 - ETA: 26s - loss: 0.6820 - accuracy: 0.795 - ETA: 25s - loss: 0.6839 - accuracy: 0.794 - ETA: 24s - loss: 0.6842 - accuracy: 0.794 - ETA: 24s - loss: 0.6851 - accuracy: 0.793 - ETA: 23s - loss: 0.6876 - accuracy: 0.792 - ETA: 22s - loss: 0.6880 - accuracy: 0.792 - ETA: 22s - loss: 0.6881 - accuracy: 0.792 - ETA: 21s - loss: 0.6903 - accuracy: 0.791 - ETA: 20s - loss: 0.6896 - accuracy: 0.792 - ETA: 20s - loss: 0.6882 - accuracy: 0.793 - ETA: 19s - loss: 0.6883 - accuracy: 0.793 - ETA: 18s - loss: 0.6874 - accuracy: 0.793 - ETA: 17s - loss: 0.6866 - accuracy: 0.793 - ETA: 17s - loss: 0.6850 - accuracy: 0.793 - ETA: 16s - loss: 0.6876 - accuracy: 0.793 - ETA: 15s - loss: 0.6861 - accuracy: 0.793 - ETA: 15s - loss: 0.6853 - accuracy: 0.793 - ETA: 14s - loss: 0.6846 - accuracy: 0.794 - ETA: 13s - loss: 0.6838 - accuracy: 0.794 - ETA: 13s - loss: 0.6837 - accuracy: 0.794 - ETA: 12s - loss: 0.6828 - accuracy: 0.794 - ETA: 11s - loss: 0.6845 - accuracy: 0.793 - ETA: 10s - loss: 0.6841 - accuracy: 0.794 - ETA: 10s - loss: 0.6854 - accuracy: 0.793 - ETA: 9s - loss: 0.6845 - accuracy: 0.793 - ETA: 8s - loss: 0.6842 - accuracy: 0.79 - ETA: 8s - loss: 0.6851 - accuracy: 0.79 - ETA: 7s - loss: 0.6841 - accuracy: 0.79 - ETA: 6s - loss: 0.6834 - accuracy: 0.79 - ETA: 6s - loss: 0.6839 - accuracy: 0.79 - ETA: 5s - loss: 0.6843 - accuracy: 0.79 - ETA: 4s - loss: 0.6845 - accuracy: 0.79 - ETA: 4s - loss: 0.6848 - accuracy: 0.79 - ETA: 3s - loss: 0.6834 - accuracy: 0.79 - ETA: 2s - loss: 0.6834 - accuracy: 0.79 - ETA: 1s - loss: 0.6837 - accuracy: 0.79 - ETA: 1s - loss: 0.6829 - accuracy: 0.79 - ETA: 0s - loss: 0.6834 - accuracy: 0.79 - 81s 6ms/step - loss: 0.6847 - accuracy: 0.7932 - val_loss: 2.9319 - val_accuracy: 0.3327\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.5362 - accuracy: 0.85 - ETA: 1:10 - loss: 0.5943 - accuracy: 0.83 - ETA: 1:09 - loss: 0.6276 - accuracy: 0.82 - ETA: 1:07 - loss: 0.6159 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6383 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6523 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6604 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6477 - accuracy: 0.81 - ETA: 1:04 - loss: 0.6651 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6593 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6609 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6490 - accuracy: 0.81 - ETA: 1:01 - loss: 0.6419 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6455 - accuracy: 0.81 - ETA: 59s - loss: 0.6497 - accuracy: 0.8089 - ETA: 59s - loss: 0.6402 - accuracy: 0.812 - ETA: 58s - loss: 0.6403 - accuracy: 0.813 - ETA: 58s - loss: 0.6377 - accuracy: 0.816 - ETA: 57s - loss: 0.6305 - accuracy: 0.817 - ETA: 56s - loss: 0.6365 - accuracy: 0.812 - ETA: 55s - loss: 0.6435 - accuracy: 0.810 - ETA: 55s - loss: 0.6511 - accuracy: 0.808 - ETA: 54s - loss: 0.6492 - accuracy: 0.809 - ETA: 53s - loss: 0.6471 - accuracy: 0.811 - ETA: 53s - loss: 0.6450 - accuracy: 0.811 - ETA: 52s - loss: 0.6461 - accuracy: 0.811 - ETA: 51s - loss: 0.6480 - accuracy: 0.809 - ETA: 50s - loss: 0.6480 - accuracy: 0.810 - ETA: 50s - loss: 0.6441 - accuracy: 0.812 - ETA: 49s - loss: 0.6483 - accuracy: 0.810 - ETA: 48s - loss: 0.6506 - accuracy: 0.810 - ETA: 48s - loss: 0.6520 - accuracy: 0.809 - ETA: 47s - loss: 0.6548 - accuracy: 0.808 - ETA: 46s - loss: 0.6512 - accuracy: 0.808 - ETA: 46s - loss: 0.6535 - accuracy: 0.807 - ETA: 45s - loss: 0.6509 - accuracy: 0.808 - ETA: 44s - loss: 0.6508 - accuracy: 0.807 - ETA: 44s - loss: 0.6533 - accuracy: 0.806 - ETA: 43s - loss: 0.6516 - accuracy: 0.807 - ETA: 42s - loss: 0.6531 - accuracy: 0.806 - ETA: 42s - loss: 0.6538 - accuracy: 0.805 - ETA: 41s - loss: 0.6534 - accuracy: 0.805 - ETA: 40s - loss: 0.6552 - accuracy: 0.804 - ETA: 40s - loss: 0.6546 - accuracy: 0.804 - ETA: 39s - loss: 0.6553 - accuracy: 0.804 - ETA: 38s - loss: 0.6551 - accuracy: 0.804 - ETA: 38s - loss: 0.6563 - accuracy: 0.803 - ETA: 37s - loss: 0.6547 - accuracy: 0.803 - ETA: 36s - loss: 0.6543 - accuracy: 0.803 - ETA: 36s - loss: 0.6556 - accuracy: 0.802 - ETA: 35s - loss: 0.6556 - accuracy: 0.802 - ETA: 34s - loss: 0.6587 - accuracy: 0.800 - ETA: 33s - loss: 0.6577 - accuracy: 0.799 - ETA: 33s - loss: 0.6570 - accuracy: 0.799 - ETA: 32s - loss: 0.6566 - accuracy: 0.800 - ETA: 31s - loss: 0.6587 - accuracy: 0.799 - ETA: 31s - loss: 0.6559 - accuracy: 0.800 - ETA: 30s - loss: 0.6547 - accuracy: 0.800 - ETA: 29s - loss: 0.6530 - accuracy: 0.801 - ETA: 29s - loss: 0.6520 - accuracy: 0.802 - ETA: 28s - loss: 0.6511 - accuracy: 0.802 - ETA: 27s - loss: 0.6519 - accuracy: 0.802 - ETA: 26s - loss: 0.6509 - accuracy: 0.802 - ETA: 26s - loss: 0.6493 - accuracy: 0.802 - ETA: 25s - loss: 0.6471 - accuracy: 0.803 - ETA: 24s - loss: 0.6496 - accuracy: 0.802 - ETA: 24s - loss: 0.6496 - accuracy: 0.802 - ETA: 23s - loss: 0.6520 - accuracy: 0.801 - ETA: 22s - loss: 0.6503 - accuracy: 0.802 - ETA: 22s - loss: 0.6492 - accuracy: 0.802 - ETA: 21s - loss: 0.6474 - accuracy: 0.803 - ETA: 20s - loss: 0.6476 - accuracy: 0.803 - ETA: 19s - loss: 0.6475 - accuracy: 0.803 - ETA: 19s - loss: 0.6466 - accuracy: 0.803 - ETA: 18s - loss: 0.6476 - accuracy: 0.803 - ETA: 17s - loss: 0.6469 - accuracy: 0.803 - ETA: 17s - loss: 0.6495 - accuracy: 0.802 - ETA: 16s - loss: 0.6507 - accuracy: 0.802 - ETA: 15s - loss: 0.6521 - accuracy: 0.802 - ETA: 15s - loss: 0.6526 - accuracy: 0.802 - ETA: 14s - loss: 0.6523 - accuracy: 0.802 - ETA: 13s - loss: 0.6519 - accuracy: 0.802 - ETA: 13s - loss: 0.6530 - accuracy: 0.802 - ETA: 12s - loss: 0.6519 - accuracy: 0.802 - ETA: 11s - loss: 0.6498 - accuracy: 0.803 - ETA: 10s - loss: 0.6474 - accuracy: 0.804 - ETA: 10s - loss: 0.6464 - accuracy: 0.804 - ETA: 9s - loss: 0.6472 - accuracy: 0.804 - ETA: 8s - loss: 0.6470 - accuracy: 0.80 - ETA: 8s - loss: 0.6468 - accuracy: 0.80 - ETA: 7s - loss: 0.6469 - accuracy: 0.80 - ETA: 6s - loss: 0.6474 - accuracy: 0.80 - ETA: 6s - loss: 0.6486 - accuracy: 0.80 - ETA: 5s - loss: 0.6486 - accuracy: 0.80 - ETA: 4s - loss: 0.6498 - accuracy: 0.80 - ETA: 3s - loss: 0.6490 - accuracy: 0.80 - ETA: 3s - loss: 0.6480 - accuracy: 0.80 - ETA: 2s - loss: 0.6482 - accuracy: 0.80 - ETA: 1s - loss: 0.6477 - accuracy: 0.80 - ETA: 1s - loss: 0.6475 - accuracy: 0.80 - ETA: 0s - loss: 0.6475 - accuracy: 0.80 - 81s 6ms/step - loss: 0.6483 - accuracy: 0.8035 - val_loss: 3.0813 - val_accuracy: 0.3458\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.6039 - accuracy: 0.82 - ETA: 1:08 - loss: 0.7033 - accuracy: 0.80 - ETA: 1:08 - loss: 0.6846 - accuracy: 0.79 - ETA: 1:06 - loss: 0.7133 - accuracy: 0.78 - ETA: 1:05 - loss: 0.7270 - accuracy: 0.78 - ETA: 1:04 - loss: 0.7472 - accuracy: 0.78 - ETA: 1:04 - loss: 0.7762 - accuracy: 0.77 - ETA: 1:03 - loss: 0.7847 - accuracy: 0.78 - ETA: 1:03 - loss: 0.7908 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7869 - accuracy: 0.77 - ETA: 1:02 - loss: 0.7724 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7614 - accuracy: 0.78 - ETA: 1:01 - loss: 0.7418 - accuracy: 0.79 - ETA: 1:00 - loss: 0.7466 - accuracy: 0.78 - ETA: 1:00 - loss: 0.7492 - accuracy: 0.78 - ETA: 59s - loss: 0.7474 - accuracy: 0.7837 - ETA: 59s - loss: 0.7404 - accuracy: 0.786 - ETA: 58s - loss: 0.7364 - accuracy: 0.787 - ETA: 57s - loss: 0.7373 - accuracy: 0.786 - ETA: 56s - loss: 0.7329 - accuracy: 0.787 - ETA: 56s - loss: 0.7338 - accuracy: 0.786 - ETA: 55s - loss: 0.7249 - accuracy: 0.788 - ETA: 54s - loss: 0.7184 - accuracy: 0.788 - ETA: 54s - loss: 0.7160 - accuracy: 0.790 - ETA: 53s - loss: 0.7121 - accuracy: 0.790 - ETA: 52s - loss: 0.7091 - accuracy: 0.790 - ETA: 52s - loss: 0.7028 - accuracy: 0.791 - ETA: 51s - loss: 0.7020 - accuracy: 0.792 - ETA: 50s - loss: 0.6954 - accuracy: 0.794 - ETA: 49s - loss: 0.7007 - accuracy: 0.791 - ETA: 49s - loss: 0.6924 - accuracy: 0.794 - ETA: 48s - loss: 0.6906 - accuracy: 0.794 - ETA: 47s - loss: 0.6866 - accuracy: 0.795 - ETA: 47s - loss: 0.6829 - accuracy: 0.796 - ETA: 46s - loss: 0.6855 - accuracy: 0.794 - ETA: 45s - loss: 0.6861 - accuracy: 0.793 - ETA: 45s - loss: 0.6895 - accuracy: 0.792 - ETA: 44s - loss: 0.6813 - accuracy: 0.794 - ETA: 43s - loss: 0.6784 - accuracy: 0.795 - ETA: 43s - loss: 0.6818 - accuracy: 0.794 - ETA: 42s - loss: 0.6792 - accuracy: 0.795 - ETA: 42s - loss: 0.6735 - accuracy: 0.798 - ETA: 41s - loss: 0.6689 - accuracy: 0.799 - ETA: 40s - loss: 0.6637 - accuracy: 0.801 - ETA: 40s - loss: 0.6610 - accuracy: 0.801 - ETA: 39s - loss: 0.6638 - accuracy: 0.801 - ETA: 38s - loss: 0.6644 - accuracy: 0.800 - ETA: 38s - loss: 0.6665 - accuracy: 0.800 - ETA: 37s - loss: 0.6649 - accuracy: 0.800 - ETA: 36s - loss: 0.6629 - accuracy: 0.801 - ETA: 35s - loss: 0.6640 - accuracy: 0.800 - ETA: 35s - loss: 0.6627 - accuracy: 0.800 - ETA: 34s - loss: 0.6617 - accuracy: 0.801 - ETA: 33s - loss: 0.6578 - accuracy: 0.802 - ETA: 32s - loss: 0.6587 - accuracy: 0.802 - ETA: 32s - loss: 0.6580 - accuracy: 0.801 - ETA: 31s - loss: 0.6574 - accuracy: 0.801 - ETA: 30s - loss: 0.6604 - accuracy: 0.801 - ETA: 30s - loss: 0.6585 - accuracy: 0.800 - ETA: 29s - loss: 0.6594 - accuracy: 0.801 - ETA: 28s - loss: 0.6613 - accuracy: 0.800 - ETA: 27s - loss: 0.6625 - accuracy: 0.800 - ETA: 27s - loss: 0.6612 - accuracy: 0.800 - ETA: 26s - loss: 0.6623 - accuracy: 0.800 - ETA: 25s - loss: 0.6642 - accuracy: 0.800 - ETA: 25s - loss: 0.6637 - accuracy: 0.800 - ETA: 24s - loss: 0.6638 - accuracy: 0.800 - ETA: 23s - loss: 0.6633 - accuracy: 0.800 - ETA: 22s - loss: 0.6632 - accuracy: 0.800 - ETA: 22s - loss: 0.6644 - accuracy: 0.799 - ETA: 21s - loss: 0.6632 - accuracy: 0.800 - ETA: 20s - loss: 0.6655 - accuracy: 0.799 - ETA: 20s - loss: 0.6661 - accuracy: 0.799 - ETA: 19s - loss: 0.6641 - accuracy: 0.799 - ETA: 18s - loss: 0.6652 - accuracy: 0.799 - ETA: 18s - loss: 0.6651 - accuracy: 0.799 - ETA: 17s - loss: 0.6638 - accuracy: 0.799 - ETA: 16s - loss: 0.6628 - accuracy: 0.800 - ETA: 15s - loss: 0.6611 - accuracy: 0.800 - ETA: 15s - loss: 0.6623 - accuracy: 0.800 - ETA: 14s - loss: 0.6631 - accuracy: 0.800 - ETA: 13s - loss: 0.6639 - accuracy: 0.800 - ETA: 13s - loss: 0.6651 - accuracy: 0.799 - ETA: 12s - loss: 0.6652 - accuracy: 0.799 - ETA: 11s - loss: 0.6654 - accuracy: 0.799 - ETA: 11s - loss: 0.6636 - accuracy: 0.799 - ETA: 10s - loss: 0.6623 - accuracy: 0.800 - ETA: 9s - loss: 0.6597 - accuracy: 0.800 - ETA: 8s - loss: 0.6610 - accuracy: 0.80 - ETA: 8s - loss: 0.6607 - accuracy: 0.80 - ETA: 7s - loss: 0.6621 - accuracy: 0.80 - ETA: 6s - loss: 0.6620 - accuracy: 0.80 - ETA: 6s - loss: 0.6629 - accuracy: 0.80 - ETA: 5s - loss: 0.6624 - accuracy: 0.80 - ETA: 4s - loss: 0.6634 - accuracy: 0.79 - ETA: 4s - loss: 0.6636 - accuracy: 0.79 - ETA: 3s - loss: 0.6659 - accuracy: 0.79 - ETA: 2s - loss: 0.6658 - accuracy: 0.79 - ETA: 1s - loss: 0.6643 - accuracy: 0.79 - ETA: 1s - loss: 0.6643 - accuracy: 0.79 - ETA: 0s - loss: 0.6647 - accuracy: 0.79 - 82s 6ms/step - loss: 0.6646 - accuracy: 0.7996 - val_loss: 3.0296 - val_accuracy: 0.3291\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:15 - loss: 0.7681 - accuracy: 0.75 - ETA: 1:10 - loss: 0.7323 - accuracy: 0.76 - ETA: 1:09 - loss: 0.6809 - accuracy: 0.77 - ETA: 1:09 - loss: 0.6769 - accuracy: 0.77 - ETA: 1:08 - loss: 0.6571 - accuracy: 0.78 - ETA: 1:07 - loss: 0.6747 - accuracy: 0.77 - ETA: 1:06 - loss: 0.6638 - accuracy: 0.78 - ETA: 1:05 - loss: 0.6609 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6625 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6541 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6457 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6536 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6506 - accuracy: 0.79 - ETA: 1:02 - loss: 0.6483 - accuracy: 0.79 - ETA: 1:01 - loss: 0.6468 - accuracy: 0.79 - ETA: 1:00 - loss: 0.6324 - accuracy: 0.80 - ETA: 59s - loss: 0.6444 - accuracy: 0.8028 - ETA: 59s - loss: 0.6356 - accuracy: 0.806 - ETA: 58s - loss: 0.6400 - accuracy: 0.806 - ETA: 57s - loss: 0.6409 - accuracy: 0.807 - ETA: 56s - loss: 0.6406 - accuracy: 0.807 - ETA: 55s - loss: 0.6435 - accuracy: 0.805 - ETA: 55s - loss: 0.6419 - accuracy: 0.805 - ETA: 54s - loss: 0.6396 - accuracy: 0.807 - ETA: 53s - loss: 0.6452 - accuracy: 0.806 - ETA: 52s - loss: 0.6456 - accuracy: 0.807 - ETA: 51s - loss: 0.6467 - accuracy: 0.808 - ETA: 51s - loss: 0.6433 - accuracy: 0.808 - ETA: 50s - loss: 0.6423 - accuracy: 0.808 - ETA: 49s - loss: 0.6410 - accuracy: 0.808 - ETA: 49s - loss: 0.6370 - accuracy: 0.808 - ETA: 48s - loss: 0.6402 - accuracy: 0.807 - ETA: 47s - loss: 0.6356 - accuracy: 0.808 - ETA: 47s - loss: 0.6381 - accuracy: 0.807 - ETA: 46s - loss: 0.6377 - accuracy: 0.807 - ETA: 45s - loss: 0.6397 - accuracy: 0.806 - ETA: 45s - loss: 0.6356 - accuracy: 0.807 - ETA: 44s - loss: 0.6379 - accuracy: 0.806 - ETA: 43s - loss: 0.6407 - accuracy: 0.805 - ETA: 42s - loss: 0.6415 - accuracy: 0.806 - ETA: 42s - loss: 0.6436 - accuracy: 0.804 - ETA: 41s - loss: 0.6474 - accuracy: 0.802 - ETA: 40s - loss: 0.6479 - accuracy: 0.802 - ETA: 39s - loss: 0.6475 - accuracy: 0.802 - ETA: 39s - loss: 0.6495 - accuracy: 0.802 - ETA: 38s - loss: 0.6532 - accuracy: 0.800 - ETA: 37s - loss: 0.6531 - accuracy: 0.801 - ETA: 37s - loss: 0.6568 - accuracy: 0.801 - ETA: 36s - loss: 0.6559 - accuracy: 0.800 - ETA: 35s - loss: 0.6546 - accuracy: 0.801 - ETA: 35s - loss: 0.6586 - accuracy: 0.800 - ETA: 34s - loss: 0.6623 - accuracy: 0.799 - ETA: 33s - loss: 0.6632 - accuracy: 0.799 - ETA: 32s - loss: 0.6617 - accuracy: 0.799 - ETA: 32s - loss: 0.6641 - accuracy: 0.799 - ETA: 31s - loss: 0.6611 - accuracy: 0.800 - ETA: 30s - loss: 0.6614 - accuracy: 0.799 - ETA: 30s - loss: 0.6614 - accuracy: 0.800 - ETA: 29s - loss: 0.6614 - accuracy: 0.800 - ETA: 28s - loss: 0.6614 - accuracy: 0.800 - ETA: 28s - loss: 0.6622 - accuracy: 0.800 - ETA: 27s - loss: 0.6616 - accuracy: 0.800 - ETA: 26s - loss: 0.6617 - accuracy: 0.799 - ETA: 26s - loss: 0.6587 - accuracy: 0.800 - ETA: 25s - loss: 0.6588 - accuracy: 0.801 - ETA: 24s - loss: 0.6574 - accuracy: 0.801 - ETA: 24s - loss: 0.6574 - accuracy: 0.801 - ETA: 23s - loss: 0.6598 - accuracy: 0.800 - ETA: 22s - loss: 0.6605 - accuracy: 0.800 - ETA: 21s - loss: 0.6589 - accuracy: 0.800 - ETA: 21s - loss: 0.6594 - accuracy: 0.800 - ETA: 20s - loss: 0.6611 - accuracy: 0.800 - ETA: 19s - loss: 0.6612 - accuracy: 0.800 - ETA: 19s - loss: 0.6616 - accuracy: 0.800 - ETA: 18s - loss: 0.6633 - accuracy: 0.800 - ETA: 17s - loss: 0.6627 - accuracy: 0.799 - ETA: 17s - loss: 0.6621 - accuracy: 0.800 - ETA: 16s - loss: 0.6599 - accuracy: 0.800 - ETA: 15s - loss: 0.6584 - accuracy: 0.800 - ETA: 15s - loss: 0.6626 - accuracy: 0.800 - ETA: 14s - loss: 0.6610 - accuracy: 0.800 - ETA: 13s - loss: 0.6611 - accuracy: 0.800 - ETA: 12s - loss: 0.6610 - accuracy: 0.800 - ETA: 12s - loss: 0.6597 - accuracy: 0.800 - ETA: 11s - loss: 0.6626 - accuracy: 0.800 - ETA: 10s - loss: 0.6627 - accuracy: 0.799 - ETA: 10s - loss: 0.6633 - accuracy: 0.799 - ETA: 9s - loss: 0.6630 - accuracy: 0.799 - ETA: 8s - loss: 0.6627 - accuracy: 0.79 - ETA: 8s - loss: 0.6609 - accuracy: 0.80 - ETA: 7s - loss: 0.6599 - accuracy: 0.80 - ETA: 6s - loss: 0.6587 - accuracy: 0.80 - ETA: 6s - loss: 0.6584 - accuracy: 0.80 - ETA: 5s - loss: 0.6584 - accuracy: 0.80 - ETA: 4s - loss: 0.6593 - accuracy: 0.79 - ETA: 3s - loss: 0.6588 - accuracy: 0.79 - ETA: 3s - loss: 0.6583 - accuracy: 0.79 - ETA: 2s - loss: 0.6586 - accuracy: 0.79 - ETA: 1s - loss: 0.6581 - accuracy: 0.79 - ETA: 1s - loss: 0.6581 - accuracy: 0.79 - ETA: 0s - loss: 0.6580 - accuracy: 0.79 - 81s 6ms/step - loss: 0.6594 - accuracy: 0.7995 - val_loss: 3.0307 - val_accuracy: 0.3469\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.6004 - accuracy: 0.78 - ETA: 1:09 - loss: 0.6336 - accuracy: 0.78 - ETA: 1:07 - loss: 0.7448 - accuracy: 0.75 - ETA: 1:07 - loss: 0.6694 - accuracy: 0.77 - ETA: 1:06 - loss: 0.6463 - accuracy: 0.78 - ETA: 1:05 - loss: 0.6819 - accuracy: 0.78 - ETA: 1:04 - loss: 0.6680 - accuracy: 0.78 - ETA: 1:04 - loss: 0.6655 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6636 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6425 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6355 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6327 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6265 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6273 - accuracy: 0.80 - ETA: 59s - loss: 0.6398 - accuracy: 0.8031 - ETA: 59s - loss: 0.6424 - accuracy: 0.802 - ETA: 58s - loss: 0.6319 - accuracy: 0.805 - ETA: 57s - loss: 0.6346 - accuracy: 0.804 - ETA: 57s - loss: 0.6308 - accuracy: 0.804 - ETA: 56s - loss: 0.6339 - accuracy: 0.803 - ETA: 55s - loss: 0.6408 - accuracy: 0.802 - ETA: 54s - loss: 0.6384 - accuracy: 0.804 - ETA: 54s - loss: 0.6419 - accuracy: 0.802 - ETA: 53s - loss: 0.6364 - accuracy: 0.803 - ETA: 53s - loss: 0.6376 - accuracy: 0.803 - ETA: 52s - loss: 0.6334 - accuracy: 0.805 - ETA: 51s - loss: 0.6312 - accuracy: 0.806 - ETA: 51s - loss: 0.6380 - accuracy: 0.805 - ETA: 50s - loss: 0.6402 - accuracy: 0.805 - ETA: 49s - loss: 0.6485 - accuracy: 0.802 - ETA: 49s - loss: 0.6521 - accuracy: 0.801 - ETA: 48s - loss: 0.6535 - accuracy: 0.801 - ETA: 47s - loss: 0.6538 - accuracy: 0.800 - ETA: 47s - loss: 0.6557 - accuracy: 0.800 - ETA: 46s - loss: 0.6568 - accuracy: 0.799 - ETA: 45s - loss: 0.6661 - accuracy: 0.796 - ETA: 44s - loss: 0.6702 - accuracy: 0.795 - ETA: 44s - loss: 0.6666 - accuracy: 0.796 - ETA: 43s - loss: 0.6656 - accuracy: 0.795 - ETA: 42s - loss: 0.6657 - accuracy: 0.795 - ETA: 42s - loss: 0.6651 - accuracy: 0.795 - ETA: 41s - loss: 0.6642 - accuracy: 0.795 - ETA: 40s - loss: 0.6680 - accuracy: 0.793 - ETA: 39s - loss: 0.6683 - accuracy: 0.793 - ETA: 39s - loss: 0.6674 - accuracy: 0.794 - ETA: 38s - loss: 0.6647 - accuracy: 0.795 - ETA: 37s - loss: 0.6650 - accuracy: 0.795 - ETA: 37s - loss: 0.6639 - accuracy: 0.794 - ETA: 36s - loss: 0.6633 - accuracy: 0.794 - ETA: 35s - loss: 0.6618 - accuracy: 0.794 - ETA: 35s - loss: 0.6613 - accuracy: 0.794 - ETA: 34s - loss: 0.6614 - accuracy: 0.795 - ETA: 33s - loss: 0.6634 - accuracy: 0.795 - ETA: 33s - loss: 0.6612 - accuracy: 0.795 - ETA: 32s - loss: 0.6602 - accuracy: 0.795 - ETA: 31s - loss: 0.6625 - accuracy: 0.794 - ETA: 30s - loss: 0.6626 - accuracy: 0.794 - ETA: 30s - loss: 0.6605 - accuracy: 0.795 - ETA: 29s - loss: 0.6611 - accuracy: 0.794 - ETA: 28s - loss: 0.6603 - accuracy: 0.794 - ETA: 28s - loss: 0.6592 - accuracy: 0.794 - ETA: 27s - loss: 0.6564 - accuracy: 0.795 - ETA: 26s - loss: 0.6565 - accuracy: 0.795 - ETA: 26s - loss: 0.6559 - accuracy: 0.795 - ETA: 25s - loss: 0.6565 - accuracy: 0.796 - ETA: 24s - loss: 0.6557 - accuracy: 0.796 - ETA: 24s - loss: 0.6564 - accuracy: 0.796 - ETA: 23s - loss: 0.6573 - accuracy: 0.795 - ETA: 22s - loss: 0.6577 - accuracy: 0.795 - ETA: 21s - loss: 0.6568 - accuracy: 0.796 - ETA: 21s - loss: 0.6570 - accuracy: 0.796 - ETA: 20s - loss: 0.6561 - accuracy: 0.796 - ETA: 19s - loss: 0.6560 - accuracy: 0.797 - ETA: 19s - loss: 0.6536 - accuracy: 0.797 - ETA: 18s - loss: 0.6545 - accuracy: 0.797 - ETA: 17s - loss: 0.6588 - accuracy: 0.796 - ETA: 17s - loss: 0.6613 - accuracy: 0.796 - ETA: 16s - loss: 0.6607 - accuracy: 0.796 - ETA: 15s - loss: 0.6610 - accuracy: 0.796 - ETA: 15s - loss: 0.6628 - accuracy: 0.796 - ETA: 14s - loss: 0.6618 - accuracy: 0.796 - ETA: 13s - loss: 0.6631 - accuracy: 0.797 - ETA: 13s - loss: 0.6628 - accuracy: 0.797 - ETA: 12s - loss: 0.6632 - accuracy: 0.796 - ETA: 11s - loss: 0.6624 - accuracy: 0.797 - ETA: 10s - loss: 0.6618 - accuracy: 0.797 - ETA: 10s - loss: 0.6635 - accuracy: 0.797 - ETA: 9s - loss: 0.6633 - accuracy: 0.797 - ETA: 8s - loss: 0.6635 - accuracy: 0.79 - ETA: 8s - loss: 0.6629 - accuracy: 0.79 - ETA: 7s - loss: 0.6614 - accuracy: 0.79 - ETA: 6s - loss: 0.6599 - accuracy: 0.79 - ETA: 6s - loss: 0.6613 - accuracy: 0.79 - ETA: 5s - loss: 0.6625 - accuracy: 0.79 - ETA: 4s - loss: 0.6635 - accuracy: 0.79 - ETA: 3s - loss: 0.6633 - accuracy: 0.79 - ETA: 3s - loss: 0.6623 - accuracy: 0.79 - ETA: 2s - loss: 0.6618 - accuracy: 0.79 - ETA: 1s - loss: 0.6618 - accuracy: 0.79 - ETA: 1s - loss: 0.6617 - accuracy: 0.79 - ETA: 0s - loss: 0.6628 - accuracy: 0.79 - 81s 6ms/step - loss: 0.6641 - accuracy: 0.7971 - val_loss: 3.0062 - val_accuracy: 0.3324\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.4925 - accuracy: 0.83 - ETA: 1:09 - loss: 0.6708 - accuracy: 0.79 - ETA: 1:09 - loss: 0.6306 - accuracy: 0.80 - ETA: 1:07 - loss: 0.6236 - accuracy: 0.80 - ETA: 1:08 - loss: 0.6425 - accuracy: 0.80 - ETA: 1:07 - loss: 0.6288 - accuracy: 0.80 - ETA: 1:06 - loss: 0.6521 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6503 - accuracy: 0.79 - ETA: 1:05 - loss: 0.6696 - accuracy: 0.78 - ETA: 1:04 - loss: 0.6554 - accuracy: 0.79 - ETA: 1:04 - loss: 0.6669 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6552 - accuracy: 0.79 - ETA: 1:02 - loss: 0.6400 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6496 - accuracy: 0.79 - ETA: 1:00 - loss: 0.6273 - accuracy: 0.80 - ETA: 59s - loss: 0.6448 - accuracy: 0.8003 - ETA: 59s - loss: 0.6537 - accuracy: 0.796 - ETA: 58s - loss: 0.6518 - accuracy: 0.797 - ETA: 57s - loss: 0.6595 - accuracy: 0.797 - ETA: 57s - loss: 0.6543 - accuracy: 0.798 - ETA: 56s - loss: 0.6513 - accuracy: 0.799 - ETA: 55s - loss: 0.6536 - accuracy: 0.799 - ETA: 54s - loss: 0.6526 - accuracy: 0.798 - ETA: 54s - loss: 0.6496 - accuracy: 0.799 - ETA: 53s - loss: 0.6474 - accuracy: 0.800 - ETA: 52s - loss: 0.6446 - accuracy: 0.800 - ETA: 51s - loss: 0.6485 - accuracy: 0.797 - ETA: 51s - loss: 0.6434 - accuracy: 0.798 - ETA: 50s - loss: 0.6437 - accuracy: 0.798 - ETA: 50s - loss: 0.6431 - accuracy: 0.798 - ETA: 49s - loss: 0.6448 - accuracy: 0.799 - ETA: 48s - loss: 0.6462 - accuracy: 0.798 - ETA: 47s - loss: 0.6463 - accuracy: 0.798 - ETA: 47s - loss: 0.6442 - accuracy: 0.798 - ETA: 46s - loss: 0.6446 - accuracy: 0.798 - ETA: 45s - loss: 0.6484 - accuracy: 0.796 - ETA: 45s - loss: 0.6507 - accuracy: 0.797 - ETA: 44s - loss: 0.6552 - accuracy: 0.795 - ETA: 43s - loss: 0.6511 - accuracy: 0.797 - ETA: 42s - loss: 0.6525 - accuracy: 0.796 - ETA: 42s - loss: 0.6481 - accuracy: 0.797 - ETA: 41s - loss: 0.6469 - accuracy: 0.797 - ETA: 40s - loss: 0.6504 - accuracy: 0.796 - ETA: 40s - loss: 0.6498 - accuracy: 0.796 - ETA: 39s - loss: 0.6494 - accuracy: 0.796 - ETA: 38s - loss: 0.6506 - accuracy: 0.796 - ETA: 38s - loss: 0.6482 - accuracy: 0.796 - ETA: 37s - loss: 0.6474 - accuracy: 0.796 - ETA: 36s - loss: 0.6489 - accuracy: 0.797 - ETA: 36s - loss: 0.6489 - accuracy: 0.797 - ETA: 35s - loss: 0.6487 - accuracy: 0.797 - ETA: 34s - loss: 0.6506 - accuracy: 0.796 - ETA: 34s - loss: 0.6510 - accuracy: 0.796 - ETA: 33s - loss: 0.6514 - accuracy: 0.795 - ETA: 32s - loss: 0.6538 - accuracy: 0.796 - ETA: 31s - loss: 0.6562 - accuracy: 0.795 - ETA: 31s - loss: 0.6568 - accuracy: 0.795 - ETA: 30s - loss: 0.6573 - accuracy: 0.795 - ETA: 29s - loss: 0.6604 - accuracy: 0.795 - ETA: 29s - loss: 0.6601 - accuracy: 0.796 - ETA: 28s - loss: 0.6625 - accuracy: 0.795 - ETA: 27s - loss: 0.6605 - accuracy: 0.796 - ETA: 27s - loss: 0.6668 - accuracy: 0.795 - ETA: 26s - loss: 0.6615 - accuracy: 0.796 - ETA: 25s - loss: 0.6596 - accuracy: 0.797 - ETA: 24s - loss: 0.6591 - accuracy: 0.797 - ETA: 24s - loss: 0.6592 - accuracy: 0.797 - ETA: 23s - loss: 0.6566 - accuracy: 0.798 - ETA: 22s - loss: 0.6567 - accuracy: 0.798 - ETA: 22s - loss: 0.6578 - accuracy: 0.798 - ETA: 21s - loss: 0.6597 - accuracy: 0.798 - ETA: 20s - loss: 0.6593 - accuracy: 0.798 - ETA: 20s - loss: 0.6611 - accuracy: 0.798 - ETA: 19s - loss: 0.6594 - accuracy: 0.798 - ETA: 18s - loss: 0.6592 - accuracy: 0.799 - ETA: 17s - loss: 0.6582 - accuracy: 0.798 - ETA: 17s - loss: 0.6569 - accuracy: 0.799 - ETA: 16s - loss: 0.6582 - accuracy: 0.799 - ETA: 15s - loss: 0.6564 - accuracy: 0.799 - ETA: 15s - loss: 0.6565 - accuracy: 0.799 - ETA: 14s - loss: 0.6561 - accuracy: 0.800 - ETA: 13s - loss: 0.6532 - accuracy: 0.800 - ETA: 13s - loss: 0.6560 - accuracy: 0.800 - ETA: 12s - loss: 0.6593 - accuracy: 0.799 - ETA: 11s - loss: 0.6617 - accuracy: 0.798 - ETA: 10s - loss: 0.6611 - accuracy: 0.799 - ETA: 10s - loss: 0.6600 - accuracy: 0.799 - ETA: 9s - loss: 0.6603 - accuracy: 0.799 - ETA: 8s - loss: 0.6583 - accuracy: 0.79 - ETA: 8s - loss: 0.6595 - accuracy: 0.79 - ETA: 7s - loss: 0.6607 - accuracy: 0.79 - ETA: 6s - loss: 0.6596 - accuracy: 0.79 - ETA: 6s - loss: 0.6606 - accuracy: 0.79 - ETA: 5s - loss: 0.6613 - accuracy: 0.79 - ETA: 4s - loss: 0.6607 - accuracy: 0.79 - ETA: 3s - loss: 0.6615 - accuracy: 0.79 - ETA: 3s - loss: 0.6617 - accuracy: 0.79 - ETA: 2s - loss: 0.6609 - accuracy: 0.79 - ETA: 1s - loss: 0.6614 - accuracy: 0.79 - ETA: 1s - loss: 0.6608 - accuracy: 0.79 - ETA: 0s - loss: 0.6599 - accuracy: 0.79 - 82s 6ms/step - loss: 0.6617 - accuracy: 0.7989 - val_loss: 3.0750 - val_accuracy: 0.3307\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:09 - loss: 0.5472 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5579 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5812 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5458 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5313 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5435 - accuracy: 0.83 - ETA: 1:07 - loss: 0.5573 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5497 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5783 - accuracy: 0.81 - ETA: 1:04 - loss: 0.5736 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5951 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5977 - accuracy: 0.81 - ETA: 1:01 - loss: 0.5917 - accuracy: 0.81 - ETA: 1:01 - loss: 0.5973 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6102 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6234 - accuracy: 0.81 - ETA: 59s - loss: 0.6329 - accuracy: 0.8102 - ETA: 58s - loss: 0.6342 - accuracy: 0.810 - ETA: 58s - loss: 0.6321 - accuracy: 0.808 - ETA: 57s - loss: 0.6431 - accuracy: 0.808 - ETA: 56s - loss: 0.6458 - accuracy: 0.807 - ETA: 55s - loss: 0.6481 - accuracy: 0.807 - ETA: 55s - loss: 0.6527 - accuracy: 0.805 - ETA: 54s - loss: 0.6572 - accuracy: 0.804 - ETA: 53s - loss: 0.6646 - accuracy: 0.804 - ETA: 53s - loss: 0.6645 - accuracy: 0.803 - ETA: 52s - loss: 0.6654 - accuracy: 0.803 - ETA: 51s - loss: 0.6699 - accuracy: 0.801 - ETA: 51s - loss: 0.6657 - accuracy: 0.801 - ETA: 50s - loss: 0.6647 - accuracy: 0.802 - ETA: 49s - loss: 0.6580 - accuracy: 0.803 - ETA: 48s - loss: 0.6512 - accuracy: 0.805 - ETA: 48s - loss: 0.6501 - accuracy: 0.805 - ETA: 47s - loss: 0.6567 - accuracy: 0.803 - ETA: 46s - loss: 0.6611 - accuracy: 0.802 - ETA: 46s - loss: 0.6699 - accuracy: 0.800 - ETA: 45s - loss: 0.6665 - accuracy: 0.801 - ETA: 44s - loss: 0.6593 - accuracy: 0.804 - ETA: 43s - loss: 0.6602 - accuracy: 0.803 - ETA: 43s - loss: 0.6602 - accuracy: 0.804 - ETA: 42s - loss: 0.6593 - accuracy: 0.803 - ETA: 41s - loss: 0.6572 - accuracy: 0.803 - ETA: 40s - loss: 0.6560 - accuracy: 0.804 - ETA: 40s - loss: 0.6552 - accuracy: 0.804 - ETA: 39s - loss: 0.6558 - accuracy: 0.804 - ETA: 38s - loss: 0.6590 - accuracy: 0.804 - ETA: 38s - loss: 0.6533 - accuracy: 0.806 - ETA: 37s - loss: 0.6543 - accuracy: 0.805 - ETA: 36s - loss: 0.6545 - accuracy: 0.806 - ETA: 36s - loss: 0.6530 - accuracy: 0.806 - ETA: 35s - loss: 0.6489 - accuracy: 0.807 - ETA: 34s - loss: 0.6492 - accuracy: 0.807 - ETA: 33s - loss: 0.6527 - accuracy: 0.806 - ETA: 33s - loss: 0.6520 - accuracy: 0.806 - ETA: 32s - loss: 0.6516 - accuracy: 0.806 - ETA: 31s - loss: 0.6478 - accuracy: 0.807 - ETA: 31s - loss: 0.6465 - accuracy: 0.807 - ETA: 30s - loss: 0.6455 - accuracy: 0.808 - ETA: 29s - loss: 0.6446 - accuracy: 0.808 - ETA: 29s - loss: 0.6454 - accuracy: 0.807 - ETA: 28s - loss: 0.6458 - accuracy: 0.807 - ETA: 27s - loss: 0.6472 - accuracy: 0.807 - ETA: 26s - loss: 0.6443 - accuracy: 0.808 - ETA: 26s - loss: 0.6453 - accuracy: 0.808 - ETA: 25s - loss: 0.6449 - accuracy: 0.808 - ETA: 24s - loss: 0.6417 - accuracy: 0.808 - ETA: 24s - loss: 0.6423 - accuracy: 0.808 - ETA: 23s - loss: 0.6407 - accuracy: 0.808 - ETA: 22s - loss: 0.6409 - accuracy: 0.808 - ETA: 22s - loss: 0.6398 - accuracy: 0.809 - ETA: 21s - loss: 0.6371 - accuracy: 0.809 - ETA: 20s - loss: 0.6362 - accuracy: 0.809 - ETA: 19s - loss: 0.6344 - accuracy: 0.810 - ETA: 19s - loss: 0.6353 - accuracy: 0.810 - ETA: 18s - loss: 0.6343 - accuracy: 0.810 - ETA: 17s - loss: 0.6338 - accuracy: 0.810 - ETA: 17s - loss: 0.6320 - accuracy: 0.811 - ETA: 16s - loss: 0.6320 - accuracy: 0.810 - ETA: 15s - loss: 0.6325 - accuracy: 0.810 - ETA: 15s - loss: 0.6319 - accuracy: 0.810 - ETA: 14s - loss: 0.6304 - accuracy: 0.811 - ETA: 13s - loss: 0.6303 - accuracy: 0.811 - ETA: 13s - loss: 0.6299 - accuracy: 0.811 - ETA: 12s - loss: 0.6318 - accuracy: 0.811 - ETA: 11s - loss: 0.6307 - accuracy: 0.810 - ETA: 10s - loss: 0.6335 - accuracy: 0.810 - ETA: 10s - loss: 0.6325 - accuracy: 0.810 - ETA: 9s - loss: 0.6325 - accuracy: 0.810 - ETA: 8s - loss: 0.6306 - accuracy: 0.81 - ETA: 8s - loss: 0.6310 - accuracy: 0.81 - ETA: 7s - loss: 0.6332 - accuracy: 0.81 - ETA: 6s - loss: 0.6328 - accuracy: 0.81 - ETA: 6s - loss: 0.6335 - accuracy: 0.81 - ETA: 5s - loss: 0.6338 - accuracy: 0.81 - ETA: 4s - loss: 0.6364 - accuracy: 0.81 - ETA: 3s - loss: 0.6362 - accuracy: 0.81 - ETA: 3s - loss: 0.6360 - accuracy: 0.81 - ETA: 2s - loss: 0.6386 - accuracy: 0.80 - ETA: 1s - loss: 0.6410 - accuracy: 0.80 - ETA: 1s - loss: 0.6402 - accuracy: 0.80 - ETA: 0s - loss: 0.6404 - accuracy: 0.80 - 81s 6ms/step - loss: 0.6413 - accuracy: 0.8092 - val_loss: 3.0130 - val_accuracy: 0.3362\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.5581 - accuracy: 0.84 - ETA: 1:15 - loss: 0.5198 - accuracy: 0.84 - ETA: 1:14 - loss: 0.5990 - accuracy: 0.82 - ETA: 1:13 - loss: 0.5889 - accuracy: 0.82 - ETA: 1:12 - loss: 0.5907 - accuracy: 0.82 - ETA: 1:11 - loss: 0.5750 - accuracy: 0.83 - ETA: 1:11 - loss: 0.5843 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5961 - accuracy: 0.81 - ETA: 1:08 - loss: 0.5931 - accuracy: 0.82 - ETA: 1:06 - loss: 0.6193 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6327 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6414 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6375 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6219 - accuracy: 0.81 - ETA: 1:02 - loss: 0.6192 - accuracy: 0.81 - ETA: 1:01 - loss: 0.6164 - accuracy: 0.81 - ETA: 1:01 - loss: 0.6115 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6142 - accuracy: 0.81 - ETA: 59s - loss: 0.6137 - accuracy: 0.8183 - ETA: 58s - loss: 0.6139 - accuracy: 0.818 - ETA: 57s - loss: 0.6173 - accuracy: 0.817 - ETA: 57s - loss: 0.6162 - accuracy: 0.817 - ETA: 56s - loss: 0.6152 - accuracy: 0.816 - ETA: 55s - loss: 0.6146 - accuracy: 0.817 - ETA: 54s - loss: 0.6177 - accuracy: 0.815 - ETA: 54s - loss: 0.6220 - accuracy: 0.812 - ETA: 53s - loss: 0.6208 - accuracy: 0.811 - ETA: 52s - loss: 0.6397 - accuracy: 0.807 - ETA: 51s - loss: 0.6425 - accuracy: 0.805 - ETA: 50s - loss: 0.6424 - accuracy: 0.805 - ETA: 50s - loss: 0.6366 - accuracy: 0.807 - ETA: 49s - loss: 0.6361 - accuracy: 0.808 - ETA: 48s - loss: 0.6370 - accuracy: 0.807 - ETA: 48s - loss: 0.6431 - accuracy: 0.807 - ETA: 47s - loss: 0.6423 - accuracy: 0.807 - ETA: 46s - loss: 0.6443 - accuracy: 0.807 - ETA: 45s - loss: 0.6439 - accuracy: 0.807 - ETA: 45s - loss: 0.6426 - accuracy: 0.807 - ETA: 44s - loss: 0.6450 - accuracy: 0.805 - ETA: 43s - loss: 0.6423 - accuracy: 0.806 - ETA: 42s - loss: 0.6378 - accuracy: 0.806 - ETA: 42s - loss: 0.6402 - accuracy: 0.806 - ETA: 41s - loss: 0.6424 - accuracy: 0.805 - ETA: 40s - loss: 0.6430 - accuracy: 0.805 - ETA: 39s - loss: 0.6448 - accuracy: 0.804 - ETA: 39s - loss: 0.6427 - accuracy: 0.804 - ETA: 38s - loss: 0.6427 - accuracy: 0.803 - ETA: 37s - loss: 0.6468 - accuracy: 0.802 - ETA: 37s - loss: 0.6467 - accuracy: 0.802 - ETA: 36s - loss: 0.6465 - accuracy: 0.802 - ETA: 35s - loss: 0.6455 - accuracy: 0.801 - ETA: 34s - loss: 0.6450 - accuracy: 0.802 - ETA: 34s - loss: 0.6414 - accuracy: 0.803 - ETA: 33s - loss: 0.6410 - accuracy: 0.803 - ETA: 32s - loss: 0.6432 - accuracy: 0.803 - ETA: 32s - loss: 0.6402 - accuracy: 0.803 - ETA: 31s - loss: 0.6364 - accuracy: 0.804 - ETA: 30s - loss: 0.6386 - accuracy: 0.804 - ETA: 29s - loss: 0.6390 - accuracy: 0.804 - ETA: 29s - loss: 0.6360 - accuracy: 0.804 - ETA: 28s - loss: 0.6382 - accuracy: 0.803 - ETA: 27s - loss: 0.6376 - accuracy: 0.804 - ETA: 27s - loss: 0.6375 - accuracy: 0.805 - ETA: 26s - loss: 0.6387 - accuracy: 0.805 - ETA: 25s - loss: 0.6395 - accuracy: 0.805 - ETA: 24s - loss: 0.6404 - accuracy: 0.804 - ETA: 24s - loss: 0.6389 - accuracy: 0.805 - ETA: 23s - loss: 0.6384 - accuracy: 0.806 - ETA: 22s - loss: 0.6380 - accuracy: 0.806 - ETA: 22s - loss: 0.6411 - accuracy: 0.806 - ETA: 21s - loss: 0.6393 - accuracy: 0.806 - ETA: 20s - loss: 0.6384 - accuracy: 0.807 - ETA: 20s - loss: 0.6399 - accuracy: 0.806 - ETA: 19s - loss: 0.6385 - accuracy: 0.807 - ETA: 18s - loss: 0.6374 - accuracy: 0.807 - ETA: 17s - loss: 0.6358 - accuracy: 0.807 - ETA: 17s - loss: 0.6359 - accuracy: 0.807 - ETA: 16s - loss: 0.6350 - accuracy: 0.808 - ETA: 15s - loss: 0.6350 - accuracy: 0.807 - ETA: 15s - loss: 0.6360 - accuracy: 0.807 - ETA: 14s - loss: 0.6365 - accuracy: 0.807 - ETA: 13s - loss: 0.6367 - accuracy: 0.807 - ETA: 13s - loss: 0.6390 - accuracy: 0.806 - ETA: 12s - loss: 0.6393 - accuracy: 0.806 - ETA: 11s - loss: 0.6396 - accuracy: 0.806 - ETA: 10s - loss: 0.6410 - accuracy: 0.806 - ETA: 10s - loss: 0.6423 - accuracy: 0.805 - ETA: 9s - loss: 0.6419 - accuracy: 0.805 - ETA: 8s - loss: 0.6424 - accuracy: 0.80 - ETA: 8s - loss: 0.6444 - accuracy: 0.80 - ETA: 7s - loss: 0.6441 - accuracy: 0.80 - ETA: 6s - loss: 0.6452 - accuracy: 0.80 - ETA: 6s - loss: 0.6468 - accuracy: 0.80 - ETA: 5s - loss: 0.6465 - accuracy: 0.80 - ETA: 4s - loss: 0.6460 - accuracy: 0.80 - ETA: 3s - loss: 0.6447 - accuracy: 0.80 - ETA: 3s - loss: 0.6451 - accuracy: 0.80 - ETA: 2s - loss: 0.6432 - accuracy: 0.80 - ETA: 1s - loss: 0.6421 - accuracy: 0.80 - ETA: 1s - loss: 0.6403 - accuracy: 0.80 - ETA: 0s - loss: 0.6400 - accuracy: 0.80 - 82s 6ms/step - loss: 0.6398 - accuracy: 0.8067 - val_loss: 3.1478 - val_accuracy: 0.3276\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:15 - loss: 0.5497 - accuracy: 0.80 - ETA: 1:12 - loss: 0.6197 - accuracy: 0.81 - ETA: 1:10 - loss: 0.6486 - accuracy: 0.80 - ETA: 1:09 - loss: 0.6362 - accuracy: 0.81 - ETA: 1:08 - loss: 0.6316 - accuracy: 0.81 - ETA: 1:07 - loss: 0.6213 - accuracy: 0.80 - ETA: 1:07 - loss: 0.6003 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6026 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6202 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6168 - accuracy: 0.80 - ETA: 1:03 - loss: 0.5913 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5956 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6033 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6058 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6028 - accuracy: 0.81 - ETA: 59s - loss: 0.6098 - accuracy: 0.8110 - ETA: 59s - loss: 0.6155 - accuracy: 0.808 - ETA: 58s - loss: 0.6237 - accuracy: 0.806 - ETA: 57s - loss: 0.6176 - accuracy: 0.810 - ETA: 56s - loss: 0.6110 - accuracy: 0.811 - ETA: 56s - loss: 0.6110 - accuracy: 0.811 - ETA: 55s - loss: 0.6101 - accuracy: 0.811 - ETA: 54s - loss: 0.6043 - accuracy: 0.813 - ETA: 54s - loss: 0.6010 - accuracy: 0.815 - ETA: 53s - loss: 0.6075 - accuracy: 0.815 - ETA: 52s - loss: 0.6041 - accuracy: 0.816 - ETA: 51s - loss: 0.6034 - accuracy: 0.816 - ETA: 51s - loss: 0.5999 - accuracy: 0.817 - ETA: 50s - loss: 0.6015 - accuracy: 0.819 - ETA: 49s - loss: 0.6022 - accuracy: 0.819 - ETA: 49s - loss: 0.6034 - accuracy: 0.819 - ETA: 48s - loss: 0.6038 - accuracy: 0.819 - ETA: 47s - loss: 0.6073 - accuracy: 0.819 - ETA: 46s - loss: 0.6164 - accuracy: 0.816 - ETA: 46s - loss: 0.6253 - accuracy: 0.814 - ETA: 45s - loss: 0.6262 - accuracy: 0.813 - ETA: 44s - loss: 0.6221 - accuracy: 0.814 - ETA: 44s - loss: 0.6212 - accuracy: 0.814 - ETA: 43s - loss: 0.6220 - accuracy: 0.814 - ETA: 42s - loss: 0.6239 - accuracy: 0.814 - ETA: 42s - loss: 0.6210 - accuracy: 0.815 - ETA: 41s - loss: 0.6226 - accuracy: 0.815 - ETA: 40s - loss: 0.6243 - accuracy: 0.815 - ETA: 40s - loss: 0.6220 - accuracy: 0.815 - ETA: 39s - loss: 0.6227 - accuracy: 0.814 - ETA: 38s - loss: 0.6213 - accuracy: 0.814 - ETA: 37s - loss: 0.6189 - accuracy: 0.815 - ETA: 37s - loss: 0.6186 - accuracy: 0.815 - ETA: 36s - loss: 0.6189 - accuracy: 0.815 - ETA: 35s - loss: 0.6217 - accuracy: 0.815 - ETA: 35s - loss: 0.6194 - accuracy: 0.815 - ETA: 34s - loss: 0.6213 - accuracy: 0.814 - ETA: 33s - loss: 0.6216 - accuracy: 0.815 - ETA: 33s - loss: 0.6207 - accuracy: 0.815 - ETA: 32s - loss: 0.6206 - accuracy: 0.815 - ETA: 31s - loss: 0.6237 - accuracy: 0.813 - ETA: 31s - loss: 0.6244 - accuracy: 0.813 - ETA: 30s - loss: 0.6238 - accuracy: 0.814 - ETA: 29s - loss: 0.6237 - accuracy: 0.814 - ETA: 28s - loss: 0.6246 - accuracy: 0.814 - ETA: 28s - loss: 0.6229 - accuracy: 0.814 - ETA: 27s - loss: 0.6230 - accuracy: 0.814 - ETA: 26s - loss: 0.6283 - accuracy: 0.813 - ETA: 26s - loss: 0.6293 - accuracy: 0.812 - ETA: 25s - loss: 0.6313 - accuracy: 0.812 - ETA: 24s - loss: 0.6283 - accuracy: 0.813 - ETA: 24s - loss: 0.6296 - accuracy: 0.812 - ETA: 23s - loss: 0.6280 - accuracy: 0.813 - ETA: 22s - loss: 0.6259 - accuracy: 0.813 - ETA: 21s - loss: 0.6243 - accuracy: 0.813 - ETA: 21s - loss: 0.6249 - accuracy: 0.813 - ETA: 20s - loss: 0.6231 - accuracy: 0.814 - ETA: 19s - loss: 0.6221 - accuracy: 0.814 - ETA: 19s - loss: 0.6237 - accuracy: 0.813 - ETA: 18s - loss: 0.6229 - accuracy: 0.814 - ETA: 17s - loss: 0.6222 - accuracy: 0.814 - ETA: 17s - loss: 0.6243 - accuracy: 0.813 - ETA: 16s - loss: 0.6239 - accuracy: 0.813 - ETA: 15s - loss: 0.6263 - accuracy: 0.812 - ETA: 15s - loss: 0.6261 - accuracy: 0.812 - ETA: 14s - loss: 0.6262 - accuracy: 0.812 - ETA: 13s - loss: 0.6264 - accuracy: 0.812 - ETA: 13s - loss: 0.6271 - accuracy: 0.812 - ETA: 12s - loss: 0.6251 - accuracy: 0.813 - ETA: 11s - loss: 0.6254 - accuracy: 0.813 - ETA: 10s - loss: 0.6275 - accuracy: 0.812 - ETA: 10s - loss: 0.6282 - accuracy: 0.812 - ETA: 9s - loss: 0.6274 - accuracy: 0.812 - ETA: 8s - loss: 0.6279 - accuracy: 0.81 - ETA: 8s - loss: 0.6306 - accuracy: 0.81 - ETA: 7s - loss: 0.6287 - accuracy: 0.81 - ETA: 6s - loss: 0.6287 - accuracy: 0.81 - ETA: 6s - loss: 0.6286 - accuracy: 0.81 - ETA: 5s - loss: 0.6286 - accuracy: 0.81 - ETA: 4s - loss: 0.6308 - accuracy: 0.81 - ETA: 3s - loss: 0.6304 - accuracy: 0.81 - ETA: 3s - loss: 0.6297 - accuracy: 0.81 - ETA: 2s - loss: 0.6286 - accuracy: 0.81 - ETA: 1s - loss: 0.6289 - accuracy: 0.81 - ETA: 1s - loss: 0.6276 - accuracy: 0.81 - ETA: 0s - loss: 0.6267 - accuracy: 0.81 - 82s 6ms/step - loss: 0.6281 - accuracy: 0.8125 - val_loss: 3.1180 - val_accuracy: 0.3485\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.4271 - accuracy: 0.87 - ETA: 1:10 - loss: 0.5277 - accuracy: 0.84 - ETA: 1:10 - loss: 0.6274 - accuracy: 0.83 - ETA: 1:08 - loss: 0.6649 - accuracy: 0.82 - ETA: 1:07 - loss: 0.6504 - accuracy: 0.81 - ETA: 1:06 - loss: 0.6313 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6415 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6343 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6351 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6438 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6500 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6479 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6442 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6317 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6309 - accuracy: 0.80 - ETA: 59s - loss: 0.6322 - accuracy: 0.8086 - ETA: 58s - loss: 0.6248 - accuracy: 0.811 - ETA: 57s - loss: 0.6191 - accuracy: 0.814 - ETA: 57s - loss: 0.6169 - accuracy: 0.814 - ETA: 56s - loss: 0.6099 - accuracy: 0.816 - ETA: 56s - loss: 0.6004 - accuracy: 0.818 - ETA: 55s - loss: 0.6000 - accuracy: 0.818 - ETA: 54s - loss: 0.6042 - accuracy: 0.818 - ETA: 53s - loss: 0.6065 - accuracy: 0.818 - ETA: 53s - loss: 0.6084 - accuracy: 0.817 - ETA: 52s - loss: 0.6117 - accuracy: 0.816 - ETA: 51s - loss: 0.6113 - accuracy: 0.816 - ETA: 50s - loss: 0.6129 - accuracy: 0.816 - ETA: 50s - loss: 0.6171 - accuracy: 0.814 - ETA: 49s - loss: 0.6183 - accuracy: 0.814 - ETA: 48s - loss: 0.6165 - accuracy: 0.816 - ETA: 47s - loss: 0.6245 - accuracy: 0.814 - ETA: 47s - loss: 0.6227 - accuracy: 0.814 - ETA: 46s - loss: 0.6222 - accuracy: 0.815 - ETA: 45s - loss: 0.6229 - accuracy: 0.814 - ETA: 45s - loss: 0.6248 - accuracy: 0.813 - ETA: 44s - loss: 0.6236 - accuracy: 0.812 - ETA: 43s - loss: 0.6236 - accuracy: 0.812 - ETA: 43s - loss: 0.6257 - accuracy: 0.811 - ETA: 42s - loss: 0.6222 - accuracy: 0.812 - ETA: 41s - loss: 0.6207 - accuracy: 0.813 - ETA: 41s - loss: 0.6207 - accuracy: 0.813 - ETA: 40s - loss: 0.6198 - accuracy: 0.813 - ETA: 39s - loss: 0.6187 - accuracy: 0.813 - ETA: 39s - loss: 0.6135 - accuracy: 0.815 - ETA: 38s - loss: 0.6137 - accuracy: 0.815 - ETA: 37s - loss: 0.6145 - accuracy: 0.815 - ETA: 37s - loss: 0.6112 - accuracy: 0.816 - ETA: 36s - loss: 0.6123 - accuracy: 0.816 - ETA: 35s - loss: 0.6133 - accuracy: 0.816 - ETA: 35s - loss: 0.6099 - accuracy: 0.816 - ETA: 34s - loss: 0.6121 - accuracy: 0.817 - ETA: 33s - loss: 0.6092 - accuracy: 0.817 - ETA: 33s - loss: 0.6116 - accuracy: 0.817 - ETA: 32s - loss: 0.6141 - accuracy: 0.817 - ETA: 31s - loss: 0.6102 - accuracy: 0.817 - ETA: 30s - loss: 0.6126 - accuracy: 0.817 - ETA: 30s - loss: 0.6108 - accuracy: 0.817 - ETA: 29s - loss: 0.6127 - accuracy: 0.816 - ETA: 28s - loss: 0.6139 - accuracy: 0.816 - ETA: 28s - loss: 0.6149 - accuracy: 0.816 - ETA: 27s - loss: 0.6154 - accuracy: 0.816 - ETA: 26s - loss: 0.6143 - accuracy: 0.816 - ETA: 26s - loss: 0.6113 - accuracy: 0.816 - ETA: 25s - loss: 0.6124 - accuracy: 0.815 - ETA: 24s - loss: 0.6124 - accuracy: 0.816 - ETA: 24s - loss: 0.6118 - accuracy: 0.816 - ETA: 23s - loss: 0.6123 - accuracy: 0.816 - ETA: 22s - loss: 0.6157 - accuracy: 0.816 - ETA: 21s - loss: 0.6144 - accuracy: 0.817 - ETA: 21s - loss: 0.6136 - accuracy: 0.817 - ETA: 20s - loss: 0.6144 - accuracy: 0.817 - ETA: 19s - loss: 0.6144 - accuracy: 0.817 - ETA: 19s - loss: 0.6163 - accuracy: 0.816 - ETA: 18s - loss: 0.6132 - accuracy: 0.817 - ETA: 17s - loss: 0.6128 - accuracy: 0.816 - ETA: 17s - loss: 0.6125 - accuracy: 0.816 - ETA: 16s - loss: 0.6135 - accuracy: 0.816 - ETA: 15s - loss: 0.6125 - accuracy: 0.816 - ETA: 15s - loss: 0.6164 - accuracy: 0.815 - ETA: 14s - loss: 0.6186 - accuracy: 0.815 - ETA: 13s - loss: 0.6198 - accuracy: 0.814 - ETA: 12s - loss: 0.6186 - accuracy: 0.814 - ETA: 12s - loss: 0.6175 - accuracy: 0.815 - ETA: 11s - loss: 0.6156 - accuracy: 0.815 - ETA: 10s - loss: 0.6159 - accuracy: 0.815 - ETA: 10s - loss: 0.6163 - accuracy: 0.815 - ETA: 9s - loss: 0.6162 - accuracy: 0.816 - ETA: 8s - loss: 0.6167 - accuracy: 0.81 - ETA: 8s - loss: 0.6149 - accuracy: 0.81 - ETA: 7s - loss: 0.6151 - accuracy: 0.81 - ETA: 6s - loss: 0.6159 - accuracy: 0.81 - ETA: 6s - loss: 0.6154 - accuracy: 0.81 - ETA: 5s - loss: 0.6154 - accuracy: 0.81 - ETA: 4s - loss: 0.6164 - accuracy: 0.81 - ETA: 3s - loss: 0.6158 - accuracy: 0.81 - ETA: 3s - loss: 0.6164 - accuracy: 0.81 - ETA: 2s - loss: 0.6164 - accuracy: 0.81 - ETA: 1s - loss: 0.6165 - accuracy: 0.81 - ETA: 1s - loss: 0.6170 - accuracy: 0.81 - ETA: 0s - loss: 0.6190 - accuracy: 0.81 - 81s 6ms/step - loss: 0.6202 - accuracy: 0.8132 - val_loss: 3.1333 - val_accuracy: 0.3358\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:16 - loss: 0.4101 - accuracy: 0.85 - ETA: 1:12 - loss: 0.5095 - accuracy: 0.83 - ETA: 1:10 - loss: 0.5678 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5995 - accuracy: 0.81 - ETA: 1:08 - loss: 0.6079 - accuracy: 0.81 - ETA: 1:07 - loss: 0.6015 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5872 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5913 - accuracy: 0.81 - ETA: 1:04 - loss: 0.5775 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5858 - accuracy: 0.81 - ETA: 1:03 - loss: 0.5784 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5809 - accuracy: 0.81 - ETA: 1:01 - loss: 0.5902 - accuracy: 0.81 - ETA: 1:00 - loss: 0.5857 - accuracy: 0.81 - ETA: 1:00 - loss: 0.5711 - accuracy: 0.82 - ETA: 59s - loss: 0.5693 - accuracy: 0.8232 - ETA: 58s - loss: 0.5723 - accuracy: 0.823 - ETA: 58s - loss: 0.5715 - accuracy: 0.822 - ETA: 57s - loss: 0.5681 - accuracy: 0.821 - ETA: 56s - loss: 0.5630 - accuracy: 0.822 - ETA: 56s - loss: 0.5596 - accuracy: 0.822 - ETA: 55s - loss: 0.5554 - accuracy: 0.822 - ETA: 54s - loss: 0.5545 - accuracy: 0.824 - ETA: 53s - loss: 0.5602 - accuracy: 0.823 - ETA: 53s - loss: 0.5615 - accuracy: 0.823 - ETA: 52s - loss: 0.5590 - accuracy: 0.823 - ETA: 51s - loss: 0.5613 - accuracy: 0.822 - ETA: 51s - loss: 0.5654 - accuracy: 0.821 - ETA: 50s - loss: 0.5650 - accuracy: 0.822 - ETA: 50s - loss: 0.5710 - accuracy: 0.821 - ETA: 49s - loss: 0.5672 - accuracy: 0.822 - ETA: 48s - loss: 0.5628 - accuracy: 0.823 - ETA: 48s - loss: 0.5657 - accuracy: 0.823 - ETA: 47s - loss: 0.5705 - accuracy: 0.821 - ETA: 46s - loss: 0.5740 - accuracy: 0.821 - ETA: 45s - loss: 0.5734 - accuracy: 0.821 - ETA: 45s - loss: 0.5737 - accuracy: 0.821 - ETA: 44s - loss: 0.5760 - accuracy: 0.822 - ETA: 43s - loss: 0.5778 - accuracy: 0.820 - ETA: 42s - loss: 0.5747 - accuracy: 0.821 - ETA: 42s - loss: 0.5758 - accuracy: 0.820 - ETA: 41s - loss: 0.5767 - accuracy: 0.821 - ETA: 40s - loss: 0.5784 - accuracy: 0.821 - ETA: 40s - loss: 0.5774 - accuracy: 0.822 - ETA: 39s - loss: 0.5748 - accuracy: 0.822 - ETA: 38s - loss: 0.5770 - accuracy: 0.822 - ETA: 38s - loss: 0.5749 - accuracy: 0.822 - ETA: 37s - loss: 0.5782 - accuracy: 0.821 - ETA: 36s - loss: 0.5754 - accuracy: 0.822 - ETA: 36s - loss: 0.5772 - accuracy: 0.822 - ETA: 35s - loss: 0.5798 - accuracy: 0.820 - ETA: 34s - loss: 0.5816 - accuracy: 0.820 - ETA: 33s - loss: 0.5818 - accuracy: 0.820 - ETA: 33s - loss: 0.5822 - accuracy: 0.820 - ETA: 32s - loss: 0.5822 - accuracy: 0.821 - ETA: 31s - loss: 0.5807 - accuracy: 0.821 - ETA: 31s - loss: 0.5807 - accuracy: 0.821 - ETA: 30s - loss: 0.5795 - accuracy: 0.821 - ETA: 29s - loss: 0.5784 - accuracy: 0.822 - ETA: 29s - loss: 0.5800 - accuracy: 0.821 - ETA: 28s - loss: 0.5807 - accuracy: 0.820 - ETA: 27s - loss: 0.5798 - accuracy: 0.821 - ETA: 26s - loss: 0.5857 - accuracy: 0.820 - ETA: 26s - loss: 0.5901 - accuracy: 0.819 - ETA: 25s - loss: 0.5885 - accuracy: 0.819 - ETA: 24s - loss: 0.5911 - accuracy: 0.818 - ETA: 24s - loss: 0.5920 - accuracy: 0.818 - ETA: 23s - loss: 0.5958 - accuracy: 0.816 - ETA: 22s - loss: 0.5966 - accuracy: 0.816 - ETA: 22s - loss: 0.5966 - accuracy: 0.817 - ETA: 21s - loss: 0.5959 - accuracy: 0.816 - ETA: 20s - loss: 0.5983 - accuracy: 0.816 - ETA: 19s - loss: 0.5987 - accuracy: 0.815 - ETA: 19s - loss: 0.5989 - accuracy: 0.815 - ETA: 18s - loss: 0.5983 - accuracy: 0.816 - ETA: 17s - loss: 0.5986 - accuracy: 0.815 - ETA: 17s - loss: 0.5990 - accuracy: 0.815 - ETA: 16s - loss: 0.5980 - accuracy: 0.815 - ETA: 15s - loss: 0.6007 - accuracy: 0.815 - ETA: 15s - loss: 0.6021 - accuracy: 0.815 - ETA: 14s - loss: 0.6013 - accuracy: 0.815 - ETA: 13s - loss: 0.6000 - accuracy: 0.815 - ETA: 12s - loss: 0.6033 - accuracy: 0.814 - ETA: 12s - loss: 0.6046 - accuracy: 0.814 - ETA: 11s - loss: 0.6043 - accuracy: 0.815 - ETA: 10s - loss: 0.6054 - accuracy: 0.815 - ETA: 10s - loss: 0.6058 - accuracy: 0.815 - ETA: 9s - loss: 0.6057 - accuracy: 0.814 - ETA: 8s - loss: 0.6096 - accuracy: 0.81 - ETA: 8s - loss: 0.6112 - accuracy: 0.81 - ETA: 7s - loss: 0.6116 - accuracy: 0.81 - ETA: 6s - loss: 0.6114 - accuracy: 0.81 - ETA: 6s - loss: 0.6107 - accuracy: 0.81 - ETA: 5s - loss: 0.6128 - accuracy: 0.81 - ETA: 4s - loss: 0.6150 - accuracy: 0.81 - ETA: 3s - loss: 0.6147 - accuracy: 0.81 - ETA: 3s - loss: 0.6156 - accuracy: 0.81 - ETA: 2s - loss: 0.6142 - accuracy: 0.81 - ETA: 1s - loss: 0.6163 - accuracy: 0.81 - ETA: 1s - loss: 0.6158 - accuracy: 0.81 - ETA: 0s - loss: 0.6145 - accuracy: 0.81 - 81s 6ms/step - loss: 0.6145 - accuracy: 0.8150 - val_loss: 3.1365 - val_accuracy: 0.3104\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.6529 - accuracy: 0.84 - ETA: 1:10 - loss: 0.5712 - accuracy: 0.83 - ETA: 1:08 - loss: 0.6108 - accuracy: 0.83 - ETA: 1:07 - loss: 0.5225 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5175 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5265 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5350 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5425 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5499 - accuracy: 0.83 - ETA: 1:05 - loss: 0.5557 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5557 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5523 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5519 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5528 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5548 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5487 - accuracy: 0.83 - ETA: 59s - loss: 0.5374 - accuracy: 0.8359 - ETA: 59s - loss: 0.5491 - accuracy: 0.831 - ETA: 58s - loss: 0.5603 - accuracy: 0.827 - ETA: 57s - loss: 0.5619 - accuracy: 0.828 - ETA: 57s - loss: 0.5674 - accuracy: 0.829 - ETA: 56s - loss: 0.5655 - accuracy: 0.830 - ETA: 55s - loss: 0.5619 - accuracy: 0.831 - ETA: 54s - loss: 0.5665 - accuracy: 0.829 - ETA: 54s - loss: 0.5681 - accuracy: 0.827 - ETA: 53s - loss: 0.5744 - accuracy: 0.827 - ETA: 52s - loss: 0.5780 - accuracy: 0.824 - ETA: 51s - loss: 0.5835 - accuracy: 0.822 - ETA: 51s - loss: 0.5845 - accuracy: 0.821 - ETA: 50s - loss: 0.5883 - accuracy: 0.820 - ETA: 49s - loss: 0.5914 - accuracy: 0.819 - ETA: 48s - loss: 0.5959 - accuracy: 0.816 - ETA: 48s - loss: 0.5973 - accuracy: 0.816 - ETA: 47s - loss: 0.5955 - accuracy: 0.818 - ETA: 46s - loss: 0.5953 - accuracy: 0.818 - ETA: 46s - loss: 0.5962 - accuracy: 0.818 - ETA: 45s - loss: 0.5961 - accuracy: 0.817 - ETA: 44s - loss: 0.5967 - accuracy: 0.817 - ETA: 43s - loss: 0.5923 - accuracy: 0.818 - ETA: 43s - loss: 0.5925 - accuracy: 0.818 - ETA: 42s - loss: 0.5888 - accuracy: 0.819 - ETA: 41s - loss: 0.5886 - accuracy: 0.819 - ETA: 41s - loss: 0.5891 - accuracy: 0.819 - ETA: 40s - loss: 0.5850 - accuracy: 0.820 - ETA: 39s - loss: 0.5917 - accuracy: 0.819 - ETA: 39s - loss: 0.5907 - accuracy: 0.820 - ETA: 38s - loss: 0.5870 - accuracy: 0.820 - ETA: 37s - loss: 0.5842 - accuracy: 0.821 - ETA: 36s - loss: 0.5868 - accuracy: 0.821 - ETA: 36s - loss: 0.5875 - accuracy: 0.820 - ETA: 35s - loss: 0.5865 - accuracy: 0.821 - ETA: 34s - loss: 0.5862 - accuracy: 0.821 - ETA: 34s - loss: 0.5870 - accuracy: 0.821 - ETA: 33s - loss: 0.5870 - accuracy: 0.821 - ETA: 32s - loss: 0.5864 - accuracy: 0.821 - ETA: 31s - loss: 0.5854 - accuracy: 0.822 - ETA: 31s - loss: 0.5880 - accuracy: 0.821 - ETA: 30s - loss: 0.5860 - accuracy: 0.821 - ETA: 29s - loss: 0.5884 - accuracy: 0.821 - ETA: 29s - loss: 0.5867 - accuracy: 0.822 - ETA: 28s - loss: 0.5844 - accuracy: 0.822 - ETA: 27s - loss: 0.5831 - accuracy: 0.823 - ETA: 27s - loss: 0.5863 - accuracy: 0.822 - ETA: 26s - loss: 0.5817 - accuracy: 0.824 - ETA: 25s - loss: 0.5799 - accuracy: 0.824 - ETA: 25s - loss: 0.5787 - accuracy: 0.824 - ETA: 24s - loss: 0.5793 - accuracy: 0.824 - ETA: 23s - loss: 0.5828 - accuracy: 0.823 - ETA: 22s - loss: 0.5828 - accuracy: 0.823 - ETA: 22s - loss: 0.5828 - accuracy: 0.823 - ETA: 21s - loss: 0.5840 - accuracy: 0.822 - ETA: 20s - loss: 0.5851 - accuracy: 0.822 - ETA: 20s - loss: 0.5853 - accuracy: 0.822 - ETA: 19s - loss: 0.5854 - accuracy: 0.822 - ETA: 18s - loss: 0.5873 - accuracy: 0.821 - ETA: 17s - loss: 0.5866 - accuracy: 0.821 - ETA: 17s - loss: 0.5841 - accuracy: 0.822 - ETA: 16s - loss: 0.5822 - accuracy: 0.822 - ETA: 15s - loss: 0.5847 - accuracy: 0.821 - ETA: 15s - loss: 0.5829 - accuracy: 0.822 - ETA: 14s - loss: 0.5836 - accuracy: 0.821 - ETA: 13s - loss: 0.5847 - accuracy: 0.822 - ETA: 13s - loss: 0.5836 - accuracy: 0.822 - ETA: 12s - loss: 0.5833 - accuracy: 0.822 - ETA: 11s - loss: 0.5840 - accuracy: 0.822 - ETA: 10s - loss: 0.5853 - accuracy: 0.822 - ETA: 10s - loss: 0.5859 - accuracy: 0.822 - ETA: 9s - loss: 0.5883 - accuracy: 0.821 - ETA: 8s - loss: 0.5884 - accuracy: 0.82 - ETA: 8s - loss: 0.5892 - accuracy: 0.82 - ETA: 7s - loss: 0.5897 - accuracy: 0.82 - ETA: 6s - loss: 0.5894 - accuracy: 0.82 - ETA: 6s - loss: 0.5899 - accuracy: 0.82 - ETA: 5s - loss: 0.5894 - accuracy: 0.82 - ETA: 4s - loss: 0.5910 - accuracy: 0.82 - ETA: 3s - loss: 0.5943 - accuracy: 0.82 - ETA: 3s - loss: 0.5943 - accuracy: 0.82 - ETA: 2s - loss: 0.5951 - accuracy: 0.81 - ETA: 1s - loss: 0.5982 - accuracy: 0.81 - ETA: 1s - loss: 0.5965 - accuracy: 0.81 - ETA: 0s - loss: 0.5969 - accuracy: 0.81 - 82s 6ms/step - loss: 0.5957 - accuracy: 0.8198 - val_loss: 3.1784 - val_accuracy: 0.3217\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.6086 - accuracy: 0.82 - ETA: 1:09 - loss: 0.6943 - accuracy: 0.80 - ETA: 1:07 - loss: 0.6660 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6602 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6553 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6360 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6401 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6353 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6512 - accuracy: 0.79 - ETA: 1:03 - loss: 0.6431 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6478 - accuracy: 0.79 - ETA: 1:02 - loss: 0.6337 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6199 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6195 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6166 - accuracy: 0.80 - ETA: 59s - loss: 0.6093 - accuracy: 0.8096 - ETA: 59s - loss: 0.6066 - accuracy: 0.813 - ETA: 58s - loss: 0.6122 - accuracy: 0.813 - ETA: 57s - loss: 0.6154 - accuracy: 0.813 - ETA: 57s - loss: 0.6193 - accuracy: 0.810 - ETA: 56s - loss: 0.6117 - accuracy: 0.814 - ETA: 55s - loss: 0.6187 - accuracy: 0.813 - ETA: 54s - loss: 0.6092 - accuracy: 0.815 - ETA: 54s - loss: 0.6077 - accuracy: 0.816 - ETA: 53s - loss: 0.6072 - accuracy: 0.818 - ETA: 52s - loss: 0.6039 - accuracy: 0.819 - ETA: 51s - loss: 0.5998 - accuracy: 0.820 - ETA: 51s - loss: 0.6061 - accuracy: 0.820 - ETA: 50s - loss: 0.6053 - accuracy: 0.818 - ETA: 49s - loss: 0.6080 - accuracy: 0.816 - ETA: 49s - loss: 0.6058 - accuracy: 0.818 - ETA: 48s - loss: 0.6010 - accuracy: 0.820 - ETA: 47s - loss: 0.5974 - accuracy: 0.821 - ETA: 46s - loss: 0.5956 - accuracy: 0.821 - ETA: 46s - loss: 0.5911 - accuracy: 0.822 - ETA: 45s - loss: 0.5861 - accuracy: 0.824 - ETA: 44s - loss: 0.5869 - accuracy: 0.824 - ETA: 44s - loss: 0.5871 - accuracy: 0.823 - ETA: 43s - loss: 0.5876 - accuracy: 0.823 - ETA: 42s - loss: 0.5904 - accuracy: 0.822 - ETA: 42s - loss: 0.5924 - accuracy: 0.822 - ETA: 41s - loss: 0.5940 - accuracy: 0.821 - ETA: 40s - loss: 0.5931 - accuracy: 0.821 - ETA: 39s - loss: 0.5906 - accuracy: 0.821 - ETA: 39s - loss: 0.5906 - accuracy: 0.821 - ETA: 38s - loss: 0.5940 - accuracy: 0.820 - ETA: 37s - loss: 0.5933 - accuracy: 0.820 - ETA: 37s - loss: 0.5932 - accuracy: 0.821 - ETA: 36s - loss: 0.5920 - accuracy: 0.822 - ETA: 35s - loss: 0.5942 - accuracy: 0.821 - ETA: 35s - loss: 0.5931 - accuracy: 0.820 - ETA: 34s - loss: 0.5980 - accuracy: 0.820 - ETA: 33s - loss: 0.6000 - accuracy: 0.819 - ETA: 32s - loss: 0.6003 - accuracy: 0.819 - ETA: 32s - loss: 0.5985 - accuracy: 0.819 - ETA: 31s - loss: 0.5967 - accuracy: 0.820 - ETA: 30s - loss: 0.5979 - accuracy: 0.820 - ETA: 30s - loss: 0.5987 - accuracy: 0.820 - ETA: 29s - loss: 0.5998 - accuracy: 0.820 - ETA: 28s - loss: 0.6007 - accuracy: 0.820 - ETA: 28s - loss: 0.6024 - accuracy: 0.819 - ETA: 27s - loss: 0.6026 - accuracy: 0.819 - ETA: 26s - loss: 0.6021 - accuracy: 0.819 - ETA: 26s - loss: 0.6023 - accuracy: 0.819 - ETA: 25s - loss: 0.6013 - accuracy: 0.819 - ETA: 24s - loss: 0.6010 - accuracy: 0.819 - ETA: 23s - loss: 0.6008 - accuracy: 0.819 - ETA: 23s - loss: 0.6008 - accuracy: 0.818 - ETA: 22s - loss: 0.6004 - accuracy: 0.819 - ETA: 21s - loss: 0.5989 - accuracy: 0.819 - ETA: 21s - loss: 0.6003 - accuracy: 0.819 - ETA: 20s - loss: 0.6007 - accuracy: 0.819 - ETA: 19s - loss: 0.6028 - accuracy: 0.818 - ETA: 19s - loss: 0.6061 - accuracy: 0.818 - ETA: 18s - loss: 0.6063 - accuracy: 0.817 - ETA: 17s - loss: 0.6058 - accuracy: 0.817 - ETA: 17s - loss: 0.6054 - accuracy: 0.818 - ETA: 16s - loss: 0.6047 - accuracy: 0.818 - ETA: 15s - loss: 0.6057 - accuracy: 0.817 - ETA: 15s - loss: 0.6034 - accuracy: 0.818 - ETA: 14s - loss: 0.6020 - accuracy: 0.818 - ETA: 13s - loss: 0.6027 - accuracy: 0.818 - ETA: 12s - loss: 0.6043 - accuracy: 0.817 - ETA: 12s - loss: 0.6035 - accuracy: 0.817 - ETA: 11s - loss: 0.6051 - accuracy: 0.817 - ETA: 10s - loss: 0.6042 - accuracy: 0.817 - ETA: 10s - loss: 0.6056 - accuracy: 0.817 - ETA: 9s - loss: 0.6047 - accuracy: 0.817 - ETA: 8s - loss: 0.6037 - accuracy: 0.81 - ETA: 8s - loss: 0.6055 - accuracy: 0.81 - ETA: 7s - loss: 0.6054 - accuracy: 0.81 - ETA: 6s - loss: 0.6035 - accuracy: 0.81 - ETA: 6s - loss: 0.6044 - accuracy: 0.81 - ETA: 5s - loss: 0.6060 - accuracy: 0.81 - ETA: 4s - loss: 0.6035 - accuracy: 0.81 - ETA: 3s - loss: 0.6034 - accuracy: 0.81 - ETA: 3s - loss: 0.6027 - accuracy: 0.81 - ETA: 2s - loss: 0.6031 - accuracy: 0.81 - ETA: 1s - loss: 0.6034 - accuracy: 0.81 - ETA: 1s - loss: 0.6021 - accuracy: 0.81 - ETA: 0s - loss: 0.6016 - accuracy: 0.81 - 81s 6ms/step - loss: 0.6018 - accuracy: 0.8175 - val_loss: 3.0444 - val_accuracy: 0.3422\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.5548 - accuracy: 0.84 - ETA: 1:14 - loss: 0.6686 - accuracy: 0.80 - ETA: 1:11 - loss: 0.7193 - accuracy: 0.79 - ETA: 1:10 - loss: 0.7196 - accuracy: 0.78 - ETA: 1:09 - loss: 0.7042 - accuracy: 0.79 - ETA: 1:08 - loss: 0.6927 - accuracy: 0.79 - ETA: 1:07 - loss: 0.6980 - accuracy: 0.79 - ETA: 1:06 - loss: 0.6850 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6782 - accuracy: 0.80 - ETA: 1:04 - loss: 0.6667 - accuracy: 0.80 - ETA: 1:03 - loss: 0.6570 - accuracy: 0.81 - ETA: 1:03 - loss: 0.6586 - accuracy: 0.80 - ETA: 1:02 - loss: 0.6519 - accuracy: 0.80 - ETA: 1:01 - loss: 0.6525 - accuracy: 0.80 - ETA: 1:00 - loss: 0.6445 - accuracy: 0.80 - ETA: 59s - loss: 0.6307 - accuracy: 0.8135 - ETA: 59s - loss: 0.6175 - accuracy: 0.815 - ETA: 58s - loss: 0.6179 - accuracy: 0.814 - ETA: 57s - loss: 0.6076 - accuracy: 0.818 - ETA: 57s - loss: 0.6016 - accuracy: 0.820 - ETA: 56s - loss: 0.6102 - accuracy: 0.818 - ETA: 55s - loss: 0.6028 - accuracy: 0.820 - ETA: 54s - loss: 0.5938 - accuracy: 0.823 - ETA: 54s - loss: 0.5979 - accuracy: 0.821 - ETA: 53s - loss: 0.6022 - accuracy: 0.819 - ETA: 52s - loss: 0.6040 - accuracy: 0.819 - ETA: 52s - loss: 0.6039 - accuracy: 0.819 - ETA: 51s - loss: 0.5984 - accuracy: 0.821 - ETA: 50s - loss: 0.5991 - accuracy: 0.821 - ETA: 50s - loss: 0.6025 - accuracy: 0.820 - ETA: 49s - loss: 0.5977 - accuracy: 0.823 - ETA: 48s - loss: 0.5989 - accuracy: 0.822 - ETA: 47s - loss: 0.5963 - accuracy: 0.822 - ETA: 47s - loss: 0.6013 - accuracy: 0.823 - ETA: 46s - loss: 0.5963 - accuracy: 0.824 - ETA: 45s - loss: 0.6015 - accuracy: 0.823 - ETA: 45s - loss: 0.6042 - accuracy: 0.822 - ETA: 44s - loss: 0.6051 - accuracy: 0.821 - ETA: 43s - loss: 0.6045 - accuracy: 0.822 - ETA: 42s - loss: 0.6018 - accuracy: 0.822 - ETA: 42s - loss: 0.6012 - accuracy: 0.821 - ETA: 41s - loss: 0.6034 - accuracy: 0.821 - ETA: 40s - loss: 0.6019 - accuracy: 0.821 - ETA: 40s - loss: 0.5994 - accuracy: 0.822 - ETA: 39s - loss: 0.6001 - accuracy: 0.822 - ETA: 38s - loss: 0.6008 - accuracy: 0.822 - ETA: 38s - loss: 0.6045 - accuracy: 0.821 - ETA: 37s - loss: 0.6060 - accuracy: 0.821 - ETA: 36s - loss: 0.6024 - accuracy: 0.822 - ETA: 35s - loss: 0.6042 - accuracy: 0.822 - ETA: 35s - loss: 0.6043 - accuracy: 0.821 - ETA: 34s - loss: 0.6071 - accuracy: 0.821 - ETA: 33s - loss: 0.6034 - accuracy: 0.822 - ETA: 33s - loss: 0.6026 - accuracy: 0.822 - ETA: 32s - loss: 0.6035 - accuracy: 0.822 - ETA: 31s - loss: 0.6020 - accuracy: 0.823 - ETA: 31s - loss: 0.6006 - accuracy: 0.822 - ETA: 30s - loss: 0.6025 - accuracy: 0.822 - ETA: 29s - loss: 0.6034 - accuracy: 0.822 - ETA: 29s - loss: 0.6043 - accuracy: 0.822 - ETA: 28s - loss: 0.6021 - accuracy: 0.822 - ETA: 27s - loss: 0.6019 - accuracy: 0.822 - ETA: 27s - loss: 0.6039 - accuracy: 0.821 - ETA: 26s - loss: 0.6019 - accuracy: 0.822 - ETA: 25s - loss: 0.6039 - accuracy: 0.822 - ETA: 25s - loss: 0.6036 - accuracy: 0.822 - ETA: 24s - loss: 0.6050 - accuracy: 0.821 - ETA: 23s - loss: 0.6054 - accuracy: 0.820 - ETA: 23s - loss: 0.6069 - accuracy: 0.819 - ETA: 22s - loss: 0.6055 - accuracy: 0.819 - ETA: 21s - loss: 0.6044 - accuracy: 0.820 - ETA: 21s - loss: 0.6045 - accuracy: 0.820 - ETA: 20s - loss: 0.6043 - accuracy: 0.820 - ETA: 19s - loss: 0.6037 - accuracy: 0.820 - ETA: 18s - loss: 0.6023 - accuracy: 0.820 - ETA: 18s - loss: 0.6040 - accuracy: 0.820 - ETA: 17s - loss: 0.6044 - accuracy: 0.820 - ETA: 16s - loss: 0.6034 - accuracy: 0.820 - ETA: 16s - loss: 0.6042 - accuracy: 0.819 - ETA: 15s - loss: 0.6036 - accuracy: 0.819 - ETA: 14s - loss: 0.6017 - accuracy: 0.820 - ETA: 13s - loss: 0.6060 - accuracy: 0.819 - ETA: 13s - loss: 0.6073 - accuracy: 0.818 - ETA: 12s - loss: 0.6055 - accuracy: 0.818 - ETA: 11s - loss: 0.6045 - accuracy: 0.819 - ETA: 11s - loss: 0.6031 - accuracy: 0.819 - ETA: 10s - loss: 0.6010 - accuracy: 0.819 - ETA: 9s - loss: 0.6019 - accuracy: 0.819 - ETA: 8s - loss: 0.6017 - accuracy: 0.81 - ETA: 8s - loss: 0.6008 - accuracy: 0.82 - ETA: 7s - loss: 0.6004 - accuracy: 0.82 - ETA: 6s - loss: 0.5996 - accuracy: 0.82 - ETA: 6s - loss: 0.6008 - accuracy: 0.82 - ETA: 5s - loss: 0.6031 - accuracy: 0.82 - ETA: 4s - loss: 0.6012 - accuracy: 0.82 - ETA: 4s - loss: 0.6038 - accuracy: 0.82 - ETA: 3s - loss: 0.6036 - accuracy: 0.82 - ETA: 2s - loss: 0.6034 - accuracy: 0.82 - ETA: 1s - loss: 0.6038 - accuracy: 0.82 - ETA: 1s - loss: 0.6036 - accuracy: 0.82 - ETA: 0s - loss: 0.6032 - accuracy: 0.81 - 82s 6ms/step - loss: 0.6033 - accuracy: 0.8200 - val_loss: 3.0599 - val_accuracy: 0.3376\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.5876 - accuracy: 0.82 - ETA: 1:10 - loss: 0.6582 - accuracy: 0.81 - ETA: 1:08 - loss: 0.6638 - accuracy: 0.81 - ETA: 1:08 - loss: 0.6796 - accuracy: 0.81 - ETA: 1:07 - loss: 0.6518 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6258 - accuracy: 0.81 - ETA: 1:05 - loss: 0.6193 - accuracy: 0.82 - ETA: 1:04 - loss: 0.6379 - accuracy: 0.81 - ETA: 1:04 - loss: 0.6375 - accuracy: 0.81 - ETA: 1:03 - loss: 0.6385 - accuracy: 0.81 - ETA: 1:03 - loss: 0.6133 - accuracy: 0.82 - ETA: 1:02 - loss: 0.6297 - accuracy: 0.82 - ETA: 1:02 - loss: 0.6290 - accuracy: 0.82 - ETA: 1:01 - loss: 0.6256 - accuracy: 0.82 - ETA: 1:00 - loss: 0.6191 - accuracy: 0.82 - ETA: 59s - loss: 0.6303 - accuracy: 0.8159 - ETA: 59s - loss: 0.6309 - accuracy: 0.817 - ETA: 58s - loss: 0.6182 - accuracy: 0.820 - ETA: 57s - loss: 0.6207 - accuracy: 0.819 - ETA: 57s - loss: 0.6285 - accuracy: 0.818 - ETA: 56s - loss: 0.6238 - accuracy: 0.818 - ETA: 55s - loss: 0.6306 - accuracy: 0.818 - ETA: 54s - loss: 0.6403 - accuracy: 0.816 - ETA: 54s - loss: 0.6382 - accuracy: 0.815 - ETA: 53s - loss: 0.6358 - accuracy: 0.814 - ETA: 52s - loss: 0.6316 - accuracy: 0.814 - ETA: 51s - loss: 0.6320 - accuracy: 0.813 - ETA: 51s - loss: 0.6261 - accuracy: 0.815 - ETA: 50s - loss: 0.6226 - accuracy: 0.816 - ETA: 49s - loss: 0.6249 - accuracy: 0.815 - ETA: 49s - loss: 0.6248 - accuracy: 0.815 - ETA: 48s - loss: 0.6285 - accuracy: 0.814 - ETA: 48s - loss: 0.6254 - accuracy: 0.815 - ETA: 47s - loss: 0.6213 - accuracy: 0.816 - ETA: 46s - loss: 0.6182 - accuracy: 0.817 - ETA: 45s - loss: 0.6136 - accuracy: 0.818 - ETA: 45s - loss: 0.6105 - accuracy: 0.818 - ETA: 44s - loss: 0.6143 - accuracy: 0.818 - ETA: 43s - loss: 0.6169 - accuracy: 0.819 - ETA: 43s - loss: 0.6178 - accuracy: 0.819 - ETA: 42s - loss: 0.6169 - accuracy: 0.819 - ETA: 41s - loss: 0.6197 - accuracy: 0.817 - ETA: 41s - loss: 0.6195 - accuracy: 0.818 - ETA: 40s - loss: 0.6224 - accuracy: 0.817 - ETA: 39s - loss: 0.6174 - accuracy: 0.817 - ETA: 38s - loss: 0.6140 - accuracy: 0.818 - ETA: 38s - loss: 0.6109 - accuracy: 0.818 - ETA: 37s - loss: 0.6105 - accuracy: 0.819 - ETA: 36s - loss: 0.6089 - accuracy: 0.818 - ETA: 36s - loss: 0.6138 - accuracy: 0.818 - ETA: 35s - loss: 0.6114 - accuracy: 0.819 - ETA: 34s - loss: 0.6126 - accuracy: 0.819 - ETA: 33s - loss: 0.6082 - accuracy: 0.820 - ETA: 33s - loss: 0.6081 - accuracy: 0.820 - ETA: 32s - loss: 0.6090 - accuracy: 0.819 - ETA: 31s - loss: 0.6092 - accuracy: 0.819 - ETA: 31s - loss: 0.6126 - accuracy: 0.818 - ETA: 30s - loss: 0.6081 - accuracy: 0.820 - ETA: 29s - loss: 0.6119 - accuracy: 0.818 - ETA: 29s - loss: 0.6101 - accuracy: 0.819 - ETA: 28s - loss: 0.6125 - accuracy: 0.818 - ETA: 27s - loss: 0.6137 - accuracy: 0.818 - ETA: 27s - loss: 0.6129 - accuracy: 0.818 - ETA: 26s - loss: 0.6152 - accuracy: 0.818 - ETA: 25s - loss: 0.6109 - accuracy: 0.819 - ETA: 24s - loss: 0.6117 - accuracy: 0.818 - ETA: 24s - loss: 0.6111 - accuracy: 0.818 - ETA: 23s - loss: 0.6130 - accuracy: 0.817 - ETA: 22s - loss: 0.6166 - accuracy: 0.816 - ETA: 22s - loss: 0.6166 - accuracy: 0.816 - ETA: 21s - loss: 0.6163 - accuracy: 0.816 - ETA: 20s - loss: 0.6162 - accuracy: 0.816 - ETA: 19s - loss: 0.6167 - accuracy: 0.816 - ETA: 19s - loss: 0.6145 - accuracy: 0.817 - ETA: 18s - loss: 0.6144 - accuracy: 0.817 - ETA: 17s - loss: 0.6149 - accuracy: 0.817 - ETA: 17s - loss: 0.6157 - accuracy: 0.817 - ETA: 16s - loss: 0.6166 - accuracy: 0.816 - ETA: 15s - loss: 0.6160 - accuracy: 0.817 - ETA: 15s - loss: 0.6149 - accuracy: 0.817 - ETA: 14s - loss: 0.6156 - accuracy: 0.817 - ETA: 13s - loss: 0.6153 - accuracy: 0.816 - ETA: 13s - loss: 0.6136 - accuracy: 0.817 - ETA: 12s - loss: 0.6142 - accuracy: 0.817 - ETA: 11s - loss: 0.6139 - accuracy: 0.817 - ETA: 10s - loss: 0.6142 - accuracy: 0.817 - ETA: 10s - loss: 0.6147 - accuracy: 0.817 - ETA: 9s - loss: 0.6143 - accuracy: 0.817 - ETA: 8s - loss: 0.6129 - accuracy: 0.81 - ETA: 8s - loss: 0.6119 - accuracy: 0.81 - ETA: 7s - loss: 0.6116 - accuracy: 0.81 - ETA: 6s - loss: 0.6107 - accuracy: 0.81 - ETA: 6s - loss: 0.6120 - accuracy: 0.81 - ETA: 5s - loss: 0.6128 - accuracy: 0.81 - ETA: 4s - loss: 0.6130 - accuracy: 0.81 - ETA: 3s - loss: 0.6118 - accuracy: 0.81 - ETA: 3s - loss: 0.6126 - accuracy: 0.81 - ETA: 2s - loss: 0.6123 - accuracy: 0.81 - ETA: 1s - loss: 0.6118 - accuracy: 0.81 - ETA: 1s - loss: 0.6118 - accuracy: 0.81 - ETA: 0s - loss: 0.6121 - accuracy: 0.81 - 82s 6ms/step - loss: 0.6146 - accuracy: 0.8172 - val_loss: 3.1219 - val_accuracy: 0.3266\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.5088 - accuracy: 0.86 - ETA: 1:09 - loss: 0.4764 - accuracy: 0.86 - ETA: 1:08 - loss: 0.5586 - accuracy: 0.84 - ETA: 1:07 - loss: 0.5217 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5455 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5287 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5379 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5509 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5515 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5758 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5793 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5803 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5935 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5955 - accuracy: 0.83 - ETA: 1:00 - loss: 0.6161 - accuracy: 0.82 - ETA: 59s - loss: 0.6160 - accuracy: 0.8252 - ETA: 59s - loss: 0.6118 - accuracy: 0.824 - ETA: 58s - loss: 0.6094 - accuracy: 0.823 - ETA: 57s - loss: 0.6190 - accuracy: 0.819 - ETA: 57s - loss: 0.6153 - accuracy: 0.820 - ETA: 56s - loss: 0.6217 - accuracy: 0.818 - ETA: 55s - loss: 0.6286 - accuracy: 0.817 - ETA: 54s - loss: 0.6198 - accuracy: 0.819 - ETA: 54s - loss: 0.6174 - accuracy: 0.820 - ETA: 53s - loss: 0.6200 - accuracy: 0.819 - ETA: 52s - loss: 0.6187 - accuracy: 0.818 - ETA: 51s - loss: 0.6160 - accuracy: 0.818 - ETA: 51s - loss: 0.6149 - accuracy: 0.819 - ETA: 50s - loss: 0.6141 - accuracy: 0.818 - ETA: 50s - loss: 0.6152 - accuracy: 0.818 - ETA: 49s - loss: 0.6137 - accuracy: 0.819 - ETA: 48s - loss: 0.6099 - accuracy: 0.820 - ETA: 48s - loss: 0.6026 - accuracy: 0.823 - ETA: 47s - loss: 0.5969 - accuracy: 0.825 - ETA: 46s - loss: 0.6023 - accuracy: 0.824 - ETA: 45s - loss: 0.5996 - accuracy: 0.825 - ETA: 45s - loss: 0.6043 - accuracy: 0.823 - ETA: 44s - loss: 0.6059 - accuracy: 0.823 - ETA: 43s - loss: 0.6031 - accuracy: 0.824 - ETA: 42s - loss: 0.6096 - accuracy: 0.822 - ETA: 42s - loss: 0.6052 - accuracy: 0.824 - ETA: 41s - loss: 0.6011 - accuracy: 0.825 - ETA: 40s - loss: 0.6053 - accuracy: 0.824 - ETA: 40s - loss: 0.6017 - accuracy: 0.825 - ETA: 39s - loss: 0.6006 - accuracy: 0.824 - ETA: 38s - loss: 0.6044 - accuracy: 0.823 - ETA: 38s - loss: 0.6031 - accuracy: 0.823 - ETA: 37s - loss: 0.6046 - accuracy: 0.822 - ETA: 36s - loss: 0.6020 - accuracy: 0.823 - ETA: 35s - loss: 0.6004 - accuracy: 0.823 - ETA: 35s - loss: 0.5998 - accuracy: 0.824 - ETA: 34s - loss: 0.5983 - accuracy: 0.825 - ETA: 33s - loss: 0.6003 - accuracy: 0.824 - ETA: 33s - loss: 0.5981 - accuracy: 0.825 - ETA: 32s - loss: 0.5971 - accuracy: 0.825 - ETA: 31s - loss: 0.5960 - accuracy: 0.825 - ETA: 31s - loss: 0.5953 - accuracy: 0.825 - ETA: 30s - loss: 0.5983 - accuracy: 0.824 - ETA: 29s - loss: 0.5989 - accuracy: 0.824 - ETA: 29s - loss: 0.5990 - accuracy: 0.824 - ETA: 28s - loss: 0.5946 - accuracy: 0.825 - ETA: 27s - loss: 0.5959 - accuracy: 0.825 - ETA: 26s - loss: 0.5961 - accuracy: 0.825 - ETA: 26s - loss: 0.5968 - accuracy: 0.825 - ETA: 25s - loss: 0.5994 - accuracy: 0.825 - ETA: 24s - loss: 0.5975 - accuracy: 0.825 - ETA: 24s - loss: 0.5996 - accuracy: 0.824 - ETA: 23s - loss: 0.5975 - accuracy: 0.825 - ETA: 22s - loss: 0.5971 - accuracy: 0.824 - ETA: 22s - loss: 0.5970 - accuracy: 0.825 - ETA: 21s - loss: 0.5972 - accuracy: 0.824 - ETA: 20s - loss: 0.5994 - accuracy: 0.823 - ETA: 19s - loss: 0.5987 - accuracy: 0.823 - ETA: 19s - loss: 0.5974 - accuracy: 0.823 - ETA: 18s - loss: 0.5965 - accuracy: 0.823 - ETA: 17s - loss: 0.5948 - accuracy: 0.824 - ETA: 17s - loss: 0.5956 - accuracy: 0.824 - ETA: 16s - loss: 0.5964 - accuracy: 0.824 - ETA: 15s - loss: 0.5969 - accuracy: 0.823 - ETA: 15s - loss: 0.5956 - accuracy: 0.823 - ETA: 14s - loss: 0.5954 - accuracy: 0.823 - ETA: 13s - loss: 0.5963 - accuracy: 0.822 - ETA: 13s - loss: 0.5994 - accuracy: 0.821 - ETA: 12s - loss: 0.5991 - accuracy: 0.821 - ETA: 11s - loss: 0.5975 - accuracy: 0.821 - ETA: 10s - loss: 0.5981 - accuracy: 0.821 - ETA: 10s - loss: 0.5980 - accuracy: 0.821 - ETA: 9s - loss: 0.5994 - accuracy: 0.821 - ETA: 8s - loss: 0.6019 - accuracy: 0.82 - ETA: 8s - loss: 0.6052 - accuracy: 0.82 - ETA: 7s - loss: 0.6050 - accuracy: 0.82 - ETA: 6s - loss: 0.6082 - accuracy: 0.81 - ETA: 6s - loss: 0.6086 - accuracy: 0.81 - ETA: 5s - loss: 0.6073 - accuracy: 0.81 - ETA: 4s - loss: 0.6060 - accuracy: 0.82 - ETA: 3s - loss: 0.6088 - accuracy: 0.81 - ETA: 3s - loss: 0.6093 - accuracy: 0.81 - ETA: 2s - loss: 0.6087 - accuracy: 0.81 - ETA: 1s - loss: 0.6070 - accuracy: 0.81 - ETA: 1s - loss: 0.6060 - accuracy: 0.81 - ETA: 0s - loss: 0.6033 - accuracy: 0.82 - 82s 6ms/step - loss: 0.6018 - accuracy: 0.8209 - val_loss: 3.0403 - val_accuracy: 0.3385\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:10 - loss: 0.5409 - accuracy: 0.84 - ETA: 1:08 - loss: 0.5143 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5391 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5217 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5274 - accuracy: 0.83 - ETA: 1:07 - loss: 0.5669 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5649 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5756 - accuracy: 0.81 - ETA: 1:04 - loss: 0.6072 - accuracy: 0.81 - ETA: 1:04 - loss: 0.5995 - accuracy: 0.81 - ETA: 1:03 - loss: 0.5934 - accuracy: 0.81 - ETA: 1:03 - loss: 0.5945 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5792 - accuracy: 0.82 - ETA: 1:01 - loss: 0.5768 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5734 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5753 - accuracy: 0.82 - ETA: 59s - loss: 0.5611 - accuracy: 0.8263 - ETA: 58s - loss: 0.5572 - accuracy: 0.827 - ETA: 57s - loss: 0.5640 - accuracy: 0.826 - ETA: 56s - loss: 0.5569 - accuracy: 0.829 - ETA: 56s - loss: 0.5568 - accuracy: 0.828 - ETA: 55s - loss: 0.5549 - accuracy: 0.828 - ETA: 54s - loss: 0.5590 - accuracy: 0.826 - ETA: 53s - loss: 0.5625 - accuracy: 0.826 - ETA: 53s - loss: 0.5655 - accuracy: 0.826 - ETA: 52s - loss: 0.5649 - accuracy: 0.826 - ETA: 51s - loss: 0.5712 - accuracy: 0.826 - ETA: 51s - loss: 0.5724 - accuracy: 0.825 - ETA: 50s - loss: 0.5736 - accuracy: 0.825 - ETA: 49s - loss: 0.5684 - accuracy: 0.827 - ETA: 49s - loss: 0.5670 - accuracy: 0.827 - ETA: 48s - loss: 0.5675 - accuracy: 0.827 - ETA: 47s - loss: 0.5670 - accuracy: 0.828 - ETA: 46s - loss: 0.5656 - accuracy: 0.828 - ETA: 46s - loss: 0.5752 - accuracy: 0.825 - ETA: 45s - loss: 0.5775 - accuracy: 0.824 - ETA: 44s - loss: 0.5785 - accuracy: 0.823 - ETA: 44s - loss: 0.5796 - accuracy: 0.822 - ETA: 43s - loss: 0.5781 - accuracy: 0.823 - ETA: 42s - loss: 0.5798 - accuracy: 0.822 - ETA: 42s - loss: 0.5755 - accuracy: 0.824 - ETA: 41s - loss: 0.5777 - accuracy: 0.823 - ETA: 40s - loss: 0.5795 - accuracy: 0.823 - ETA: 39s - loss: 0.5761 - accuracy: 0.823 - ETA: 39s - loss: 0.5752 - accuracy: 0.823 - ETA: 38s - loss: 0.5722 - accuracy: 0.824 - ETA: 37s - loss: 0.5716 - accuracy: 0.823 - ETA: 37s - loss: 0.5721 - accuracy: 0.823 - ETA: 36s - loss: 0.5725 - accuracy: 0.823 - ETA: 35s - loss: 0.5715 - accuracy: 0.823 - ETA: 35s - loss: 0.5741 - accuracy: 0.823 - ETA: 34s - loss: 0.5748 - accuracy: 0.824 - ETA: 33s - loss: 0.5758 - accuracy: 0.823 - ETA: 32s - loss: 0.5768 - accuracy: 0.823 - ETA: 32s - loss: 0.5796 - accuracy: 0.823 - ETA: 31s - loss: 0.5767 - accuracy: 0.824 - ETA: 30s - loss: 0.5751 - accuracy: 0.824 - ETA: 30s - loss: 0.5757 - accuracy: 0.824 - ETA: 29s - loss: 0.5750 - accuracy: 0.825 - ETA: 28s - loss: 0.5761 - accuracy: 0.824 - ETA: 28s - loss: 0.5775 - accuracy: 0.824 - ETA: 27s - loss: 0.5783 - accuracy: 0.823 - ETA: 26s - loss: 0.5780 - accuracy: 0.823 - ETA: 26s - loss: 0.5782 - accuracy: 0.823 - ETA: 25s - loss: 0.5767 - accuracy: 0.823 - ETA: 24s - loss: 0.5775 - accuracy: 0.823 - ETA: 24s - loss: 0.5785 - accuracy: 0.823 - ETA: 23s - loss: 0.5784 - accuracy: 0.823 - ETA: 22s - loss: 0.5812 - accuracy: 0.822 - ETA: 21s - loss: 0.5775 - accuracy: 0.823 - ETA: 21s - loss: 0.5774 - accuracy: 0.823 - ETA: 20s - loss: 0.5749 - accuracy: 0.823 - ETA: 19s - loss: 0.5741 - accuracy: 0.824 - ETA: 19s - loss: 0.5770 - accuracy: 0.823 - ETA: 18s - loss: 0.5778 - accuracy: 0.823 - ETA: 17s - loss: 0.5780 - accuracy: 0.823 - ETA: 17s - loss: 0.5792 - accuracy: 0.822 - ETA: 16s - loss: 0.5784 - accuracy: 0.823 - ETA: 15s - loss: 0.5786 - accuracy: 0.822 - ETA: 15s - loss: 0.5776 - accuracy: 0.822 - ETA: 14s - loss: 0.5772 - accuracy: 0.823 - ETA: 13s - loss: 0.5778 - accuracy: 0.823 - ETA: 13s - loss: 0.5749 - accuracy: 0.824 - ETA: 12s - loss: 0.5752 - accuracy: 0.823 - ETA: 11s - loss: 0.5781 - accuracy: 0.823 - ETA: 10s - loss: 0.5779 - accuracy: 0.823 - ETA: 10s - loss: 0.5764 - accuracy: 0.823 - ETA: 9s - loss: 0.5758 - accuracy: 0.823 - ETA: 8s - loss: 0.5769 - accuracy: 0.82 - ETA: 8s - loss: 0.5764 - accuracy: 0.82 - ETA: 7s - loss: 0.5775 - accuracy: 0.82 - ETA: 6s - loss: 0.5808 - accuracy: 0.82 - ETA: 6s - loss: 0.5818 - accuracy: 0.82 - ETA: 5s - loss: 0.5814 - accuracy: 0.82 - ETA: 4s - loss: 0.5825 - accuracy: 0.82 - ETA: 3s - loss: 0.5829 - accuracy: 0.82 - ETA: 3s - loss: 0.5828 - accuracy: 0.82 - ETA: 2s - loss: 0.5844 - accuracy: 0.82 - ETA: 1s - loss: 0.5843 - accuracy: 0.82 - ETA: 1s - loss: 0.5837 - accuracy: 0.82 - ETA: 0s - loss: 0.5845 - accuracy: 0.82 - 82s 6ms/step - loss: 0.5839 - accuracy: 0.8227 - val_loss: 3.1110 - val_accuracy: 0.3249\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:16 - loss: 0.5205 - accuracy: 0.84 - ETA: 1:12 - loss: 0.5969 - accuracy: 0.80 - ETA: 1:09 - loss: 0.5580 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5604 - accuracy: 0.81 - ETA: 1:06 - loss: 0.5483 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5522 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5571 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5820 - accuracy: 0.81 - ETA: 1:04 - loss: 0.6005 - accuracy: 0.81 - ETA: 1:03 - loss: 0.6017 - accuracy: 0.81 - ETA: 1:02 - loss: 0.6082 - accuracy: 0.81 - ETA: 1:01 - loss: 0.6210 - accuracy: 0.81 - ETA: 1:01 - loss: 0.6225 - accuracy: 0.81 - ETA: 1:00 - loss: 0.6131 - accuracy: 0.81 - ETA: 59s - loss: 0.6114 - accuracy: 0.8130 - ETA: 59s - loss: 0.6018 - accuracy: 0.815 - ETA: 58s - loss: 0.5907 - accuracy: 0.818 - ETA: 57s - loss: 0.5913 - accuracy: 0.818 - ETA: 57s - loss: 0.5994 - accuracy: 0.815 - ETA: 56s - loss: 0.5949 - accuracy: 0.819 - ETA: 55s - loss: 0.6017 - accuracy: 0.817 - ETA: 54s - loss: 0.5987 - accuracy: 0.818 - ETA: 54s - loss: 0.5927 - accuracy: 0.820 - ETA: 53s - loss: 0.5965 - accuracy: 0.818 - ETA: 53s - loss: 0.5933 - accuracy: 0.820 - ETA: 52s - loss: 0.5888 - accuracy: 0.820 - ETA: 51s - loss: 0.5908 - accuracy: 0.818 - ETA: 51s - loss: 0.5925 - accuracy: 0.817 - ETA: 50s - loss: 0.5931 - accuracy: 0.817 - ETA: 49s - loss: 0.5911 - accuracy: 0.818 - ETA: 48s - loss: 0.5899 - accuracy: 0.819 - ETA: 48s - loss: 0.5847 - accuracy: 0.820 - ETA: 47s - loss: 0.5873 - accuracy: 0.819 - ETA: 46s - loss: 0.5913 - accuracy: 0.818 - ETA: 46s - loss: 0.5962 - accuracy: 0.817 - ETA: 45s - loss: 0.5936 - accuracy: 0.818 - ETA: 44s - loss: 0.5977 - accuracy: 0.816 - ETA: 44s - loss: 0.6092 - accuracy: 0.814 - ETA: 43s - loss: 0.6075 - accuracy: 0.814 - ETA: 42s - loss: 0.6062 - accuracy: 0.815 - ETA: 42s - loss: 0.6070 - accuracy: 0.815 - ETA: 41s - loss: 0.6104 - accuracy: 0.814 - ETA: 40s - loss: 0.6126 - accuracy: 0.814 - ETA: 40s - loss: 0.6111 - accuracy: 0.815 - ETA: 39s - loss: 0.6070 - accuracy: 0.817 - ETA: 38s - loss: 0.6042 - accuracy: 0.817 - ETA: 38s - loss: 0.6055 - accuracy: 0.818 - ETA: 37s - loss: 0.6030 - accuracy: 0.819 - ETA: 36s - loss: 0.6057 - accuracy: 0.818 - ETA: 35s - loss: 0.6067 - accuracy: 0.817 - ETA: 35s - loss: 0.6072 - accuracy: 0.817 - ETA: 34s - loss: 0.6128 - accuracy: 0.817 - ETA: 33s - loss: 0.6133 - accuracy: 0.818 - ETA: 33s - loss: 0.6141 - accuracy: 0.817 - ETA: 32s - loss: 0.6198 - accuracy: 0.815 - ETA: 31s - loss: 0.6182 - accuracy: 0.816 - ETA: 31s - loss: 0.6182 - accuracy: 0.816 - ETA: 30s - loss: 0.6161 - accuracy: 0.816 - ETA: 29s - loss: 0.6157 - accuracy: 0.815 - ETA: 28s - loss: 0.6179 - accuracy: 0.815 - ETA: 28s - loss: 0.6161 - accuracy: 0.815 - ETA: 27s - loss: 0.6153 - accuracy: 0.815 - ETA: 26s - loss: 0.6168 - accuracy: 0.814 - ETA: 26s - loss: 0.6172 - accuracy: 0.815 - ETA: 25s - loss: 0.6155 - accuracy: 0.815 - ETA: 24s - loss: 0.6145 - accuracy: 0.816 - ETA: 24s - loss: 0.6150 - accuracy: 0.815 - ETA: 23s - loss: 0.6133 - accuracy: 0.816 - ETA: 22s - loss: 0.6127 - accuracy: 0.816 - ETA: 21s - loss: 0.6131 - accuracy: 0.817 - ETA: 21s - loss: 0.6113 - accuracy: 0.817 - ETA: 20s - loss: 0.6110 - accuracy: 0.817 - ETA: 19s - loss: 0.6092 - accuracy: 0.817 - ETA: 19s - loss: 0.6077 - accuracy: 0.818 - ETA: 18s - loss: 0.6073 - accuracy: 0.818 - ETA: 17s - loss: 0.6057 - accuracy: 0.819 - ETA: 17s - loss: 0.6072 - accuracy: 0.818 - ETA: 16s - loss: 0.6061 - accuracy: 0.819 - ETA: 15s - loss: 0.6062 - accuracy: 0.819 - ETA: 15s - loss: 0.6076 - accuracy: 0.818 - ETA: 14s - loss: 0.6067 - accuracy: 0.818 - ETA: 13s - loss: 0.6058 - accuracy: 0.819 - ETA: 12s - loss: 0.6047 - accuracy: 0.819 - ETA: 12s - loss: 0.6036 - accuracy: 0.819 - ETA: 11s - loss: 0.6029 - accuracy: 0.819 - ETA: 10s - loss: 0.6037 - accuracy: 0.819 - ETA: 10s - loss: 0.6027 - accuracy: 0.819 - ETA: 9s - loss: 0.6035 - accuracy: 0.819 - ETA: 8s - loss: 0.6050 - accuracy: 0.81 - ETA: 8s - loss: 0.6032 - accuracy: 0.81 - ETA: 7s - loss: 0.6009 - accuracy: 0.82 - ETA: 6s - loss: 0.6009 - accuracy: 0.82 - ETA: 6s - loss: 0.6020 - accuracy: 0.82 - ETA: 5s - loss: 0.6033 - accuracy: 0.82 - ETA: 4s - loss: 0.6026 - accuracy: 0.82 - ETA: 3s - loss: 0.6018 - accuracy: 0.82 - ETA: 3s - loss: 0.6056 - accuracy: 0.82 - ETA: 2s - loss: 0.6037 - accuracy: 0.82 - ETA: 1s - loss: 0.6038 - accuracy: 0.82 - ETA: 1s - loss: 0.6039 - accuracy: 0.82 - ETA: 0s - loss: 0.6040 - accuracy: 0.81 - 81s 6ms/step - loss: 0.6037 - accuracy: 0.8197 - val_loss: 3.0902 - val_accuracy: 0.3365\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.7467 - accuracy: 0.74 - ETA: 1:11 - loss: 0.5989 - accuracy: 0.80 - ETA: 1:11 - loss: 0.6213 - accuracy: 0.79 - ETA: 1:11 - loss: 0.6095 - accuracy: 0.80 - ETA: 1:09 - loss: 0.5880 - accuracy: 0.81 - ETA: 1:09 - loss: 0.5754 - accuracy: 0.81 - ETA: 1:08 - loss: 0.5577 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5410 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5449 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5549 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5488 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5699 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5768 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5763 - accuracy: 0.81 - ETA: 1:01 - loss: 0.5725 - accuracy: 0.81 - ETA: 1:00 - loss: 0.5855 - accuracy: 0.81 - ETA: 59s - loss: 0.5840 - accuracy: 0.8180 - ETA: 59s - loss: 0.5814 - accuracy: 0.818 - ETA: 58s - loss: 0.5829 - accuracy: 0.819 - ETA: 57s - loss: 0.5725 - accuracy: 0.822 - ETA: 56s - loss: 0.5716 - accuracy: 0.822 - ETA: 55s - loss: 0.5718 - accuracy: 0.823 - ETA: 55s - loss: 0.5717 - accuracy: 0.824 - ETA: 54s - loss: 0.5703 - accuracy: 0.823 - ETA: 53s - loss: 0.5701 - accuracy: 0.823 - ETA: 52s - loss: 0.5763 - accuracy: 0.822 - ETA: 52s - loss: 0.5814 - accuracy: 0.820 - ETA: 51s - loss: 0.5797 - accuracy: 0.822 - ETA: 50s - loss: 0.5834 - accuracy: 0.823 - ETA: 50s - loss: 0.5864 - accuracy: 0.821 - ETA: 49s - loss: 0.5793 - accuracy: 0.823 - ETA: 48s - loss: 0.5797 - accuracy: 0.823 - ETA: 48s - loss: 0.5819 - accuracy: 0.822 - ETA: 47s - loss: 0.5840 - accuracy: 0.821 - ETA: 46s - loss: 0.5798 - accuracy: 0.822 - ETA: 46s - loss: 0.5832 - accuracy: 0.822 - ETA: 45s - loss: 0.5805 - accuracy: 0.823 - ETA: 44s - loss: 0.5794 - accuracy: 0.823 - ETA: 44s - loss: 0.5815 - accuracy: 0.822 - ETA: 43s - loss: 0.5801 - accuracy: 0.823 - ETA: 42s - loss: 0.5829 - accuracy: 0.822 - ETA: 41s - loss: 0.5776 - accuracy: 0.823 - ETA: 41s - loss: 0.5818 - accuracy: 0.823 - ETA: 40s - loss: 0.5818 - accuracy: 0.823 - ETA: 39s - loss: 0.5815 - accuracy: 0.823 - ETA: 39s - loss: 0.5804 - accuracy: 0.823 - ETA: 38s - loss: 0.5793 - accuracy: 0.824 - ETA: 37s - loss: 0.5776 - accuracy: 0.824 - ETA: 37s - loss: 0.5804 - accuracy: 0.823 - ETA: 36s - loss: 0.5798 - accuracy: 0.823 - ETA: 35s - loss: 0.5804 - accuracy: 0.823 - ETA: 34s - loss: 0.5786 - accuracy: 0.823 - ETA: 34s - loss: 0.5800 - accuracy: 0.823 - ETA: 33s - loss: 0.5783 - accuracy: 0.824 - ETA: 32s - loss: 0.5768 - accuracy: 0.824 - ETA: 32s - loss: 0.5755 - accuracy: 0.825 - ETA: 31s - loss: 0.5738 - accuracy: 0.825 - ETA: 30s - loss: 0.5739 - accuracy: 0.825 - ETA: 29s - loss: 0.5746 - accuracy: 0.824 - ETA: 29s - loss: 0.5752 - accuracy: 0.824 - ETA: 28s - loss: 0.5729 - accuracy: 0.825 - ETA: 27s - loss: 0.5709 - accuracy: 0.825 - ETA: 27s - loss: 0.5711 - accuracy: 0.825 - ETA: 26s - loss: 0.5711 - accuracy: 0.824 - ETA: 25s - loss: 0.5732 - accuracy: 0.824 - ETA: 24s - loss: 0.5761 - accuracy: 0.823 - ETA: 24s - loss: 0.5770 - accuracy: 0.823 - ETA: 23s - loss: 0.5756 - accuracy: 0.823 - ETA: 22s - loss: 0.5771 - accuracy: 0.823 - ETA: 22s - loss: 0.5770 - accuracy: 0.823 - ETA: 21s - loss: 0.5770 - accuracy: 0.823 - ETA: 20s - loss: 0.5781 - accuracy: 0.824 - ETA: 20s - loss: 0.5766 - accuracy: 0.824 - ETA: 19s - loss: 0.5766 - accuracy: 0.823 - ETA: 18s - loss: 0.5760 - accuracy: 0.823 - ETA: 17s - loss: 0.5753 - accuracy: 0.824 - ETA: 17s - loss: 0.5755 - accuracy: 0.824 - ETA: 16s - loss: 0.5762 - accuracy: 0.823 - ETA: 15s - loss: 0.5759 - accuracy: 0.823 - ETA: 15s - loss: 0.5772 - accuracy: 0.822 - ETA: 14s - loss: 0.5764 - accuracy: 0.823 - ETA: 13s - loss: 0.5745 - accuracy: 0.823 - ETA: 13s - loss: 0.5738 - accuracy: 0.824 - ETA: 12s - loss: 0.5737 - accuracy: 0.824 - ETA: 11s - loss: 0.5723 - accuracy: 0.824 - ETA: 10s - loss: 0.5730 - accuracy: 0.824 - ETA: 10s - loss: 0.5731 - accuracy: 0.824 - ETA: 9s - loss: 0.5767 - accuracy: 0.824 - ETA: 8s - loss: 0.5762 - accuracy: 0.82 - ETA: 8s - loss: 0.5779 - accuracy: 0.82 - ETA: 7s - loss: 0.5762 - accuracy: 0.82 - ETA: 6s - loss: 0.5758 - accuracy: 0.82 - ETA: 6s - loss: 0.5749 - accuracy: 0.82 - ETA: 5s - loss: 0.5738 - accuracy: 0.82 - ETA: 4s - loss: 0.5742 - accuracy: 0.82 - ETA: 3s - loss: 0.5742 - accuracy: 0.82 - ETA: 3s - loss: 0.5740 - accuracy: 0.82 - ETA: 2s - loss: 0.5736 - accuracy: 0.82 - ETA: 1s - loss: 0.5740 - accuracy: 0.82 - ETA: 1s - loss: 0.5730 - accuracy: 0.82 - ETA: 0s - loss: 0.5733 - accuracy: 0.82 - 82s 6ms/step - loss: 0.5726 - accuracy: 0.8254 - val_loss: 3.3704 - val_accuracy: 0.3229\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.4730 - accuracy: 0.84 - ETA: 1:10 - loss: 0.5307 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5434 - accuracy: 0.84 - ETA: 1:08 - loss: 0.5755 - accuracy: 0.83 - ETA: 1:07 - loss: 0.5695 - accuracy: 0.83 - ETA: 1:07 - loss: 0.5934 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5939 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5772 - accuracy: 0.83 - ETA: 1:05 - loss: 0.5964 - accuracy: 0.82 - ETA: 1:04 - loss: 0.6189 - accuracy: 0.82 - ETA: 1:04 - loss: 0.6170 - accuracy: 0.82 - ETA: 1:03 - loss: 0.6094 - accuracy: 0.82 - ETA: 1:02 - loss: 0.5893 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5909 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5895 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5912 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5878 - accuracy: 0.83 - ETA: 59s - loss: 0.5805 - accuracy: 0.8325 - ETA: 58s - loss: 0.5757 - accuracy: 0.833 - ETA: 58s - loss: 0.5764 - accuracy: 0.831 - ETA: 57s - loss: 0.5716 - accuracy: 0.832 - ETA: 56s - loss: 0.5717 - accuracy: 0.831 - ETA: 55s - loss: 0.5744 - accuracy: 0.829 - ETA: 54s - loss: 0.5701 - accuracy: 0.832 - ETA: 54s - loss: 0.5712 - accuracy: 0.832 - ETA: 53s - loss: 0.5710 - accuracy: 0.832 - ETA: 52s - loss: 0.5681 - accuracy: 0.833 - ETA: 51s - loss: 0.5691 - accuracy: 0.832 - ETA: 51s - loss: 0.5669 - accuracy: 0.833 - ETA: 50s - loss: 0.5658 - accuracy: 0.833 - ETA: 49s - loss: 0.5670 - accuracy: 0.832 - ETA: 49s - loss: 0.5669 - accuracy: 0.833 - ETA: 48s - loss: 0.5673 - accuracy: 0.833 - ETA: 47s - loss: 0.5642 - accuracy: 0.835 - ETA: 46s - loss: 0.5669 - accuracy: 0.833 - ETA: 46s - loss: 0.5708 - accuracy: 0.832 - ETA: 45s - loss: 0.5689 - accuracy: 0.833 - ETA: 44s - loss: 0.5710 - accuracy: 0.832 - ETA: 44s - loss: 0.5707 - accuracy: 0.833 - ETA: 43s - loss: 0.5663 - accuracy: 0.834 - ETA: 42s - loss: 0.5696 - accuracy: 0.834 - ETA: 41s - loss: 0.5654 - accuracy: 0.834 - ETA: 41s - loss: 0.5627 - accuracy: 0.835 - ETA: 40s - loss: 0.5624 - accuracy: 0.835 - ETA: 39s - loss: 0.5624 - accuracy: 0.836 - ETA: 39s - loss: 0.5677 - accuracy: 0.835 - ETA: 38s - loss: 0.5663 - accuracy: 0.835 - ETA: 37s - loss: 0.5653 - accuracy: 0.835 - ETA: 36s - loss: 0.5652 - accuracy: 0.835 - ETA: 36s - loss: 0.5681 - accuracy: 0.834 - ETA: 35s - loss: 0.5686 - accuracy: 0.833 - ETA: 34s - loss: 0.5688 - accuracy: 0.833 - ETA: 34s - loss: 0.5758 - accuracy: 0.832 - ETA: 33s - loss: 0.5772 - accuracy: 0.832 - ETA: 32s - loss: 0.5804 - accuracy: 0.831 - ETA: 31s - loss: 0.5879 - accuracy: 0.829 - ETA: 31s - loss: 0.5859 - accuracy: 0.829 - ETA: 30s - loss: 0.5877 - accuracy: 0.828 - ETA: 29s - loss: 0.5885 - accuracy: 0.828 - ETA: 29s - loss: 0.5907 - accuracy: 0.828 - ETA: 28s - loss: 0.5879 - accuracy: 0.829 - ETA: 27s - loss: 0.5890 - accuracy: 0.828 - ETA: 26s - loss: 0.5875 - accuracy: 0.828 - ETA: 26s - loss: 0.5841 - accuracy: 0.830 - ETA: 25s - loss: 0.5833 - accuracy: 0.829 - ETA: 24s - loss: 0.5824 - accuracy: 0.830 - ETA: 24s - loss: 0.5849 - accuracy: 0.829 - ETA: 23s - loss: 0.5854 - accuracy: 0.829 - ETA: 22s - loss: 0.5858 - accuracy: 0.829 - ETA: 22s - loss: 0.5846 - accuracy: 0.829 - ETA: 21s - loss: 0.5814 - accuracy: 0.830 - ETA: 20s - loss: 0.5810 - accuracy: 0.830 - ETA: 20s - loss: 0.5843 - accuracy: 0.829 - ETA: 19s - loss: 0.5848 - accuracy: 0.829 - ETA: 18s - loss: 0.5832 - accuracy: 0.830 - ETA: 17s - loss: 0.5806 - accuracy: 0.831 - ETA: 17s - loss: 0.5815 - accuracy: 0.830 - ETA: 16s - loss: 0.5834 - accuracy: 0.830 - ETA: 15s - loss: 0.5828 - accuracy: 0.829 - ETA: 15s - loss: 0.5815 - accuracy: 0.830 - ETA: 14s - loss: 0.5823 - accuracy: 0.829 - ETA: 13s - loss: 0.5832 - accuracy: 0.829 - ETA: 13s - loss: 0.5835 - accuracy: 0.829 - ETA: 12s - loss: 0.5830 - accuracy: 0.829 - ETA: 11s - loss: 0.5845 - accuracy: 0.829 - ETA: 10s - loss: 0.5842 - accuracy: 0.829 - ETA: 10s - loss: 0.5834 - accuracy: 0.829 - ETA: 9s - loss: 0.5838 - accuracy: 0.829 - ETA: 8s - loss: 0.5845 - accuracy: 0.82 - ETA: 8s - loss: 0.5824 - accuracy: 0.82 - ETA: 7s - loss: 0.5805 - accuracy: 0.82 - ETA: 6s - loss: 0.5823 - accuracy: 0.82 - ETA: 6s - loss: 0.5821 - accuracy: 0.82 - ETA: 5s - loss: 0.5818 - accuracy: 0.82 - ETA: 4s - loss: 0.5834 - accuracy: 0.82 - ETA: 3s - loss: 0.5857 - accuracy: 0.82 - ETA: 3s - loss: 0.5885 - accuracy: 0.82 - ETA: 2s - loss: 0.5887 - accuracy: 0.82 - ETA: 1s - loss: 0.5884 - accuracy: 0.82 - ETA: 1s - loss: 0.5878 - accuracy: 0.82 - ETA: 0s - loss: 0.5861 - accuracy: 0.82 - 82s 6ms/step - loss: 0.5869 - accuracy: 0.8273 - val_loss: 3.2789 - val_accuracy: 0.3227\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.5635 - accuracy: 0.82 - ETA: 1:10 - loss: 0.6053 - accuracy: 0.82 - ETA: 1:10 - loss: 0.6173 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5938 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5819 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5643 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5652 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5905 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5936 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5889 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5884 - accuracy: 0.82 - ETA: 1:02 - loss: 0.5804 - accuracy: 0.82 - ETA: 1:01 - loss: 0.5771 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5693 - accuracy: 0.83 - ETA: 59s - loss: 0.5841 - accuracy: 0.8281 - ETA: 59s - loss: 0.5862 - accuracy: 0.828 - ETA: 58s - loss: 0.5965 - accuracy: 0.827 - ETA: 58s - loss: 0.5959 - accuracy: 0.826 - ETA: 57s - loss: 0.5987 - accuracy: 0.826 - ETA: 56s - loss: 0.5843 - accuracy: 0.829 - ETA: 56s - loss: 0.5842 - accuracy: 0.828 - ETA: 55s - loss: 0.5915 - accuracy: 0.825 - ETA: 54s - loss: 0.5952 - accuracy: 0.824 - ETA: 54s - loss: 0.5906 - accuracy: 0.825 - ETA: 53s - loss: 0.5883 - accuracy: 0.825 - ETA: 52s - loss: 0.5869 - accuracy: 0.824 - ETA: 51s - loss: 0.5793 - accuracy: 0.827 - ETA: 51s - loss: 0.5819 - accuracy: 0.825 - ETA: 50s - loss: 0.5802 - accuracy: 0.826 - ETA: 49s - loss: 0.5873 - accuracy: 0.824 - ETA: 48s - loss: 0.5862 - accuracy: 0.825 - ETA: 48s - loss: 0.5816 - accuracy: 0.825 - ETA: 47s - loss: 0.5868 - accuracy: 0.824 - ETA: 47s - loss: 0.5923 - accuracy: 0.823 - ETA: 46s - loss: 0.5976 - accuracy: 0.821 - ETA: 45s - loss: 0.5945 - accuracy: 0.821 - ETA: 45s - loss: 0.5926 - accuracy: 0.821 - ETA: 44s - loss: 0.5860 - accuracy: 0.823 - ETA: 43s - loss: 0.5899 - accuracy: 0.822 - ETA: 43s - loss: 0.5862 - accuracy: 0.824 - ETA: 42s - loss: 0.5851 - accuracy: 0.823 - ETA: 41s - loss: 0.5886 - accuracy: 0.823 - ETA: 40s - loss: 0.5964 - accuracy: 0.821 - ETA: 40s - loss: 0.5969 - accuracy: 0.820 - ETA: 39s - loss: 0.5949 - accuracy: 0.821 - ETA: 38s - loss: 0.6001 - accuracy: 0.820 - ETA: 38s - loss: 0.6021 - accuracy: 0.821 - ETA: 37s - loss: 0.5992 - accuracy: 0.822 - ETA: 36s - loss: 0.6030 - accuracy: 0.822 - ETA: 36s - loss: 0.6023 - accuracy: 0.822 - ETA: 35s - loss: 0.6013 - accuracy: 0.823 - ETA: 34s - loss: 0.5994 - accuracy: 0.823 - ETA: 33s - loss: 0.5947 - accuracy: 0.824 - ETA: 33s - loss: 0.5977 - accuracy: 0.822 - ETA: 32s - loss: 0.5955 - accuracy: 0.823 - ETA: 31s - loss: 0.5959 - accuracy: 0.823 - ETA: 31s - loss: 0.5928 - accuracy: 0.824 - ETA: 30s - loss: 0.5962 - accuracy: 0.822 - ETA: 29s - loss: 0.5950 - accuracy: 0.823 - ETA: 29s - loss: 0.5945 - accuracy: 0.822 - ETA: 28s - loss: 0.5939 - accuracy: 0.823 - ETA: 27s - loss: 0.5925 - accuracy: 0.824 - ETA: 26s - loss: 0.5894 - accuracy: 0.824 - ETA: 26s - loss: 0.5887 - accuracy: 0.824 - ETA: 25s - loss: 0.5897 - accuracy: 0.825 - ETA: 24s - loss: 0.5911 - accuracy: 0.824 - ETA: 24s - loss: 0.5889 - accuracy: 0.824 - ETA: 23s - loss: 0.5893 - accuracy: 0.824 - ETA: 22s - loss: 0.5891 - accuracy: 0.824 - ETA: 22s - loss: 0.5904 - accuracy: 0.824 - ETA: 21s - loss: 0.5893 - accuracy: 0.824 - ETA: 20s - loss: 0.5905 - accuracy: 0.823 - ETA: 20s - loss: 0.5917 - accuracy: 0.823 - ETA: 19s - loss: 0.5911 - accuracy: 0.824 - ETA: 18s - loss: 0.5911 - accuracy: 0.824 - ETA: 17s - loss: 0.5919 - accuracy: 0.823 - ETA: 17s - loss: 0.5931 - accuracy: 0.823 - ETA: 16s - loss: 0.5951 - accuracy: 0.822 - ETA: 15s - loss: 0.5955 - accuracy: 0.822 - ETA: 15s - loss: 0.5935 - accuracy: 0.823 - ETA: 14s - loss: 0.5929 - accuracy: 0.823 - ETA: 13s - loss: 0.5915 - accuracy: 0.823 - ETA: 13s - loss: 0.5916 - accuracy: 0.823 - ETA: 12s - loss: 0.5906 - accuracy: 0.823 - ETA: 11s - loss: 0.5910 - accuracy: 0.824 - ETA: 11s - loss: 0.5898 - accuracy: 0.823 - ETA: 10s - loss: 0.5881 - accuracy: 0.824 - ETA: 9s - loss: 0.5874 - accuracy: 0.824 - ETA: 8s - loss: 0.5867 - accuracy: 0.82 - ETA: 8s - loss: 0.5867 - accuracy: 0.82 - ETA: 7s - loss: 0.5866 - accuracy: 0.82 - ETA: 6s - loss: 0.5868 - accuracy: 0.82 - ETA: 6s - loss: 0.5844 - accuracy: 0.82 - ETA: 5s - loss: 0.5854 - accuracy: 0.82 - ETA: 4s - loss: 0.5851 - accuracy: 0.82 - ETA: 4s - loss: 0.5853 - accuracy: 0.82 - ETA: 3s - loss: 0.5844 - accuracy: 0.82 - ETA: 2s - loss: 0.5851 - accuracy: 0.82 - ETA: 1s - loss: 0.5856 - accuracy: 0.82 - ETA: 1s - loss: 0.5828 - accuracy: 0.82 - ETA: 0s - loss: 0.5835 - accuracy: 0.82 - 82s 6ms/step - loss: 0.5835 - accuracy: 0.8254 - val_loss: 2.9998 - val_accuracy: 0.3374\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.6183 - accuracy: 0.82 - ETA: 1:11 - loss: 0.5284 - accuracy: 0.83 - ETA: 1:11 - loss: 0.5613 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5914 - accuracy: 0.82 - ETA: 1:07 - loss: 0.6082 - accuracy: 0.81 - ETA: 1:07 - loss: 0.6348 - accuracy: 0.80 - ETA: 1:06 - loss: 0.6310 - accuracy: 0.80 - ETA: 1:05 - loss: 0.6244 - accuracy: 0.81 - ETA: 1:04 - loss: 0.6092 - accuracy: 0.81 - ETA: 1:03 - loss: 0.6049 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5955 - accuracy: 0.82 - ETA: 1:02 - loss: 0.5993 - accuracy: 0.82 - ETA: 1:01 - loss: 0.5961 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5898 - accuracy: 0.82 - ETA: 1:00 - loss: 0.5928 - accuracy: 0.82 - ETA: 59s - loss: 0.6023 - accuracy: 0.8193 - ETA: 58s - loss: 0.6021 - accuracy: 0.819 - ETA: 58s - loss: 0.5979 - accuracy: 0.820 - ETA: 57s - loss: 0.5965 - accuracy: 0.821 - ETA: 56s - loss: 0.5882 - accuracy: 0.825 - ETA: 55s - loss: 0.5807 - accuracy: 0.826 - ETA: 55s - loss: 0.5791 - accuracy: 0.826 - ETA: 54s - loss: 0.5723 - accuracy: 0.828 - ETA: 53s - loss: 0.5806 - accuracy: 0.826 - ETA: 53s - loss: 0.5797 - accuracy: 0.826 - ETA: 52s - loss: 0.5782 - accuracy: 0.826 - ETA: 51s - loss: 0.5846 - accuracy: 0.825 - ETA: 50s - loss: 0.5776 - accuracy: 0.827 - ETA: 50s - loss: 0.5708 - accuracy: 0.828 - ETA: 49s - loss: 0.5714 - accuracy: 0.829 - ETA: 48s - loss: 0.5714 - accuracy: 0.830 - ETA: 48s - loss: 0.5688 - accuracy: 0.830 - ETA: 47s - loss: 0.5691 - accuracy: 0.830 - ETA: 46s - loss: 0.5675 - accuracy: 0.830 - ETA: 46s - loss: 0.5678 - accuracy: 0.829 - ETA: 45s - loss: 0.5658 - accuracy: 0.829 - ETA: 44s - loss: 0.5703 - accuracy: 0.829 - ETA: 43s - loss: 0.5756 - accuracy: 0.826 - ETA: 43s - loss: 0.5760 - accuracy: 0.826 - ETA: 42s - loss: 0.5727 - accuracy: 0.827 - ETA: 41s - loss: 0.5758 - accuracy: 0.826 - ETA: 41s - loss: 0.5774 - accuracy: 0.825 - ETA: 40s - loss: 0.5777 - accuracy: 0.826 - ETA: 39s - loss: 0.5792 - accuracy: 0.824 - ETA: 39s - loss: 0.5818 - accuracy: 0.824 - ETA: 38s - loss: 0.5778 - accuracy: 0.825 - ETA: 37s - loss: 0.5771 - accuracy: 0.825 - ETA: 37s - loss: 0.5760 - accuracy: 0.826 - ETA: 36s - loss: 0.5771 - accuracy: 0.825 - ETA: 35s - loss: 0.5755 - accuracy: 0.825 - ETA: 35s - loss: 0.5748 - accuracy: 0.825 - ETA: 34s - loss: 0.5739 - accuracy: 0.825 - ETA: 33s - loss: 0.5770 - accuracy: 0.825 - ETA: 32s - loss: 0.5799 - accuracy: 0.824 - ETA: 32s - loss: 0.5780 - accuracy: 0.825 - ETA: 31s - loss: 0.5788 - accuracy: 0.825 - ETA: 30s - loss: 0.5779 - accuracy: 0.825 - ETA: 30s - loss: 0.5792 - accuracy: 0.824 - ETA: 29s - loss: 0.5783 - accuracy: 0.824 - ETA: 28s - loss: 0.5768 - accuracy: 0.825 - ETA: 28s - loss: 0.5773 - accuracy: 0.825 - ETA: 27s - loss: 0.5751 - accuracy: 0.826 - ETA: 26s - loss: 0.5774 - accuracy: 0.826 - ETA: 26s - loss: 0.5764 - accuracy: 0.826 - ETA: 25s - loss: 0.5768 - accuracy: 0.826 - ETA: 24s - loss: 0.5763 - accuracy: 0.826 - ETA: 24s - loss: 0.5754 - accuracy: 0.826 - ETA: 23s - loss: 0.5743 - accuracy: 0.826 - ETA: 22s - loss: 0.5746 - accuracy: 0.826 - ETA: 22s - loss: 0.5757 - accuracy: 0.826 - ETA: 21s - loss: 0.5783 - accuracy: 0.825 - ETA: 20s - loss: 0.5765 - accuracy: 0.826 - ETA: 19s - loss: 0.5765 - accuracy: 0.826 - ETA: 19s - loss: 0.5791 - accuracy: 0.826 - ETA: 18s - loss: 0.5806 - accuracy: 0.825 - ETA: 17s - loss: 0.5809 - accuracy: 0.825 - ETA: 17s - loss: 0.5801 - accuracy: 0.826 - ETA: 16s - loss: 0.5826 - accuracy: 0.825 - ETA: 15s - loss: 0.5845 - accuracy: 0.825 - ETA: 15s - loss: 0.5853 - accuracy: 0.825 - ETA: 14s - loss: 0.5867 - accuracy: 0.824 - ETA: 13s - loss: 0.5872 - accuracy: 0.824 - ETA: 13s - loss: 0.5883 - accuracy: 0.824 - ETA: 12s - loss: 0.5893 - accuracy: 0.824 - ETA: 11s - loss: 0.5911 - accuracy: 0.824 - ETA: 10s - loss: 0.5905 - accuracy: 0.824 - ETA: 10s - loss: 0.5903 - accuracy: 0.824 - ETA: 9s - loss: 0.5914 - accuracy: 0.823 - ETA: 8s - loss: 0.5908 - accuracy: 0.82 - ETA: 8s - loss: 0.5904 - accuracy: 0.82 - ETA: 7s - loss: 0.5882 - accuracy: 0.82 - ETA: 6s - loss: 0.5898 - accuracy: 0.82 - ETA: 6s - loss: 0.5880 - accuracy: 0.82 - ETA: 5s - loss: 0.5878 - accuracy: 0.82 - ETA: 4s - loss: 0.5860 - accuracy: 0.82 - ETA: 3s - loss: 0.5840 - accuracy: 0.82 - ETA: 3s - loss: 0.5847 - accuracy: 0.82 - ETA: 2s - loss: 0.5837 - accuracy: 0.82 - ETA: 1s - loss: 0.5826 - accuracy: 0.82 - ETA: 1s - loss: 0.5828 - accuracy: 0.82 - ETA: 0s - loss: 0.5835 - accuracy: 0.82 - 82s 6ms/step - loss: 0.5828 - accuracy: 0.8264 - val_loss: 3.1355 - val_accuracy: 0.3278\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:10 - loss: 0.5733 - accuracy: 0.81 - ETA: 1:09 - loss: 0.5757 - accuracy: 0.81 - ETA: 1:07 - loss: 0.5243 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5721 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5865 - accuracy: 0.81 - ETA: 1:06 - loss: 0.5778 - accuracy: 0.81 - ETA: 1:05 - loss: 0.5905 - accuracy: 0.81 - ETA: 1:05 - loss: 0.5996 - accuracy: 0.81 - ETA: 1:04 - loss: 0.5951 - accuracy: 0.81 - ETA: 1:03 - loss: 0.5990 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5953 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5966 - accuracy: 0.81 - ETA: 1:02 - loss: 0.5931 - accuracy: 0.81 - ETA: 1:01 - loss: 0.5976 - accuracy: 0.81 - ETA: 1:00 - loss: 0.5903 - accuracy: 0.81 - ETA: 59s - loss: 0.5860 - accuracy: 0.8188 - ETA: 59s - loss: 0.5865 - accuracy: 0.819 - ETA: 58s - loss: 0.5939 - accuracy: 0.816 - ETA: 57s - loss: 0.5942 - accuracy: 0.816 - ETA: 56s - loss: 0.5872 - accuracy: 0.817 - ETA: 56s - loss: 0.5796 - accuracy: 0.819 - ETA: 55s - loss: 0.5788 - accuracy: 0.820 - ETA: 54s - loss: 0.5780 - accuracy: 0.821 - ETA: 53s - loss: 0.5843 - accuracy: 0.819 - ETA: 53s - loss: 0.5852 - accuracy: 0.819 - ETA: 52s - loss: 0.5902 - accuracy: 0.819 - ETA: 51s - loss: 0.5841 - accuracy: 0.820 - ETA: 51s - loss: 0.5809 - accuracy: 0.822 - ETA: 50s - loss: 0.5800 - accuracy: 0.823 - ETA: 49s - loss: 0.5829 - accuracy: 0.823 - ETA: 49s - loss: 0.5788 - accuracy: 0.824 - ETA: 48s - loss: 0.5852 - accuracy: 0.823 - ETA: 47s - loss: 0.5852 - accuracy: 0.823 - ETA: 47s - loss: 0.5889 - accuracy: 0.822 - ETA: 46s - loss: 0.5875 - accuracy: 0.823 - ETA: 45s - loss: 0.5897 - accuracy: 0.822 - ETA: 45s - loss: 0.5906 - accuracy: 0.823 - ETA: 44s - loss: 0.5933 - accuracy: 0.822 - ETA: 43s - loss: 0.5894 - accuracy: 0.823 - ETA: 43s - loss: 0.5880 - accuracy: 0.823 - ETA: 42s - loss: 0.5905 - accuracy: 0.822 - ETA: 41s - loss: 0.5894 - accuracy: 0.822 - ETA: 41s - loss: 0.5875 - accuracy: 0.823 - ETA: 40s - loss: 0.5889 - accuracy: 0.821 - ETA: 39s - loss: 0.5889 - accuracy: 0.822 - ETA: 38s - loss: 0.5913 - accuracy: 0.821 - ETA: 38s - loss: 0.5919 - accuracy: 0.820 - ETA: 37s - loss: 0.5936 - accuracy: 0.820 - ETA: 36s - loss: 0.5924 - accuracy: 0.820 - ETA: 36s - loss: 0.5872 - accuracy: 0.822 - ETA: 35s - loss: 0.5858 - accuracy: 0.822 - ETA: 34s - loss: 0.5863 - accuracy: 0.822 - ETA: 33s - loss: 0.5832 - accuracy: 0.822 - ETA: 33s - loss: 0.5857 - accuracy: 0.821 - ETA: 32s - loss: 0.5837 - accuracy: 0.822 - ETA: 31s - loss: 0.5850 - accuracy: 0.821 - ETA: 31s - loss: 0.5880 - accuracy: 0.820 - ETA: 30s - loss: 0.5877 - accuracy: 0.821 - ETA: 29s - loss: 0.5875 - accuracy: 0.820 - ETA: 29s - loss: 0.5894 - accuracy: 0.819 - ETA: 28s - loss: 0.5892 - accuracy: 0.819 - ETA: 27s - loss: 0.5895 - accuracy: 0.819 - ETA: 26s - loss: 0.5879 - accuracy: 0.820 - ETA: 26s - loss: 0.5870 - accuracy: 0.820 - ETA: 25s - loss: 0.5885 - accuracy: 0.820 - ETA: 24s - loss: 0.5888 - accuracy: 0.820 - ETA: 24s - loss: 0.5869 - accuracy: 0.821 - ETA: 23s - loss: 0.5855 - accuracy: 0.821 - ETA: 22s - loss: 0.5862 - accuracy: 0.821 - ETA: 22s - loss: 0.5872 - accuracy: 0.821 - ETA: 21s - loss: 0.5864 - accuracy: 0.821 - ETA: 20s - loss: 0.5871 - accuracy: 0.821 - ETA: 20s - loss: 0.5880 - accuracy: 0.821 - ETA: 19s - loss: 0.5894 - accuracy: 0.820 - ETA: 18s - loss: 0.5888 - accuracy: 0.821 - ETA: 17s - loss: 0.5896 - accuracy: 0.821 - ETA: 17s - loss: 0.5898 - accuracy: 0.821 - ETA: 16s - loss: 0.5891 - accuracy: 0.821 - ETA: 15s - loss: 0.5887 - accuracy: 0.821 - ETA: 15s - loss: 0.5916 - accuracy: 0.821 - ETA: 14s - loss: 0.5929 - accuracy: 0.820 - ETA: 13s - loss: 0.5927 - accuracy: 0.820 - ETA: 13s - loss: 0.5919 - accuracy: 0.820 - ETA: 12s - loss: 0.5915 - accuracy: 0.820 - ETA: 11s - loss: 0.5940 - accuracy: 0.819 - ETA: 10s - loss: 0.5951 - accuracy: 0.819 - ETA: 10s - loss: 0.5951 - accuracy: 0.818 - ETA: 9s - loss: 0.5945 - accuracy: 0.818 - ETA: 8s - loss: 0.5930 - accuracy: 0.81 - ETA: 8s - loss: 0.5908 - accuracy: 0.82 - ETA: 7s - loss: 0.5893 - accuracy: 0.82 - ETA: 6s - loss: 0.5900 - accuracy: 0.82 - ETA: 6s - loss: 0.5891 - accuracy: 0.82 - ETA: 5s - loss: 0.5878 - accuracy: 0.82 - ETA: 4s - loss: 0.5894 - accuracy: 0.82 - ETA: 3s - loss: 0.5898 - accuracy: 0.82 - ETA: 3s - loss: 0.5886 - accuracy: 0.82 - ETA: 2s - loss: 0.5893 - accuracy: 0.82 - ETA: 1s - loss: 0.5900 - accuracy: 0.82 - ETA: 1s - loss: 0.5895 - accuracy: 0.82 - ETA: 0s - loss: 0.5888 - accuracy: 0.82 - 82s 6ms/step - loss: 0.5906 - accuracy: 0.8210 - val_loss: 3.1731 - val_accuracy: 0.3264\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:10 - loss: 0.4721 - accuracy: 0.83 - ETA: 1:12 - loss: 0.4723 - accuracy: 0.84 - ETA: 1:11 - loss: 0.5684 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5420 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5049 - accuracy: 0.84 - ETA: 1:08 - loss: 0.5021 - accuracy: 0.84 - ETA: 1:07 - loss: 0.5184 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5512 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5460 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5497 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5517 - accuracy: 0.85 - ETA: 1:03 - loss: 0.5467 - accuracy: 0.85 - ETA: 1:02 - loss: 0.5484 - accuracy: 0.85 - ETA: 1:01 - loss: 0.5559 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5494 - accuracy: 0.85 - ETA: 1:00 - loss: 0.5514 - accuracy: 0.85 - ETA: 59s - loss: 0.5692 - accuracy: 0.8479 - ETA: 59s - loss: 0.5713 - accuracy: 0.846 - ETA: 58s - loss: 0.5716 - accuracy: 0.845 - ETA: 57s - loss: 0.5680 - accuracy: 0.845 - ETA: 56s - loss: 0.5588 - accuracy: 0.846 - ETA: 55s - loss: 0.5616 - accuracy: 0.846 - ETA: 55s - loss: 0.5587 - accuracy: 0.847 - ETA: 54s - loss: 0.5595 - accuracy: 0.846 - ETA: 53s - loss: 0.5585 - accuracy: 0.845 - ETA: 52s - loss: 0.5535 - accuracy: 0.846 - ETA: 52s - loss: 0.5491 - accuracy: 0.846 - ETA: 51s - loss: 0.5602 - accuracy: 0.844 - ETA: 50s - loss: 0.5613 - accuracy: 0.843 - ETA: 50s - loss: 0.5571 - accuracy: 0.843 - ETA: 49s - loss: 0.5597 - accuracy: 0.842 - ETA: 48s - loss: 0.5600 - accuracy: 0.841 - ETA: 48s - loss: 0.5686 - accuracy: 0.838 - ETA: 47s - loss: 0.5657 - accuracy: 0.839 - ETA: 46s - loss: 0.5654 - accuracy: 0.839 - ETA: 46s - loss: 0.5703 - accuracy: 0.837 - ETA: 45s - loss: 0.5701 - accuracy: 0.837 - ETA: 44s - loss: 0.5708 - accuracy: 0.837 - ETA: 43s - loss: 0.5705 - accuracy: 0.836 - ETA: 43s - loss: 0.5675 - accuracy: 0.836 - ETA: 42s - loss: 0.5633 - accuracy: 0.837 - ETA: 41s - loss: 0.5661 - accuracy: 0.836 - ETA: 41s - loss: 0.5693 - accuracy: 0.835 - ETA: 40s - loss: 0.5682 - accuracy: 0.835 - ETA: 39s - loss: 0.5693 - accuracy: 0.834 - ETA: 38s - loss: 0.5678 - accuracy: 0.835 - ETA: 38s - loss: 0.5690 - accuracy: 0.835 - ETA: 37s - loss: 0.5685 - accuracy: 0.835 - ETA: 36s - loss: 0.5674 - accuracy: 0.836 - ETA: 36s - loss: 0.5656 - accuracy: 0.836 - ETA: 35s - loss: 0.5659 - accuracy: 0.836 - ETA: 34s - loss: 0.5671 - accuracy: 0.837 - ETA: 33s - loss: 0.5662 - accuracy: 0.837 - ETA: 33s - loss: 0.5679 - accuracy: 0.837 - ETA: 32s - loss: 0.5663 - accuracy: 0.838 - ETA: 31s - loss: 0.5640 - accuracy: 0.838 - ETA: 31s - loss: 0.5642 - accuracy: 0.839 - ETA: 30s - loss: 0.5645 - accuracy: 0.839 - ETA: 29s - loss: 0.5619 - accuracy: 0.839 - ETA: 29s - loss: 0.5609 - accuracy: 0.839 - ETA: 28s - loss: 0.5598 - accuracy: 0.839 - ETA: 27s - loss: 0.5612 - accuracy: 0.838 - ETA: 26s - loss: 0.5613 - accuracy: 0.838 - ETA: 26s - loss: 0.5595 - accuracy: 0.839 - ETA: 25s - loss: 0.5588 - accuracy: 0.838 - ETA: 24s - loss: 0.5585 - accuracy: 0.838 - ETA: 24s - loss: 0.5578 - accuracy: 0.838 - ETA: 23s - loss: 0.5574 - accuracy: 0.838 - ETA: 22s - loss: 0.5568 - accuracy: 0.838 - ETA: 22s - loss: 0.5571 - accuracy: 0.838 - ETA: 21s - loss: 0.5551 - accuracy: 0.839 - ETA: 20s - loss: 0.5569 - accuracy: 0.839 - ETA: 19s - loss: 0.5589 - accuracy: 0.838 - ETA: 19s - loss: 0.5584 - accuracy: 0.838 - ETA: 18s - loss: 0.5561 - accuracy: 0.839 - ETA: 17s - loss: 0.5553 - accuracy: 0.839 - ETA: 17s - loss: 0.5544 - accuracy: 0.839 - ETA: 16s - loss: 0.5525 - accuracy: 0.839 - ETA: 15s - loss: 0.5518 - accuracy: 0.839 - ETA: 15s - loss: 0.5527 - accuracy: 0.839 - ETA: 14s - loss: 0.5524 - accuracy: 0.840 - ETA: 13s - loss: 0.5528 - accuracy: 0.839 - ETA: 13s - loss: 0.5539 - accuracy: 0.838 - ETA: 12s - loss: 0.5537 - accuracy: 0.838 - ETA: 11s - loss: 0.5529 - accuracy: 0.838 - ETA: 10s - loss: 0.5532 - accuracy: 0.838 - ETA: 10s - loss: 0.5532 - accuracy: 0.838 - ETA: 9s - loss: 0.5538 - accuracy: 0.837 - ETA: 8s - loss: 0.5536 - accuracy: 0.83 - ETA: 8s - loss: 0.5555 - accuracy: 0.83 - ETA: 7s - loss: 0.5568 - accuracy: 0.83 - ETA: 6s - loss: 0.5573 - accuracy: 0.83 - ETA: 6s - loss: 0.5567 - accuracy: 0.83 - ETA: 5s - loss: 0.5601 - accuracy: 0.83 - ETA: 4s - loss: 0.5632 - accuracy: 0.83 - ETA: 3s - loss: 0.5638 - accuracy: 0.83 - ETA: 3s - loss: 0.5641 - accuracy: 0.83 - ETA: 2s - loss: 0.5654 - accuracy: 0.83 - ETA: 1s - loss: 0.5668 - accuracy: 0.83 - ETA: 1s - loss: 0.5674 - accuracy: 0.83 - ETA: 0s - loss: 0.5662 - accuracy: 0.83 - 82s 6ms/step - loss: 0.5661 - accuracy: 0.8347 - val_loss: 3.1622 - val_accuracy: 0.3171\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.4795 - accuracy: 0.82 - ETA: 1:09 - loss: 0.5260 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4944 - accuracy: 0.84 - ETA: 1:08 - loss: 0.5154 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5185 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5374 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5302 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5534 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5368 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5303 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5441 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5503 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5595 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5482 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5384 - accuracy: 0.83 - ETA: 59s - loss: 0.5290 - accuracy: 0.8384 - ETA: 58s - loss: 0.5258 - accuracy: 0.839 - ETA: 57s - loss: 0.5309 - accuracy: 0.839 - ETA: 57s - loss: 0.5248 - accuracy: 0.840 - ETA: 56s - loss: 0.5218 - accuracy: 0.841 - ETA: 55s - loss: 0.5140 - accuracy: 0.843 - ETA: 55s - loss: 0.5144 - accuracy: 0.842 - ETA: 54s - loss: 0.5155 - accuracy: 0.842 - ETA: 53s - loss: 0.5165 - accuracy: 0.841 - ETA: 53s - loss: 0.5125 - accuracy: 0.841 - ETA: 52s - loss: 0.5172 - accuracy: 0.841 - ETA: 51s - loss: 0.5222 - accuracy: 0.841 - ETA: 51s - loss: 0.5198 - accuracy: 0.841 - ETA: 50s - loss: 0.5197 - accuracy: 0.841 - ETA: 49s - loss: 0.5198 - accuracy: 0.841 - ETA: 48s - loss: 0.5212 - accuracy: 0.840 - ETA: 48s - loss: 0.5193 - accuracy: 0.840 - ETA: 47s - loss: 0.5172 - accuracy: 0.841 - ETA: 46s - loss: 0.5167 - accuracy: 0.840 - ETA: 46s - loss: 0.5230 - accuracy: 0.838 - ETA: 45s - loss: 0.5210 - accuracy: 0.839 - ETA: 44s - loss: 0.5289 - accuracy: 0.837 - ETA: 43s - loss: 0.5304 - accuracy: 0.837 - ETA: 43s - loss: 0.5282 - accuracy: 0.837 - ETA: 42s - loss: 0.5276 - accuracy: 0.837 - ETA: 41s - loss: 0.5247 - accuracy: 0.838 - ETA: 41s - loss: 0.5267 - accuracy: 0.837 - ETA: 40s - loss: 0.5269 - accuracy: 0.836 - ETA: 39s - loss: 0.5276 - accuracy: 0.836 - ETA: 39s - loss: 0.5254 - accuracy: 0.838 - ETA: 38s - loss: 0.5263 - accuracy: 0.838 - ETA: 37s - loss: 0.5280 - accuracy: 0.838 - ETA: 37s - loss: 0.5268 - accuracy: 0.838 - ETA: 36s - loss: 0.5246 - accuracy: 0.839 - ETA: 35s - loss: 0.5240 - accuracy: 0.840 - ETA: 34s - loss: 0.5236 - accuracy: 0.839 - ETA: 34s - loss: 0.5231 - accuracy: 0.840 - ETA: 33s - loss: 0.5222 - accuracy: 0.840 - ETA: 32s - loss: 0.5211 - accuracy: 0.840 - ETA: 32s - loss: 0.5204 - accuracy: 0.839 - ETA: 31s - loss: 0.5213 - accuracy: 0.840 - ETA: 30s - loss: 0.5212 - accuracy: 0.840 - ETA: 30s - loss: 0.5195 - accuracy: 0.840 - ETA: 29s - loss: 0.5204 - accuracy: 0.840 - ETA: 28s - loss: 0.5225 - accuracy: 0.840 - ETA: 28s - loss: 0.5226 - accuracy: 0.840 - ETA: 27s - loss: 0.5202 - accuracy: 0.840 - ETA: 26s - loss: 0.5176 - accuracy: 0.841 - ETA: 26s - loss: 0.5171 - accuracy: 0.842 - ETA: 25s - loss: 0.5188 - accuracy: 0.842 - ETA: 24s - loss: 0.5228 - accuracy: 0.841 - ETA: 24s - loss: 0.5215 - accuracy: 0.841 - ETA: 23s - loss: 0.5197 - accuracy: 0.842 - ETA: 22s - loss: 0.5189 - accuracy: 0.842 - ETA: 21s - loss: 0.5206 - accuracy: 0.841 - ETA: 21s - loss: 0.5204 - accuracy: 0.841 - ETA: 20s - loss: 0.5193 - accuracy: 0.841 - ETA: 19s - loss: 0.5194 - accuracy: 0.841 - ETA: 19s - loss: 0.5203 - accuracy: 0.841 - ETA: 18s - loss: 0.5206 - accuracy: 0.841 - ETA: 17s - loss: 0.5240 - accuracy: 0.840 - ETA: 17s - loss: 0.5238 - accuracy: 0.840 - ETA: 16s - loss: 0.5247 - accuracy: 0.840 - ETA: 15s - loss: 0.5258 - accuracy: 0.840 - ETA: 15s - loss: 0.5245 - accuracy: 0.840 - ETA: 14s - loss: 0.5239 - accuracy: 0.841 - ETA: 13s - loss: 0.5273 - accuracy: 0.840 - ETA: 13s - loss: 0.5262 - accuracy: 0.840 - ETA: 12s - loss: 0.5277 - accuracy: 0.841 - ETA: 11s - loss: 0.5295 - accuracy: 0.839 - ETA: 11s - loss: 0.5274 - accuracy: 0.840 - ETA: 10s - loss: 0.5260 - accuracy: 0.840 - ETA: 9s - loss: 0.5255 - accuracy: 0.841 - ETA: 8s - loss: 0.5248 - accuracy: 0.84 - ETA: 8s - loss: 0.5246 - accuracy: 0.84 - ETA: 7s - loss: 0.5256 - accuracy: 0.84 - ETA: 6s - loss: 0.5240 - accuracy: 0.84 - ETA: 6s - loss: 0.5236 - accuracy: 0.84 - ETA: 5s - loss: 0.5252 - accuracy: 0.84 - ETA: 4s - loss: 0.5244 - accuracy: 0.84 - ETA: 4s - loss: 0.5257 - accuracy: 0.84 - ETA: 3s - loss: 0.5267 - accuracy: 0.84 - ETA: 2s - loss: 0.5305 - accuracy: 0.84 - ETA: 1s - loss: 0.5319 - accuracy: 0.83 - ETA: 1s - loss: 0.5328 - accuracy: 0.83 - ETA: 0s - loss: 0.5342 - accuracy: 0.83 - 82s 6ms/step - loss: 0.5335 - accuracy: 0.8393 - val_loss: 3.2684 - val_accuracy: 0.3278\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.5294 - accuracy: 0.86 - ETA: 1:10 - loss: 0.4952 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5036 - accuracy: 0.83 - ETA: 1:09 - loss: 0.4975 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4792 - accuracy: 0.85 - ETA: 1:08 - loss: 0.4679 - accuracy: 0.85 - ETA: 1:07 - loss: 0.4734 - accuracy: 0.85 - ETA: 1:06 - loss: 0.4779 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4950 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5079 - accuracy: 0.84 - ETA: 1:03 - loss: 0.4983 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5011 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5010 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4987 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5144 - accuracy: 0.84 - ETA: 59s - loss: 0.5250 - accuracy: 0.8423 - ETA: 59s - loss: 0.5383 - accuracy: 0.838 - ETA: 58s - loss: 0.5349 - accuracy: 0.839 - ETA: 57s - loss: 0.5472 - accuracy: 0.836 - ETA: 56s - loss: 0.5644 - accuracy: 0.831 - ETA: 55s - loss: 0.5594 - accuracy: 0.833 - ETA: 55s - loss: 0.5572 - accuracy: 0.832 - ETA: 54s - loss: 0.5542 - accuracy: 0.832 - ETA: 53s - loss: 0.5573 - accuracy: 0.832 - ETA: 52s - loss: 0.5631 - accuracy: 0.833 - ETA: 52s - loss: 0.5590 - accuracy: 0.834 - ETA: 51s - loss: 0.5599 - accuracy: 0.833 - ETA: 51s - loss: 0.5634 - accuracy: 0.832 - ETA: 50s - loss: 0.5607 - accuracy: 0.833 - ETA: 49s - loss: 0.5589 - accuracy: 0.833 - ETA: 49s - loss: 0.5554 - accuracy: 0.832 - ETA: 48s - loss: 0.5565 - accuracy: 0.831 - ETA: 47s - loss: 0.5625 - accuracy: 0.830 - ETA: 47s - loss: 0.5603 - accuracy: 0.831 - ETA: 46s - loss: 0.5609 - accuracy: 0.830 - ETA: 45s - loss: 0.5618 - accuracy: 0.830 - ETA: 44s - loss: 0.5584 - accuracy: 0.830 - ETA: 44s - loss: 0.5591 - accuracy: 0.830 - ETA: 43s - loss: 0.5599 - accuracy: 0.830 - ETA: 42s - loss: 0.5612 - accuracy: 0.830 - ETA: 42s - loss: 0.5597 - accuracy: 0.831 - ETA: 41s - loss: 0.5600 - accuracy: 0.830 - ETA: 40s - loss: 0.5613 - accuracy: 0.829 - ETA: 40s - loss: 0.5645 - accuracy: 0.829 - ETA: 39s - loss: 0.5639 - accuracy: 0.829 - ETA: 38s - loss: 0.5650 - accuracy: 0.828 - ETA: 37s - loss: 0.5661 - accuracy: 0.828 - ETA: 37s - loss: 0.5669 - accuracy: 0.828 - ETA: 36s - loss: 0.5652 - accuracy: 0.829 - ETA: 35s - loss: 0.5617 - accuracy: 0.830 - ETA: 35s - loss: 0.5592 - accuracy: 0.830 - ETA: 34s - loss: 0.5603 - accuracy: 0.830 - ETA: 33s - loss: 0.5599 - accuracy: 0.830 - ETA: 33s - loss: 0.5604 - accuracy: 0.830 - ETA: 32s - loss: 0.5585 - accuracy: 0.831 - ETA: 31s - loss: 0.5587 - accuracy: 0.831 - ETA: 31s - loss: 0.5570 - accuracy: 0.831 - ETA: 30s - loss: 0.5585 - accuracy: 0.831 - ETA: 29s - loss: 0.5587 - accuracy: 0.831 - ETA: 29s - loss: 0.5592 - accuracy: 0.831 - ETA: 28s - loss: 0.5602 - accuracy: 0.831 - ETA: 27s - loss: 0.5619 - accuracy: 0.831 - ETA: 27s - loss: 0.5621 - accuracy: 0.832 - ETA: 26s - loss: 0.5613 - accuracy: 0.832 - ETA: 25s - loss: 0.5624 - accuracy: 0.832 - ETA: 24s - loss: 0.5651 - accuracy: 0.832 - ETA: 24s - loss: 0.5629 - accuracy: 0.832 - ETA: 23s - loss: 0.5636 - accuracy: 0.832 - ETA: 22s - loss: 0.5617 - accuracy: 0.833 - ETA: 22s - loss: 0.5623 - accuracy: 0.832 - ETA: 21s - loss: 0.5602 - accuracy: 0.833 - ETA: 20s - loss: 0.5624 - accuracy: 0.833 - ETA: 20s - loss: 0.5620 - accuracy: 0.833 - ETA: 19s - loss: 0.5603 - accuracy: 0.833 - ETA: 18s - loss: 0.5614 - accuracy: 0.832 - ETA: 17s - loss: 0.5595 - accuracy: 0.833 - ETA: 17s - loss: 0.5589 - accuracy: 0.833 - ETA: 16s - loss: 0.5577 - accuracy: 0.833 - ETA: 15s - loss: 0.5567 - accuracy: 0.833 - ETA: 15s - loss: 0.5568 - accuracy: 0.834 - ETA: 14s - loss: 0.5573 - accuracy: 0.833 - ETA: 13s - loss: 0.5572 - accuracy: 0.833 - ETA: 13s - loss: 0.5583 - accuracy: 0.833 - ETA: 12s - loss: 0.5586 - accuracy: 0.833 - ETA: 11s - loss: 0.5607 - accuracy: 0.833 - ETA: 10s - loss: 0.5606 - accuracy: 0.832 - ETA: 10s - loss: 0.5612 - accuracy: 0.833 - ETA: 9s - loss: 0.5626 - accuracy: 0.832 - ETA: 8s - loss: 0.5616 - accuracy: 0.83 - ETA: 8s - loss: 0.5600 - accuracy: 0.83 - ETA: 7s - loss: 0.5598 - accuracy: 0.83 - ETA: 6s - loss: 0.5603 - accuracy: 0.83 - ETA: 6s - loss: 0.5608 - accuracy: 0.83 - ETA: 5s - loss: 0.5612 - accuracy: 0.83 - ETA: 4s - loss: 0.5615 - accuracy: 0.83 - ETA: 3s - loss: 0.5611 - accuracy: 0.83 - ETA: 3s - loss: 0.5592 - accuracy: 0.83 - ETA: 2s - loss: 0.5611 - accuracy: 0.83 - ETA: 1s - loss: 0.5606 - accuracy: 0.83 - ETA: 1s - loss: 0.5617 - accuracy: 0.83 - ETA: 0s - loss: 0.5605 - accuracy: 0.83 - 81s 6ms/step - loss: 0.5610 - accuracy: 0.8330 - val_loss: 3.4189 - val_accuracy: 0.3204\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.6321 - accuracy: 0.80 - ETA: 1:10 - loss: 0.5106 - accuracy: 0.85 - ETA: 1:09 - loss: 0.5392 - accuracy: 0.85 - ETA: 1:09 - loss: 0.5272 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5646 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5744 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5671 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5415 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5573 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5503 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5448 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5578 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5530 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5557 - accuracy: 0.83 - ETA: 59s - loss: 0.5596 - accuracy: 0.8380 - ETA: 58s - loss: 0.5522 - accuracy: 0.839 - ETA: 58s - loss: 0.5551 - accuracy: 0.838 - ETA: 57s - loss: 0.5522 - accuracy: 0.836 - ETA: 56s - loss: 0.5512 - accuracy: 0.835 - ETA: 56s - loss: 0.5379 - accuracy: 0.838 - ETA: 55s - loss: 0.5423 - accuracy: 0.836 - ETA: 54s - loss: 0.5466 - accuracy: 0.835 - ETA: 54s - loss: 0.5537 - accuracy: 0.833 - ETA: 53s - loss: 0.5608 - accuracy: 0.833 - ETA: 52s - loss: 0.5590 - accuracy: 0.835 - ETA: 52s - loss: 0.5583 - accuracy: 0.835 - ETA: 51s - loss: 0.5585 - accuracy: 0.835 - ETA: 50s - loss: 0.5611 - accuracy: 0.834 - ETA: 50s - loss: 0.5547 - accuracy: 0.837 - ETA: 49s - loss: 0.5549 - accuracy: 0.836 - ETA: 49s - loss: 0.5573 - accuracy: 0.835 - ETA: 48s - loss: 0.5538 - accuracy: 0.835 - ETA: 47s - loss: 0.5546 - accuracy: 0.834 - ETA: 47s - loss: 0.5520 - accuracy: 0.834 - ETA: 46s - loss: 0.5547 - accuracy: 0.834 - ETA: 45s - loss: 0.5545 - accuracy: 0.833 - ETA: 45s - loss: 0.5522 - accuracy: 0.834 - ETA: 44s - loss: 0.5538 - accuracy: 0.833 - ETA: 43s - loss: 0.5524 - accuracy: 0.833 - ETA: 43s - loss: 0.5577 - accuracy: 0.832 - ETA: 42s - loss: 0.5575 - accuracy: 0.832 - ETA: 41s - loss: 0.5653 - accuracy: 0.832 - ETA: 41s - loss: 0.5655 - accuracy: 0.831 - ETA: 40s - loss: 0.5653 - accuracy: 0.832 - ETA: 39s - loss: 0.5713 - accuracy: 0.831 - ETA: 38s - loss: 0.5703 - accuracy: 0.831 - ETA: 38s - loss: 0.5685 - accuracy: 0.831 - ETA: 37s - loss: 0.5702 - accuracy: 0.831 - ETA: 36s - loss: 0.5677 - accuracy: 0.832 - ETA: 36s - loss: 0.5701 - accuracy: 0.831 - ETA: 35s - loss: 0.5665 - accuracy: 0.833 - ETA: 34s - loss: 0.5620 - accuracy: 0.834 - ETA: 34s - loss: 0.5629 - accuracy: 0.833 - ETA: 33s - loss: 0.5628 - accuracy: 0.833 - ETA: 32s - loss: 0.5663 - accuracy: 0.832 - ETA: 31s - loss: 0.5694 - accuracy: 0.830 - ETA: 31s - loss: 0.5681 - accuracy: 0.831 - ETA: 30s - loss: 0.5676 - accuracy: 0.831 - ETA: 29s - loss: 0.5673 - accuracy: 0.831 - ETA: 29s - loss: 0.5675 - accuracy: 0.831 - ETA: 28s - loss: 0.5677 - accuracy: 0.831 - ETA: 27s - loss: 0.5692 - accuracy: 0.830 - ETA: 26s - loss: 0.5708 - accuracy: 0.830 - ETA: 26s - loss: 0.5686 - accuracy: 0.830 - ETA: 25s - loss: 0.5671 - accuracy: 0.831 - ETA: 24s - loss: 0.5664 - accuracy: 0.830 - ETA: 24s - loss: 0.5702 - accuracy: 0.829 - ETA: 23s - loss: 0.5722 - accuracy: 0.829 - ETA: 22s - loss: 0.5761 - accuracy: 0.828 - ETA: 22s - loss: 0.5752 - accuracy: 0.828 - ETA: 21s - loss: 0.5796 - accuracy: 0.827 - ETA: 20s - loss: 0.5793 - accuracy: 0.827 - ETA: 20s - loss: 0.5790 - accuracy: 0.827 - ETA: 19s - loss: 0.5786 - accuracy: 0.827 - ETA: 18s - loss: 0.5773 - accuracy: 0.828 - ETA: 17s - loss: 0.5767 - accuracy: 0.828 - ETA: 17s - loss: 0.5760 - accuracy: 0.828 - ETA: 16s - loss: 0.5740 - accuracy: 0.829 - ETA: 15s - loss: 0.5741 - accuracy: 0.829 - ETA: 15s - loss: 0.5766 - accuracy: 0.828 - ETA: 14s - loss: 0.5761 - accuracy: 0.829 - ETA: 13s - loss: 0.5784 - accuracy: 0.829 - ETA: 13s - loss: 0.5787 - accuracy: 0.828 - ETA: 12s - loss: 0.5787 - accuracy: 0.828 - ETA: 11s - loss: 0.5794 - accuracy: 0.828 - ETA: 10s - loss: 0.5781 - accuracy: 0.828 - ETA: 10s - loss: 0.5776 - accuracy: 0.828 - ETA: 9s - loss: 0.5774 - accuracy: 0.828 - ETA: 8s - loss: 0.5760 - accuracy: 0.82 - ETA: 8s - loss: 0.5794 - accuracy: 0.82 - ETA: 7s - loss: 0.5807 - accuracy: 0.82 - ETA: 6s - loss: 0.5810 - accuracy: 0.82 - ETA: 6s - loss: 0.5821 - accuracy: 0.82 - ETA: 5s - loss: 0.5819 - accuracy: 0.82 - ETA: 4s - loss: 0.5810 - accuracy: 0.82 - ETA: 3s - loss: 0.5825 - accuracy: 0.82 - ETA: 3s - loss: 0.5816 - accuracy: 0.82 - ETA: 2s - loss: 0.5830 - accuracy: 0.82 - ETA: 1s - loss: 0.5827 - accuracy: 0.82 - ETA: 1s - loss: 0.5824 - accuracy: 0.82 - ETA: 0s - loss: 0.5813 - accuracy: 0.82 - 81s 6ms/step - loss: 0.5798 - accuracy: 0.8287 - val_loss: 3.3056 - val_accuracy: 0.3122\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.8808 - accuracy: 0.76 - ETA: 1:13 - loss: 0.6856 - accuracy: 0.81 - ETA: 1:11 - loss: 0.6257 - accuracy: 0.82 - ETA: 1:10 - loss: 0.5932 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5733 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5424 - accuracy: 0.84 - ETA: 1:07 - loss: 0.5801 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5855 - accuracy: 0.83 - ETA: 1:05 - loss: 0.5986 - accuracy: 0.83 - ETA: 1:04 - loss: 0.6104 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5951 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5798 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5840 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5863 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5840 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5865 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5940 - accuracy: 0.83 - ETA: 1:00 - loss: 0.6005 - accuracy: 0.82 - ETA: 59s - loss: 0.6022 - accuracy: 0.8289 - ETA: 58s - loss: 0.6066 - accuracy: 0.826 - ETA: 57s - loss: 0.6052 - accuracy: 0.826 - ETA: 56s - loss: 0.6003 - accuracy: 0.826 - ETA: 55s - loss: 0.5946 - accuracy: 0.827 - ETA: 55s - loss: 0.5895 - accuracy: 0.829 - ETA: 54s - loss: 0.5862 - accuracy: 0.830 - ETA: 53s - loss: 0.5874 - accuracy: 0.829 - ETA: 53s - loss: 0.5898 - accuracy: 0.829 - ETA: 52s - loss: 0.5948 - accuracy: 0.828 - ETA: 51s - loss: 0.5907 - accuracy: 0.828 - ETA: 50s - loss: 0.5855 - accuracy: 0.829 - ETA: 50s - loss: 0.5851 - accuracy: 0.828 - ETA: 49s - loss: 0.5858 - accuracy: 0.827 - ETA: 48s - loss: 0.5808 - accuracy: 0.828 - ETA: 47s - loss: 0.5763 - accuracy: 0.828 - ETA: 46s - loss: 0.5732 - accuracy: 0.829 - ETA: 46s - loss: 0.5722 - accuracy: 0.829 - ETA: 45s - loss: 0.5708 - accuracy: 0.830 - ETA: 44s - loss: 0.5701 - accuracy: 0.830 - ETA: 43s - loss: 0.5739 - accuracy: 0.830 - ETA: 43s - loss: 0.5747 - accuracy: 0.830 - ETA: 42s - loss: 0.5713 - accuracy: 0.830 - ETA: 41s - loss: 0.5748 - accuracy: 0.829 - ETA: 41s - loss: 0.5745 - accuracy: 0.829 - ETA: 40s - loss: 0.5777 - accuracy: 0.827 - ETA: 39s - loss: 0.5755 - accuracy: 0.828 - ETA: 38s - loss: 0.5762 - accuracy: 0.826 - ETA: 38s - loss: 0.5749 - accuracy: 0.827 - ETA: 37s - loss: 0.5771 - accuracy: 0.826 - ETA: 36s - loss: 0.5783 - accuracy: 0.827 - ETA: 36s - loss: 0.5780 - accuracy: 0.828 - ETA: 35s - loss: 0.5740 - accuracy: 0.829 - ETA: 34s - loss: 0.5738 - accuracy: 0.829 - ETA: 34s - loss: 0.5751 - accuracy: 0.828 - ETA: 33s - loss: 0.5756 - accuracy: 0.828 - ETA: 32s - loss: 0.5778 - accuracy: 0.828 - ETA: 31s - loss: 0.5772 - accuracy: 0.827 - ETA: 31s - loss: 0.5760 - accuracy: 0.828 - ETA: 30s - loss: 0.5772 - accuracy: 0.828 - ETA: 29s - loss: 0.5757 - accuracy: 0.829 - ETA: 29s - loss: 0.5736 - accuracy: 0.829 - ETA: 28s - loss: 0.5718 - accuracy: 0.829 - ETA: 27s - loss: 0.5741 - accuracy: 0.829 - ETA: 26s - loss: 0.5749 - accuracy: 0.828 - ETA: 26s - loss: 0.5731 - accuracy: 0.829 - ETA: 25s - loss: 0.5697 - accuracy: 0.829 - ETA: 24s - loss: 0.5671 - accuracy: 0.830 - ETA: 24s - loss: 0.5669 - accuracy: 0.830 - ETA: 23s - loss: 0.5653 - accuracy: 0.831 - ETA: 22s - loss: 0.5655 - accuracy: 0.831 - ETA: 22s - loss: 0.5649 - accuracy: 0.831 - ETA: 21s - loss: 0.5657 - accuracy: 0.830 - ETA: 20s - loss: 0.5656 - accuracy: 0.830 - ETA: 19s - loss: 0.5677 - accuracy: 0.830 - ETA: 19s - loss: 0.5689 - accuracy: 0.830 - ETA: 18s - loss: 0.5681 - accuracy: 0.830 - ETA: 17s - loss: 0.5684 - accuracy: 0.830 - ETA: 17s - loss: 0.5677 - accuracy: 0.830 - ETA: 16s - loss: 0.5688 - accuracy: 0.830 - ETA: 15s - loss: 0.5711 - accuracy: 0.830 - ETA: 15s - loss: 0.5679 - accuracy: 0.831 - ETA: 14s - loss: 0.5682 - accuracy: 0.830 - ETA: 13s - loss: 0.5682 - accuracy: 0.831 - ETA: 13s - loss: 0.5685 - accuracy: 0.830 - ETA: 12s - loss: 0.5701 - accuracy: 0.831 - ETA: 11s - loss: 0.5701 - accuracy: 0.830 - ETA: 10s - loss: 0.5697 - accuracy: 0.830 - ETA: 10s - loss: 0.5679 - accuracy: 0.831 - ETA: 9s - loss: 0.5680 - accuracy: 0.831 - ETA: 8s - loss: 0.5696 - accuracy: 0.83 - ETA: 8s - loss: 0.5698 - accuracy: 0.83 - ETA: 7s - loss: 0.5686 - accuracy: 0.83 - ETA: 6s - loss: 0.5672 - accuracy: 0.83 - ETA: 6s - loss: 0.5685 - accuracy: 0.83 - ETA: 5s - loss: 0.5678 - accuracy: 0.83 - ETA: 4s - loss: 0.5679 - accuracy: 0.83 - ETA: 3s - loss: 0.5698 - accuracy: 0.83 - ETA: 3s - loss: 0.5696 - accuracy: 0.83 - ETA: 2s - loss: 0.5676 - accuracy: 0.83 - ETA: 1s - loss: 0.5665 - accuracy: 0.83 - ETA: 1s - loss: 0.5662 - accuracy: 0.83 - ETA: 0s - loss: 0.5675 - accuracy: 0.83 - 82s 6ms/step - loss: 0.5676 - accuracy: 0.8310 - val_loss: 3.2131 - val_accuracy: 0.3306\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.6574 - accuracy: 0.82 - ETA: 1:10 - loss: 0.6082 - accuracy: 0.82 - ETA: 1:08 - loss: 0.6079 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5791 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5712 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5958 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5811 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5873 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5777 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5778 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5735 - accuracy: 0.82 - ETA: 1:02 - loss: 0.5650 - accuracy: 0.82 - ETA: 1:01 - loss: 0.5613 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5524 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5396 - accuracy: 0.83 - ETA: 59s - loss: 0.5356 - accuracy: 0.8389 - ETA: 58s - loss: 0.5346 - accuracy: 0.839 - ETA: 58s - loss: 0.5393 - accuracy: 0.837 - ETA: 57s - loss: 0.5428 - accuracy: 0.836 - ETA: 56s - loss: 0.5533 - accuracy: 0.834 - ETA: 55s - loss: 0.5515 - accuracy: 0.834 - ETA: 55s - loss: 0.5475 - accuracy: 0.834 - ETA: 54s - loss: 0.5456 - accuracy: 0.834 - ETA: 53s - loss: 0.5500 - accuracy: 0.834 - ETA: 53s - loss: 0.5506 - accuracy: 0.834 - ETA: 52s - loss: 0.5438 - accuracy: 0.835 - ETA: 51s - loss: 0.5398 - accuracy: 0.836 - ETA: 51s - loss: 0.5409 - accuracy: 0.835 - ETA: 50s - loss: 0.5366 - accuracy: 0.836 - ETA: 49s - loss: 0.5353 - accuracy: 0.835 - ETA: 49s - loss: 0.5353 - accuracy: 0.836 - ETA: 48s - loss: 0.5296 - accuracy: 0.838 - ETA: 47s - loss: 0.5325 - accuracy: 0.837 - ETA: 46s - loss: 0.5392 - accuracy: 0.836 - ETA: 46s - loss: 0.5451 - accuracy: 0.833 - ETA: 45s - loss: 0.5477 - accuracy: 0.833 - ETA: 44s - loss: 0.5501 - accuracy: 0.833 - ETA: 44s - loss: 0.5495 - accuracy: 0.833 - ETA: 43s - loss: 0.5496 - accuracy: 0.832 - ETA: 42s - loss: 0.5532 - accuracy: 0.831 - ETA: 42s - loss: 0.5546 - accuracy: 0.831 - ETA: 41s - loss: 0.5554 - accuracy: 0.831 - ETA: 40s - loss: 0.5618 - accuracy: 0.829 - ETA: 39s - loss: 0.5650 - accuracy: 0.828 - ETA: 39s - loss: 0.5685 - accuracy: 0.828 - ETA: 38s - loss: 0.5701 - accuracy: 0.827 - ETA: 37s - loss: 0.5667 - accuracy: 0.828 - ETA: 37s - loss: 0.5637 - accuracy: 0.829 - ETA: 36s - loss: 0.5632 - accuracy: 0.828 - ETA: 35s - loss: 0.5637 - accuracy: 0.829 - ETA: 35s - loss: 0.5636 - accuracy: 0.828 - ETA: 34s - loss: 0.5616 - accuracy: 0.829 - ETA: 33s - loss: 0.5589 - accuracy: 0.830 - ETA: 33s - loss: 0.5565 - accuracy: 0.830 - ETA: 32s - loss: 0.5543 - accuracy: 0.830 - ETA: 31s - loss: 0.5530 - accuracy: 0.831 - ETA: 30s - loss: 0.5535 - accuracy: 0.831 - ETA: 30s - loss: 0.5567 - accuracy: 0.830 - ETA: 29s - loss: 0.5542 - accuracy: 0.830 - ETA: 28s - loss: 0.5531 - accuracy: 0.831 - ETA: 28s - loss: 0.5560 - accuracy: 0.830 - ETA: 27s - loss: 0.5562 - accuracy: 0.830 - ETA: 26s - loss: 0.5533 - accuracy: 0.830 - ETA: 26s - loss: 0.5534 - accuracy: 0.830 - ETA: 25s - loss: 0.5568 - accuracy: 0.830 - ETA: 24s - loss: 0.5579 - accuracy: 0.829 - ETA: 24s - loss: 0.5558 - accuracy: 0.830 - ETA: 23s - loss: 0.5572 - accuracy: 0.830 - ETA: 22s - loss: 0.5567 - accuracy: 0.830 - ETA: 22s - loss: 0.5547 - accuracy: 0.831 - ETA: 21s - loss: 0.5535 - accuracy: 0.831 - ETA: 20s - loss: 0.5532 - accuracy: 0.831 - ETA: 19s - loss: 0.5537 - accuracy: 0.831 - ETA: 19s - loss: 0.5565 - accuracy: 0.831 - ETA: 18s - loss: 0.5543 - accuracy: 0.831 - ETA: 17s - loss: 0.5535 - accuracy: 0.832 - ETA: 17s - loss: 0.5529 - accuracy: 0.832 - ETA: 16s - loss: 0.5536 - accuracy: 0.832 - ETA: 15s - loss: 0.5527 - accuracy: 0.832 - ETA: 15s - loss: 0.5512 - accuracy: 0.832 - ETA: 14s - loss: 0.5508 - accuracy: 0.832 - ETA: 13s - loss: 0.5490 - accuracy: 0.833 - ETA: 12s - loss: 0.5510 - accuracy: 0.832 - ETA: 12s - loss: 0.5502 - accuracy: 0.833 - ETA: 11s - loss: 0.5490 - accuracy: 0.832 - ETA: 10s - loss: 0.5490 - accuracy: 0.833 - ETA: 10s - loss: 0.5487 - accuracy: 0.833 - ETA: 9s - loss: 0.5485 - accuracy: 0.833 - ETA: 8s - loss: 0.5490 - accuracy: 0.83 - ETA: 8s - loss: 0.5512 - accuracy: 0.83 - ETA: 7s - loss: 0.5505 - accuracy: 0.83 - ETA: 6s - loss: 0.5518 - accuracy: 0.83 - ETA: 6s - loss: 0.5500 - accuracy: 0.83 - ETA: 5s - loss: 0.5486 - accuracy: 0.83 - ETA: 4s - loss: 0.5498 - accuracy: 0.83 - ETA: 3s - loss: 0.5505 - accuracy: 0.83 - ETA: 3s - loss: 0.5491 - accuracy: 0.83 - ETA: 2s - loss: 0.5514 - accuracy: 0.83 - ETA: 1s - loss: 0.5512 - accuracy: 0.83 - ETA: 1s - loss: 0.5511 - accuracy: 0.83 - ETA: 0s - loss: 0.5497 - accuracy: 0.83 - 81s 6ms/step - loss: 0.5500 - accuracy: 0.8332 - val_loss: 3.4510 - val_accuracy: 0.3142\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.4849 - accuracy: 0.83 - ETA: 1:10 - loss: 0.5206 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5673 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5501 - accuracy: 0.83 - ETA: 1:08 - loss: 0.5195 - accuracy: 0.84 - ETA: 1:07 - loss: 0.5062 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4967 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5165 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4996 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5138 - accuracy: 0.84 - ETA: 1:02 - loss: 0.4892 - accuracy: 0.84 - ETA: 1:02 - loss: 0.4905 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4836 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4836 - accuracy: 0.84 - ETA: 59s - loss: 0.4873 - accuracy: 0.8474 - ETA: 59s - loss: 0.4854 - accuracy: 0.848 - ETA: 58s - loss: 0.5093 - accuracy: 0.844 - ETA: 57s - loss: 0.5080 - accuracy: 0.844 - ETA: 56s - loss: 0.5122 - accuracy: 0.840 - ETA: 56s - loss: 0.5027 - accuracy: 0.843 - ETA: 55s - loss: 0.5054 - accuracy: 0.843 - ETA: 55s - loss: 0.5022 - accuracy: 0.844 - ETA: 54s - loss: 0.4996 - accuracy: 0.845 - ETA: 54s - loss: 0.5001 - accuracy: 0.844 - ETA: 53s - loss: 0.5001 - accuracy: 0.845 - ETA: 52s - loss: 0.4989 - accuracy: 0.845 - ETA: 51s - loss: 0.4985 - accuracy: 0.845 - ETA: 51s - loss: 0.4967 - accuracy: 0.845 - ETA: 50s - loss: 0.4956 - accuracy: 0.845 - ETA: 49s - loss: 0.5053 - accuracy: 0.845 - ETA: 49s - loss: 0.5098 - accuracy: 0.844 - ETA: 48s - loss: 0.5050 - accuracy: 0.844 - ETA: 47s - loss: 0.5070 - accuracy: 0.844 - ETA: 46s - loss: 0.5061 - accuracy: 0.844 - ETA: 46s - loss: 0.5065 - accuracy: 0.844 - ETA: 45s - loss: 0.5048 - accuracy: 0.845 - ETA: 44s - loss: 0.5127 - accuracy: 0.843 - ETA: 44s - loss: 0.5107 - accuracy: 0.844 - ETA: 43s - loss: 0.5072 - accuracy: 0.844 - ETA: 42s - loss: 0.5162 - accuracy: 0.842 - ETA: 42s - loss: 0.5182 - accuracy: 0.842 - ETA: 41s - loss: 0.5228 - accuracy: 0.841 - ETA: 40s - loss: 0.5210 - accuracy: 0.841 - ETA: 40s - loss: 0.5232 - accuracy: 0.840 - ETA: 39s - loss: 0.5321 - accuracy: 0.839 - ETA: 38s - loss: 0.5315 - accuracy: 0.839 - ETA: 37s - loss: 0.5295 - accuracy: 0.839 - ETA: 37s - loss: 0.5327 - accuracy: 0.838 - ETA: 36s - loss: 0.5338 - accuracy: 0.838 - ETA: 35s - loss: 0.5359 - accuracy: 0.838 - ETA: 35s - loss: 0.5406 - accuracy: 0.837 - ETA: 34s - loss: 0.5414 - accuracy: 0.836 - ETA: 33s - loss: 0.5416 - accuracy: 0.837 - ETA: 32s - loss: 0.5417 - accuracy: 0.836 - ETA: 32s - loss: 0.5404 - accuracy: 0.836 - ETA: 31s - loss: 0.5396 - accuracy: 0.836 - ETA: 30s - loss: 0.5401 - accuracy: 0.836 - ETA: 30s - loss: 0.5430 - accuracy: 0.835 - ETA: 29s - loss: 0.5453 - accuracy: 0.835 - ETA: 28s - loss: 0.5436 - accuracy: 0.835 - ETA: 28s - loss: 0.5461 - accuracy: 0.834 - ETA: 27s - loss: 0.5469 - accuracy: 0.833 - ETA: 26s - loss: 0.5454 - accuracy: 0.834 - ETA: 26s - loss: 0.5456 - accuracy: 0.834 - ETA: 25s - loss: 0.5453 - accuracy: 0.834 - ETA: 24s - loss: 0.5456 - accuracy: 0.834 - ETA: 24s - loss: 0.5466 - accuracy: 0.833 - ETA: 23s - loss: 0.5460 - accuracy: 0.834 - ETA: 22s - loss: 0.5430 - accuracy: 0.835 - ETA: 22s - loss: 0.5453 - accuracy: 0.833 - ETA: 21s - loss: 0.5450 - accuracy: 0.833 - ETA: 20s - loss: 0.5443 - accuracy: 0.833 - ETA: 19s - loss: 0.5464 - accuracy: 0.833 - ETA: 19s - loss: 0.5485 - accuracy: 0.833 - ETA: 18s - loss: 0.5528 - accuracy: 0.831 - ETA: 17s - loss: 0.5502 - accuracy: 0.832 - ETA: 17s - loss: 0.5497 - accuracy: 0.832 - ETA: 16s - loss: 0.5519 - accuracy: 0.832 - ETA: 15s - loss: 0.5545 - accuracy: 0.832 - ETA: 15s - loss: 0.5529 - accuracy: 0.832 - ETA: 14s - loss: 0.5556 - accuracy: 0.831 - ETA: 13s - loss: 0.5580 - accuracy: 0.831 - ETA: 13s - loss: 0.5622 - accuracy: 0.830 - ETA: 12s - loss: 0.5604 - accuracy: 0.831 - ETA: 11s - loss: 0.5608 - accuracy: 0.831 - ETA: 10s - loss: 0.5605 - accuracy: 0.831 - ETA: 10s - loss: 0.5611 - accuracy: 0.831 - ETA: 9s - loss: 0.5609 - accuracy: 0.831 - ETA: 8s - loss: 0.5632 - accuracy: 0.83 - ETA: 8s - loss: 0.5622 - accuracy: 0.83 - ETA: 7s - loss: 0.5625 - accuracy: 0.83 - ETA: 6s - loss: 0.5626 - accuracy: 0.83 - ETA: 6s - loss: 0.5617 - accuracy: 0.83 - ETA: 5s - loss: 0.5619 - accuracy: 0.83 - ETA: 4s - loss: 0.5615 - accuracy: 0.83 - ETA: 3s - loss: 0.5618 - accuracy: 0.83 - ETA: 3s - loss: 0.5633 - accuracy: 0.83 - ETA: 2s - loss: 0.5630 - accuracy: 0.83 - ETA: 1s - loss: 0.5647 - accuracy: 0.83 - ETA: 1s - loss: 0.5638 - accuracy: 0.83 - ETA: 0s - loss: 0.5624 - accuracy: 0.83 - 81s 6ms/step - loss: 0.5624 - accuracy: 0.8321 - val_loss: 3.2353 - val_accuracy: 0.3238\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.4435 - accuracy: 0.87 - ETA: 1:09 - loss: 0.4687 - accuracy: 0.85 - ETA: 1:08 - loss: 0.4479 - accuracy: 0.86 - ETA: 1:07 - loss: 0.4998 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5043 - accuracy: 0.85 - ETA: 1:05 - loss: 0.4853 - accuracy: 0.85 - ETA: 1:05 - loss: 0.4948 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5026 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5180 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5466 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5414 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5321 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5356 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5462 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5438 - accuracy: 0.84 - ETA: 59s - loss: 0.5409 - accuracy: 0.8408 - ETA: 59s - loss: 0.5533 - accuracy: 0.836 - ETA: 58s - loss: 0.5469 - accuracy: 0.838 - ETA: 57s - loss: 0.5462 - accuracy: 0.838 - ETA: 57s - loss: 0.5451 - accuracy: 0.839 - ETA: 56s - loss: 0.5414 - accuracy: 0.839 - ETA: 55s - loss: 0.5365 - accuracy: 0.839 - ETA: 54s - loss: 0.5347 - accuracy: 0.839 - ETA: 54s - loss: 0.5399 - accuracy: 0.837 - ETA: 53s - loss: 0.5369 - accuracy: 0.838 - ETA: 52s - loss: 0.5343 - accuracy: 0.837 - ETA: 52s - loss: 0.5313 - accuracy: 0.838 - ETA: 51s - loss: 0.5352 - accuracy: 0.838 - ETA: 50s - loss: 0.5311 - accuracy: 0.840 - ETA: 50s - loss: 0.5258 - accuracy: 0.841 - ETA: 49s - loss: 0.5301 - accuracy: 0.840 - ETA: 48s - loss: 0.5265 - accuracy: 0.841 - ETA: 47s - loss: 0.5294 - accuracy: 0.841 - ETA: 47s - loss: 0.5276 - accuracy: 0.842 - ETA: 46s - loss: 0.5271 - accuracy: 0.843 - ETA: 45s - loss: 0.5248 - accuracy: 0.843 - ETA: 44s - loss: 0.5241 - accuracy: 0.844 - ETA: 44s - loss: 0.5220 - accuracy: 0.844 - ETA: 43s - loss: 0.5244 - accuracy: 0.844 - ETA: 43s - loss: 0.5252 - accuracy: 0.844 - ETA: 42s - loss: 0.5250 - accuracy: 0.843 - ETA: 41s - loss: 0.5229 - accuracy: 0.843 - ETA: 41s - loss: 0.5280 - accuracy: 0.843 - ETA: 40s - loss: 0.5263 - accuracy: 0.842 - ETA: 39s - loss: 0.5253 - accuracy: 0.843 - ETA: 38s - loss: 0.5282 - accuracy: 0.843 - ETA: 38s - loss: 0.5283 - accuracy: 0.842 - ETA: 37s - loss: 0.5306 - accuracy: 0.843 - ETA: 36s - loss: 0.5292 - accuracy: 0.843 - ETA: 36s - loss: 0.5320 - accuracy: 0.842 - ETA: 35s - loss: 0.5335 - accuracy: 0.842 - ETA: 34s - loss: 0.5323 - accuracy: 0.842 - ETA: 33s - loss: 0.5361 - accuracy: 0.841 - ETA: 33s - loss: 0.5389 - accuracy: 0.840 - ETA: 32s - loss: 0.5396 - accuracy: 0.840 - ETA: 31s - loss: 0.5382 - accuracy: 0.840 - ETA: 31s - loss: 0.5354 - accuracy: 0.841 - ETA: 30s - loss: 0.5343 - accuracy: 0.841 - ETA: 29s - loss: 0.5313 - accuracy: 0.842 - ETA: 28s - loss: 0.5341 - accuracy: 0.841 - ETA: 28s - loss: 0.5339 - accuracy: 0.840 - ETA: 27s - loss: 0.5354 - accuracy: 0.841 - ETA: 26s - loss: 0.5320 - accuracy: 0.842 - ETA: 26s - loss: 0.5317 - accuracy: 0.842 - ETA: 25s - loss: 0.5304 - accuracy: 0.842 - ETA: 24s - loss: 0.5305 - accuracy: 0.842 - ETA: 24s - loss: 0.5294 - accuracy: 0.842 - ETA: 23s - loss: 0.5296 - accuracy: 0.842 - ETA: 22s - loss: 0.5329 - accuracy: 0.841 - ETA: 22s - loss: 0.5334 - accuracy: 0.841 - ETA: 21s - loss: 0.5309 - accuracy: 0.842 - ETA: 20s - loss: 0.5297 - accuracy: 0.842 - ETA: 19s - loss: 0.5280 - accuracy: 0.842 - ETA: 19s - loss: 0.5299 - accuracy: 0.842 - ETA: 18s - loss: 0.5298 - accuracy: 0.842 - ETA: 17s - loss: 0.5309 - accuracy: 0.841 - ETA: 17s - loss: 0.5312 - accuracy: 0.841 - ETA: 16s - loss: 0.5320 - accuracy: 0.841 - ETA: 15s - loss: 0.5348 - accuracy: 0.841 - ETA: 15s - loss: 0.5353 - accuracy: 0.840 - ETA: 14s - loss: 0.5353 - accuracy: 0.840 - ETA: 13s - loss: 0.5338 - accuracy: 0.840 - ETA: 12s - loss: 0.5345 - accuracy: 0.840 - ETA: 12s - loss: 0.5363 - accuracy: 0.840 - ETA: 11s - loss: 0.5368 - accuracy: 0.840 - ETA: 10s - loss: 0.5355 - accuracy: 0.840 - ETA: 10s - loss: 0.5357 - accuracy: 0.840 - ETA: 9s - loss: 0.5340 - accuracy: 0.840 - ETA: 8s - loss: 0.5317 - accuracy: 0.84 - ETA: 8s - loss: 0.5313 - accuracy: 0.84 - ETA: 7s - loss: 0.5325 - accuracy: 0.84 - ETA: 6s - loss: 0.5327 - accuracy: 0.84 - ETA: 6s - loss: 0.5322 - accuracy: 0.84 - ETA: 5s - loss: 0.5333 - accuracy: 0.84 - ETA: 4s - loss: 0.5320 - accuracy: 0.84 - ETA: 3s - loss: 0.5335 - accuracy: 0.84 - ETA: 3s - loss: 0.5349 - accuracy: 0.84 - ETA: 2s - loss: 0.5365 - accuracy: 0.84 - ETA: 1s - loss: 0.5364 - accuracy: 0.84 - ETA: 1s - loss: 0.5383 - accuracy: 0.83 - ETA: 0s - loss: 0.5366 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5377 - accuracy: 0.8402 - val_loss: 3.2601 - val_accuracy: 0.3209\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.7300 - accuracy: 0.77 - ETA: 1:09 - loss: 0.6166 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5652 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5598 - accuracy: 0.82 - ETA: 1:07 - loss: 0.5660 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5375 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5605 - accuracy: 0.83 - ETA: 1:05 - loss: 0.5506 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5379 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5165 - accuracy: 0.85 - ETA: 1:03 - loss: 0.5295 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5246 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5204 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5291 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5280 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5320 - accuracy: 0.84 - ETA: 59s - loss: 0.5384 - accuracy: 0.8410 - ETA: 58s - loss: 0.5482 - accuracy: 0.837 - ETA: 58s - loss: 0.5540 - accuracy: 0.835 - ETA: 57s - loss: 0.5543 - accuracy: 0.835 - ETA: 57s - loss: 0.5576 - accuracy: 0.833 - ETA: 56s - loss: 0.5727 - accuracy: 0.829 - ETA: 55s - loss: 0.5764 - accuracy: 0.828 - ETA: 55s - loss: 0.5801 - accuracy: 0.826 - ETA: 54s - loss: 0.5764 - accuracy: 0.826 - ETA: 53s - loss: 0.5727 - accuracy: 0.826 - ETA: 52s - loss: 0.5748 - accuracy: 0.825 - ETA: 52s - loss: 0.5704 - accuracy: 0.827 - ETA: 51s - loss: 0.5694 - accuracy: 0.827 - ETA: 50s - loss: 0.5678 - accuracy: 0.827 - ETA: 49s - loss: 0.5677 - accuracy: 0.827 - ETA: 49s - loss: 0.5602 - accuracy: 0.829 - ETA: 48s - loss: 0.5559 - accuracy: 0.830 - ETA: 47s - loss: 0.5597 - accuracy: 0.829 - ETA: 46s - loss: 0.5614 - accuracy: 0.828 - ETA: 46s - loss: 0.5625 - accuracy: 0.828 - ETA: 45s - loss: 0.5639 - accuracy: 0.828 - ETA: 44s - loss: 0.5630 - accuracy: 0.827 - ETA: 44s - loss: 0.5643 - accuracy: 0.827 - ETA: 43s - loss: 0.5636 - accuracy: 0.826 - ETA: 42s - loss: 0.5628 - accuracy: 0.826 - ETA: 42s - loss: 0.5609 - accuracy: 0.826 - ETA: 41s - loss: 0.5610 - accuracy: 0.826 - ETA: 40s - loss: 0.5592 - accuracy: 0.826 - ETA: 39s - loss: 0.5595 - accuracy: 0.826 - ETA: 39s - loss: 0.5570 - accuracy: 0.827 - ETA: 38s - loss: 0.5540 - accuracy: 0.828 - ETA: 37s - loss: 0.5540 - accuracy: 0.829 - ETA: 36s - loss: 0.5525 - accuracy: 0.829 - ETA: 36s - loss: 0.5507 - accuracy: 0.829 - ETA: 35s - loss: 0.5514 - accuracy: 0.829 - ETA: 34s - loss: 0.5502 - accuracy: 0.829 - ETA: 34s - loss: 0.5522 - accuracy: 0.829 - ETA: 33s - loss: 0.5526 - accuracy: 0.829 - ETA: 32s - loss: 0.5500 - accuracy: 0.830 - ETA: 31s - loss: 0.5500 - accuracy: 0.829 - ETA: 31s - loss: 0.5492 - accuracy: 0.829 - ETA: 30s - loss: 0.5486 - accuracy: 0.829 - ETA: 29s - loss: 0.5470 - accuracy: 0.830 - ETA: 29s - loss: 0.5501 - accuracy: 0.830 - ETA: 28s - loss: 0.5499 - accuracy: 0.830 - ETA: 27s - loss: 0.5541 - accuracy: 0.829 - ETA: 27s - loss: 0.5542 - accuracy: 0.829 - ETA: 26s - loss: 0.5517 - accuracy: 0.829 - ETA: 25s - loss: 0.5543 - accuracy: 0.829 - ETA: 24s - loss: 0.5550 - accuracy: 0.829 - ETA: 24s - loss: 0.5545 - accuracy: 0.829 - ETA: 23s - loss: 0.5519 - accuracy: 0.830 - ETA: 22s - loss: 0.5515 - accuracy: 0.830 - ETA: 22s - loss: 0.5503 - accuracy: 0.831 - ETA: 21s - loss: 0.5482 - accuracy: 0.832 - ETA: 20s - loss: 0.5477 - accuracy: 0.832 - ETA: 20s - loss: 0.5459 - accuracy: 0.832 - ETA: 19s - loss: 0.5444 - accuracy: 0.833 - ETA: 18s - loss: 0.5445 - accuracy: 0.833 - ETA: 17s - loss: 0.5442 - accuracy: 0.833 - ETA: 17s - loss: 0.5447 - accuracy: 0.833 - ETA: 16s - loss: 0.5458 - accuracy: 0.833 - ETA: 15s - loss: 0.5469 - accuracy: 0.833 - ETA: 15s - loss: 0.5453 - accuracy: 0.833 - ETA: 14s - loss: 0.5436 - accuracy: 0.833 - ETA: 13s - loss: 0.5447 - accuracy: 0.833 - ETA: 13s - loss: 0.5448 - accuracy: 0.833 - ETA: 12s - loss: 0.5448 - accuracy: 0.833 - ETA: 11s - loss: 0.5442 - accuracy: 0.832 - ETA: 10s - loss: 0.5422 - accuracy: 0.833 - ETA: 10s - loss: 0.5399 - accuracy: 0.834 - ETA: 9s - loss: 0.5408 - accuracy: 0.834 - ETA: 8s - loss: 0.5407 - accuracy: 0.83 - ETA: 8s - loss: 0.5404 - accuracy: 0.83 - ETA: 7s - loss: 0.5400 - accuracy: 0.83 - ETA: 6s - loss: 0.5381 - accuracy: 0.83 - ETA: 6s - loss: 0.5364 - accuracy: 0.83 - ETA: 5s - loss: 0.5373 - accuracy: 0.83 - ETA: 4s - loss: 0.5386 - accuracy: 0.83 - ETA: 3s - loss: 0.5401 - accuracy: 0.83 - ETA: 3s - loss: 0.5395 - accuracy: 0.83 - ETA: 2s - loss: 0.5395 - accuracy: 0.83 - ETA: 1s - loss: 0.5397 - accuracy: 0.83 - ETA: 1s - loss: 0.5385 - accuracy: 0.83 - ETA: 0s - loss: 0.5390 - accuracy: 0.83 - 82s 6ms/step - loss: 0.5396 - accuracy: 0.8357 - val_loss: 3.2629 - val_accuracy: 0.3186\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:15 - loss: 0.4517 - accuracy: 0.85 - ETA: 1:11 - loss: 0.4971 - accuracy: 0.84 - ETA: 1:08 - loss: 0.4769 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5108 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5357 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5336 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5401 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5387 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5333 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5661 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5631 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5656 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5659 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5772 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5817 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5763 - accuracy: 0.83 - ETA: 59s - loss: 0.5821 - accuracy: 0.8332 - ETA: 58s - loss: 0.5765 - accuracy: 0.834 - ETA: 57s - loss: 0.5745 - accuracy: 0.834 - ETA: 57s - loss: 0.5756 - accuracy: 0.834 - ETA: 56s - loss: 0.5819 - accuracy: 0.832 - ETA: 55s - loss: 0.5837 - accuracy: 0.833 - ETA: 55s - loss: 0.5795 - accuracy: 0.835 - ETA: 54s - loss: 0.5737 - accuracy: 0.835 - ETA: 53s - loss: 0.5621 - accuracy: 0.838 - ETA: 52s - loss: 0.5642 - accuracy: 0.839 - ETA: 52s - loss: 0.5608 - accuracy: 0.840 - ETA: 51s - loss: 0.5613 - accuracy: 0.838 - ETA: 50s - loss: 0.5684 - accuracy: 0.837 - ETA: 49s - loss: 0.5696 - accuracy: 0.835 - ETA: 49s - loss: 0.5758 - accuracy: 0.833 - ETA: 48s - loss: 0.5721 - accuracy: 0.835 - ETA: 47s - loss: 0.5713 - accuracy: 0.834 - ETA: 47s - loss: 0.5706 - accuracy: 0.834 - ETA: 46s - loss: 0.5689 - accuracy: 0.834 - ETA: 45s - loss: 0.5685 - accuracy: 0.835 - ETA: 45s - loss: 0.5708 - accuracy: 0.834 - ETA: 44s - loss: 0.5691 - accuracy: 0.835 - ETA: 43s - loss: 0.5647 - accuracy: 0.836 - ETA: 43s - loss: 0.5641 - accuracy: 0.836 - ETA: 42s - loss: 0.5640 - accuracy: 0.836 - ETA: 41s - loss: 0.5665 - accuracy: 0.835 - ETA: 40s - loss: 0.5659 - accuracy: 0.835 - ETA: 40s - loss: 0.5656 - accuracy: 0.836 - ETA: 39s - loss: 0.5640 - accuracy: 0.835 - ETA: 38s - loss: 0.5649 - accuracy: 0.834 - ETA: 38s - loss: 0.5618 - accuracy: 0.834 - ETA: 37s - loss: 0.5593 - accuracy: 0.835 - ETA: 36s - loss: 0.5574 - accuracy: 0.835 - ETA: 35s - loss: 0.5574 - accuracy: 0.835 - ETA: 35s - loss: 0.5550 - accuracy: 0.836 - ETA: 34s - loss: 0.5527 - accuracy: 0.836 - ETA: 33s - loss: 0.5494 - accuracy: 0.838 - ETA: 33s - loss: 0.5470 - accuracy: 0.838 - ETA: 32s - loss: 0.5480 - accuracy: 0.838 - ETA: 31s - loss: 0.5481 - accuracy: 0.838 - ETA: 30s - loss: 0.5507 - accuracy: 0.837 - ETA: 30s - loss: 0.5501 - accuracy: 0.837 - ETA: 29s - loss: 0.5535 - accuracy: 0.836 - ETA: 28s - loss: 0.5553 - accuracy: 0.836 - ETA: 28s - loss: 0.5521 - accuracy: 0.837 - ETA: 27s - loss: 0.5525 - accuracy: 0.837 - ETA: 26s - loss: 0.5525 - accuracy: 0.837 - ETA: 26s - loss: 0.5527 - accuracy: 0.837 - ETA: 25s - loss: 0.5528 - accuracy: 0.837 - ETA: 24s - loss: 0.5518 - accuracy: 0.837 - ETA: 24s - loss: 0.5519 - accuracy: 0.837 - ETA: 23s - loss: 0.5497 - accuracy: 0.837 - ETA: 22s - loss: 0.5520 - accuracy: 0.837 - ETA: 22s - loss: 0.5506 - accuracy: 0.837 - ETA: 21s - loss: 0.5503 - accuracy: 0.837 - ETA: 20s - loss: 0.5506 - accuracy: 0.836 - ETA: 19s - loss: 0.5492 - accuracy: 0.837 - ETA: 19s - loss: 0.5497 - accuracy: 0.837 - ETA: 18s - loss: 0.5477 - accuracy: 0.837 - ETA: 17s - loss: 0.5478 - accuracy: 0.837 - ETA: 17s - loss: 0.5486 - accuracy: 0.837 - ETA: 16s - loss: 0.5503 - accuracy: 0.837 - ETA: 15s - loss: 0.5523 - accuracy: 0.837 - ETA: 15s - loss: 0.5500 - accuracy: 0.837 - ETA: 14s - loss: 0.5505 - accuracy: 0.837 - ETA: 13s - loss: 0.5483 - accuracy: 0.838 - ETA: 12s - loss: 0.5474 - accuracy: 0.838 - ETA: 12s - loss: 0.5455 - accuracy: 0.838 - ETA: 11s - loss: 0.5463 - accuracy: 0.838 - ETA: 10s - loss: 0.5488 - accuracy: 0.838 - ETA: 10s - loss: 0.5485 - accuracy: 0.838 - ETA: 9s - loss: 0.5479 - accuracy: 0.838 - ETA: 8s - loss: 0.5472 - accuracy: 0.83 - ETA: 8s - loss: 0.5484 - accuracy: 0.83 - ETA: 7s - loss: 0.5486 - accuracy: 0.83 - ETA: 6s - loss: 0.5483 - accuracy: 0.83 - ETA: 6s - loss: 0.5478 - accuracy: 0.83 - ETA: 5s - loss: 0.5478 - accuracy: 0.83 - ETA: 4s - loss: 0.5478 - accuracy: 0.83 - ETA: 3s - loss: 0.5498 - accuracy: 0.83 - ETA: 3s - loss: 0.5500 - accuracy: 0.83 - ETA: 2s - loss: 0.5500 - accuracy: 0.83 - ETA: 1s - loss: 0.5510 - accuracy: 0.83 - ETA: 1s - loss: 0.5512 - accuracy: 0.83 - ETA: 0s - loss: 0.5511 - accuracy: 0.83 - 81s 6ms/step - loss: 0.5508 - accuracy: 0.8370 - val_loss: 3.2863 - val_accuracy: 0.3184\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:14 - loss: 0.4623 - accuracy: 0.86 - ETA: 1:12 - loss: 0.4957 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4462 - accuracy: 0.86 - ETA: 1:10 - loss: 0.5047 - accuracy: 0.85 - ETA: 1:08 - loss: 0.4741 - accuracy: 0.86 - ETA: 1:07 - loss: 0.4761 - accuracy: 0.85 - ETA: 1:06 - loss: 0.4880 - accuracy: 0.85 - ETA: 1:05 - loss: 0.4922 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4989 - accuracy: 0.84 - ETA: 1:04 - loss: 0.4916 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5107 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5096 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5152 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5314 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5555 - accuracy: 0.83 - ETA: 59s - loss: 0.5536 - accuracy: 0.8398 - ETA: 59s - loss: 0.5415 - accuracy: 0.843 - ETA: 58s - loss: 0.5420 - accuracy: 0.841 - ETA: 57s - loss: 0.5556 - accuracy: 0.835 - ETA: 56s - loss: 0.5537 - accuracy: 0.835 - ETA: 55s - loss: 0.5462 - accuracy: 0.836 - ETA: 55s - loss: 0.5518 - accuracy: 0.836 - ETA: 54s - loss: 0.5540 - accuracy: 0.835 - ETA: 53s - loss: 0.5549 - accuracy: 0.835 - ETA: 53s - loss: 0.5547 - accuracy: 0.835 - ETA: 52s - loss: 0.5491 - accuracy: 0.837 - ETA: 51s - loss: 0.5627 - accuracy: 0.837 - ETA: 50s - loss: 0.5559 - accuracy: 0.839 - ETA: 50s - loss: 0.5592 - accuracy: 0.840 - ETA: 49s - loss: 0.5563 - accuracy: 0.841 - ETA: 48s - loss: 0.5519 - accuracy: 0.843 - ETA: 48s - loss: 0.5498 - accuracy: 0.844 - ETA: 47s - loss: 0.5482 - accuracy: 0.843 - ETA: 46s - loss: 0.5497 - accuracy: 0.842 - ETA: 46s - loss: 0.5479 - accuracy: 0.843 - ETA: 45s - loss: 0.5490 - accuracy: 0.843 - ETA: 44s - loss: 0.5507 - accuracy: 0.842 - ETA: 44s - loss: 0.5458 - accuracy: 0.844 - ETA: 43s - loss: 0.5440 - accuracy: 0.844 - ETA: 42s - loss: 0.5450 - accuracy: 0.843 - ETA: 42s - loss: 0.5428 - accuracy: 0.844 - ETA: 41s - loss: 0.5414 - accuracy: 0.844 - ETA: 40s - loss: 0.5391 - accuracy: 0.845 - ETA: 40s - loss: 0.5405 - accuracy: 0.844 - ETA: 39s - loss: 0.5390 - accuracy: 0.844 - ETA: 38s - loss: 0.5370 - accuracy: 0.845 - ETA: 37s - loss: 0.5336 - accuracy: 0.845 - ETA: 37s - loss: 0.5323 - accuracy: 0.846 - ETA: 36s - loss: 0.5293 - accuracy: 0.846 - ETA: 35s - loss: 0.5308 - accuracy: 0.846 - ETA: 35s - loss: 0.5331 - accuracy: 0.845 - ETA: 34s - loss: 0.5349 - accuracy: 0.843 - ETA: 33s - loss: 0.5359 - accuracy: 0.843 - ETA: 32s - loss: 0.5374 - accuracy: 0.842 - ETA: 32s - loss: 0.5361 - accuracy: 0.843 - ETA: 31s - loss: 0.5377 - accuracy: 0.842 - ETA: 30s - loss: 0.5363 - accuracy: 0.842 - ETA: 30s - loss: 0.5364 - accuracy: 0.842 - ETA: 29s - loss: 0.5357 - accuracy: 0.843 - ETA: 28s - loss: 0.5348 - accuracy: 0.843 - ETA: 28s - loss: 0.5323 - accuracy: 0.844 - ETA: 27s - loss: 0.5348 - accuracy: 0.844 - ETA: 26s - loss: 0.5370 - accuracy: 0.843 - ETA: 26s - loss: 0.5376 - accuracy: 0.843 - ETA: 25s - loss: 0.5378 - accuracy: 0.842 - ETA: 24s - loss: 0.5396 - accuracy: 0.841 - ETA: 24s - loss: 0.5382 - accuracy: 0.842 - ETA: 23s - loss: 0.5373 - accuracy: 0.842 - ETA: 22s - loss: 0.5385 - accuracy: 0.841 - ETA: 22s - loss: 0.5401 - accuracy: 0.841 - ETA: 21s - loss: 0.5384 - accuracy: 0.842 - ETA: 20s - loss: 0.5380 - accuracy: 0.842 - ETA: 19s - loss: 0.5363 - accuracy: 0.842 - ETA: 19s - loss: 0.5372 - accuracy: 0.842 - ETA: 18s - loss: 0.5389 - accuracy: 0.842 - ETA: 17s - loss: 0.5380 - accuracy: 0.842 - ETA: 17s - loss: 0.5363 - accuracy: 0.842 - ETA: 16s - loss: 0.5371 - accuracy: 0.842 - ETA: 15s - loss: 0.5373 - accuracy: 0.842 - ETA: 15s - loss: 0.5354 - accuracy: 0.843 - ETA: 14s - loss: 0.5337 - accuracy: 0.843 - ETA: 13s - loss: 0.5346 - accuracy: 0.842 - ETA: 13s - loss: 0.5339 - accuracy: 0.842 - ETA: 12s - loss: 0.5339 - accuracy: 0.842 - ETA: 11s - loss: 0.5333 - accuracy: 0.842 - ETA: 10s - loss: 0.5330 - accuracy: 0.842 - ETA: 10s - loss: 0.5328 - accuracy: 0.842 - ETA: 9s - loss: 0.5358 - accuracy: 0.841 - ETA: 8s - loss: 0.5356 - accuracy: 0.84 - ETA: 8s - loss: 0.5342 - accuracy: 0.84 - ETA: 7s - loss: 0.5352 - accuracy: 0.84 - ETA: 6s - loss: 0.5327 - accuracy: 0.84 - ETA: 6s - loss: 0.5324 - accuracy: 0.84 - ETA: 5s - loss: 0.5320 - accuracy: 0.84 - ETA: 4s - loss: 0.5311 - accuracy: 0.84 - ETA: 3s - loss: 0.5316 - accuracy: 0.84 - ETA: 3s - loss: 0.5320 - accuracy: 0.84 - ETA: 2s - loss: 0.5335 - accuracy: 0.84 - ETA: 1s - loss: 0.5321 - accuracy: 0.84 - ETA: 1s - loss: 0.5320 - accuracy: 0.84 - ETA: 0s - loss: 0.5324 - accuracy: 0.84 - 82s 6ms/step - loss: 0.5314 - accuracy: 0.8423 - val_loss: 3.2090 - val_accuracy: 0.3325\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:18 - loss: 0.5230 - accuracy: 0.86 - ETA: 1:14 - loss: 0.4820 - accuracy: 0.86 - ETA: 1:11 - loss: 0.4904 - accuracy: 0.86 - ETA: 1:09 - loss: 0.4877 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4685 - accuracy: 0.86 - ETA: 1:07 - loss: 0.4557 - accuracy: 0.86 - ETA: 1:07 - loss: 0.4279 - accuracy: 0.87 - ETA: 1:06 - loss: 0.4374 - accuracy: 0.86 - ETA: 1:05 - loss: 0.4582 - accuracy: 0.86 - ETA: 1:04 - loss: 0.4639 - accuracy: 0.86 - ETA: 1:04 - loss: 0.4610 - accuracy: 0.86 - ETA: 1:03 - loss: 0.4700 - accuracy: 0.86 - ETA: 1:02 - loss: 0.4645 - accuracy: 0.86 - ETA: 1:01 - loss: 0.4743 - accuracy: 0.86 - ETA: 1:00 - loss: 0.4814 - accuracy: 0.86 - ETA: 1:00 - loss: 0.4822 - accuracy: 0.86 - ETA: 59s - loss: 0.4791 - accuracy: 0.8621 - ETA: 58s - loss: 0.4850 - accuracy: 0.860 - ETA: 57s - loss: 0.4842 - accuracy: 0.859 - ETA: 57s - loss: 0.4804 - accuracy: 0.860 - ETA: 56s - loss: 0.4881 - accuracy: 0.857 - ETA: 56s - loss: 0.4921 - accuracy: 0.855 - ETA: 55s - loss: 0.5004 - accuracy: 0.855 - ETA: 54s - loss: 0.5072 - accuracy: 0.852 - ETA: 53s - loss: 0.5115 - accuracy: 0.851 - ETA: 53s - loss: 0.5139 - accuracy: 0.850 - ETA: 52s - loss: 0.5081 - accuracy: 0.850 - ETA: 51s - loss: 0.5034 - accuracy: 0.851 - ETA: 50s - loss: 0.5017 - accuracy: 0.851 - ETA: 50s - loss: 0.5046 - accuracy: 0.850 - ETA: 49s - loss: 0.5004 - accuracy: 0.852 - ETA: 48s - loss: 0.5050 - accuracy: 0.850 - ETA: 48s - loss: 0.5033 - accuracy: 0.851 - ETA: 47s - loss: 0.5078 - accuracy: 0.850 - ETA: 46s - loss: 0.5101 - accuracy: 0.850 - ETA: 45s - loss: 0.5106 - accuracy: 0.849 - ETA: 45s - loss: 0.5123 - accuracy: 0.849 - ETA: 44s - loss: 0.5143 - accuracy: 0.849 - ETA: 43s - loss: 0.5162 - accuracy: 0.849 - ETA: 43s - loss: 0.5197 - accuracy: 0.847 - ETA: 42s - loss: 0.5205 - accuracy: 0.847 - ETA: 41s - loss: 0.5213 - accuracy: 0.847 - ETA: 40s - loss: 0.5235 - accuracy: 0.846 - ETA: 40s - loss: 0.5238 - accuracy: 0.847 - ETA: 39s - loss: 0.5225 - accuracy: 0.847 - ETA: 38s - loss: 0.5204 - accuracy: 0.847 - ETA: 38s - loss: 0.5191 - accuracy: 0.847 - ETA: 37s - loss: 0.5180 - accuracy: 0.847 - ETA: 36s - loss: 0.5166 - accuracy: 0.847 - ETA: 36s - loss: 0.5173 - accuracy: 0.847 - ETA: 35s - loss: 0.5169 - accuracy: 0.848 - ETA: 34s - loss: 0.5194 - accuracy: 0.847 - ETA: 34s - loss: 0.5189 - accuracy: 0.847 - ETA: 33s - loss: 0.5149 - accuracy: 0.848 - ETA: 32s - loss: 0.5144 - accuracy: 0.848 - ETA: 31s - loss: 0.5141 - accuracy: 0.848 - ETA: 31s - loss: 0.5159 - accuracy: 0.848 - ETA: 30s - loss: 0.5161 - accuracy: 0.848 - ETA: 29s - loss: 0.5146 - accuracy: 0.848 - ETA: 29s - loss: 0.5143 - accuracy: 0.847 - ETA: 28s - loss: 0.5149 - accuracy: 0.847 - ETA: 27s - loss: 0.5158 - accuracy: 0.847 - ETA: 27s - loss: 0.5168 - accuracy: 0.847 - ETA: 26s - loss: 0.5194 - accuracy: 0.846 - ETA: 25s - loss: 0.5211 - accuracy: 0.846 - ETA: 24s - loss: 0.5201 - accuracy: 0.847 - ETA: 24s - loss: 0.5170 - accuracy: 0.847 - ETA: 23s - loss: 0.5176 - accuracy: 0.847 - ETA: 22s - loss: 0.5168 - accuracy: 0.846 - ETA: 22s - loss: 0.5161 - accuracy: 0.847 - ETA: 21s - loss: 0.5176 - accuracy: 0.847 - ETA: 20s - loss: 0.5166 - accuracy: 0.847 - ETA: 20s - loss: 0.5194 - accuracy: 0.846 - ETA: 19s - loss: 0.5185 - accuracy: 0.846 - ETA: 18s - loss: 0.5187 - accuracy: 0.847 - ETA: 17s - loss: 0.5185 - accuracy: 0.846 - ETA: 17s - loss: 0.5180 - accuracy: 0.846 - ETA: 16s - loss: 0.5189 - accuracy: 0.846 - ETA: 15s - loss: 0.5205 - accuracy: 0.845 - ETA: 15s - loss: 0.5216 - accuracy: 0.845 - ETA: 14s - loss: 0.5244 - accuracy: 0.845 - ETA: 13s - loss: 0.5280 - accuracy: 0.844 - ETA: 13s - loss: 0.5264 - accuracy: 0.845 - ETA: 12s - loss: 0.5268 - accuracy: 0.844 - ETA: 11s - loss: 0.5253 - accuracy: 0.844 - ETA: 10s - loss: 0.5248 - accuracy: 0.844 - ETA: 10s - loss: 0.5255 - accuracy: 0.844 - ETA: 9s - loss: 0.5269 - accuracy: 0.844 - ETA: 8s - loss: 0.5303 - accuracy: 0.84 - ETA: 8s - loss: 0.5310 - accuracy: 0.84 - ETA: 7s - loss: 0.5293 - accuracy: 0.84 - ETA: 6s - loss: 0.5273 - accuracy: 0.84 - ETA: 6s - loss: 0.5287 - accuracy: 0.84 - ETA: 5s - loss: 0.5265 - accuracy: 0.84 - ETA: 4s - loss: 0.5253 - accuracy: 0.84 - ETA: 3s - loss: 0.5253 - accuracy: 0.84 - ETA: 3s - loss: 0.5254 - accuracy: 0.84 - ETA: 2s - loss: 0.5252 - accuracy: 0.84 - ETA: 1s - loss: 0.5260 - accuracy: 0.84 - ETA: 1s - loss: 0.5249 - accuracy: 0.84 - ETA: 0s - loss: 0.5243 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5236 - accuracy: 0.8448 - val_loss: 3.1159 - val_accuracy: 0.3322\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.3708 - accuracy: 0.88 - ETA: 1:10 - loss: 0.4337 - accuracy: 0.87 - ETA: 1:08 - loss: 0.4434 - accuracy: 0.86 - ETA: 1:08 - loss: 0.4839 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5157 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5187 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5389 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5211 - accuracy: 0.85 - ETA: 1:05 - loss: 0.5508 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5421 - accuracy: 0.85 - ETA: 1:03 - loss: 0.5438 - accuracy: 0.85 - ETA: 1:02 - loss: 0.5426 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5359 - accuracy: 0.85 - ETA: 1:01 - loss: 0.5335 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5302 - accuracy: 0.85 - ETA: 59s - loss: 0.5224 - accuracy: 0.8535 - ETA: 59s - loss: 0.5209 - accuracy: 0.851 - ETA: 58s - loss: 0.5241 - accuracy: 0.851 - ETA: 57s - loss: 0.5127 - accuracy: 0.855 - ETA: 56s - loss: 0.5179 - accuracy: 0.854 - ETA: 56s - loss: 0.5174 - accuracy: 0.854 - ETA: 55s - loss: 0.5122 - accuracy: 0.855 - ETA: 55s - loss: 0.5187 - accuracy: 0.854 - ETA: 54s - loss: 0.5251 - accuracy: 0.852 - ETA: 53s - loss: 0.5279 - accuracy: 0.851 - ETA: 53s - loss: 0.5255 - accuracy: 0.852 - ETA: 52s - loss: 0.5333 - accuracy: 0.852 - ETA: 51s - loss: 0.5257 - accuracy: 0.853 - ETA: 51s - loss: 0.5366 - accuracy: 0.850 - ETA: 50s - loss: 0.5418 - accuracy: 0.849 - ETA: 49s - loss: 0.5457 - accuracy: 0.848 - ETA: 48s - loss: 0.5517 - accuracy: 0.846 - ETA: 48s - loss: 0.5495 - accuracy: 0.846 - ETA: 47s - loss: 0.5501 - accuracy: 0.846 - ETA: 46s - loss: 0.5529 - accuracy: 0.845 - ETA: 46s - loss: 0.5502 - accuracy: 0.846 - ETA: 45s - loss: 0.5503 - accuracy: 0.847 - ETA: 44s - loss: 0.5469 - accuracy: 0.847 - ETA: 43s - loss: 0.5560 - accuracy: 0.846 - ETA: 43s - loss: 0.5567 - accuracy: 0.845 - ETA: 42s - loss: 0.5529 - accuracy: 0.846 - ETA: 41s - loss: 0.5485 - accuracy: 0.847 - ETA: 40s - loss: 0.5511 - accuracy: 0.845 - ETA: 40s - loss: 0.5548 - accuracy: 0.845 - ETA: 39s - loss: 0.5554 - accuracy: 0.845 - ETA: 38s - loss: 0.5509 - accuracy: 0.846 - ETA: 38s - loss: 0.5498 - accuracy: 0.847 - ETA: 37s - loss: 0.5479 - accuracy: 0.848 - ETA: 36s - loss: 0.5483 - accuracy: 0.847 - ETA: 35s - loss: 0.5456 - accuracy: 0.848 - ETA: 35s - loss: 0.5447 - accuracy: 0.847 - ETA: 34s - loss: 0.5467 - accuracy: 0.847 - ETA: 33s - loss: 0.5464 - accuracy: 0.846 - ETA: 33s - loss: 0.5498 - accuracy: 0.845 - ETA: 32s - loss: 0.5493 - accuracy: 0.845 - ETA: 31s - loss: 0.5491 - accuracy: 0.845 - ETA: 31s - loss: 0.5497 - accuracy: 0.844 - ETA: 30s - loss: 0.5475 - accuracy: 0.845 - ETA: 29s - loss: 0.5482 - accuracy: 0.844 - ETA: 28s - loss: 0.5477 - accuracy: 0.844 - ETA: 28s - loss: 0.5478 - accuracy: 0.844 - ETA: 27s - loss: 0.5460 - accuracy: 0.844 - ETA: 26s - loss: 0.5440 - accuracy: 0.844 - ETA: 26s - loss: 0.5445 - accuracy: 0.844 - ETA: 25s - loss: 0.5433 - accuracy: 0.844 - ETA: 24s - loss: 0.5411 - accuracy: 0.845 - ETA: 24s - loss: 0.5400 - accuracy: 0.845 - ETA: 23s - loss: 0.5436 - accuracy: 0.844 - ETA: 22s - loss: 0.5411 - accuracy: 0.845 - ETA: 21s - loss: 0.5441 - accuracy: 0.845 - ETA: 21s - loss: 0.5467 - accuracy: 0.844 - ETA: 20s - loss: 0.5473 - accuracy: 0.844 - ETA: 19s - loss: 0.5473 - accuracy: 0.843 - ETA: 19s - loss: 0.5465 - accuracy: 0.844 - ETA: 18s - loss: 0.5474 - accuracy: 0.843 - ETA: 17s - loss: 0.5463 - accuracy: 0.844 - ETA: 17s - loss: 0.5464 - accuracy: 0.843 - ETA: 16s - loss: 0.5463 - accuracy: 0.843 - ETA: 15s - loss: 0.5458 - accuracy: 0.843 - ETA: 15s - loss: 0.5453 - accuracy: 0.843 - ETA: 14s - loss: 0.5456 - accuracy: 0.843 - ETA: 13s - loss: 0.5456 - accuracy: 0.842 - ETA: 12s - loss: 0.5443 - accuracy: 0.843 - ETA: 12s - loss: 0.5424 - accuracy: 0.843 - ETA: 11s - loss: 0.5402 - accuracy: 0.843 - ETA: 10s - loss: 0.5394 - accuracy: 0.843 - ETA: 10s - loss: 0.5407 - accuracy: 0.843 - ETA: 9s - loss: 0.5403 - accuracy: 0.843 - ETA: 8s - loss: 0.5410 - accuracy: 0.84 - ETA: 8s - loss: 0.5421 - accuracy: 0.84 - ETA: 7s - loss: 0.5416 - accuracy: 0.84 - ETA: 6s - loss: 0.5414 - accuracy: 0.84 - ETA: 6s - loss: 0.5410 - accuracy: 0.84 - ETA: 5s - loss: 0.5416 - accuracy: 0.84 - ETA: 4s - loss: 0.5392 - accuracy: 0.84 - ETA: 3s - loss: 0.5404 - accuracy: 0.84 - ETA: 3s - loss: 0.5426 - accuracy: 0.84 - ETA: 2s - loss: 0.5427 - accuracy: 0.84 - ETA: 1s - loss: 0.5428 - accuracy: 0.84 - ETA: 1s - loss: 0.5426 - accuracy: 0.84 - ETA: 0s - loss: 0.5412 - accuracy: 0.84 - 82s 6ms/step - loss: 0.5409 - accuracy: 0.8430 - val_loss: 3.2144 - val_accuracy: 0.3298\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.5304 - accuracy: 0.87 - ETA: 1:09 - loss: 0.4904 - accuracy: 0.86 - ETA: 1:10 - loss: 0.5097 - accuracy: 0.86 - ETA: 1:09 - loss: 0.4937 - accuracy: 0.86 - ETA: 1:08 - loss: 0.5163 - accuracy: 0.85 - ETA: 1:07 - loss: 0.5262 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5412 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5452 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5492 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5494 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5476 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5391 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5558 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5537 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5404 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5377 - accuracy: 0.84 - ETA: 59s - loss: 0.5381 - accuracy: 0.8470 - ETA: 58s - loss: 0.5358 - accuracy: 0.844 - ETA: 57s - loss: 0.5348 - accuracy: 0.845 - ETA: 57s - loss: 0.5344 - accuracy: 0.844 - ETA: 56s - loss: 0.5368 - accuracy: 0.843 - ETA: 55s - loss: 0.5303 - accuracy: 0.843 - ETA: 54s - loss: 0.5303 - accuracy: 0.845 - ETA: 54s - loss: 0.5335 - accuracy: 0.843 - ETA: 53s - loss: 0.5293 - accuracy: 0.844 - ETA: 52s - loss: 0.5320 - accuracy: 0.844 - ETA: 52s - loss: 0.5331 - accuracy: 0.844 - ETA: 51s - loss: 0.5322 - accuracy: 0.843 - ETA: 50s - loss: 0.5371 - accuracy: 0.842 - ETA: 49s - loss: 0.5412 - accuracy: 0.841 - ETA: 49s - loss: 0.5444 - accuracy: 0.841 - ETA: 48s - loss: 0.5435 - accuracy: 0.842 - ETA: 47s - loss: 0.5444 - accuracy: 0.841 - ETA: 47s - loss: 0.5402 - accuracy: 0.842 - ETA: 46s - loss: 0.5377 - accuracy: 0.844 - ETA: 45s - loss: 0.5363 - accuracy: 0.844 - ETA: 44s - loss: 0.5323 - accuracy: 0.846 - ETA: 44s - loss: 0.5341 - accuracy: 0.845 - ETA: 43s - loss: 0.5338 - accuracy: 0.845 - ETA: 42s - loss: 0.5367 - accuracy: 0.844 - ETA: 42s - loss: 0.5366 - accuracy: 0.845 - ETA: 41s - loss: 0.5374 - accuracy: 0.844 - ETA: 40s - loss: 0.5410 - accuracy: 0.843 - ETA: 40s - loss: 0.5417 - accuracy: 0.843 - ETA: 39s - loss: 0.5463 - accuracy: 0.841 - ETA: 38s - loss: 0.5470 - accuracy: 0.841 - ETA: 37s - loss: 0.5442 - accuracy: 0.841 - ETA: 37s - loss: 0.5512 - accuracy: 0.840 - ETA: 36s - loss: 0.5492 - accuracy: 0.840 - ETA: 35s - loss: 0.5483 - accuracy: 0.840 - ETA: 35s - loss: 0.5459 - accuracy: 0.841 - ETA: 34s - loss: 0.5462 - accuracy: 0.841 - ETA: 33s - loss: 0.5466 - accuracy: 0.841 - ETA: 33s - loss: 0.5446 - accuracy: 0.841 - ETA: 32s - loss: 0.5474 - accuracy: 0.840 - ETA: 31s - loss: 0.5498 - accuracy: 0.839 - ETA: 30s - loss: 0.5496 - accuracy: 0.839 - ETA: 30s - loss: 0.5470 - accuracy: 0.839 - ETA: 29s - loss: 0.5477 - accuracy: 0.840 - ETA: 28s - loss: 0.5474 - accuracy: 0.840 - ETA: 28s - loss: 0.5500 - accuracy: 0.839 - ETA: 27s - loss: 0.5495 - accuracy: 0.839 - ETA: 26s - loss: 0.5500 - accuracy: 0.839 - ETA: 26s - loss: 0.5502 - accuracy: 0.839 - ETA: 25s - loss: 0.5521 - accuracy: 0.838 - ETA: 24s - loss: 0.5498 - accuracy: 0.839 - ETA: 24s - loss: 0.5511 - accuracy: 0.839 - ETA: 23s - loss: 0.5496 - accuracy: 0.839 - ETA: 22s - loss: 0.5478 - accuracy: 0.840 - ETA: 21s - loss: 0.5487 - accuracy: 0.840 - ETA: 21s - loss: 0.5495 - accuracy: 0.839 - ETA: 20s - loss: 0.5488 - accuracy: 0.840 - ETA: 19s - loss: 0.5499 - accuracy: 0.839 - ETA: 19s - loss: 0.5529 - accuracy: 0.838 - ETA: 18s - loss: 0.5515 - accuracy: 0.838 - ETA: 17s - loss: 0.5526 - accuracy: 0.838 - ETA: 17s - loss: 0.5498 - accuracy: 0.838 - ETA: 16s - loss: 0.5492 - accuracy: 0.838 - ETA: 15s - loss: 0.5486 - accuracy: 0.838 - ETA: 15s - loss: 0.5484 - accuracy: 0.838 - ETA: 14s - loss: 0.5489 - accuracy: 0.838 - ETA: 13s - loss: 0.5476 - accuracy: 0.839 - ETA: 12s - loss: 0.5470 - accuracy: 0.839 - ETA: 12s - loss: 0.5506 - accuracy: 0.838 - ETA: 11s - loss: 0.5509 - accuracy: 0.838 - ETA: 10s - loss: 0.5509 - accuracy: 0.838 - ETA: 10s - loss: 0.5507 - accuracy: 0.839 - ETA: 9s - loss: 0.5502 - accuracy: 0.838 - ETA: 8s - loss: 0.5481 - accuracy: 0.83 - ETA: 8s - loss: 0.5505 - accuracy: 0.83 - ETA: 7s - loss: 0.5502 - accuracy: 0.83 - ETA: 6s - loss: 0.5517 - accuracy: 0.83 - ETA: 6s - loss: 0.5519 - accuracy: 0.83 - ETA: 5s - loss: 0.5511 - accuracy: 0.83 - ETA: 4s - loss: 0.5495 - accuracy: 0.84 - ETA: 3s - loss: 0.5491 - accuracy: 0.84 - ETA: 3s - loss: 0.5504 - accuracy: 0.84 - ETA: 2s - loss: 0.5490 - accuracy: 0.84 - ETA: 1s - loss: 0.5497 - accuracy: 0.84 - ETA: 1s - loss: 0.5497 - accuracy: 0.84 - ETA: 0s - loss: 0.5500 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5508 - accuracy: 0.8416 - val_loss: 3.2432 - val_accuracy: 0.3298\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:16 - loss: 0.4665 - accuracy: 0.85 - ETA: 1:14 - loss: 0.4859 - accuracy: 0.86 - ETA: 1:12 - loss: 0.5092 - accuracy: 0.85 - ETA: 1:11 - loss: 0.5512 - accuracy: 0.84 - ETA: 1:09 - loss: 0.5034 - accuracy: 0.85 - ETA: 1:09 - loss: 0.5212 - accuracy: 0.85 - ETA: 1:08 - loss: 0.5299 - accuracy: 0.85 - ETA: 1:06 - loss: 0.5406 - accuracy: 0.85 - ETA: 1:05 - loss: 0.5452 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5626 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5583 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5623 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5740 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5739 - accuracy: 0.83 - ETA: 1:00 - loss: 0.5649 - accuracy: 0.83 - ETA: 59s - loss: 0.5681 - accuracy: 0.8379 - ETA: 59s - loss: 0.5618 - accuracy: 0.840 - ETA: 58s - loss: 0.5628 - accuracy: 0.838 - ETA: 57s - loss: 0.5565 - accuracy: 0.840 - ETA: 56s - loss: 0.5501 - accuracy: 0.843 - ETA: 56s - loss: 0.5537 - accuracy: 0.841 - ETA: 55s - loss: 0.5511 - accuracy: 0.842 - ETA: 54s - loss: 0.5590 - accuracy: 0.841 - ETA: 54s - loss: 0.5607 - accuracy: 0.842 - ETA: 53s - loss: 0.5560 - accuracy: 0.842 - ETA: 52s - loss: 0.5593 - accuracy: 0.839 - ETA: 52s - loss: 0.5602 - accuracy: 0.839 - ETA: 51s - loss: 0.5579 - accuracy: 0.840 - ETA: 50s - loss: 0.5562 - accuracy: 0.841 - ETA: 49s - loss: 0.5595 - accuracy: 0.840 - ETA: 49s - loss: 0.5582 - accuracy: 0.840 - ETA: 48s - loss: 0.5579 - accuracy: 0.840 - ETA: 47s - loss: 0.5546 - accuracy: 0.841 - ETA: 47s - loss: 0.5542 - accuracy: 0.840 - ETA: 46s - loss: 0.5527 - accuracy: 0.840 - ETA: 45s - loss: 0.5527 - accuracy: 0.839 - ETA: 45s - loss: 0.5546 - accuracy: 0.839 - ETA: 44s - loss: 0.5592 - accuracy: 0.837 - ETA: 43s - loss: 0.5534 - accuracy: 0.839 - ETA: 42s - loss: 0.5565 - accuracy: 0.839 - ETA: 42s - loss: 0.5522 - accuracy: 0.839 - ETA: 41s - loss: 0.5546 - accuracy: 0.838 - ETA: 40s - loss: 0.5533 - accuracy: 0.839 - ETA: 40s - loss: 0.5520 - accuracy: 0.840 - ETA: 39s - loss: 0.5478 - accuracy: 0.841 - ETA: 38s - loss: 0.5480 - accuracy: 0.840 - ETA: 38s - loss: 0.5428 - accuracy: 0.842 - ETA: 37s - loss: 0.5458 - accuracy: 0.840 - ETA: 36s - loss: 0.5425 - accuracy: 0.841 - ETA: 36s - loss: 0.5410 - accuracy: 0.841 - ETA: 35s - loss: 0.5359 - accuracy: 0.843 - ETA: 34s - loss: 0.5356 - accuracy: 0.843 - ETA: 33s - loss: 0.5374 - accuracy: 0.842 - ETA: 32s - loss: 0.5367 - accuracy: 0.842 - ETA: 32s - loss: 0.5369 - accuracy: 0.842 - ETA: 31s - loss: 0.5348 - accuracy: 0.843 - ETA: 30s - loss: 0.5338 - accuracy: 0.844 - ETA: 29s - loss: 0.5313 - accuracy: 0.844 - ETA: 28s - loss: 0.5296 - accuracy: 0.844 - ETA: 27s - loss: 0.5291 - accuracy: 0.845 - ETA: 27s - loss: 0.5323 - accuracy: 0.844 - ETA: 26s - loss: 0.5300 - accuracy: 0.845 - ETA: 25s - loss: 0.5258 - accuracy: 0.846 - ETA: 24s - loss: 0.5250 - accuracy: 0.845 - ETA: 24s - loss: 0.5239 - accuracy: 0.846 - ETA: 23s - loss: 0.5272 - accuracy: 0.845 - ETA: 22s - loss: 0.5264 - accuracy: 0.845 - ETA: 22s - loss: 0.5288 - accuracy: 0.845 - ETA: 21s - loss: 0.5280 - accuracy: 0.845 - ETA: 21s - loss: 0.5279 - accuracy: 0.845 - ETA: 20s - loss: 0.5262 - accuracy: 0.845 - ETA: 19s - loss: 0.5256 - accuracy: 0.845 - ETA: 19s - loss: 0.5238 - accuracy: 0.846 - ETA: 18s - loss: 0.5215 - accuracy: 0.846 - ETA: 17s - loss: 0.5244 - accuracy: 0.846 - ETA: 17s - loss: 0.5250 - accuracy: 0.846 - ETA: 16s - loss: 0.5245 - accuracy: 0.846 - ETA: 15s - loss: 0.5244 - accuracy: 0.846 - ETA: 15s - loss: 0.5263 - accuracy: 0.845 - ETA: 14s - loss: 0.5276 - accuracy: 0.845 - ETA: 13s - loss: 0.5261 - accuracy: 0.846 - ETA: 13s - loss: 0.5289 - accuracy: 0.846 - ETA: 12s - loss: 0.5298 - accuracy: 0.845 - ETA: 11s - loss: 0.5292 - accuracy: 0.845 - ETA: 11s - loss: 0.5305 - accuracy: 0.845 - ETA: 10s - loss: 0.5296 - accuracy: 0.845 - ETA: 9s - loss: 0.5287 - accuracy: 0.845 - ETA: 9s - loss: 0.5279 - accuracy: 0.84 - ETA: 8s - loss: 0.5279 - accuracy: 0.84 - ETA: 7s - loss: 0.5278 - accuracy: 0.84 - ETA: 7s - loss: 0.5273 - accuracy: 0.84 - ETA: 6s - loss: 0.5281 - accuracy: 0.84 - ETA: 5s - loss: 0.5283 - accuracy: 0.84 - ETA: 5s - loss: 0.5274 - accuracy: 0.84 - ETA: 4s - loss: 0.5261 - accuracy: 0.84 - ETA: 3s - loss: 0.5240 - accuracy: 0.84 - ETA: 3s - loss: 0.5226 - accuracy: 0.84 - ETA: 2s - loss: 0.5230 - accuracy: 0.84 - ETA: 1s - loss: 0.5241 - accuracy: 0.84 - ETA: 1s - loss: 0.5229 - accuracy: 0.84 - ETA: 0s - loss: 0.5220 - accuracy: 0.84 - 79s 6ms/step - loss: 0.5217 - accuracy: 0.8486 - val_loss: 3.2943 - val_accuracy: 0.3100\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.3971 - accuracy: 0.86 - ETA: 1:12 - loss: 0.4560 - accuracy: 0.84 - ETA: 1:11 - loss: 0.4141 - accuracy: 0.86 - ETA: 1:09 - loss: 0.4380 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4570 - accuracy: 0.85 - ETA: 1:08 - loss: 0.4726 - accuracy: 0.85 - ETA: 1:07 - loss: 0.4945 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5142 - accuracy: 0.84 - ETA: 1:06 - loss: 0.5173 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5172 - accuracy: 0.85 - ETA: 1:04 - loss: 0.5252 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5173 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5164 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5105 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5240 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5302 - accuracy: 0.84 - ETA: 59s - loss: 0.5304 - accuracy: 0.8415 - ETA: 59s - loss: 0.5354 - accuracy: 0.841 - ETA: 58s - loss: 0.5281 - accuracy: 0.843 - ETA: 57s - loss: 0.5217 - accuracy: 0.846 - ETA: 56s - loss: 0.5259 - accuracy: 0.844 - ETA: 55s - loss: 0.5347 - accuracy: 0.844 - ETA: 55s - loss: 0.5302 - accuracy: 0.845 - ETA: 54s - loss: 0.5370 - accuracy: 0.843 - ETA: 53s - loss: 0.5362 - accuracy: 0.846 - ETA: 53s - loss: 0.5338 - accuracy: 0.846 - ETA: 52s - loss: 0.5402 - accuracy: 0.845 - ETA: 51s - loss: 0.5418 - accuracy: 0.844 - ETA: 50s - loss: 0.5423 - accuracy: 0.842 - ETA: 50s - loss: 0.5392 - accuracy: 0.843 - ETA: 49s - loss: 0.5357 - accuracy: 0.843 - ETA: 48s - loss: 0.5384 - accuracy: 0.843 - ETA: 48s - loss: 0.5444 - accuracy: 0.842 - ETA: 47s - loss: 0.5421 - accuracy: 0.843 - ETA: 46s - loss: 0.5371 - accuracy: 0.843 - ETA: 45s - loss: 0.5407 - accuracy: 0.842 - ETA: 45s - loss: 0.5423 - accuracy: 0.842 - ETA: 44s - loss: 0.5371 - accuracy: 0.844 - ETA: 43s - loss: 0.5379 - accuracy: 0.842 - ETA: 43s - loss: 0.5372 - accuracy: 0.843 - ETA: 42s - loss: 0.5379 - accuracy: 0.842 - ETA: 41s - loss: 0.5397 - accuracy: 0.842 - ETA: 41s - loss: 0.5397 - accuracy: 0.842 - ETA: 40s - loss: 0.5421 - accuracy: 0.841 - ETA: 39s - loss: 0.5439 - accuracy: 0.841 - ETA: 38s - loss: 0.5461 - accuracy: 0.840 - ETA: 38s - loss: 0.5441 - accuracy: 0.841 - ETA: 37s - loss: 0.5472 - accuracy: 0.840 - ETA: 36s - loss: 0.5500 - accuracy: 0.839 - ETA: 36s - loss: 0.5496 - accuracy: 0.840 - ETA: 35s - loss: 0.5482 - accuracy: 0.841 - ETA: 34s - loss: 0.5459 - accuracy: 0.841 - ETA: 34s - loss: 0.5462 - accuracy: 0.841 - ETA: 33s - loss: 0.5468 - accuracy: 0.841 - ETA: 32s - loss: 0.5472 - accuracy: 0.841 - ETA: 32s - loss: 0.5468 - accuracy: 0.842 - ETA: 31s - loss: 0.5470 - accuracy: 0.842 - ETA: 30s - loss: 0.5480 - accuracy: 0.841 - ETA: 29s - loss: 0.5473 - accuracy: 0.842 - ETA: 29s - loss: 0.5480 - accuracy: 0.842 - ETA: 28s - loss: 0.5480 - accuracy: 0.841 - ETA: 27s - loss: 0.5457 - accuracy: 0.842 - ETA: 27s - loss: 0.5461 - accuracy: 0.842 - ETA: 26s - loss: 0.5455 - accuracy: 0.842 - ETA: 25s - loss: 0.5442 - accuracy: 0.842 - ETA: 25s - loss: 0.5402 - accuracy: 0.843 - ETA: 24s - loss: 0.5389 - accuracy: 0.844 - ETA: 23s - loss: 0.5393 - accuracy: 0.844 - ETA: 22s - loss: 0.5387 - accuracy: 0.844 - ETA: 22s - loss: 0.5370 - accuracy: 0.844 - ETA: 21s - loss: 0.5366 - accuracy: 0.844 - ETA: 20s - loss: 0.5366 - accuracy: 0.844 - ETA: 20s - loss: 0.5359 - accuracy: 0.844 - ETA: 19s - loss: 0.5348 - accuracy: 0.844 - ETA: 18s - loss: 0.5353 - accuracy: 0.844 - ETA: 18s - loss: 0.5328 - accuracy: 0.844 - ETA: 17s - loss: 0.5325 - accuracy: 0.845 - ETA: 16s - loss: 0.5325 - accuracy: 0.844 - ETA: 15s - loss: 0.5298 - accuracy: 0.845 - ETA: 15s - loss: 0.5290 - accuracy: 0.845 - ETA: 14s - loss: 0.5320 - accuracy: 0.844 - ETA: 13s - loss: 0.5319 - accuracy: 0.845 - ETA: 13s - loss: 0.5312 - accuracy: 0.845 - ETA: 12s - loss: 0.5304 - accuracy: 0.845 - ETA: 11s - loss: 0.5300 - accuracy: 0.845 - ETA: 10s - loss: 0.5305 - accuracy: 0.845 - ETA: 10s - loss: 0.5310 - accuracy: 0.845 - ETA: 9s - loss: 0.5302 - accuracy: 0.845 - ETA: 8s - loss: 0.5311 - accuracy: 0.84 - ETA: 8s - loss: 0.5295 - accuracy: 0.84 - ETA: 7s - loss: 0.5292 - accuracy: 0.84 - ETA: 6s - loss: 0.5268 - accuracy: 0.84 - ETA: 6s - loss: 0.5294 - accuracy: 0.84 - ETA: 5s - loss: 0.5289 - accuracy: 0.84 - ETA: 4s - loss: 0.5305 - accuracy: 0.84 - ETA: 4s - loss: 0.5323 - accuracy: 0.84 - ETA: 3s - loss: 0.5339 - accuracy: 0.84 - ETA: 2s - loss: 0.5347 - accuracy: 0.84 - ETA: 1s - loss: 0.5339 - accuracy: 0.84 - ETA: 1s - loss: 0.5350 - accuracy: 0.84 - ETA: 0s - loss: 0.5345 - accuracy: 0.84 - 82s 6ms/step - loss: 0.5344 - accuracy: 0.8441 - val_loss: 3.3845 - val_accuracy: 0.3104\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.5019 - accuracy: 0.84 - ETA: 1:10 - loss: 0.5145 - accuracy: 0.83 - ETA: 1:08 - loss: 0.4745 - accuracy: 0.84 - ETA: 1:07 - loss: 0.5346 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5514 - accuracy: 0.82 - ETA: 1:06 - loss: 0.5408 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5507 - accuracy: 0.83 - ETA: 1:05 - loss: 0.5442 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5299 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5228 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5357 - accuracy: 0.83 - ETA: 1:02 - loss: 0.5342 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5340 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5320 - accuracy: 0.84 - ETA: 59s - loss: 0.5231 - accuracy: 0.8443 - ETA: 59s - loss: 0.5217 - accuracy: 0.844 - ETA: 58s - loss: 0.5160 - accuracy: 0.844 - ETA: 57s - loss: 0.5198 - accuracy: 0.842 - ETA: 57s - loss: 0.5235 - accuracy: 0.842 - ETA: 56s - loss: 0.5145 - accuracy: 0.843 - ETA: 55s - loss: 0.5133 - accuracy: 0.844 - ETA: 54s - loss: 0.5229 - accuracy: 0.843 - ETA: 54s - loss: 0.5261 - accuracy: 0.842 - ETA: 53s - loss: 0.5294 - accuracy: 0.841 - ETA: 53s - loss: 0.5279 - accuracy: 0.842 - ETA: 52s - loss: 0.5200 - accuracy: 0.845 - ETA: 51s - loss: 0.5204 - accuracy: 0.846 - ETA: 51s - loss: 0.5256 - accuracy: 0.844 - ETA: 50s - loss: 0.5221 - accuracy: 0.846 - ETA: 50s - loss: 0.5245 - accuracy: 0.846 - ETA: 49s - loss: 0.5194 - accuracy: 0.847 - ETA: 48s - loss: 0.5199 - accuracy: 0.848 - ETA: 48s - loss: 0.5196 - accuracy: 0.849 - ETA: 47s - loss: 0.5175 - accuracy: 0.849 - ETA: 46s - loss: 0.5232 - accuracy: 0.850 - ETA: 45s - loss: 0.5243 - accuracy: 0.849 - ETA: 45s - loss: 0.5213 - accuracy: 0.850 - ETA: 44s - loss: 0.5203 - accuracy: 0.850 - ETA: 43s - loss: 0.5216 - accuracy: 0.851 - ETA: 43s - loss: 0.5255 - accuracy: 0.850 - ETA: 42s - loss: 0.5244 - accuracy: 0.851 - ETA: 41s - loss: 0.5230 - accuracy: 0.851 - ETA: 40s - loss: 0.5285 - accuracy: 0.850 - ETA: 40s - loss: 0.5299 - accuracy: 0.849 - ETA: 39s - loss: 0.5336 - accuracy: 0.848 - ETA: 38s - loss: 0.5329 - accuracy: 0.849 - ETA: 38s - loss: 0.5342 - accuracy: 0.848 - ETA: 37s - loss: 0.5345 - accuracy: 0.849 - ETA: 36s - loss: 0.5349 - accuracy: 0.848 - ETA: 35s - loss: 0.5353 - accuracy: 0.848 - ETA: 35s - loss: 0.5348 - accuracy: 0.848 - ETA: 34s - loss: 0.5343 - accuracy: 0.848 - ETA: 33s - loss: 0.5346 - accuracy: 0.848 - ETA: 33s - loss: 0.5340 - accuracy: 0.848 - ETA: 32s - loss: 0.5327 - accuracy: 0.848 - ETA: 31s - loss: 0.5322 - accuracy: 0.848 - ETA: 31s - loss: 0.5331 - accuracy: 0.848 - ETA: 30s - loss: 0.5316 - accuracy: 0.848 - ETA: 29s - loss: 0.5309 - accuracy: 0.848 - ETA: 28s - loss: 0.5323 - accuracy: 0.848 - ETA: 28s - loss: 0.5326 - accuracy: 0.848 - ETA: 27s - loss: 0.5357 - accuracy: 0.847 - ETA: 26s - loss: 0.5352 - accuracy: 0.846 - ETA: 26s - loss: 0.5341 - accuracy: 0.846 - ETA: 25s - loss: 0.5331 - accuracy: 0.846 - ETA: 24s - loss: 0.5307 - accuracy: 0.847 - ETA: 24s - loss: 0.5298 - accuracy: 0.847 - ETA: 23s - loss: 0.5314 - accuracy: 0.847 - ETA: 22s - loss: 0.5307 - accuracy: 0.847 - ETA: 22s - loss: 0.5310 - accuracy: 0.847 - ETA: 21s - loss: 0.5297 - accuracy: 0.848 - ETA: 20s - loss: 0.5293 - accuracy: 0.848 - ETA: 19s - loss: 0.5288 - accuracy: 0.848 - ETA: 19s - loss: 0.5283 - accuracy: 0.848 - ETA: 18s - loss: 0.5312 - accuracy: 0.848 - ETA: 17s - loss: 0.5304 - accuracy: 0.848 - ETA: 17s - loss: 0.5314 - accuracy: 0.848 - ETA: 16s - loss: 0.5336 - accuracy: 0.848 - ETA: 15s - loss: 0.5333 - accuracy: 0.848 - ETA: 15s - loss: 0.5312 - accuracy: 0.848 - ETA: 14s - loss: 0.5315 - accuracy: 0.848 - ETA: 13s - loss: 0.5332 - accuracy: 0.847 - ETA: 12s - loss: 0.5345 - accuracy: 0.847 - ETA: 12s - loss: 0.5365 - accuracy: 0.846 - ETA: 11s - loss: 0.5373 - accuracy: 0.846 - ETA: 10s - loss: 0.5376 - accuracy: 0.846 - ETA: 10s - loss: 0.5380 - accuracy: 0.845 - ETA: 9s - loss: 0.5366 - accuracy: 0.845 - ETA: 8s - loss: 0.5361 - accuracy: 0.84 - ETA: 8s - loss: 0.5351 - accuracy: 0.84 - ETA: 7s - loss: 0.5362 - accuracy: 0.84 - ETA: 6s - loss: 0.5354 - accuracy: 0.84 - ETA: 6s - loss: 0.5349 - accuracy: 0.84 - ETA: 5s - loss: 0.5357 - accuracy: 0.84 - ETA: 4s - loss: 0.5362 - accuracy: 0.84 - ETA: 3s - loss: 0.5359 - accuracy: 0.84 - ETA: 3s - loss: 0.5349 - accuracy: 0.84 - ETA: 2s - loss: 0.5350 - accuracy: 0.84 - ETA: 1s - loss: 0.5358 - accuracy: 0.84 - ETA: 1s - loss: 0.5350 - accuracy: 0.84 - ETA: 0s - loss: 0.5352 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5359 - accuracy: 0.8446 - val_loss: 3.2794 - val_accuracy: 0.3226\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:15 - loss: 0.4164 - accuracy: 0.87 - ETA: 1:11 - loss: 0.4054 - accuracy: 0.89 - ETA: 1:10 - loss: 0.4363 - accuracy: 0.87 - ETA: 1:09 - loss: 0.4443 - accuracy: 0.87 - ETA: 1:10 - loss: 0.4552 - accuracy: 0.87 - ETA: 1:09 - loss: 0.4622 - accuracy: 0.86 - ETA: 1:09 - loss: 0.4570 - accuracy: 0.86 - ETA: 1:08 - loss: 0.4630 - accuracy: 0.86 - ETA: 1:07 - loss: 0.4781 - accuracy: 0.86 - ETA: 1:06 - loss: 0.4849 - accuracy: 0.86 - ETA: 1:04 - loss: 0.4913 - accuracy: 0.85 - ETA: 1:04 - loss: 0.4902 - accuracy: 0.85 - ETA: 1:03 - loss: 0.4912 - accuracy: 0.85 - ETA: 1:02 - loss: 0.5163 - accuracy: 0.85 - ETA: 1:01 - loss: 0.5171 - accuracy: 0.85 - ETA: 1:00 - loss: 0.5220 - accuracy: 0.85 - ETA: 59s - loss: 0.5291 - accuracy: 0.8516 - ETA: 58s - loss: 0.5307 - accuracy: 0.852 - ETA: 58s - loss: 0.5444 - accuracy: 0.849 - ETA: 57s - loss: 0.5404 - accuracy: 0.850 - ETA: 57s - loss: 0.5370 - accuracy: 0.851 - ETA: 56s - loss: 0.5369 - accuracy: 0.850 - ETA: 55s - loss: 0.5348 - accuracy: 0.850 - ETA: 54s - loss: 0.5361 - accuracy: 0.849 - ETA: 54s - loss: 0.5452 - accuracy: 0.848 - ETA: 53s - loss: 0.5481 - accuracy: 0.847 - ETA: 52s - loss: 0.5359 - accuracy: 0.850 - ETA: 51s - loss: 0.5340 - accuracy: 0.851 - ETA: 51s - loss: 0.5344 - accuracy: 0.849 - ETA: 50s - loss: 0.5437 - accuracy: 0.849 - ETA: 49s - loss: 0.5436 - accuracy: 0.848 - ETA: 48s - loss: 0.5393 - accuracy: 0.850 - ETA: 48s - loss: 0.5403 - accuracy: 0.849 - ETA: 47s - loss: 0.5426 - accuracy: 0.848 - ETA: 46s - loss: 0.5451 - accuracy: 0.846 - ETA: 45s - loss: 0.5428 - accuracy: 0.847 - ETA: 45s - loss: 0.5442 - accuracy: 0.845 - ETA: 44s - loss: 0.5405 - accuracy: 0.846 - ETA: 43s - loss: 0.5376 - accuracy: 0.847 - ETA: 43s - loss: 0.5413 - accuracy: 0.845 - ETA: 42s - loss: 0.5398 - accuracy: 0.845 - ETA: 41s - loss: 0.5366 - accuracy: 0.846 - ETA: 41s - loss: 0.5405 - accuracy: 0.845 - ETA: 40s - loss: 0.5408 - accuracy: 0.845 - ETA: 39s - loss: 0.5419 - accuracy: 0.844 - ETA: 39s - loss: 0.5403 - accuracy: 0.844 - ETA: 38s - loss: 0.5364 - accuracy: 0.845 - ETA: 37s - loss: 0.5369 - accuracy: 0.845 - ETA: 36s - loss: 0.5370 - accuracy: 0.845 - ETA: 36s - loss: 0.5415 - accuracy: 0.844 - ETA: 35s - loss: 0.5394 - accuracy: 0.844 - ETA: 34s - loss: 0.5397 - accuracy: 0.844 - ETA: 34s - loss: 0.5391 - accuracy: 0.844 - ETA: 33s - loss: 0.5465 - accuracy: 0.844 - ETA: 32s - loss: 0.5459 - accuracy: 0.844 - ETA: 31s - loss: 0.5441 - accuracy: 0.844 - ETA: 31s - loss: 0.5419 - accuracy: 0.845 - ETA: 30s - loss: 0.5395 - accuracy: 0.846 - ETA: 29s - loss: 0.5383 - accuracy: 0.846 - ETA: 29s - loss: 0.5364 - accuracy: 0.846 - ETA: 28s - loss: 0.5367 - accuracy: 0.846 - ETA: 27s - loss: 0.5350 - accuracy: 0.846 - ETA: 27s - loss: 0.5361 - accuracy: 0.846 - ETA: 26s - loss: 0.5372 - accuracy: 0.845 - ETA: 25s - loss: 0.5358 - accuracy: 0.845 - ETA: 24s - loss: 0.5340 - accuracy: 0.845 - ETA: 24s - loss: 0.5311 - accuracy: 0.846 - ETA: 23s - loss: 0.5299 - accuracy: 0.846 - ETA: 22s - loss: 0.5292 - accuracy: 0.846 - ETA: 22s - loss: 0.5289 - accuracy: 0.846 - ETA: 21s - loss: 0.5310 - accuracy: 0.846 - ETA: 20s - loss: 0.5320 - accuracy: 0.845 - ETA: 20s - loss: 0.5303 - accuracy: 0.845 - ETA: 19s - loss: 0.5287 - accuracy: 0.846 - ETA: 18s - loss: 0.5269 - accuracy: 0.846 - ETA: 17s - loss: 0.5269 - accuracy: 0.846 - ETA: 17s - loss: 0.5288 - accuracy: 0.846 - ETA: 16s - loss: 0.5285 - accuracy: 0.846 - ETA: 15s - loss: 0.5293 - accuracy: 0.845 - ETA: 15s - loss: 0.5286 - accuracy: 0.845 - ETA: 14s - loss: 0.5312 - accuracy: 0.845 - ETA: 13s - loss: 0.5298 - accuracy: 0.845 - ETA: 13s - loss: 0.5299 - accuracy: 0.845 - ETA: 12s - loss: 0.5288 - accuracy: 0.845 - ETA: 11s - loss: 0.5282 - accuracy: 0.845 - ETA: 10s - loss: 0.5276 - accuracy: 0.845 - ETA: 10s - loss: 0.5289 - accuracy: 0.845 - ETA: 9s - loss: 0.5292 - accuracy: 0.845 - ETA: 8s - loss: 0.5297 - accuracy: 0.84 - ETA: 8s - loss: 0.5285 - accuracy: 0.84 - ETA: 7s - loss: 0.5277 - accuracy: 0.84 - ETA: 6s - loss: 0.5301 - accuracy: 0.84 - ETA: 6s - loss: 0.5293 - accuracy: 0.84 - ETA: 5s - loss: 0.5287 - accuracy: 0.84 - ETA: 4s - loss: 0.5288 - accuracy: 0.84 - ETA: 3s - loss: 0.5286 - accuracy: 0.84 - ETA: 3s - loss: 0.5288 - accuracy: 0.84 - ETA: 2s - loss: 0.5293 - accuracy: 0.84 - ETA: 1s - loss: 0.5291 - accuracy: 0.84 - ETA: 1s - loss: 0.5292 - accuracy: 0.84 - ETA: 0s - loss: 0.5300 - accuracy: 0.84 - 82s 6ms/step - loss: 0.5297 - accuracy: 0.8445 - val_loss: 3.3141 - val_accuracy: 0.3079\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.5625 - accuracy: 0.82 - ETA: 1:08 - loss: 0.5497 - accuracy: 0.83 - ETA: 1:07 - loss: 0.5504 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5406 - accuracy: 0.83 - ETA: 1:05 - loss: 0.5575 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5750 - accuracy: 0.82 - ETA: 1:04 - loss: 0.5545 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5449 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5496 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5445 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5324 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5321 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5424 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5398 - accuracy: 0.84 - ETA: 59s - loss: 0.5445 - accuracy: 0.8458 - ETA: 59s - loss: 0.5531 - accuracy: 0.842 - ETA: 58s - loss: 0.5477 - accuracy: 0.841 - ETA: 57s - loss: 0.5466 - accuracy: 0.842 - ETA: 57s - loss: 0.5450 - accuracy: 0.842 - ETA: 56s - loss: 0.5410 - accuracy: 0.843 - ETA: 55s - loss: 0.5472 - accuracy: 0.842 - ETA: 54s - loss: 0.5380 - accuracy: 0.843 - ETA: 54s - loss: 0.5421 - accuracy: 0.842 - ETA: 53s - loss: 0.5368 - accuracy: 0.843 - ETA: 52s - loss: 0.5399 - accuracy: 0.842 - ETA: 52s - loss: 0.5442 - accuracy: 0.842 - ETA: 51s - loss: 0.5458 - accuracy: 0.840 - ETA: 50s - loss: 0.5455 - accuracy: 0.839 - ETA: 50s - loss: 0.5422 - accuracy: 0.839 - ETA: 49s - loss: 0.5432 - accuracy: 0.840 - ETA: 48s - loss: 0.5463 - accuracy: 0.840 - ETA: 47s - loss: 0.5456 - accuracy: 0.839 - ETA: 47s - loss: 0.5446 - accuracy: 0.839 - ETA: 46s - loss: 0.5448 - accuracy: 0.839 - ETA: 45s - loss: 0.5462 - accuracy: 0.838 - ETA: 45s - loss: 0.5490 - accuracy: 0.838 - ETA: 44s - loss: 0.5481 - accuracy: 0.838 - ETA: 43s - loss: 0.5508 - accuracy: 0.837 - ETA: 43s - loss: 0.5555 - accuracy: 0.836 - ETA: 42s - loss: 0.5572 - accuracy: 0.835 - ETA: 41s - loss: 0.5601 - accuracy: 0.834 - ETA: 41s - loss: 0.5610 - accuracy: 0.834 - ETA: 40s - loss: 0.5603 - accuracy: 0.834 - ETA: 39s - loss: 0.5572 - accuracy: 0.835 - ETA: 39s - loss: 0.5565 - accuracy: 0.835 - ETA: 38s - loss: 0.5582 - accuracy: 0.835 - ETA: 37s - loss: 0.5539 - accuracy: 0.836 - ETA: 37s - loss: 0.5535 - accuracy: 0.836 - ETA: 36s - loss: 0.5539 - accuracy: 0.836 - ETA: 35s - loss: 0.5581 - accuracy: 0.835 - ETA: 35s - loss: 0.5594 - accuracy: 0.834 - ETA: 34s - loss: 0.5570 - accuracy: 0.835 - ETA: 33s - loss: 0.5560 - accuracy: 0.835 - ETA: 32s - loss: 0.5548 - accuracy: 0.835 - ETA: 32s - loss: 0.5559 - accuracy: 0.835 - ETA: 31s - loss: 0.5583 - accuracy: 0.834 - ETA: 30s - loss: 0.5567 - accuracy: 0.834 - ETA: 30s - loss: 0.5560 - accuracy: 0.835 - ETA: 29s - loss: 0.5545 - accuracy: 0.835 - ETA: 28s - loss: 0.5532 - accuracy: 0.835 - ETA: 28s - loss: 0.5513 - accuracy: 0.836 - ETA: 27s - loss: 0.5484 - accuracy: 0.837 - ETA: 26s - loss: 0.5505 - accuracy: 0.837 - ETA: 26s - loss: 0.5514 - accuracy: 0.837 - ETA: 25s - loss: 0.5498 - accuracy: 0.837 - ETA: 24s - loss: 0.5494 - accuracy: 0.837 - ETA: 23s - loss: 0.5474 - accuracy: 0.838 - ETA: 23s - loss: 0.5474 - accuracy: 0.838 - ETA: 22s - loss: 0.5467 - accuracy: 0.837 - ETA: 21s - loss: 0.5456 - accuracy: 0.838 - ETA: 21s - loss: 0.5433 - accuracy: 0.838 - ETA: 20s - loss: 0.5410 - accuracy: 0.839 - ETA: 19s - loss: 0.5422 - accuracy: 0.838 - ETA: 19s - loss: 0.5411 - accuracy: 0.839 - ETA: 18s - loss: 0.5396 - accuracy: 0.840 - ETA: 17s - loss: 0.5410 - accuracy: 0.840 - ETA: 17s - loss: 0.5403 - accuracy: 0.840 - ETA: 16s - loss: 0.5393 - accuracy: 0.840 - ETA: 15s - loss: 0.5390 - accuracy: 0.840 - ETA: 15s - loss: 0.5357 - accuracy: 0.841 - ETA: 14s - loss: 0.5335 - accuracy: 0.842 - ETA: 13s - loss: 0.5346 - accuracy: 0.841 - ETA: 12s - loss: 0.5352 - accuracy: 0.841 - ETA: 12s - loss: 0.5343 - accuracy: 0.841 - ETA: 11s - loss: 0.5328 - accuracy: 0.841 - ETA: 10s - loss: 0.5330 - accuracy: 0.841 - ETA: 10s - loss: 0.5351 - accuracy: 0.841 - ETA: 9s - loss: 0.5351 - accuracy: 0.841 - ETA: 8s - loss: 0.5362 - accuracy: 0.84 - ETA: 8s - loss: 0.5361 - accuracy: 0.84 - ETA: 7s - loss: 0.5361 - accuracy: 0.84 - ETA: 6s - loss: 0.5372 - accuracy: 0.84 - ETA: 6s - loss: 0.5384 - accuracy: 0.84 - ETA: 5s - loss: 0.5382 - accuracy: 0.84 - ETA: 4s - loss: 0.5376 - accuracy: 0.84 - ETA: 3s - loss: 0.5383 - accuracy: 0.84 - ETA: 3s - loss: 0.5379 - accuracy: 0.84 - ETA: 2s - loss: 0.5371 - accuracy: 0.84 - ETA: 1s - loss: 0.5372 - accuracy: 0.84 - ETA: 1s - loss: 0.5364 - accuracy: 0.84 - ETA: 0s - loss: 0.5353 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5346 - accuracy: 0.8422 - val_loss: 3.3034 - val_accuracy: 0.3316\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:12 - loss: 0.6799 - accuracy: 0.79 - ETA: 1:09 - loss: 0.6424 - accuracy: 0.81 - ETA: 1:08 - loss: 0.5996 - accuracy: 0.82 - ETA: 1:07 - loss: 0.6161 - accuracy: 0.81 - ETA: 1:06 - loss: 0.5922 - accuracy: 0.82 - ETA: 1:06 - loss: 0.6116 - accuracy: 0.82 - ETA: 1:05 - loss: 0.5726 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5720 - accuracy: 0.82 - ETA: 1:03 - loss: 0.5484 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5259 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5258 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5270 - accuracy: 0.83 - ETA: 1:01 - loss: 0.5429 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5344 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5277 - accuracy: 0.84 - ETA: 59s - loss: 0.5403 - accuracy: 0.8389 - ETA: 58s - loss: 0.5416 - accuracy: 0.837 - ETA: 58s - loss: 0.5376 - accuracy: 0.839 - ETA: 57s - loss: 0.5371 - accuracy: 0.838 - ETA: 56s - loss: 0.5400 - accuracy: 0.838 - ETA: 55s - loss: 0.5401 - accuracy: 0.838 - ETA: 55s - loss: 0.5493 - accuracy: 0.836 - ETA: 54s - loss: 0.5475 - accuracy: 0.837 - ETA: 53s - loss: 0.5501 - accuracy: 0.838 - ETA: 52s - loss: 0.5472 - accuracy: 0.838 - ETA: 52s - loss: 0.5434 - accuracy: 0.838 - ETA: 51s - loss: 0.5397 - accuracy: 0.841 - ETA: 50s - loss: 0.5445 - accuracy: 0.840 - ETA: 50s - loss: 0.5413 - accuracy: 0.841 - ETA: 49s - loss: 0.5418 - accuracy: 0.842 - ETA: 48s - loss: 0.5408 - accuracy: 0.842 - ETA: 47s - loss: 0.5374 - accuracy: 0.843 - ETA: 47s - loss: 0.5378 - accuracy: 0.844 - ETA: 46s - loss: 0.5436 - accuracy: 0.841 - ETA: 45s - loss: 0.5424 - accuracy: 0.841 - ETA: 45s - loss: 0.5449 - accuracy: 0.840 - ETA: 44s - loss: 0.5422 - accuracy: 0.841 - ETA: 43s - loss: 0.5490 - accuracy: 0.839 - ETA: 43s - loss: 0.5494 - accuracy: 0.839 - ETA: 42s - loss: 0.5458 - accuracy: 0.841 - ETA: 41s - loss: 0.5473 - accuracy: 0.841 - ETA: 41s - loss: 0.5462 - accuracy: 0.842 - ETA: 40s - loss: 0.5482 - accuracy: 0.841 - ETA: 39s - loss: 0.5465 - accuracy: 0.841 - ETA: 39s - loss: 0.5457 - accuracy: 0.841 - ETA: 38s - loss: 0.5431 - accuracy: 0.842 - ETA: 37s - loss: 0.5437 - accuracy: 0.841 - ETA: 37s - loss: 0.5460 - accuracy: 0.841 - ETA: 36s - loss: 0.5477 - accuracy: 0.840 - ETA: 35s - loss: 0.5497 - accuracy: 0.839 - ETA: 35s - loss: 0.5493 - accuracy: 0.840 - ETA: 34s - loss: 0.5497 - accuracy: 0.839 - ETA: 33s - loss: 0.5479 - accuracy: 0.839 - ETA: 33s - loss: 0.5507 - accuracy: 0.838 - ETA: 32s - loss: 0.5505 - accuracy: 0.839 - ETA: 31s - loss: 0.5498 - accuracy: 0.839 - ETA: 31s - loss: 0.5514 - accuracy: 0.839 - ETA: 30s - loss: 0.5506 - accuracy: 0.839 - ETA: 29s - loss: 0.5491 - accuracy: 0.840 - ETA: 29s - loss: 0.5459 - accuracy: 0.841 - ETA: 28s - loss: 0.5456 - accuracy: 0.841 - ETA: 27s - loss: 0.5409 - accuracy: 0.842 - ETA: 26s - loss: 0.5407 - accuracy: 0.842 - ETA: 26s - loss: 0.5440 - accuracy: 0.842 - ETA: 25s - loss: 0.5398 - accuracy: 0.843 - ETA: 24s - loss: 0.5405 - accuracy: 0.842 - ETA: 24s - loss: 0.5431 - accuracy: 0.842 - ETA: 23s - loss: 0.5415 - accuracy: 0.842 - ETA: 22s - loss: 0.5408 - accuracy: 0.843 - ETA: 22s - loss: 0.5400 - accuracy: 0.843 - ETA: 21s - loss: 0.5389 - accuracy: 0.844 - ETA: 20s - loss: 0.5389 - accuracy: 0.843 - ETA: 20s - loss: 0.5379 - accuracy: 0.844 - ETA: 19s - loss: 0.5378 - accuracy: 0.844 - ETA: 18s - loss: 0.5379 - accuracy: 0.844 - ETA: 17s - loss: 0.5393 - accuracy: 0.843 - ETA: 17s - loss: 0.5384 - accuracy: 0.844 - ETA: 16s - loss: 0.5385 - accuracy: 0.844 - ETA: 15s - loss: 0.5385 - accuracy: 0.844 - ETA: 15s - loss: 0.5361 - accuracy: 0.844 - ETA: 14s - loss: 0.5348 - accuracy: 0.844 - ETA: 13s - loss: 0.5341 - accuracy: 0.844 - ETA: 12s - loss: 0.5349 - accuracy: 0.844 - ETA: 12s - loss: 0.5335 - accuracy: 0.844 - ETA: 11s - loss: 0.5337 - accuracy: 0.844 - ETA: 10s - loss: 0.5341 - accuracy: 0.844 - ETA: 10s - loss: 0.5373 - accuracy: 0.843 - ETA: 9s - loss: 0.5376 - accuracy: 0.843 - ETA: 8s - loss: 0.5372 - accuracy: 0.84 - ETA: 8s - loss: 0.5367 - accuracy: 0.84 - ETA: 7s - loss: 0.5358 - accuracy: 0.84 - ETA: 6s - loss: 0.5382 - accuracy: 0.84 - ETA: 6s - loss: 0.5378 - accuracy: 0.84 - ETA: 5s - loss: 0.5369 - accuracy: 0.84 - ETA: 4s - loss: 0.5359 - accuracy: 0.84 - ETA: 3s - loss: 0.5361 - accuracy: 0.84 - ETA: 3s - loss: 0.5376 - accuracy: 0.84 - ETA: 2s - loss: 0.5359 - accuracy: 0.84 - ETA: 1s - loss: 0.5363 - accuracy: 0.84 - ETA: 1s - loss: 0.5345 - accuracy: 0.84 - ETA: 0s - loss: 0.5329 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5322 - accuracy: 0.8446 - val_loss: 3.5888 - val_accuracy: 0.3142\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:11 - loss: 0.3994 - accuracy: 0.87 - ETA: 1:07 - loss: 0.3183 - accuracy: 0.90 - ETA: 1:07 - loss: 0.4180 - accuracy: 0.87 - ETA: 1:06 - loss: 0.3846 - accuracy: 0.88 - ETA: 1:04 - loss: 0.4394 - accuracy: 0.86 - ETA: 1:04 - loss: 0.4452 - accuracy: 0.85 - ETA: 1:03 - loss: 0.4522 - accuracy: 0.85 - ETA: 1:02 - loss: 0.4559 - accuracy: 0.85 - ETA: 1:02 - loss: 0.4681 - accuracy: 0.85 - ETA: 1:01 - loss: 0.4787 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4974 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4968 - accuracy: 0.84 - ETA: 59s - loss: 0.5023 - accuracy: 0.8450 - ETA: 59s - loss: 0.5006 - accuracy: 0.844 - ETA: 59s - loss: 0.4986 - accuracy: 0.844 - ETA: 58s - loss: 0.5005 - accuracy: 0.844 - ETA: 58s - loss: 0.4915 - accuracy: 0.848 - ETA: 57s - loss: 0.4921 - accuracy: 0.845 - ETA: 57s - loss: 0.4948 - accuracy: 0.847 - ETA: 56s - loss: 0.4909 - accuracy: 0.849 - ETA: 55s - loss: 0.4886 - accuracy: 0.849 - ETA: 54s - loss: 0.4858 - accuracy: 0.849 - ETA: 54s - loss: 0.4902 - accuracy: 0.848 - ETA: 53s - loss: 0.4972 - accuracy: 0.847 - ETA: 52s - loss: 0.4976 - accuracy: 0.847 - ETA: 52s - loss: 0.5041 - accuracy: 0.846 - ETA: 51s - loss: 0.5011 - accuracy: 0.847 - ETA: 50s - loss: 0.4973 - accuracy: 0.849 - ETA: 50s - loss: 0.5074 - accuracy: 0.847 - ETA: 49s - loss: 0.5136 - accuracy: 0.846 - ETA: 48s - loss: 0.5138 - accuracy: 0.845 - ETA: 48s - loss: 0.5158 - accuracy: 0.845 - ETA: 47s - loss: 0.5168 - accuracy: 0.844 - ETA: 46s - loss: 0.5168 - accuracy: 0.844 - ETA: 46s - loss: 0.5134 - accuracy: 0.845 - ETA: 45s - loss: 0.5133 - accuracy: 0.845 - ETA: 44s - loss: 0.5098 - accuracy: 0.846 - ETA: 44s - loss: 0.5112 - accuracy: 0.845 - ETA: 43s - loss: 0.5125 - accuracy: 0.846 - ETA: 42s - loss: 0.5150 - accuracy: 0.845 - ETA: 42s - loss: 0.5205 - accuracy: 0.843 - ETA: 41s - loss: 0.5212 - accuracy: 0.843 - ETA: 40s - loss: 0.5211 - accuracy: 0.844 - ETA: 40s - loss: 0.5234 - accuracy: 0.843 - ETA: 39s - loss: 0.5254 - accuracy: 0.843 - ETA: 38s - loss: 0.5255 - accuracy: 0.843 - ETA: 37s - loss: 0.5309 - accuracy: 0.841 - ETA: 37s - loss: 0.5285 - accuracy: 0.842 - ETA: 36s - loss: 0.5230 - accuracy: 0.844 - ETA: 35s - loss: 0.5250 - accuracy: 0.843 - ETA: 35s - loss: 0.5242 - accuracy: 0.843 - ETA: 34s - loss: 0.5204 - accuracy: 0.844 - ETA: 33s - loss: 0.5209 - accuracy: 0.844 - ETA: 33s - loss: 0.5220 - accuracy: 0.844 - ETA: 32s - loss: 0.5237 - accuracy: 0.843 - ETA: 31s - loss: 0.5273 - accuracy: 0.843 - ETA: 30s - loss: 0.5285 - accuracy: 0.843 - ETA: 30s - loss: 0.5295 - accuracy: 0.843 - ETA: 29s - loss: 0.5305 - accuracy: 0.842 - ETA: 28s - loss: 0.5316 - accuracy: 0.841 - ETA: 28s - loss: 0.5298 - accuracy: 0.842 - ETA: 27s - loss: 0.5315 - accuracy: 0.841 - ETA: 26s - loss: 0.5310 - accuracy: 0.841 - ETA: 26s - loss: 0.5306 - accuracy: 0.841 - ETA: 25s - loss: 0.5321 - accuracy: 0.841 - ETA: 24s - loss: 0.5320 - accuracy: 0.841 - ETA: 24s - loss: 0.5319 - accuracy: 0.841 - ETA: 23s - loss: 0.5297 - accuracy: 0.841 - ETA: 22s - loss: 0.5311 - accuracy: 0.841 - ETA: 21s - loss: 0.5314 - accuracy: 0.841 - ETA: 21s - loss: 0.5311 - accuracy: 0.841 - ETA: 20s - loss: 0.5318 - accuracy: 0.840 - ETA: 19s - loss: 0.5312 - accuracy: 0.840 - ETA: 19s - loss: 0.5319 - accuracy: 0.840 - ETA: 18s - loss: 0.5319 - accuracy: 0.840 - ETA: 17s - loss: 0.5341 - accuracy: 0.840 - ETA: 17s - loss: 0.5330 - accuracy: 0.840 - ETA: 16s - loss: 0.5336 - accuracy: 0.840 - ETA: 15s - loss: 0.5324 - accuracy: 0.840 - ETA: 15s - loss: 0.5317 - accuracy: 0.841 - ETA: 14s - loss: 0.5313 - accuracy: 0.841 - ETA: 13s - loss: 0.5309 - accuracy: 0.841 - ETA: 12s - loss: 0.5297 - accuracy: 0.841 - ETA: 12s - loss: 0.5294 - accuracy: 0.841 - ETA: 11s - loss: 0.5305 - accuracy: 0.841 - ETA: 10s - loss: 0.5330 - accuracy: 0.840 - ETA: 10s - loss: 0.5346 - accuracy: 0.840 - ETA: 9s - loss: 0.5338 - accuracy: 0.840 - ETA: 8s - loss: 0.5336 - accuracy: 0.84 - ETA: 8s - loss: 0.5338 - accuracy: 0.84 - ETA: 7s - loss: 0.5340 - accuracy: 0.84 - ETA: 6s - loss: 0.5347 - accuracy: 0.84 - ETA: 6s - loss: 0.5348 - accuracy: 0.84 - ETA: 5s - loss: 0.5345 - accuracy: 0.84 - ETA: 4s - loss: 0.5329 - accuracy: 0.84 - ETA: 3s - loss: 0.5340 - accuracy: 0.84 - ETA: 3s - loss: 0.5342 - accuracy: 0.84 - ETA: 2s - loss: 0.5344 - accuracy: 0.84 - ETA: 1s - loss: 0.5350 - accuracy: 0.84 - ETA: 1s - loss: 0.5343 - accuracy: 0.84 - ETA: 0s - loss: 0.5338 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5343 - accuracy: 0.8410 - val_loss: 3.4833 - val_accuracy: 0.3073\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:13 - loss: 0.4793 - accuracy: 0.84 - ETA: 1:10 - loss: 0.4810 - accuracy: 0.83 - ETA: 1:08 - loss: 0.4917 - accuracy: 0.83 - ETA: 1:07 - loss: 0.5039 - accuracy: 0.83 - ETA: 1:06 - loss: 0.5297 - accuracy: 0.83 - ETA: 1:05 - loss: 0.5347 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5383 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5430 - accuracy: 0.83 - ETA: 1:04 - loss: 0.5303 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5231 - accuracy: 0.83 - ETA: 1:03 - loss: 0.5293 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5217 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5090 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5005 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5057 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5175 - accuracy: 0.84 - ETA: 59s - loss: 0.5164 - accuracy: 0.8447 - ETA: 58s - loss: 0.5140 - accuracy: 0.845 - ETA: 57s - loss: 0.5119 - accuracy: 0.845 - ETA: 57s - loss: 0.5165 - accuracy: 0.843 - ETA: 56s - loss: 0.5182 - accuracy: 0.841 - ETA: 55s - loss: 0.5152 - accuracy: 0.843 - ETA: 54s - loss: 0.5141 - accuracy: 0.844 - ETA: 54s - loss: 0.5185 - accuracy: 0.842 - ETA: 53s - loss: 0.5260 - accuracy: 0.840 - ETA: 52s - loss: 0.5301 - accuracy: 0.840 - ETA: 51s - loss: 0.5276 - accuracy: 0.841 - ETA: 51s - loss: 0.5261 - accuracy: 0.842 - ETA: 50s - loss: 0.5251 - accuracy: 0.841 - ETA: 49s - loss: 0.5244 - accuracy: 0.843 - ETA: 49s - loss: 0.5218 - accuracy: 0.844 - ETA: 48s - loss: 0.5214 - accuracy: 0.844 - ETA: 47s - loss: 0.5204 - accuracy: 0.843 - ETA: 47s - loss: 0.5171 - accuracy: 0.844 - ETA: 46s - loss: 0.5107 - accuracy: 0.846 - ETA: 45s - loss: 0.5102 - accuracy: 0.846 - ETA: 45s - loss: 0.5092 - accuracy: 0.848 - ETA: 44s - loss: 0.5148 - accuracy: 0.847 - ETA: 43s - loss: 0.5150 - accuracy: 0.846 - ETA: 43s - loss: 0.5168 - accuracy: 0.846 - ETA: 42s - loss: 0.5144 - accuracy: 0.847 - ETA: 41s - loss: 0.5149 - accuracy: 0.846 - ETA: 40s - loss: 0.5117 - accuracy: 0.847 - ETA: 40s - loss: 0.5141 - accuracy: 0.847 - ETA: 39s - loss: 0.5128 - accuracy: 0.848 - ETA: 38s - loss: 0.5148 - accuracy: 0.848 - ETA: 38s - loss: 0.5149 - accuracy: 0.848 - ETA: 37s - loss: 0.5169 - accuracy: 0.847 - ETA: 36s - loss: 0.5156 - accuracy: 0.848 - ETA: 35s - loss: 0.5148 - accuracy: 0.848 - ETA: 35s - loss: 0.5136 - accuracy: 0.848 - ETA: 34s - loss: 0.5162 - accuracy: 0.847 - ETA: 33s - loss: 0.5187 - accuracy: 0.847 - ETA: 33s - loss: 0.5169 - accuracy: 0.847 - ETA: 32s - loss: 0.5181 - accuracy: 0.847 - ETA: 31s - loss: 0.5189 - accuracy: 0.847 - ETA: 31s - loss: 0.5170 - accuracy: 0.847 - ETA: 30s - loss: 0.5140 - accuracy: 0.848 - ETA: 29s - loss: 0.5133 - accuracy: 0.848 - ETA: 28s - loss: 0.5136 - accuracy: 0.848 - ETA: 28s - loss: 0.5123 - accuracy: 0.848 - ETA: 27s - loss: 0.5110 - accuracy: 0.848 - ETA: 26s - loss: 0.5091 - accuracy: 0.849 - ETA: 26s - loss: 0.5103 - accuracy: 0.849 - ETA: 25s - loss: 0.5101 - accuracy: 0.849 - ETA: 24s - loss: 0.5088 - accuracy: 0.849 - ETA: 24s - loss: 0.5074 - accuracy: 0.850 - ETA: 23s - loss: 0.5084 - accuracy: 0.849 - ETA: 22s - loss: 0.5068 - accuracy: 0.850 - ETA: 21s - loss: 0.5074 - accuracy: 0.850 - ETA: 21s - loss: 0.5105 - accuracy: 0.849 - ETA: 20s - loss: 0.5096 - accuracy: 0.850 - ETA: 19s - loss: 0.5091 - accuracy: 0.850 - ETA: 19s - loss: 0.5082 - accuracy: 0.849 - ETA: 18s - loss: 0.5069 - accuracy: 0.850 - ETA: 17s - loss: 0.5090 - accuracy: 0.849 - ETA: 17s - loss: 0.5083 - accuracy: 0.850 - ETA: 16s - loss: 0.5072 - accuracy: 0.850 - ETA: 15s - loss: 0.5067 - accuracy: 0.850 - ETA: 15s - loss: 0.5057 - accuracy: 0.850 - ETA: 14s - loss: 0.5060 - accuracy: 0.850 - ETA: 13s - loss: 0.5076 - accuracy: 0.850 - ETA: 12s - loss: 0.5077 - accuracy: 0.850 - ETA: 12s - loss: 0.5075 - accuracy: 0.849 - ETA: 11s - loss: 0.5105 - accuracy: 0.848 - ETA: 10s - loss: 0.5118 - accuracy: 0.848 - ETA: 10s - loss: 0.5101 - accuracy: 0.848 - ETA: 9s - loss: 0.5101 - accuracy: 0.848 - ETA: 8s - loss: 0.5108 - accuracy: 0.84 - ETA: 8s - loss: 0.5123 - accuracy: 0.84 - ETA: 7s - loss: 0.5121 - accuracy: 0.84 - ETA: 6s - loss: 0.5103 - accuracy: 0.84 - ETA: 6s - loss: 0.5088 - accuracy: 0.84 - ETA: 5s - loss: 0.5118 - accuracy: 0.84 - ETA: 4s - loss: 0.5111 - accuracy: 0.84 - ETA: 3s - loss: 0.5139 - accuracy: 0.84 - ETA: 3s - loss: 0.5147 - accuracy: 0.84 - ETA: 2s - loss: 0.5143 - accuracy: 0.84 - ETA: 1s - loss: 0.5149 - accuracy: 0.84 - ETA: 1s - loss: 0.5146 - accuracy: 0.84 - ETA: 0s - loss: 0.5168 - accuracy: 0.84 - 82s 6ms/step - loss: 0.5162 - accuracy: 0.8473 - val_loss: 3.6539 - val_accuracy: 0.2991\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:10 - loss: 0.4735 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4893 - accuracy: 0.84 - ETA: 1:07 - loss: 0.5023 - accuracy: 0.85 - ETA: 1:06 - loss: 0.4985 - accuracy: 0.85 - ETA: 1:05 - loss: 0.5034 - accuracy: 0.85 - ETA: 1:05 - loss: 0.5043 - accuracy: 0.85 - ETA: 1:04 - loss: 0.5432 - accuracy: 0.84 - ETA: 1:05 - loss: 0.5311 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5181 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5010 - accuracy: 0.85 - ETA: 1:03 - loss: 0.5015 - accuracy: 0.85 - ETA: 1:02 - loss: 0.5126 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5217 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5175 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5203 - accuracy: 0.84 - ETA: 59s - loss: 0.5215 - accuracy: 0.8452 - ETA: 59s - loss: 0.5227 - accuracy: 0.844 - ETA: 58s - loss: 0.5196 - accuracy: 0.844 - ETA: 57s - loss: 0.5164 - accuracy: 0.845 - ETA: 57s - loss: 0.5197 - accuracy: 0.843 - ETA: 56s - loss: 0.5193 - accuracy: 0.843 - ETA: 55s - loss: 0.5272 - accuracy: 0.843 - ETA: 54s - loss: 0.5268 - accuracy: 0.841 - ETA: 54s - loss: 0.5331 - accuracy: 0.840 - ETA: 53s - loss: 0.5337 - accuracy: 0.840 - ETA: 52s - loss: 0.5368 - accuracy: 0.840 - ETA: 51s - loss: 0.5335 - accuracy: 0.841 - ETA: 51s - loss: 0.5288 - accuracy: 0.842 - ETA: 50s - loss: 0.5279 - accuracy: 0.843 - ETA: 49s - loss: 0.5253 - accuracy: 0.844 - ETA: 49s - loss: 0.5252 - accuracy: 0.843 - ETA: 48s - loss: 0.5224 - accuracy: 0.844 - ETA: 47s - loss: 0.5178 - accuracy: 0.844 - ETA: 47s - loss: 0.5244 - accuracy: 0.843 - ETA: 46s - loss: 0.5288 - accuracy: 0.840 - ETA: 45s - loss: 0.5292 - accuracy: 0.839 - ETA: 44s - loss: 0.5308 - accuracy: 0.839 - ETA: 44s - loss: 0.5347 - accuracy: 0.839 - ETA: 43s - loss: 0.5316 - accuracy: 0.840 - ETA: 42s - loss: 0.5349 - accuracy: 0.840 - ETA: 42s - loss: 0.5375 - accuracy: 0.839 - ETA: 41s - loss: 0.5354 - accuracy: 0.840 - ETA: 40s - loss: 0.5360 - accuracy: 0.840 - ETA: 39s - loss: 0.5355 - accuracy: 0.840 - ETA: 39s - loss: 0.5330 - accuracy: 0.840 - ETA: 38s - loss: 0.5325 - accuracy: 0.840 - ETA: 37s - loss: 0.5349 - accuracy: 0.840 - ETA: 37s - loss: 0.5310 - accuracy: 0.841 - ETA: 36s - loss: 0.5302 - accuracy: 0.842 - ETA: 35s - loss: 0.5307 - accuracy: 0.841 - ETA: 35s - loss: 0.5299 - accuracy: 0.842 - ETA: 34s - loss: 0.5298 - accuracy: 0.842 - ETA: 33s - loss: 0.5282 - accuracy: 0.843 - ETA: 33s - loss: 0.5258 - accuracy: 0.844 - ETA: 32s - loss: 0.5254 - accuracy: 0.844 - ETA: 31s - loss: 0.5225 - accuracy: 0.845 - ETA: 30s - loss: 0.5206 - accuracy: 0.845 - ETA: 30s - loss: 0.5181 - accuracy: 0.846 - ETA: 29s - loss: 0.5191 - accuracy: 0.846 - ETA: 28s - loss: 0.5170 - accuracy: 0.846 - ETA: 28s - loss: 0.5162 - accuracy: 0.846 - ETA: 27s - loss: 0.5181 - accuracy: 0.846 - ETA: 26s - loss: 0.5190 - accuracy: 0.845 - ETA: 26s - loss: 0.5196 - accuracy: 0.845 - ETA: 25s - loss: 0.5234 - accuracy: 0.845 - ETA: 24s - loss: 0.5261 - accuracy: 0.845 - ETA: 24s - loss: 0.5260 - accuracy: 0.845 - ETA: 23s - loss: 0.5281 - accuracy: 0.844 - ETA: 22s - loss: 0.5292 - accuracy: 0.844 - ETA: 21s - loss: 0.5274 - accuracy: 0.844 - ETA: 21s - loss: 0.5246 - accuracy: 0.845 - ETA: 20s - loss: 0.5268 - accuracy: 0.844 - ETA: 19s - loss: 0.5270 - accuracy: 0.844 - ETA: 19s - loss: 0.5254 - accuracy: 0.844 - ETA: 18s - loss: 0.5249 - accuracy: 0.845 - ETA: 17s - loss: 0.5231 - accuracy: 0.845 - ETA: 17s - loss: 0.5242 - accuracy: 0.844 - ETA: 16s - loss: 0.5233 - accuracy: 0.845 - ETA: 15s - loss: 0.5277 - accuracy: 0.844 - ETA: 15s - loss: 0.5275 - accuracy: 0.843 - ETA: 14s - loss: 0.5245 - accuracy: 0.844 - ETA: 13s - loss: 0.5251 - accuracy: 0.844 - ETA: 12s - loss: 0.5243 - accuracy: 0.845 - ETA: 12s - loss: 0.5250 - accuracy: 0.844 - ETA: 11s - loss: 0.5232 - accuracy: 0.845 - ETA: 10s - loss: 0.5220 - accuracy: 0.845 - ETA: 10s - loss: 0.5210 - accuracy: 0.845 - ETA: 9s - loss: 0.5218 - accuracy: 0.845 - ETA: 8s - loss: 0.5207 - accuracy: 0.84 - ETA: 8s - loss: 0.5210 - accuracy: 0.84 - ETA: 7s - loss: 0.5200 - accuracy: 0.84 - ETA: 6s - loss: 0.5191 - accuracy: 0.84 - ETA: 6s - loss: 0.5181 - accuracy: 0.84 - ETA: 5s - loss: 0.5160 - accuracy: 0.84 - ETA: 4s - loss: 0.5143 - accuracy: 0.84 - ETA: 3s - loss: 0.5151 - accuracy: 0.84 - ETA: 3s - loss: 0.5151 - accuracy: 0.84 - ETA: 2s - loss: 0.5168 - accuracy: 0.84 - ETA: 1s - loss: 0.5157 - accuracy: 0.84 - ETA: 1s - loss: 0.5145 - accuracy: 0.84 - ETA: 0s - loss: 0.5137 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5142 - accuracy: 0.8467 - val_loss: 3.3848 - val_accuracy: 0.3209\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:16 - loss: 0.6620 - accuracy: 0.86 - ETA: 1:11 - loss: 0.5345 - accuracy: 0.87 - ETA: 1:09 - loss: 0.4736 - accuracy: 0.87 - ETA: 1:08 - loss: 0.4891 - accuracy: 0.86 - ETA: 1:07 - loss: 0.4886 - accuracy: 0.86 - ETA: 1:06 - loss: 0.4697 - accuracy: 0.86 - ETA: 1:06 - loss: 0.4670 - accuracy: 0.86 - ETA: 1:06 - loss: 0.5047 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4953 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4922 - accuracy: 0.85 - ETA: 1:04 - loss: 0.4929 - accuracy: 0.85 - ETA: 1:03 - loss: 0.4950 - accuracy: 0.85 - ETA: 1:02 - loss: 0.4977 - accuracy: 0.85 - ETA: 1:01 - loss: 0.5095 - accuracy: 0.84 - ETA: 1:01 - loss: 0.5177 - accuracy: 0.84 - ETA: 1:00 - loss: 0.5247 - accuracy: 0.84 - ETA: 59s - loss: 0.5368 - accuracy: 0.8355 - ETA: 58s - loss: 0.5360 - accuracy: 0.835 - ETA: 57s - loss: 0.5341 - accuracy: 0.836 - ETA: 56s - loss: 0.5303 - accuracy: 0.839 - ETA: 56s - loss: 0.5173 - accuracy: 0.843 - ETA: 55s - loss: 0.5220 - accuracy: 0.840 - ETA: 54s - loss: 0.5234 - accuracy: 0.841 - ETA: 54s - loss: 0.5254 - accuracy: 0.841 - ETA: 53s - loss: 0.5387 - accuracy: 0.838 - ETA: 52s - loss: 0.5391 - accuracy: 0.838 - ETA: 51s - loss: 0.5377 - accuracy: 0.839 - ETA: 51s - loss: 0.5369 - accuracy: 0.839 - ETA: 50s - loss: 0.5334 - accuracy: 0.840 - ETA: 49s - loss: 0.5352 - accuracy: 0.840 - ETA: 49s - loss: 0.5324 - accuracy: 0.841 - ETA: 48s - loss: 0.5384 - accuracy: 0.840 - ETA: 47s - loss: 0.5364 - accuracy: 0.841 - ETA: 47s - loss: 0.5388 - accuracy: 0.840 - ETA: 46s - loss: 0.5379 - accuracy: 0.841 - ETA: 45s - loss: 0.5304 - accuracy: 0.843 - ETA: 45s - loss: 0.5281 - accuracy: 0.843 - ETA: 44s - loss: 0.5344 - accuracy: 0.843 - ETA: 43s - loss: 0.5337 - accuracy: 0.843 - ETA: 42s - loss: 0.5331 - accuracy: 0.843 - ETA: 42s - loss: 0.5349 - accuracy: 0.842 - ETA: 41s - loss: 0.5336 - accuracy: 0.843 - ETA: 40s - loss: 0.5320 - accuracy: 0.843 - ETA: 40s - loss: 0.5337 - accuracy: 0.842 - ETA: 39s - loss: 0.5317 - accuracy: 0.842 - ETA: 38s - loss: 0.5283 - accuracy: 0.844 - ETA: 38s - loss: 0.5274 - accuracy: 0.843 - ETA: 37s - loss: 0.5284 - accuracy: 0.844 - ETA: 36s - loss: 0.5308 - accuracy: 0.843 - ETA: 35s - loss: 0.5345 - accuracy: 0.843 - ETA: 35s - loss: 0.5324 - accuracy: 0.843 - ETA: 34s - loss: 0.5343 - accuracy: 0.842 - ETA: 33s - loss: 0.5309 - accuracy: 0.843 - ETA: 33s - loss: 0.5310 - accuracy: 0.843 - ETA: 32s - loss: 0.5293 - accuracy: 0.843 - ETA: 31s - loss: 0.5273 - accuracy: 0.844 - ETA: 31s - loss: 0.5279 - accuracy: 0.845 - ETA: 30s - loss: 0.5291 - accuracy: 0.844 - ETA: 29s - loss: 0.5297 - accuracy: 0.844 - ETA: 28s - loss: 0.5301 - accuracy: 0.844 - ETA: 28s - loss: 0.5263 - accuracy: 0.845 - ETA: 27s - loss: 0.5276 - accuracy: 0.844 - ETA: 26s - loss: 0.5289 - accuracy: 0.844 - ETA: 26s - loss: 0.5284 - accuracy: 0.845 - ETA: 25s - loss: 0.5288 - accuracy: 0.845 - ETA: 24s - loss: 0.5296 - accuracy: 0.845 - ETA: 24s - loss: 0.5283 - accuracy: 0.846 - ETA: 23s - loss: 0.5297 - accuracy: 0.846 - ETA: 22s - loss: 0.5303 - accuracy: 0.845 - ETA: 22s - loss: 0.5290 - accuracy: 0.846 - ETA: 21s - loss: 0.5276 - accuracy: 0.846 - ETA: 20s - loss: 0.5268 - accuracy: 0.846 - ETA: 19s - loss: 0.5300 - accuracy: 0.845 - ETA: 19s - loss: 0.5309 - accuracy: 0.845 - ETA: 18s - loss: 0.5312 - accuracy: 0.845 - ETA: 17s - loss: 0.5308 - accuracy: 0.845 - ETA: 17s - loss: 0.5293 - accuracy: 0.845 - ETA: 16s - loss: 0.5281 - accuracy: 0.846 - ETA: 15s - loss: 0.5275 - accuracy: 0.846 - ETA: 15s - loss: 0.5308 - accuracy: 0.845 - ETA: 14s - loss: 0.5302 - accuracy: 0.846 - ETA: 13s - loss: 0.5300 - accuracy: 0.845 - ETA: 12s - loss: 0.5292 - accuracy: 0.846 - ETA: 12s - loss: 0.5303 - accuracy: 0.846 - ETA: 11s - loss: 0.5301 - accuracy: 0.847 - ETA: 10s - loss: 0.5295 - accuracy: 0.846 - ETA: 10s - loss: 0.5303 - accuracy: 0.846 - ETA: 9s - loss: 0.5288 - accuracy: 0.846 - ETA: 8s - loss: 0.5307 - accuracy: 0.84 - ETA: 8s - loss: 0.5304 - accuracy: 0.84 - ETA: 7s - loss: 0.5293 - accuracy: 0.84 - ETA: 6s - loss: 0.5281 - accuracy: 0.84 - ETA: 6s - loss: 0.5284 - accuracy: 0.84 - ETA: 5s - loss: 0.5287 - accuracy: 0.84 - ETA: 4s - loss: 0.5295 - accuracy: 0.84 - ETA: 3s - loss: 0.5283 - accuracy: 0.84 - ETA: 3s - loss: 0.5285 - accuracy: 0.84 - ETA: 2s - loss: 0.5291 - accuracy: 0.84 - ETA: 1s - loss: 0.5286 - accuracy: 0.84 - ETA: 1s - loss: 0.5281 - accuracy: 0.84 - ETA: 0s - loss: 0.5286 - accuracy: 0.84 - 81s 6ms/step - loss: 0.5322 - accuracy: 0.8458 - val_loss: 3.4146 - val_accuracy: 0.3044\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13022/13022 [==============================] - ETA: 1:17 - loss: 0.5820 - accuracy: 0.76 - ETA: 1:17 - loss: 0.6323 - accuracy: 0.78 - ETA: 1:14 - loss: 0.6072 - accuracy: 0.81 - ETA: 1:14 - loss: 0.5360 - accuracy: 0.83 - ETA: 1:13 - loss: 0.5184 - accuracy: 0.83 - ETA: 1:11 - loss: 0.5220 - accuracy: 0.83 - ETA: 1:10 - loss: 0.5253 - accuracy: 0.83 - ETA: 1:09 - loss: 0.5219 - accuracy: 0.84 - ETA: 1:08 - loss: 0.5112 - accuracy: 0.84 - ETA: 1:07 - loss: 0.4965 - accuracy: 0.84 - ETA: 1:06 - loss: 0.4961 - accuracy: 0.84 - ETA: 1:05 - loss: 0.4878 - accuracy: 0.84 - ETA: 1:04 - loss: 0.5033 - accuracy: 0.84 - ETA: 1:03 - loss: 0.5060 - accuracy: 0.84 - ETA: 1:02 - loss: 0.5090 - accuracy: 0.84 - ETA: 1:01 - loss: 0.4989 - accuracy: 0.84 - ETA: 1:00 - loss: 0.4958 - accuracy: 0.84 - ETA: 59s - loss: 0.4985 - accuracy: 0.8433 - ETA: 59s - loss: 0.4966 - accuracy: 0.843 - ETA: 58s - loss: 0.4956 - accuracy: 0.843 - ETA: 57s - loss: 0.4965 - accuracy: 0.844 - ETA: 57s - loss: 0.4977 - accuracy: 0.843 - ETA: 56s - loss: 0.4969 - accuracy: 0.844 - ETA: 55s - loss: 0.4996 - accuracy: 0.844 - ETA: 54s - loss: 0.5014 - accuracy: 0.844 - ETA: 53s - loss: 0.5060 - accuracy: 0.842 - ETA: 53s - loss: 0.5051 - accuracy: 0.843 - ETA: 52s - loss: 0.5062 - accuracy: 0.844 - ETA: 51s - loss: 0.5104 - accuracy: 0.843 - ETA: 50s - loss: 0.5078 - accuracy: 0.844 - ETA: 50s - loss: 0.5072 - accuracy: 0.846 - ETA: 49s - loss: 0.5123 - accuracy: 0.844 - ETA: 48s - loss: 0.5088 - accuracy: 0.846 - ETA: 48s - loss: 0.5068 - accuracy: 0.847 - ETA: 47s - loss: 0.5096 - accuracy: 0.846 - ETA: 46s - loss: 0.5077 - accuracy: 0.847 - ETA: 46s - loss: 0.5061 - accuracy: 0.847 - ETA: 45s - loss: 0.5083 - accuracy: 0.847 - ETA: 44s - loss: 0.5082 - accuracy: 0.847 - ETA: 44s - loss: 0.5095 - accuracy: 0.847 - ETA: 43s - loss: 0.5100 - accuracy: 0.847 - ETA: 42s - loss: 0.5107 - accuracy: 0.847 - ETA: 41s - loss: 0.5112 - accuracy: 0.848 - ETA: 41s - loss: 0.5075 - accuracy: 0.848 - ETA: 40s - loss: 0.5050 - accuracy: 0.849 - ETA: 39s - loss: 0.5065 - accuracy: 0.849 - ETA: 38s - loss: 0.5107 - accuracy: 0.848 - ETA: 38s - loss: 0.5109 - accuracy: 0.849 - ETA: 37s - loss: 0.5107 - accuracy: 0.849 - ETA: 36s - loss: 0.5126 - accuracy: 0.849 - ETA: 35s - loss: 0.5094 - accuracy: 0.850 - ETA: 35s - loss: 0.5099 - accuracy: 0.849 - ETA: 34s - loss: 0.5128 - accuracy: 0.848 - ETA: 33s - loss: 0.5155 - accuracy: 0.847 - ETA: 33s - loss: 0.5146 - accuracy: 0.848 - ETA: 32s - loss: 0.5148 - accuracy: 0.847 - ETA: 31s - loss: 0.5129 - accuracy: 0.848 - ETA: 30s - loss: 0.5140 - accuracy: 0.847 - ETA: 30s - loss: 0.5147 - accuracy: 0.848 - ETA: 29s - loss: 0.5131 - accuracy: 0.848 - ETA: 28s - loss: 0.5111 - accuracy: 0.849 - ETA: 27s - loss: 0.5107 - accuracy: 0.848 - ETA: 27s - loss: 0.5083 - accuracy: 0.849 - ETA: 26s - loss: 0.5076 - accuracy: 0.850 - ETA: 25s - loss: 0.5070 - accuracy: 0.850 - ETA: 25s - loss: 0.5067 - accuracy: 0.850 - ETA: 24s - loss: 0.5051 - accuracy: 0.849 - ETA: 23s - loss: 0.5037 - accuracy: 0.850 - ETA: 22s - loss: 0.5048 - accuracy: 0.850 - ETA: 22s - loss: 0.5036 - accuracy: 0.850 - ETA: 21s - loss: 0.5023 - accuracy: 0.850 - ETA: 20s - loss: 0.5025 - accuracy: 0.850 - ETA: 20s - loss: 0.5016 - accuracy: 0.850 - ETA: 19s - loss: 0.5007 - accuracy: 0.851 - ETA: 18s - loss: 0.5029 - accuracy: 0.850 - ETA: 18s - loss: 0.5024 - accuracy: 0.850 - ETA: 17s - loss: 0.5037 - accuracy: 0.851 - ETA: 16s - loss: 0.5040 - accuracy: 0.850 - ETA: 15s - loss: 0.5026 - accuracy: 0.850 - ETA: 15s - loss: 0.5053 - accuracy: 0.849 - ETA: 14s - loss: 0.5047 - accuracy: 0.850 - ETA: 13s - loss: 0.5046 - accuracy: 0.850 - ETA: 13s - loss: 0.5039 - accuracy: 0.850 - ETA: 12s - loss: 0.5037 - accuracy: 0.850 - ETA: 11s - loss: 0.5044 - accuracy: 0.850 - ETA: 11s - loss: 0.5060 - accuracy: 0.849 - ETA: 10s - loss: 0.5071 - accuracy: 0.848 - ETA: 9s - loss: 0.5047 - accuracy: 0.849 - ETA: 8s - loss: 0.5062 - accuracy: 0.84 - ETA: 8s - loss: 0.5054 - accuracy: 0.84 - ETA: 7s - loss: 0.5031 - accuracy: 0.84 - ETA: 6s - loss: 0.5031 - accuracy: 0.85 - ETA: 6s - loss: 0.5030 - accuracy: 0.85 - ETA: 5s - loss: 0.5032 - accuracy: 0.84 - ETA: 4s - loss: 0.5028 - accuracy: 0.84 - ETA: 4s - loss: 0.5019 - accuracy: 0.85 - ETA: 3s - loss: 0.5046 - accuracy: 0.84 - ETA: 2s - loss: 0.5031 - accuracy: 0.85 - ETA: 1s - loss: 0.5022 - accuracy: 0.85 - ETA: 1s - loss: 0.5033 - accuracy: 0.85 - ETA: 0s - loss: 0.5045 - accuracy: 0.84 - 82s 6ms/step - loss: 0.5032 - accuracy: 0.8502 - val_loss: 3.5062 - val_accuracy: 0.3227\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history=model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Pickle/InceptionResNetV2_history.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model as a pickle in a file \n",
    "joblib.dump(history, '../Pickle/InceptionResNetV2_history.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file \n",
    "history = joblib.load('../Pickle/InceptionResNetV2_history.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [3.8142622051664867, 3.5690128463520763, 3.3553221669338167, 3.139762801599494, 3.0447685088408494, 2.854985564346646, 2.6827248437669926, 2.652034117665259, 2.697887734246786, 2.7094399848549524, 2.60240749240376, 2.5171060061839947, 2.487154458693918, 2.6266289612497777, 2.5906026214063655, 2.6117915676994277, 2.637202183679652, 2.68886749937868, 2.6495479716863404, 2.663513161738353, 2.6771033316996724, 2.6954066608838883, 2.667167577710639, 2.7942957485148425, 2.723408267943347, 2.658820311567445, 2.708743774689657, 2.833185364901857, 2.760532494767605, 2.7667251499232806, 2.813494336910182, 2.8586559119512778, 2.799028995877105, 2.9675845593067973, 2.7216200951029026, 2.86247690768267, 2.8256665888661847, 2.8440116875226624, 2.9623232138829865, 2.800511079294146, 2.9598041593076356, 2.963030147344756, 2.876803053963918, 3.103161237605104, 2.9344893136178545, 2.8696040251571397, 3.045118202854142, 2.918146829776916, 2.912468064370141, 2.926547774344136, 2.9216568202110316, 3.0137233867427144, 2.931877829890477, 3.0813185729398813, 3.029595950572065, 3.0306546339042653, 3.0061979048436904, 3.074986173531433, 3.012979468279686, 3.147772384525146, 3.117994528572839, 3.1333282154427398, 3.1365461513943758, 3.178388054540963, 3.0443887990039062, 3.0598903479875164, 3.1218656283105255, 3.040256284936021, 3.1110128823199146, 3.0902089491840887, 3.3703724807177338, 3.278931653809041, 2.9997848972345484, 3.1354630810094846, 3.173131273670927, 3.1622197082718264, 3.2683687235617036, 3.418918966316532, 3.3056322177582977, 3.2130898147859295, 3.450965292442081, 3.235316942955972, 3.2601204979390497, 3.262864804707155, 3.2862970864389784, 3.208981446701378, 3.115905795800186, 3.214367643417951, 3.243153987876039, 3.294294881358686, 3.3845458005599434, 3.279413688916393, 3.3140713501201606, 3.3034105647560215, 3.5888153327790246, 3.4832911455581486, 3.6538727508307067, 3.3848176960785867, 3.4146487257626115, 3.5062132229283653], 'val_accuracy': [0.060446541756391525, 0.09947358816862106, 0.1582864373922348, 0.2377927005290985, 0.25031766295433044, 0.3125794231891632, 0.3554184138774872, 0.33290979266166687, 0.32982391119003296, 0.3216554820537567, 0.37248140573501587, 0.3942639231681824, 0.3859139680862427, 0.344164103269577, 0.3387184739112854, 0.3570520877838135, 0.37066617608070374, 0.3367217183113098, 0.3624977171421051, 0.3735705316066742, 0.332002192735672, 0.3485206067562103, 0.3641314208507538, 0.3383554220199585, 0.3229261338710785, 0.353421688079834, 0.3241967558860779, 0.31003811955451965, 0.3241967558860779, 0.33055001497268677, 0.34162279963493347, 0.3280087113380432, 0.34017062187194824, 0.3145761489868164, 0.34561625123023987, 0.3332728147506714, 0.3467053771018982, 0.32510438561439514, 0.3229261338710785, 0.34017062187194824, 0.32673805952072144, 0.33145761489868164, 0.34797602891921997, 0.33726629614830017, 0.31911417841911316, 0.3300054371356964, 0.3494282066822052, 0.32583045959472656, 0.3312760889530182, 0.34017062187194824, 0.35160645842552185, 0.3550553619861603, 0.3327282667160034, 0.3457977771759033, 0.32909783720970154, 0.34688690304756165, 0.3323652148246765, 0.3307315409183502, 0.33617717027664185, 0.3276456594467163, 0.3485206067562103, 0.33581411838531494, 0.31040117144584656, 0.3216554820537567, 0.34216734766960144, 0.3376293480396271, 0.326556533575058, 0.33853694796562195, 0.3249228596687317, 0.33654019236564636, 0.3229261338710785, 0.32274460792541504, 0.3374478220939636, 0.32782718539237976, 0.3263750374317169, 0.31711745262145996, 0.32782718539237976, 0.32038483023643494, 0.3122163712978363, 0.33055001497268677, 0.3142130970954895, 0.32383373379707336, 0.3209293782711029, 0.3185696005821228, 0.31838810443878174, 0.33254674077033997, 0.33218368887901306, 0.32982391119003296, 0.32982391119003296, 0.31003811955451965, 0.31040117144584656, 0.3225630819797516, 0.307859867811203, 0.3316391408443451, 0.3142130970954895, 0.30731528997421265, 0.2991468608379364, 0.3209293782711029, 0.3044109642505646, 0.32274460792541504], 'loss': [3.88995654343863, 3.3710341795928795, 2.90096092392563, 2.5522496743129706, 2.259105874579946, 2.078791554595556, 1.9036069323144702, 1.7496003740083932, 1.6572346079095024, 1.5477343676295667, 1.4486757238016317, 1.3732961927429173, 1.3579104993222881, 1.2783308194321141, 1.2344802328562923, 1.221970215057598, 1.1726742644149613, 1.144326294059853, 1.108508396223748, 1.085451185511034, 1.0346482060431994, 1.0189333679195995, 1.0108029005659687, 0.965780691220965, 0.942911561779338, 0.9343558417690677, 0.9392360207892072, 0.9181758263861414, 0.9055510171271565, 0.879690566062561, 0.8567254011522257, 0.8561921640486784, 0.8417014792536356, 0.8376003944769449, 0.8375803512593895, 0.7954280958382915, 0.8112932772446734, 0.8203049348697302, 0.7710042415245981, 0.7703170182792443, 0.7555636819414857, 0.7409175751378068, 0.7443493311351354, 0.732092992096082, 0.7386640691295818, 0.6877439100609417, 0.7083695641477213, 0.7418842407950716, 0.7120958093563509, 0.6833656985004309, 0.6871512280212095, 0.6839219866086766, 0.6846850713795917, 0.6482548591105953, 0.6646000419119282, 0.6594389590355058, 0.664128578161428, 0.6617284549251164, 0.6412730863375921, 0.6397883987906451, 0.628107948020167, 0.6201510230456057, 0.614544118508969, 0.5956553088787458, 0.6018372712423131, 0.6033462265672598, 0.6145907672497739, 0.6018094463642063, 0.5839135950564825, 0.6037119368202509, 0.5726404038282642, 0.5869097180070644, 0.5835261456777086, 0.5827905255251263, 0.5905959789351263, 0.5661048254939639, 0.5335164011495122, 0.5609510441636402, 0.5798087209586704, 0.5676284766548736, 0.5500459320588039, 0.562385319409292, 0.5376556575655334, 0.5396296201424561, 0.5507542849172921, 0.5313899223201378, 0.5235609249244031, 0.5408849592738723, 0.5507556480428367, 0.5216558369105724, 0.5343583259251494, 0.535860660264357, 0.529687748139693, 0.5345565727359046, 0.5321916596229643, 0.5342832958985723, 0.516203703267511, 0.5141830873313614, 0.5322372648796898, 0.5031532317267239], 'accuracy': [0.048610043, 0.14928582, 0.2432806, 0.3204577, 0.38442636, 0.42213178, 0.46690217, 0.5001536, 0.5244202, 0.549378, 0.5723391, 0.5867762, 0.595761, 0.6194901, 0.62578714, 0.63216096, 0.6432192, 0.64913225, 0.6646444, 0.6720934, 0.67931193, 0.68775916, 0.69037014, 0.6985102, 0.7031946, 0.71233296, 0.7129473, 0.716787, 0.72477347, 0.72653973, 0.73721397, 0.73521733, 0.7395945, 0.7435878, 0.74266624, 0.7566426, 0.7491169, 0.75165105, 0.7584856, 0.76478267, 0.76862234, 0.7758409, 0.76962066, 0.77637845, 0.77637845, 0.7882814, 0.7827523, 0.77607125, 0.7857472, 0.7866687, 0.7945016, 0.7917371, 0.79319614, 0.8034864, 0.79964674, 0.7994932, 0.7971126, 0.79887885, 0.8091691, 0.80671173, 0.8124712, 0.8131623, 0.81500536, 0.8197665, 0.81746274, 0.81999695, 0.8172324, 0.82091844, 0.8226847, 0.81968975, 0.82537246, 0.82729226, 0.8254492, 0.82644755, 0.8209952, 0.8346644, 0.8393488, 0.832975, 0.82867455, 0.83097833, 0.83320534, 0.83213025, 0.8401935, 0.8357395, 0.837045, 0.8422669, 0.8448011, 0.84303486, 0.8415758, 0.84864074, 0.84410995, 0.8446475, 0.8444939, 0.84219015, 0.8446475, 0.84096146, 0.8473353, 0.84672093, 0.84579945, 0.85017663]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = np.arange(0, len(history.history['loss']))\n",
    "\n",
    "# You can chose the style of your preference\n",
    "# print(plt.style.available) to see the available options\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "plt.figure()\n",
    "plt.plot(N, history.history['loss'], label = \"train_loss\")\n",
    "plt.plot(N, history.history['accuracy'], label = \"train_acc\")\n",
    "plt.plot(N, history.history['val_loss'], label = \"val_loss\")\n",
    "plt.plot(N, history.history['val_accuracy'], label = \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "# Make sure there exists a folder called output in the current directory\n",
    "# or replace 'output' with whatever direcory you want to put in the plots\n",
    "plt.show()\n",
    "plt.savefig('../Output/EpochInceptionResNetV2.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
